<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Natural Language Processing on Decoding AI&#39;s Evolution</title>
    <link>https://amanpriyanshu.github.io/blogs/categories/natural-language-processing/</link>
    <description>Recent content in Natural Language Processing on Decoding AI&#39;s Evolution</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright> </copyright>
    <lastBuildDate>Wed, 06 Nov 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://amanpriyanshu.github.io/blogs/categories/natural-language-processing/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Contra-Topic-bottleneck-t5: Efficient Topic Extraction Without the Computational Overhead</title>
      <link>https://amanpriyanshu.github.io/blogs/posts/2024/contra-topic/</link>
      <pubDate>Wed, 06 Nov 2024 00:00:00 +0000</pubDate>
      
      <guid>https://amanpriyanshu.github.io/blogs/posts/2024/contra-topic/</guid>
      <description>Quick Links: Model on HuggingFace | Interactive Demo
When it comes to topic extraction, the AI world seems fixated on massive models and expensive compute. But what if there was a simpler way? ü§î
The Genesis: Simplicity Through Linear Transformation Picture this: There I was, looking for an open-source solution to extract topics from text at scale. The available options were either massive language models or complex fine-tuning pipelines. That&amp;rsquo;s when it hit me ‚Äì what if we could leverage the semantic structure of existing embeddings with just a linear transformation?</description>
    </item>
    
    <item>
      <title>AdaptKeyBERT: Stumbling Through Two Years of Keyword Extraction</title>
      <link>https://amanpriyanshu.github.io/blogs/posts/2024/adaptkeybert/</link>
      <pubDate>Sun, 22 Sep 2024 00:00:00 +0000</pubDate>
      
      <guid>https://amanpriyanshu.github.io/blogs/posts/2024/adaptkeybert/</guid>
      <description>Quick links (in case you want to skip my ramblings):
PyPI Package GitHub Repository
Alright, gather &amp;lsquo;round, word enthusiasts and syntax sorcerers! üßô‚Äç‚ôÇÔ∏èüìö Remember that time you tried to explain machine learning to your grandma and ended up comparing neural networks to her knitting patterns? Well, buckle up, because we&amp;rsquo;re about to dive into a similar realm of &amp;ldquo;What was I thinking?&amp;rdquo; ‚Äì the saga of AdaptKeyBERT.
It&amp;rsquo;s been two trips around the sun since I cobbled together this quirky little keyword extractor and sent it off into the wild world of NLP.</description>
    </item>
    
  </channel>
</rss>
