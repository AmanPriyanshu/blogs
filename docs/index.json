[{"content":"YC-Dendrolinguistics: Planting Linguistic Trees in the Startup Forest Hey there, fellow AI adventurers and startup enthusiasts! üå≥üöÄ Today, I\u0026rsquo;m excited to give you a peek into my latest passion project: YC-Dendrolinguistics. Buckle up as we embark on a journey through the linguistic forests of Y-Combinator pitches!\nThe Seed of an Idea Picture this: It\u0026rsquo;s 2 AM, I\u0026rsquo;m knee-deep in YC application videos, and suddenly it hits me ‚Äì what if startup pitches are like trees? ü§î Each word a branch, each phrase a limb, growing into this complex organism we call a pitch. That\u0026rsquo;s when YC-Dendrolinguistics was born, my wild attempt to map the DNA of startup communication.\nCultivating the Startup Vocabulary So, what exactly am I doing? Well, imagine if David Attenborough decided to narrate a nature documentary about startup pitches instead of penguins. That\u0026rsquo;s basically me, minus the soothing accent. I\u0026rsquo;m analyzing YC startup descriptions, breaking them down to their roots, and seeing what kind of linguistic forest they create.\nHere\u0026rsquo;s what\u0026rsquo;s growing in our little experiment:\nPitch Decomposition: Slicing and dicing startup pitches into their fundamental components. It\u0026rsquo;s like linguistic bonsai, but with more buzzwords. Grammar Trees: Creating tree structures that represent pitch patterns. Theme Spotting: Hunting for common elements across pitches. Data Visualization: Turning all this linguistic madness into pretty graphs. Because nothing says \u0026ldquo;I understand startups\u0026rdquo; like a forest of colorful scatterplots. The YC-Dendrolinguistics Toolkit Startup Similarity Search: Your Personal Pitch Compass (Now with Extra Privacy!) Remember that time you tried to explain your startup idea and accidentally described a toaster? Well, fear not! I\u0026rsquo;ve built a similarity search tool that lets you explore how different startups describe themselves.\nBut here\u0026rsquo;s the kicker ‚Äì I\u0026rsquo;ve gone full-on privacy nerd with this one. üïµÔ∏è‚Äç‚ôÇÔ∏è I\u0026rsquo;ve created an on-prem, user-browser live semantic search that runs entirely within static GitHub pages. That\u0026rsquo;s right, we\u0026rsquo;re bringing the power of semantic search right to your browser, no server required!\nHow does it work? Well, I download a huggingface local model onto your browser, and you do all the computing right there on your machine. It\u0026rsquo;s like having a mini AI assistant camping out in your browser tabs. No need to worry about your brilliant startup ideas being sent off to some mysterious cloud server. Your searches stay between you, your computer, and the linguistic forest we\u0026rsquo;re growing together.\nInteractive Scatterplots: Where Pitches Go to Party Picture a disco, but instead of people, it\u0026rsquo;s startup pitches dancing around. That\u0026rsquo;s essentially what my interactive scatterplots look like. Each colorful dot represents a different aspect of a startup pitch. It\u0026rsquo;s part data visualization, part modern art, hopefully addictive to play with.\nProbability Trees: Sentence Diagrams on Steroids Remember those sentence diagrams from school that made you question your life choices? I\u0026rsquo;ve resurrected them, gave them an AI makeover, and set them loose on startup pitches. The result? Probability trees that show how different parts of a pitch tend to branch out. It\u0026rsquo;s part linguistics, part data science, and entirely too much fun to be considered work.\nWhy Am I Doing This? Good question! Part of me wants to say it\u0026rsquo;s for the greater good of startup-kind. But let\u0026rsquo;s be real ‚Äì I\u0026rsquo;m doing this because it\u0026rsquo;s absolutely fascinating. It\u0026rsquo;s like being a linguistic Nathan Drake, only instead of ancient treasures, I\u0026rsquo;m uncovering the hidden patterns in how we talk about innovation.\nBut hey, if this project ends up:\nHelping a few aspiring entrepreneurs craft pitches Giving investors a new lens to view startup trends Or just providing some entertainment for fellow language and startup nerds Then I\u0026rsquo;ll consider it a success. And if not, well, at least I\u0026rsquo;ll have some pretty cool graphs to show.\nWhat\u0026rsquo;s Next in Our Linguistic Forest? Who knows? Maybe we\u0026rsquo;ll discover the startup pitch equivalent of the Loch Ness Monster. Or perhaps we\u0026rsquo;ll find that one magical phrase that guarantees funding (spoiler: it probably doesn\u0026rsquo;t exist, but we can dream).\nIn all seriousness, this project is as much about the journey as it is about the destination. I\u0026rsquo;m learning new things every day, and I\u0026rsquo;m excited to see where this trail of linguistic breadcrumbs leads us.\nGot ideas? Suggestions? Want to geek out about grammar trees or startup lingo? Drop me a line! My inbox is always open.\nP.S. If you found this dive into the startup linguistic forest intriguing (or at least mildly entertaining), stay tuned! There\u0026rsquo;s plenty more where this came from. And hey, if you want to collaborate on some wild AI-meets-startup experiment, don\u0026rsquo;t hesitate to reach out. My email is still amanpriyanshusms2001[at]gmail[dot]com. Let\u0026rsquo;s grow this forest together! üå±ü§ñüìä\n","permalink":"https://amanpriyanshu.github.io/blogs/posts/2024/startup-linguistic-trees/","summary":"YC-Dendrolinguistics: Planting Linguistic Trees in the Startup Forest Hey there, fellow AI adventurers and startup enthusiasts! üå≥üöÄ Today, I\u0026rsquo;m excited to give you a peek into my latest passion project: YC-Dendrolinguistics. Buckle up as we embark on a journey through the linguistic forests of Y-Combinator pitches!\nThe Seed of an Idea Picture this: It\u0026rsquo;s 2 AM, I\u0026rsquo;m knee-deep in YC application videos, and suddenly it hits me ‚Äì what if startup pitches are like trees?","title":"YC-Dendrolinguistics: Planting Linguistic Trees in the Startup Forest"},{"content":"Synaptic Sparks: Why I\u0026rsquo;m Wiring My Thoughts into a Neural Blogosphere Hey there, fellow AI enthusiasts and curious minds! üß†ü§ñ Today, I just want to document what\u0026rsquo;s leading to this new adventure in regular blogging.\nThe Knowledge Synapse Picture me back in 2019, a wide-eyed novice bouncing around the vast landscape of machine learning. I was devouring every GitHub gist, Medium post, and arXiv paper I could find, growing and learning at a dizzying pace. Fast forward to today, and it feels like I\u0026rsquo;ve stepped into an alternate universe. So much of that knowledge that shaped me is now locked behind paywalls, long arduous youtube playlists, feeling almost alien to the very person who spent countless hours absorbing it.\nThat\u0026rsquo;s why I\u0026rsquo;m stepping up to the plate. This blog is my way of paying it forward, creating a freely accessible hub of AI insights on GitHub Pages. It\u0026rsquo;s for that version of me from 2019, and for anyone else out there hungry for knowledge but hitting walls of subscription prompts. Let\u0026rsquo;s keep the neurons firing and the information flowing!\nThe Memory Engram: Documenting the Journey The AI world moves fast. Sometimes, it\u0026rsquo;s hard to remember what I learned last month, let alone last year. That\u0026rsquo;s why I\u0026rsquo;m starting this blog. It\u0026rsquo;s not about big breakthroughs or fancy ideas ‚Äì it\u0026rsquo;s just my online diary for AI stuff. Here, I\u0026rsquo;ll write down the little \u0026ldquo;oh, I get it!\u0026rdquo; moments, the times I got stuck, and the cool things I think might be possible. It\u0026rsquo;s like leaving notes for myself along the way.\nThis isn\u0026rsquo;t for AI experts or future scientists ‚Äì it\u0026rsquo;s just for me. But who knows? Maybe one day I\u0026rsquo;ll read these posts and think, \u0026ldquo;Wow, I\u0026rsquo;ve really learned a lot since then!\u0026rdquo; That would be pretty cool (hopefully also true).\nThe Dopamine Circuit: Chasing the Thrill of Discovery You know that rush when your code finally compiles without errors? That\u0026rsquo;s the good stuff. By blogging about the topics that get my neurons firing, I\u0026rsquo;m creating a positive feedback loop of curiosity and creation. It\u0026rsquo;s like training a reinforcement learning agent, but the agent is me!\nThe Bio-Inspired Architecture: Small, Fast, and Evolved I\u0026rsquo;ve always been fascinated by how nature solves problems. Lately, I\u0026rsquo;ve been really interested in AI systems that try to learn from biology. There\u0026rsquo;s something exciting about compact neural networks that work a bit like animal brains or evolutionary processes or even behaviors. I\u0026rsquo;m not an expert, but I\u0026rsquo;m eager to learn and share what I discover about these smaller, nature-inspired AI approaches. It\u0026rsquo;s a big field, and I\u0026rsquo;m just starting to scratch the surface, but I hope to grow my understanding as I go along.\nThe Human-AI Interface: Building for People During my summer internship in the silicon jungle of San Francisco, I had an epiphany: the real magic happens when you build for people, not just for projects or hackathons. It\u0026rsquo;s time to shift my focus from hackathons to real-world problems. I want to bridge the gap between silicon and synapse!\nThe Output Layer: Wrapping It Up So, there you have it ‚Äì the reasons why I\u0026rsquo;m starting this blog. It\u0026rsquo;s not because I have all the answers, but because I have so many questions. This is my little corner of the internet where I\u0026rsquo;ll be thinking out loud about AI, learning as I go, and maybe stumbling upon some interesting ideas along the way.\nI\u0026rsquo;m excited to see where this journey takes me, and I hope that by documenting my thoughts and discoveries, I\u0026rsquo;ll be able to look back one day and see how far I\u0026rsquo;ve come. If you happen to find any of this useful or interesting, that\u0026rsquo;s great! But mostly, this is for future me, a breadcrumb trail through the fascinating world of AI.\nHere\u0026rsquo;s to the adventure ahead ‚Äì may it be full of learning, growth, and maybe a few \u0026ldquo;aha!\u0026rdquo; moments. Let\u0026rsquo;s see what we can figure out together! üß†üíªüöÄ\nP.S. If you found this blog post intriguing (or at least mildly entertaining), buckle up! There\u0026rsquo;s plenty more where this came from. And hey, if you want to geek out about the latest in AI or collaborate on a mind-bending project, don\u0026rsquo;t hesitate to reach out. My email is: amanpriyanshusms2001[at]gmail[dot]com üî¨\n","permalink":"https://amanpriyanshu.github.io/blogs/posts/2024/synaptic-sparks/","summary":"Synaptic Sparks: Why I\u0026rsquo;m Wiring My Thoughts into a Neural Blogosphere Hey there, fellow AI enthusiasts and curious minds! üß†ü§ñ Today, I just want to document what\u0026rsquo;s leading to this new adventure in regular blogging.\nThe Knowledge Synapse Picture me back in 2019, a wide-eyed novice bouncing around the vast landscape of machine learning. I was devouring every GitHub gist, Medium post, and arXiv paper I could find, growing and learning at a dizzying pace.","title":"Synaptic Sparks: Why I'm Wiring My Thoughts into a Neural Blogosphere"},{"content":"FRACTURED-SORRY-Bench: When Decomposition Meets AI Safety Hello, fellow AI enthusiasts! ü§ñ Today, I wanted to dive into the FRACTURED-SORRY-Bench framework and dataset we just released. Check out the dataset, website, and github for the dataset!\nThe FRACTURED-SORRY Saga: A Tale of Adaptation and Decomposition Picture this: you\u0026rsquo;re wandering through the lush collection of prompt-injection and llm-red-teaming papers, marveling at some of the weird and some of the crazier attack mechanisms that have been released recently. When suddenly, you realize that there aren\u0026rsquo;t many Proof-of-Concept resources for multi-shot red-teaming. That\u0026rsquo;s essentially the story behind creating FRACTURED-SORRY-Bench.\nWhat\u0026rsquo;s in a Name? FRACTURED-SORRY-Bench isn\u0026rsquo;t just a mouthful; it\u0026rsquo;s a clever acronym we probably spent the most time on. It stands for:\nFramework for Revealing Attacks in Conversational Turns Undermining Refusal Efficacy and Defenses over SORRY-Bench The FRACTURED Approach: Divide and Conquer Vanilla Responses:\nModel Harmful \u0026amp; Relevant Harmful but Irrelevant Harmless ASR (%) GPT-4o 52 3 395 11.56 GPT-3.5 21 4 425 4.67 GPT-4o-mini 58 2 390 12.89 GPT-4 45 3 402 10.00 Decomposed Responses:\nModel Harmful \u0026amp; Relevant Harmful but Irrelevant Harmless ASR (%) GPT-4o 223 103 124 49.56 GPT-3.5 229 106 115 50.89 GPT-4o-mini 226 106 118 50.22 GPT-4 221 104 125 49.11 The FRACTURED-SORRY-Bench framework takes a page out of our everyday conversations playbook by breaking down complex problems into simpler, more manageable pieces. Just like how we breakdown complex sometimes malicious instructions into simpler manageable chunks so as to not reveal true intentions, this framework dissects AI vulnerabilities by:\nDecomposing potentially harmful queries into seemingly innocuous sub-questions Presenting these sub-questions sequentially in a conversational format Analyzing the cumulative response to determine if the original harmful intent was fulfilled Exploiting the AI\u0026rsquo;s inability to recognize malicious intent spread across multiple interactions From Theory to Practice: The Jailbreak Jamboree Now, let\u0026rsquo;s get to the juicy part ‚Äì the jailbreaks! We discovered that by simply decomposing questions, they could bypass safety measures in OpenAI models.\nHere\u0026rsquo;s a taste of what we found:\nA significant increase in Attack Success Rate (ASR) on average 6x Simple exploits that are zero-shot effective in communicating harmful intent in 49% of cases through decomposition During my summer internship at Robust Intelligence, I got a firsthand look at how these kinds of vulnerabilities are discovered and addressed Media Coverage, Jailbreak Meta\u0026rsquo;s Prompt-Guard LLaMA3.1 Family within 24 hours, and Jailbreaking OpenAI\u0026rsquo;s structured response within 3 hours. Now, back at CMU, I\u0026rsquo;m excited to continue exploring this fascinating field.\nThe Moral of the Story: Stay FRACTURED, My Friends So, what can we learn from this decomposed madness? A few key takeaways:\nSimplicity is key: We have a long way before we begin exploring complex jailbreaks as options for red-teaming, there\u0026rsquo;s still opportunity for lots of smaller \u0026amp; simpler attacks. Protection against multi-shot attacks: There\u0026rsquo;s a need to explore and defend against multi-shot attacks. Conclusion: The Adventure Continues As we wrap up this whirlwind tour of FRACTURED-SORRY-Bench, remember that the quest for AI safety is an ongoing journey!!\nAlso, thanks a tonne to my co-author Supriti Vijay!!\nP.S. If you found this blog post helpful (or at least mildly entertaining), I\u0026rsquo;ll be releasing quite a few more so do on-board for this adventure. Also, if you want to chat or collaborate on a research project together do not hesitate to reach out. My email is: amanpriyanshusms2001[at]gmail[dot]com üî¨\n","permalink":"https://amanpriyanshu.github.io/blogs/posts/2024/fractured-sorry-bench/","summary":"FRACTURED-SORRY-Bench: When Decomposition Meets AI Safety Hello, fellow AI enthusiasts! ü§ñ Today, I wanted to dive into the FRACTURED-SORRY-Bench framework and dataset we just released. Check out the dataset, website, and github for the dataset!\nThe FRACTURED-SORRY Saga: A Tale of Adaptation and Decomposition Picture this: you\u0026rsquo;re wandering through the lush collection of prompt-injection and llm-red-teaming papers, marveling at some of the weird and some of the crazier attack mechanisms that have been released recently.","title":"FRACTURED-SORRY-Bench: Unraveling AI Safety through Decomposing Malicious Intents"}]