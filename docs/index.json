[{"content":"This semester I am taking part in a seminar on $\\infty$-categories, administered by Rune Haugseng. So far we have covered roughly: the basic definitions, fibrations, limits, colimits, Joyal’s lifting theorem, equivalences, straightening, Yoneda lemma, adjunctions and Kan extensions. This week it is my turn to give a talk on stable $\\infty$-categories, and this blog post will hopefully be some sort of lecture notes for this talk. The intersection of things in this post and the contents of the talk should at least be non-empty.\nThe plan for this post, and the talk, is to cover the basics as well as the two motivating examples: the $\\infty$-category of spectra, and the derived $\\infty$-category of an abelian category. Most of this theory can be found in the first chapter of “Higher algebra” (denoted henceforth by HA) by Jacob Lurie.\nBasics The first thing that should be said is that by $\\infty$-category we mean quasi-category. These are simplicial complexes that satisfy the lifting property for every inner horn. We have covered the definition and some intuition in an older blog post, so the reader unfamiliar with the definition and what it means should look there first (or into any of the other hundreds of much better sources on quasi-categories). We will assume basic knowledge on $\\infty$-categories in this post, and will try to refer to other posts with relevant material whenever applicable.\nDefinition:  Let $\\mathcal{C}$ be an $\\infty$-category. A zero object in $\\mathcal{C}$ is an object $0$ which is both initial and terminal. If such an object exists, then we say that $\\mathcal{C}$ is a pointed $\\infty$-category.\nDefinition:  A triangle in $\\mathcal{C}$ is a diagram where $0$ denotes a zero object in $\\mathcal{C}$. We say a triangle is a fiber sequence if the diagram is a pullback square, and a cofiber sequence if the diagram is a pushout square. If we have a map $f:X\\longrightarrow Y$, then a fiber of $f$ is a fiber sequence and a cofiber of $f$ is a cofiber sequence We often denote just the object as the fiber and cofiber, i.e. $fib(f)=F$ and $cofib(f)=C$, and leave the maps hidden in the notation.\nNote that fiber sequences are sometimes called exact triangles, while cofiber sequences are sometimes called coexact triangles. We stick to the naming convention of HA, where this material is developed in detail.\nWe are now ready to define a stable $\\infty$-category. The definition should hopefully feel somewhat familiar to any reader that have heard about stable model categories or abelian categories. Readers of this blog have encountered stable model categories in the post the stable homotopy category, so it is possible to go there for some intuition. Stable $\\infty$-categories should be thought of as an $\\infty$-categorical refinement of stable model categories, in the sense that presentations of stable $\\infty$-categories are stable model categories.\nDefinition:  A stable $\\infty$-category is a pointed $\\infty$-category $\\mathcal{C}$, such that all morphisms have both fibers and cofibers, and a triangle is a fiber sequence if and only if it is a cofiber sequence.\nThe similarity to stable model categories is maybe not immediately apparent, as they are defined using an autoequivalence $\\Sigma: \\mathcal{C}\\longrightarrow \\mathcal{C}$, which is not visible in the above definition. We will however soon see that it is there. The similarity with abelian categories is maybe more apparent. An abelian category is a category with zero object (and some other stuff to get an additive category) such that every morphism has a kernel and a cokernel, and such that the image is isomorphic to the coimage, which means that the kernel of a cokernel is isomorphic to the cokernel of the kernel. This last requirement is similar to the requirement that fiber sequences and cofiber sequences coincide. The requirement to be an additive category is equivalent to saying that the category is enriched over abelian groups. It turns out that any stable $\\infty$-category is enriched in spectra, helping solidify the idea that spectra should be thought of as a homotopical extension of abelian groups. We will talk more about these similarities in a later post I hope.\nFrom the definition there are two immediate things one can do. We know that we have a zero object $0$, which means that for any other object $X$, we have unique (up to contractible choice) maps $0\\longrightarrow X$ and $X\\longrightarrow 0$. We also know that any map has both a fiber and a cofiber, so a natural thing to look at are the fibers and cofibers of these two unique maps into and out from the zero object. These two definitions should hopefully feel familiar from algebraic topology.\nDefinition:  A cofiber of the map $0\\longrightarrow X$ is a pushout of the diagram This pushout is called the suspension object of $X$, and is denoted $\\Sigma X$.\nDefinition:  A fiber of the map $X\\longrightarrow 0$ is a pullback of the diagram This pullback is called the loop object of $X$, and is denoted $\\Omega X$.\nSince the category we form these is stable, we know that fiber sequences and cofiber sequences coincide, which gives us that $\\Sigma$ and $\\Omega$ are mutually inverse equivalences on $\\mathcal{C}$.\nThe first idea of a stable $\\infty$-category comes from exactly these two above constructions. The idea is to iteratively use the above two constructions to create so-called spectrum objects in any $\\infty$-category.\nSpectrum objects We have several times looked at the category of spectra, $Sp$, and its associated homotopy category — the stable homotopy category, $SHC$. The idea behind spectrum objects in a $\\infty$-category is to emulate the construction of spactra from topological spaces. For some background on these objects see this post, and this post for some insight into the stable homotopy category. The emulation will be made in such a way that the spectrum objects in the $\\infty$-category of spaces are precisely the spectra we are already familiar with. The reader unfamiliar with spectra in the classical sense should at least look up the definition of a sequential spectrum, also called a pre-spectrum, in order to feel the familiarity with the following definition.\nDefinition:  Let $\\mathcal{C}$ be a pointed $\\infty$-category with all finite limits and colimits. A pre-spectrum object in $\\mathcal{C}$ is a functor $$E:\\Z\\times\\Z\\longrightarrow \\mathcal{C},$$ such that $E(i,j)=0$ for $i\\neq j$.\nIn particular this means that only the diagonal elements $E(n,n)$ are non-trivial, so we denote these by $E_n$. We can then visualize a pre-spectrum object as This should look familiar to any reader that has seen the classical definition of a sequential spectrum. We see that in this diagram we have a setup that looks a lot like the diagrams for suspension and loops, just strung together in an infinitely long sequence. Due to the definition of $\\Sigma$ and $\\Omega$ as the pushout and pullback respectively, we get by universal property, for any pre-spectrum object $E$ in $\\mathcal{C}$, maps $$\\alpha_n:\\Sigma E_n\\longrightarrow E_{n+1} \\text{ and } \\beta_n:E_n\\longrightarrow \\Omega E_{n+1}.$$\nWe can now look at som nicer types of pre-spectrum objects, where we make some restrictions on the above maps.\nDefinition:  Let $E$ be a pre-spectrum object in $\\mathcal{C}$. We say $E$ is a spectrum object if the maps $$\\beta_n:E_n\\longrightarrow \\Omega E_{n+1}$$ is an equivalence for all $n$. Note that these are also sometimes called the $\\Omega$-spectrum objects, as to remind us that these are the analogues of $\\Omega$-spectra from topology. We say $E$ is a suspension spectrum object if the maps $$\\alpha_n:\\Sigma E_n\\longrightarrow E_{n+1}$$ is an equivalence for all $n$. The full subcategory spanned by the spectrum objects in $\\mathcal{C}$ is denoted by $Sp(\\mathcal{C})$.\nDefinition:  Let $\\mathcal{C}$ be an $\\infty$-category with finite limits, in particular it has a terminal object, $\\ast$. We define the stabilization of $\\mathcal{C}$ to be the $\\infty$-category $$Stab(\\mathcal{C})=Sp(\\mathcal{C}_ \\ast),$$ where $\\mathcal{C}_\\ast$ is the category of pointed objects, i.e. the under category of a the terminal object, $\\ast$.\nWe wont prove here that the stabilization of a $\\infty$-category is in fact a stable $\\infty$-category, but this is in fact the case. Equivalently, the stabilzation can be thought of as the category of reduced excisive functors $E:\\mathcal{S}^{fin}_{\\ast/}\\longrightarrow \\mathcal{C}$ from the $\\infty$-category of finite type pointed spaces (this is the $\\infty$-categorical analogue of pointed CW-complexes) into $\\mathcal{C}$. These are the functors that send pushout squares to pullback squares, and sends the point object $\\Delta^0$ to the terminal object $\\ast$. This definition can be thought of as more in line with the Brown representability focused way of constructing spectra, as reduced excisive functors can be thought of as the homology theories on spaces with values in $\\mathcal{C}$.\nAs mentioned in the beginning of the section, we have $Sp = Stab(\\mathcal{S})$, or in words: the stabilization of the $\\infty$-category of spaces is the category of spectra. This means that we now have a description of $Sp$ as an $\\infty$-category, and not just as a stable model category — which is the best we have accomplished so far on this blog. The $\\infty$-category of spectra is in a precise sense the universal example of stable $\\infty$-category. It is in fact the free stable $\\infty$-category on one generator, the sphere spectrum.\nDerived $\\infty$-category In normal homological algebra we are familiar with the concept of derived categories of abelian categories, these being a localization of the category of chain complexes at the quasi-equivalences. The category of chain complexes has a concept of homotopy, often called chain-homotopy, which hints at the idea that there is some $\\infty$-categorical things going on. The theory of derived $\\infty$-categories seeks to be an “enhancement” of the normal derived category into the world of $\\infty$-categories, in the sense that the homotopy category of the derived $\\infty$-category should be the normal derived category.\nThe construction of the derived $\\infty$-category uses the concept of enriched categories, which we have covered a bit of in an earlier post, so the reader unfamiliar with this theory should look there for a half-ok overview.\nThe objects we want to have in the derived $\\infty$-category are — as in the case of the normal derived category — the chain complexes of objects in the abelian category. To be even more specific, for an abelian category $\\mathcal{A}$, we want the objects of $D_\\infty(\\mathcal{A})$ to be the unbounded chain complexes in $\\mathcal{A}$. Since we want the homotopy category to be the usual derived category, we should want that the equivalence classes of morphisms are the usual derived hom, $RHom$.\nDefinition:  Let $\\mathcal{A}$ be an abelian category. We write $Ch(\\mathcal{A})$ for the category of unbounded chain complexes in $\\mathcal{A}$. Any such category is enriched in chain complexes of abelian groups, $Ch(\\Z)=Ch(Ab)$.\nIn order to create an $\\infty$-category we will use the simplicial nerve construction, but, in order to use this we need to produce a category that is enriched over simplicial sets. From the above definition we now have a category enriched over chan complexes of abelian groups, so the question turns into finding a translation between chain complexes of abelian groups and simplicial sets. Luckily for us, there is one such translation, namely the Dold-Kan correspondence.\nTheorem (Dold-Kan correspondence):  Let $\\mathcal{A}$ be an abelian category. There is an equivalence of categories $$\\Gamma:Ch^+(\\Z)\\leftrightarrows Ab_\\Delta:N$$ between the category of connective chain complexes of abelian groups, and the category of simplicial abelian groups. The functors $N$ and $\\Gamma$ are certain nerve and realization functors, which we wont go into detail about.\nThe two important things here is that we can turn a chain complex into a simplicial abelian group, and that the equivalence is a Quillen equivalence if we equip these categories with their standard model structures. Being a Quillen equivalence means that these model structures are preserved, in particular that the chain homotopies correspond to simplicial homotopies, and homology of a chain complex corresponds to the homotopy of the corresponding simplicial abelian group.\nFrom a simplicial abelian group we can easily get a simplicial set, by just forgetting the group structure. This is just the forgetful functor $$For: Ab_\\Delta\\longrightarrow Set_\\Delta.$$\nThe remaining piece of the puzzle is getting from unbounded chain complexes to connective chain complexes. We want to do this in a homology preserving way, hence we send an unbounded chain complex $$\\cdots\\longrightarrow A_{2}\\longrightarrow A_1\\longrightarrow A_0\\overset{f_0}\\longrightarrow A_1\\longrightarrow A_2\\longrightarrow \\cdots$$ to the connective chain complex $$\\cdots\\longrightarrow 0\\longrightarrow 0\\longrightarrow ker(f_0)\\longrightarrow A_1\\longrightarrow A_2\\longrightarrow \\cdots.$$\nWe can then finally form the functor $$K:Ch(\\Z)\\longrightarrow Ch^+(\\Z)\\overset{\\Gamma}\\longrightarrow Ab_\\Delta\\longrightarrow Set_\\Delta. $$\nBy using this functor we can turn any dg-category — that is, categories enriched in $Ch(\\Z)$ — into a simplicially enriched category. Since we want to use the simplicial nerve construction, we need one more piece of information in order to be certain that we actually get a $\\infty$-category. The fact we need is that the simplicial set $K(A_\\bullet)$, for some chain complex $A_\\bullet$, is a Kan complex, and not just an arbitrary simplicial set. We do in fact get that this holds, due to the underlying simplicial set of any simplicial group being a Kan complex. The Kan complexes that are simplicial groups even have nice algorithms to determine the lifts of inner and outer horns, so these are particularily nice Kan complexes. For an intuitive explanation of why the underlying simplicial set of a simplicial group is a Kan complex, we can consider the fact that a group can be viewed as a one-object groupoid. A simplicial group can in this light be thought of as a simplicial groupoid, which along with Kan complexes are models for $\\infty$-groupoids. The fact that a simplicial group has an underlying Kan complex can then be thought of a a sort of change of model. This is not in any way precise, but serves (for me at least) as some motivation and insight into why the abovementioned fact is true.\nAnyway, we can now form the $\\infty$-categorical analogue of $Ch(\\mathcal{A})$, which we will denote by $K_\\infty(\\mathcal{A})$. To do this we first define the so-called dg-nerve of a dg-category.\nDefinition:  Let $\\mathcal{C}$ be a dg-category, i.e. a category enriched in $Ch(\\Z)$. We define its dg-nerve to be $$N^{dg}(\\mathcal{C})=N^\\Delta(\\mathcal{C}_ \\Delta)$$ where $\\mathcal{C}_\\Delta$ is the Kan enriched category obtained from $\\mathcal{C}$ via the functor $K$ constructed above.\nThe name of this nerve-construction is sometimes used for another way to construct another equivalent category, mainly in HA, so beware that this notation and naming convention is not perfect. Since $K(A)$ is a Kan-complex, we have that $N^{dg}(\\mathcal{C})$ is an $\\infty$-category.\nDefinition:  Let $\\mathcal{A}$ be an abelian category. We define an $\\infty$-category $K_\\infty(\\mathcal{A})$ by $$K_\\infty(\\mathcal{A})=N^{dg}(Ch(\\mathcal{A})).$$\nThis category should be thought of as the $\\infty$-category of chain complexes in $\\mathcal{A}$. The homotopy category of $K_\\infty(\\mathcal{A})$ is the homotopy category of chain complexes we are used to from homological algebra, often denoted $K(\\mathcal{A})$ — hence the suggestive notation of $K_\\infty$. We want to continue to emulate the standard homological algebra case, in which we localize the category of chain complexes at the quasi-isomorphisms. This is because we mostly care about information in homology, but the existence of non-invertible quasi-isomorphisms means that we have to be a bit careful. By inverting these non-invertible maps we can be less careful, and get in the end a nicer category. In the classical scenario, the derived category — being the chain complexes localized at the quasi-isomorphisms — is a triangulated category, which is a nice structure to have around. So, we need to know what the $\\infty$-categorical analogue of localization is.\nDwyer-Kan localization The idea of the below construction is to emulate the universal property of localizations in the situation of $1$-categories. The below construction and definitions are mostly taken from the nice [lecture series] by Achim Krause and Thomas Nicolaus on Cyclic homology.\nDefinition:  Let $\\mathcal{C}$ be an $\\infty$-category and $W\\subseteq \\mathcal{C}_1$ be any subset of morphisms. A functor $F:\\mathcal{C}\\longrightarrow \\mathcal{D}$ is called a Dwyer-Kan localization at $W$ if\n $F$ takes morphisms in $W$ to equivalences in $\\mathcal{D}$ For every $\\infty$-category $\\mathcal{E}$, the map $Fun(\\mathcal{D}, \\mathcal{E})\\longrightarrow Fun(\\mathcal{C}, \\mathcal{E})$ is fully faithful, and has essential image equivalent to the full subcategory $Fun^W(\\mathcal{C}, \\mathcal{E})\\subseteq Fun(\\mathcal{C}, \\mathcal{E})$ of those functors that send $W$ to equivalences.  This last requirement is a sort of universal property for the functor $F$, in that functors out of $\\mathcal{D}$ correspond to functors out of $\\mathcal{C}$ that send $W$ to equivalences. This means that $\\mathcal{D}$ is a sort of universal category where maps in $W$ are invertible. We denote a Dwyer-Kan localization of $\\mathcal{C}$ at $W$ by $\\mathcal{C}[W^{-1}]$.\nThe most simple example we can make is on the category $\\mathcal{C}=\\Delta^1$. This category has three maps: the identities $0\\longrightarrow 1$, $1\\longrightarrow 1$ and the map $0\\longrightarrow 1$, being the only map that is not an equivalence. We choose $W$ to be the singleton set containing this last map.\nWe need to check that $Fun(\\Delta^0, \\mathcal{E})\\longrightarrow Fun^W(\\Delta^1, \\mathcal{E})$ is an equivalence of categories for all $\\infty$-categories $\\mathcal{E}$. We can do this by proving that it is both fully faithful and essentially surjective. In order to show the latter we need to find a preimage to any diagram $E\\overset{w}\\longrightarrow E'$, where $w$ is an equivalence in the image of $W$. This can be given by $E\\overset{id_E}\\longrightarrow E$. In the category $Fun(\\Delta^1, \\mathcal{E})$ we have that $Map(A\\to A', B\\to B')$ is equivalent to the pullback of But, in the subcategory $Fun^W(\\Delta^1, \\mathcal{E})$ the maps $f$ and $g$ will be equivalences, which makes also the maps $g\\circ -$ and $-\\circ f$ into equivalences. This means that the pullback will just be $Map(A, B)$, which means that $Fun(\\Delta^0, \\mathcal{E})\\longrightarrow Fun^W(\\Delta^1, \\mathcal{E})$ is fully faithful.\nWe can use this example to construct Dwyer-Kan localizations for all $\\infty$-categories. We simply take the pushout in the category of $\\infty$-categories, $Cat_\\infty$. We do not, however, prove that this in fact produces a localization of the category $\\mathcal{C}$.\nNow that we know that Dwyer-Kan localizations exist, we can finally state the definition of the derived $\\infty$-category of an abelian category $\\mathcal{A}$. Recall first that the set of quasi-isomorphisms are the maps that induce isomorphisms in homology. In our case, we have transferred the enrichment over chain complexes into an enrichment over Kan complexes, in a way that turns homology into homotopy. Hence we can define quasi-isomorphisms in the category $K_\\infty(\\mathcal{A})$ as the $\\pi_\\ast$-isomorphisms, i.e. the weak homotopy equivalences.\nDefinition:  Let $\\mathcal{A}$ be an abelian category and $W$ be the set of quasi-isomorphisms in $K_\\infty(\\mathcal{A})$. We define the derived $\\infty$-category of $\\mathcal{A}$ to be the Dwyer-Kan localization of the $\\infty$-category of chain complexes in $\\mathcal{A}$ at the quasi-isomorphisms, i.e. $D_\\infty(\\mathcal{A})=K_\\infty(\\mathcal{A})[W^{-1}]$.\nWe will also not prove that the derived $\\infty$-category $D_\\infty(\\mathcal{A})$ for an abelian category $\\mathcal{A}$ is actually stable, but this is in face the case. We mentioned a bit earlier that the nice thing about the classical derived category is that it is triangulated. We have constructed $D_\\infty(\\mathcal{A})$ in such a way that we have $hD_\\infty(\\mathcal{A})\\simeq D(\\mathcal{A})$; the homotopy category of the derived $\\infty$-category is the classical derived category. This means in particular that the homotopy category of the derived $\\infty$-category is triangulated. We round off this post by asking and answering a natural followup question to this information. Is the fact that $hD_\\infty(\\mathcal{A})$ is triangulated a special case, or is this a consequence of a more general fact about stable $\\infty$-categories? In more precise words: is the homotopy category of a stable $\\infty$-category always triangulated? This turns out to be true. In order to have a triangulated structure, we need to know what the distinguished triangles are, so lets quickly define these.\nDefinition:  A diagram $X\\overset{f}\\longrightarrow Y\\overset{g}\\longrightarrow Z\\overset{h}\\longrightarrow \\Sigma X$ in $h\\mathcal{C}$ is a called a distinguished triangle, if there is a diagram in $\\mathcal{C}$, such that both squares are pushout squares, $\\tilde{f}$ and $\\tilde{g}$ represent $f$ and $g$ respectively, and such that the map $h$ is the composition of the homotopy class of $\\tilde{h}$ with the equivalence $W\\simeq \\Sigma X$.\nTheorem:  Let $\\mathcal{C}$ be a stable $\\infty$-category. Then the class of distinguished triangles, together with the induced suspension object functor $\\Sigma$ make $h\\mathcal{C}$ into a triangulated category.\nThis means in particular that stable $\\infty$-categories are enhancements of triangulated categories. We will not go through the proof, but we suggest looking at the proof in HA. In particular, we suggest looking at the proof for the octrahedral axiom, which is really neat and simple in this framework.\nRemark on exotic algebraic models As a final end to this post we contemplate the following thoughts. We have now found two examples of stable $\\infty$-categories, one that emulates algebraic topology, and one that emulates homological algebra. We can ask, are there similarities between these two constructions? Are there stable $\\infty$-categories that have the structure of both of these examples? More precisely, are there ever equivalences between categories of spectra and derived $\\infty$ -categories, or $\\infty$-categories of chain complexes? This turns out to almost never be the case, mainly because the higher homotopy information contained in spectra are too complicated to be realised using algebraic gadgets. One of the only equivalences of $\\infty$-categories of this form is the equivalence $$Sp_\\mathbb{Q} \\simeq K_\\infty(\\mathbb{Q})$$ between rational spectra and chain complexes of rational vector spaces. But, we can ask a more nuanced question. Even though there are few of these equivalences of $\\infty$-categories, there might be equivalences between them if we remove, or truncate, the higher homotopy information. We might therefore look for equivalences $$h_k \\mathcal{C} \\simeq h_k D(\\mathcal{A})$$ for some subcategory $\\mathcal{C}\\subseteq Sp$ and some abelian category $\\mathcal{A}$. Here $h_k$ denotes the homotopy $k$-category, and such equivalences are called exotic algebraic models. This is in fact exactly what my phd-project centres around, finding exotic algebraic models of special categories of spectra in a subfield of stable homotopy theory called chromatic homotopy theory. We will then naturally meet this topic a lot in the future, as I hopefully continue to write about what I am learning.\n","permalink":"https://torgeiraamboe.github.io/posts/2022/stable-infinity-categories/","summary":"This semester I am taking part in a seminar on $\\infty$-categories, administered by Rune Haugseng. So far we have covered roughly: the basic definitions, fibrations, limits, colimits, Joyal’s lifting theorem, equivalences, straightening, Yoneda lemma, adjunctions and Kan extensions. This week it is my turn to give a talk on stable $\\infty$-categories, and this blog post will hopefully be some sort of lecture notes for this talk. The intersection of things in this post and the contents of the talk should at least be non-empty.","title":"Stable infinity-categories"},{"content":"Recently my friend Elias started his own math blog adventure, and his first post gave a nice introduction to spectral sequences. Reading it I remembered that I should really understand some of the parts better myself, because a lot of the arguments one makes in chromatic homotopy theory are based on spectral sequences. There is a framework for constructing spectral sequences that are not covered in my old post on them, as well as Elias’ post, and that is creating spectral sequences from exact couples. So, since I will use these techniques later in my research, and probably later on this blog, I thought it worthwhile to discuss. In particular we look into producing spectral sequences from filtered spectra, as this is the part that is most relevant for my research.\nExact couples Spectral sequences are very iterative objects. One starts on a place of coarse and not very comprehensive information and iterates a procedure in order to refine this information. If we are careful in our construction, and use it in nice situations, this iterative information converges to the thing we are interested in. The information we are interested in is usually some form of homology, cohomology or derived functor, and the iteration process is usually made by creating some differentials and producing some form of homology or cohomology. For some general information about this you can see my old blog post or Elias’ post.\nOk, let’s start off by defining what an exact couple actually is.\nDefinition:  An exact couple $(D, E; i,j,k)$ is a pair of modules $D$ and $E$, together with homomorphisms $i, j, k$ such that the diagram\nis exact at each vertex.\nThe notion of being exact at each vertex here means that we have $Im(i)=Ker(j)$, $Im(j)=Ker(k)$ and $Im(k)=ker(i)$. So it is the standard exactness we use in homological algebra. Notice also that the composition $d:=j\\circ k:E\\longrightarrow E$ is a differential on $E$, as we have\n$$ d\\circ d = (j\\circ k)\\circ (j\\circ k) = j\\circ (k\\circ j)\\circ k = j\\circ 0\\circ k=0. $$\nThe composition $k\\circ j$ is zero as we have $Ker(k)=Im(j)$. So having an exact couple gives us a differential on the module $E$, and this is exactly how we start the iterative process.\nSo, how does the iteration work? When we have a differential one of the first things we should think about doing is taking homology. This is precisely the thing we do to form the so-called derived couple of an exact couple.\nDefinition:  Let $(D, E;i,j,k)$ be an exact couple. We define its derived couple as the tuple $(D', E';i', j', k')$ defined by\n $D'=iD$ $E'=H(E, d)$ $i'=i_{|D'}$ $j'$ takes $i(x)$ into the $d$-homology class $[j(x)]$ for $x\\in D$ $k'$ takes $[y]$ for some $y\\in E$ to $k(y)$.  And in diagram form:\nWe see that we make several choices in this definition, as we choose representatives from different homology classes. But one can show that these choices does not matter, and we get well defined maps.\nLemma:  The derived couple of an exact couple is again an exact couple.\nProof: We need to check that the diagram is exact at each vertex. We show only for $Im(k')=Ker(i')$, the other vertices are similar types of diagram chase arguments.\nLet $x\\in Ker(i)$. In particular we know $x\\in D'$, which means $x=i(y)$ for some $y\\in D$. We then have $0=i'(i(y))$ since its in the kernel. But $i'$ is just the restriction of $i$ to its image, hence we have $0=i(i(y))$, which means $i(y)$ is in the kernel of $i$, and by exactness that $i(y)$ is in the image of $k$. Hence we can find $a\\in E$ such that $i(y)=k(a)$. Choosing the class $[a]\\in E'$ gives us $k'[a] = k(a)=i(y)=x$, hence we have that $x$ is in the image of $k'$.\nChoose now $x\\in Im(k')$. This means we have a homology class $[a]$ such that $k'[a]=x$. By definition this means that $x=k(a)$. We then have $i'(x)=i'(k(a))=i(k(a))=0$ by exactness.\nThe cool thing about this result is that we can start iterating this procedure, and form an infinite tower $(D^n, E^n;i^n, j^n, k^n)$ of exact couples. In each of these towers $E^n$ is a differential group with $d^n=j^n\\circ k^n$ and $E^{n+1}=H(E^n, d^n)$.\nDefinition:  The sequence $E^n$ is called the spectral sequence of the exact couple $(D, E;i,j,k)$.\nFor the people familiar with spectral sequences this should look familiar, but perhaps feel a bit weird. It seems like we have only one grading, where in the usual scenario we have three. This can easily be implemented by considering $D$ and $E$ to be bigraded modules instead. We will do so below. Even though most examples use three gradings, there are also examples in the more simple situation described above, like the Bockstein spectral sequence.\nExact couples in spectra One important use case of the theory we developed above is to study spectra, i.e. stable phenomena in topology. One of the crucial ways to do this is by understanding their homotopy groups, which we know from earlier discussions generalize the notion of stable homotopy groups of topological spaces via the suspension spectrum construction. We want to create spectral sequences that allows us to compute these homotopy groups, in particular the coefficients $\\pi_* X$ of some spectrum $X$. One way to do this is to use filtered spectra.\nDefinition:  A filtration on a spectrum $X$ is a $\\Z$-graded sequence of spectra $X_\\bullet$, such that $X$ is the homotopy colimit $X\\simeq \\underrightarrow{\\lim}_kX_k$. A *filtered spectrum* is then a spectrum together with a chosen filtration.\nOften we work with a simpler definition, namely that a filtration is simply a sequence\n$$ \\cdots \\rightarrow X_n\\overset{f_n}\\rightarrow X_{n-1}\\rightarrow \\cdots \\rightarrow X_1\\overset{f_0}\\rightarrow X_0=X. $$\nThis is a special case of the above definition, which is usually enough in the case of spectra. We will from this point onwards be using this simpler definition of a filtration, however, we note that the general definition is particularly nice, as it works just as well in any (nice) stable $\\infty$-category.\nSince the category of spectra has a model structure, we can for all filtrations produce one where the $f_n$’s are all fibrations (or cofibrations) by taking fibrant (cofibrant) replacements everywhere. In consequence filtrations of a spectrum $X$ is in the literature sometimes called a tower of fibrations over $X$.\nGiven a filtered spectrum $X$ we write $A_k$ for the homotopy cofiber of its $k$’th stage, i.e. $A_k = cofib(f_k)$. We then obtain the diagram\nwhere each stage $X_{n+1}\\longrightarrow X_n\\longrightarrow A_n$ is a homotopy fiber sequence by construction. Recall that the goal is to understand $\\pi_\\ast X$. If we now apply $\\pi_\\ast$ to the diagram we get a new diagram\nThe functor $\\pi_\\ast$ sends fiber sequences to long exact sequences, i.e. the long exact sequence in homotopy groups we are familiar with from algebraic topology. In our situation we get for each of the fiber sequences $X_{k+1}\\longrightarrow X_k\\longrightarrow A_k$ the long exact sequence\n$$ \\cdots \\rightarrow \\pi_{*+1}A_k\\overset{\\delta^k_{*+1}}\\rightarrow \\pi_*X_{k+1}\\rightarrow \\pi_*X_k\\rightarrow \\pi_*A_k\\rightarrow \\cdots $$\nWe can interpret the connecting homomorphisms $\\delta_*^k$ as maps of degree $-1$. This means we that we can incorporate it into the above diagram to get\nwhere now each triangle is a sort of rolled up version of the long exact sequence. Note that these triangles are NOT commuting.\nWe can even further compress this diagram, and roll it up again, but instead considering the bigraded abelian groups $\\pi_* X_\\bullet$ and $\\pi_* A_\\bullet$. This gives us the diagram\nwhich should remind us of the diagrams in the beginning, namely an exact couple! We do not show here that the diagram is exact at each vertex. As we have now compressed two gradings into a single diagram we have bigraded maps, and the maps have the following bidegrees:\n $i^1=\\pi_* f_\\bullet : (-1,-1)$ $j^1=\\pi_* cofib(f_*) : (0,0)$ $k^1=\\delta: (1, 0)$ or $(-1,0)$ depending on homological or cohomological grading  When we pass to the corresponding derived couple the bidegrees of $i$ and $k$ are preserved, i.e. we have $|i^2|=(-1, -1)$ and $|k^2|=(1, 0)$. The bidegree of $j$ does change however. As we can think about $j^1$ as first choosing a preimage of $i$ and then applying $j$ we get $|j^2|=|j|-|i| = (1,1)$. In particular this means that the bidegree of $j^r$ increases by $(1,1)$ each time we pass to the next derived couple, i.e. $|j^r|=(r-1,r-1)$. The first differential $d^1$ is given by the composition $j\\circ k$, hence has bidegree $|d^1|=|j|+|k|=(1,0)$. Since we have $d^r=j^r\\circ k^r$ the bidegree of the $r$’th differential is given by $|d^r|=|j^r|+|k^r| = (r,r-1)$, which is what we are familiar with from normal spectral sequences, i.e.\n$$ d^r:E^{s,t}_r\\longrightarrow E^{s+r, t+r-1}_r . $$\nIt is at this stage often convenient and customary to shift the grading from $(s,t)$ into $(t-s, s)$ before drawing the normal spectral sequence diagrams. This convention is often called the Adams type grading convention, and it makes it such that $t$ counts the number of times we have wounded around the triangle in the derived couple. Drawing the differentials in the $r$’th page in the spectral sequence then always goes one to the left and $r$ upwards:\nThe Adams spectral sequence To quickly summarize all we have discussed until now: for each filtered spectrum $X_{\\bullet}$ we get a spectral sequence $E_r$ with first page given by $$E^{s,t}_1 = \\pi_{t-s}cofib(X_{s}\\overset{f_s}\\longrightarrow X_{s-1}).$$\nWhat can we use this for? Maybe the most used applications is the socalled Adams spectral sequence, and its generalization, the $E$-Adams spectral sequence. Let’s construct the most general spectral sequence, and then try to see how it is specialized afterwards.\nFor the construction we must choose a commutative ring spectrum $E$ such that the module $E_\\ast E$ is flat over over $\\pi_\\ast E$. Since the sphere spectrum is the monoidal unit in $Sp$, we have a unit map $\\mathbb{S}\\overset{e}\\longrightarrow E$. Denote the cofiber of $e$ by $\\overline{E}$, hence we have a cofiber sequence (or equivalently a fiber sequence as $Sp$ is stable) $$\\overline E \\longrightarrow \\mathbb{S}\\longrightarrow E.$$ If we now take some spectrum $X$ that we are interested in, we can smash $X$ with the unit map to get a map $X\\longrightarrow E\\wedge X$, where we have used the fact that $\\mathbb{S}$ is the unit, hence $\\mathbb{S}\\wedge X \\simeq X$. The fiber of this map is $\\overline E\\wedge X$ due to the fiber sequence from the unit map. We now have a map $\\overline E\\wedge \\overline E \\wedge X\\longrightarrow \\overline E\\wedge X$, that has cofiber $E\\wedge \\overline E\\wedge X$ . In general we have a map $\\overline E^n\\wedge X \\longrightarrow \\overline E^{n-1} \\wedge X$, that has cofiber $E\\wedge \\overline E^{n-1} \\wedge X$. we assemble all these maps we get a sequence\nThis sequence is a filtration on $X$, and is called the $E$-Adams filtration or the $E$-Adams tower. We can think about this tower as iteratively projecting out all of the $E$-homology of $X$.\nIf we write $X_n = \\overline E^n \\wedge X$ and $A_n = E\\wedge X_n$ we get the standard for of a the filtration\nFrom the previous discussion we know that from a filtered spectrum we can produce a spectral sequence. This we now know has first page $E^{s,t}_ 1 = \\pi_{t-s}(A_s)$. This spectral sequence is called the $E$-Adams spectral sequence.\nWe also know that homotopy groups are just maps from the sphere spectrum (by definition), so we have $E^{s,t}_ 1 = [ \\mathbb{S}, A_s]_{t-s}$. This is the point where it becomes important that we assumed that $E$ had a flatness condition, i.e. that $E_\\ast E$ is flat over $\\pi_\\ast E$. For any spectrum $Y$ we have an isomorphism\n$$ \\pi_\\ast (E\\wedge Y)\\cong Hom^\\ast_{\\pi_\\ast E}(\\pi_\\ast E, E_\\ast Y), $$\nbut when $E$ has this flatness condition, the group homomorphisms on the right lift to morphisms in an even nicer category, namely the category of comodules over $E_\\ast E$. The group $E_\\ast E$ is actually a Hopf algebra, and is often called the dual $E$-Steenrod algebra. Even more is true, the pair $(E_\\ast E, \\pi_\\ast E)$ is a commutative flat Hopf algebroid. What this is and what it means we will save for a later post. This means we have a description of the $E$-Adams spectral sequence we produced above for a spectrum $X$ as\n$$ E_1^{s,t} \\cong Hom_{Comod_{E_\\ast E}}^{t-s}(\\pi_\\ast E, E_\\ast(A_s)). $$\nThe category of comodules over a flat Hopf algebroid turns out to be a pretty nice abelian category. In particular, as the second page is computed as the homology of the previous, we get that the second page consists of $Ext$ groups in $Comod_{E_\\ast E}$, i.e.\n$$ E_2^{s,t} \\cong Ext_{Comod_{E_\\ast E}}^{s,t}(\\pi_\\ast E, E_\\ast (A_s)). $$\nThis is of course a complicated object, but $Ext$ groups are possible to calculate.\nSo what does this $E$-Adams spectral sequence converge to? It turns out to be highly related to localization and completion of homotopy groups, or if we recall the theory of Bousfield localization, the localization of spectra. If we for example choose $E=H\\mathbb{F_p}$, the Eilenberg-Maclane spectrum of the finite field with $p$ elements, then the spectral sequence converges to the $p$-complete homotopy groups, i.e.\n$$ E^{s,t}_ r \\implies \\pi_\\ast X_p^\\wedge $$\nIn particular, if we choose $p=2$ and $X=\\mathbb{S}$, then this is the classical Adams spectral sequence used to compute the $2$-primary component of the homotopy groups of spheres, i.e.\n$$ Ext^{s,t}_ {\\mathscr{A}^\\ast}(\\mathbb{F_2}, \\mathbb{F}_2)\\implies \\pi_\\ast \\mathbb{S}_2^\\wedge . $$\nHere $\\mathscr{A}^\\ast$ is the dual Steenrod algebra, which is isomorphic to $H\\mathbb{F}_ {2\\ast}H\\mathbb{F}_2$, and $\\pi_\\ast H\\mathbb{F}_2 = \\mathbb{F}_2$. Much of the beginning of this spectral sequence has been calculated, but much reasearch is still going into it. Here is an image, curtesy of Allen Hatcher, of parts of the $E_2$ page.\nHere each dot represents a copy of $\\Z_2$, the differentials are the lines sloping to the left, while the lines going straight up represent multiplication by $2$, and the lines sloping to the right represent multiplication by $h_1$. Hence we also encounter in this picture the multiplicative structure in the spectral sequence, which we have not yet talked about. The elements $h_1$, $h_2$, and $h_3$ are the elements corresponding to the classical Hopf maps, i.e. the maps of spheres with Hopf invariant $1$. We studied $h_1$ quite a bit in the first blog post about homotopy groups of spheres. The fact that $h_4$ is killed by a differential can then be described as the reason there is no finite dimensional real division algebras other than $\\mathbb{R}$, $\\mathbb{C}$, $\\mathbb{H}$ and $\\mathbb{O}$, as the maps of spheres with Hopf invariant $1$ form the only dimensions where this is possible. I reccommend reading the explanation of the diagram featured in the link above to Hatcher, as I have been very brief here.\nWe can also choose other spectra to create spectral sequences, like $E=MU$, the complex cobordism spectrum. This produces the so-called Adams-Novikov spectral sequence. This is a very complicated spectral sequence due to its strong potential. We haven’t gone into why these $E$-Adams spectral sequences have something to do with localization and completion, but it is related to a concept called nilpotent completion of spectra. So, the Adams-Novikov spectral sequence\n$$ E_2^{s,t} \\cong Ext_{Comod_{MU_\\ast MU}}^{s,t}(\\pi_\\ast MU, MU_\\ast (A_s)) $$\nconverges to the homotopy groups of the $MU$-nilpotent completion of the spectrum $X$. But all spectra are already $MU$-nilpotent complete, hence this just gives the full homotopy groups of $X$. We could then use this to compute the stable homotopy groups of the spheres by letting $X=\\mathbb{S}$, i.e.\n$$ E_2^{s,t} \\cong Ext_{Comod_{MU_\\ast MU}}^{s,t}(\\pi_\\ast MU, \\pi_\\ast MU)\\implies \\pi_\\ast \\mathbb{S}. $$\nAs we already know that the homotopy groups of spheres are terribly complicated, we should expect this spectral sequence to also be terribly complicated. We can make it a bit simpler by using $BP$, the Brown-Peterson spectrum, instead of $MU$. This would allow us to compute the homotopy groups of $\\mathbb{S}$ “one prime at the time”, which we could later use to compute the full homotopy groups. This spectral sequence is also usually called the Adams-Novikov spectral sequence, as its really exactly the same as the one above based on $MU$, just in the category of $p$-local spectra instead of all spectra. Because the potential for computing the homotopy groups of spheres is there, we should however also expect it to be very difficult to compute.\nI will leave off this blog post by stating a recurring theme of these last few paragraphs — a theme we have also encountered before. It is a statement sometimes called Mahovald’s uncertainty principle, and very informally says: Any easy to compute spectral sequence converging to the homotopy groups of spheres that can be written down using homological algebra, will be infinitely wrong.\n","permalink":"https://torgeiraamboe.github.io/posts/2022/the-adams-spectral-sequence/","summary":"Recently my friend Elias started his own math blog adventure, and his first post gave a nice introduction to spectral sequences. Reading it I remembered that I should really understand some of the parts better myself, because a lot of the arguments one makes in chromatic homotopy theory are based on spectral sequences. There is a framework for constructing spectral sequences that are not covered in my old post on them, as well as Elias’ post, and that is creating spectral sequences from exact couples.","title":"The Adams spectral sequence"},{"content":"Over the holidays sadly Edgar H. Brown passed away. He was one of the influential men behind many of the concepts this blog has featured and will feature in the future. This post is in particular focused on one of these concepts, namely Brown-Peterson cohomology and the Brown-Peterson spectrum.\nIn the last post we developed the category of $p$-local spectra, and in the post before that we explored complex cobordism cohomology. Today we will merge these two together, and try to understand what happens to the complex cobordism spectrum $MU$ when we travel to the $p$-local category. The spectrum $MU$ is a normal spectrum — it is not $p$-local. But, as we now know, we can create a $p$-local version of it by $p$-localizing it. We then get a spectrum $MU\\wedge \\Z_{(p)}$ which we simply denote by $MU_{(p)}$. This is the spectrum we want to understand today. The idea for understanding $MU_{(p)}$ will be to split it into nicer pieces which have similar — and actually better — properties.\nDecomposing spectra In order to break apart $MU_{(p)}$ into nicer pieces we need to understand two things:\n What does this mean? How can we do this?  In mathematics the concept of decomposing objects are very important. In its essence it gives us the opportunity to break apart complicated things into easier to understand — more fundamental — pieces. Take for example the fundamental theorem of finitely generated abelian groups. This gives a decomposition of a finitely generated abelian group $G$ into a direct sum of the familiar infinite cyclic groups and primary cyclic groups, i.e. $G\\cong \\Z^k\\oplus \\Z/q_1\\oplus\\cdots \\oplus \\Z/q_1$, where $q_i = p^t$ for some prime $p$. More generally we say that we can decompose $G$ into two groups $H_1$ and $H_2$ if we have an isomorphism $G\\cong H_1\\oplus H_2$. This is the same style of decomposition we want for $MU_{(p)}$. In the category of spectra we also have an analogue of the direct sum, namely the wedge product, $\\vee$. Decomposing the spectrum $MU_{(p)}$ then means that we have an equivalence $MU_{(p)} \\simeq F_1\\vee F_2$ for two $p$-local spectra $F_1$ and $F_2$. Ok, that answers the first point.\nThe strategy we will use is to do the second point is to construct an idempotent self map $e:MU_{(p)}\\longrightarrow MU_{(p)}$. This idea is inspired from ring theory where an idempotent self map of rings gives us decompositions. More precisely, given a commutative ring $R$ and an idempotent endomorphism $e:R\\longrightarrow R$, we get a decomposition $R\\cong eR\\oplus (1-e)R$. As $MU$ is a ring spectrum we also get an induced ring structure on it $p$-localization, i.e. $MU_{(p)}$ is also a ring spectrum. If we for a moment believe that what works for rings also works for ring spectra, then constructing an idempotent map $e:MU_{(p)}\\longrightarrow MU_{(p)}$ should get us a splitting $MU_{(p)}\\simeq eMU_{(p)}\\vee (1-e)MU_{(p)}$. It is not true that absolutely *everything* that work for rings work for ring spectra, but it is not too far off. Ring spectra1 can be thought of as the homotopical analogue of rings, and this analogue actually gets us quite far as we will see in the future.\n$p$-typical formal group laws The idempotent $e$ will come from a familiar structure, namely from the fact that $MU$ is the universal complex oriented cohomology theory. We have discussed this before, but let\u0026rsquo;s recall what this means.\nLemma:  Let $E$ be a complex oriented cohomology theory with orientation $x^E$. Then there exists a unique multiplicative map $f:MU\\longrightarrow E$ such that $f^\\ast (x^{MU})= x^E$, where $x^{MU}$ is the canonical complex orientation on $MU$. In other words, complex orientations on $E$ are in one to one correspondence with multiplicative maps $MU\\longrightarrow E$.\nWe also know that $MU$ carries the universal formal group law $G$ over its coefficient ring, the Lazard ring $L$. What happens then when we $p$-localize? The coefficient ring becomes $L\\otimes \\Z_{(p)}$ and we can ask whether we again get some sort of universal formal group law, now not for all rings but for all $\\Z_{(p)}$-algebras. To reiterate the question formally: Is there a formal group law over $L\\otimes \\Z_{(p)}$ that is universal among $\\Z_{(p)}$-algebras? The answer is yes, and it is simply the image $G_{(p)}$ of the universal group law $G$ under the canonical map $L\\longrightarrow L\\otimes \\Z_{(p)}$. Thus also orientations on $p$-local spectra are classified by multiplicative maps $MU_{(p)}\\longrightarrow E$.\nWe are now going to do something that might seem very unmotivated, due to the fact that there are some tricky mathematics lying in the background that we will not cover in this post. For the interested this is called $p$-typical formal group laws. My intuition behind them is that they are nice formal group laws over $\\Z_{(p)}$-algebras that have generators in exponential periodic degrees. We will see what we mean by this soon.\nOk, take the formal group law $G_{(p)}$ over the ring $L\\otimes \\Z_{(p)}$ as described above. Recall that the Lazard ring $L$ is the ring $\\Z[b_1, b_2, \\ldots]$ where $b_i$ has degree $2i$. We construct an endomorphism $\\psi:L\\otimes \\Z_{(p)} \\longrightarrow L\\otimes \\Z_{(p)}$ by $\\psi(b_i) = b_i$ if $i=p^k-1$ for some $k$, and $\\psi(b_i)=0$ otherwise. The image of $\\psi$ is a subring $V\\subset L\\otimes \\Z_{(p)}$, more specifically it is the subring $\\Z_{(p)}[v_1, v_2, \\ldots ]$ where $v_i$ has degree $2(p^i-1)$. This is the periodicity in degrees we mentioned above. This ring carries a formal group law $G^p$ that is universal among $p$-typical formal group laws. This means that among $p$-typical formal group laws, $V$ acts like the Lazard ring does for all formal group laws. Because of this $V$ is often denoted $L^p$ and called the $p$-typical Lazard ring.\nA question we can ask is then: Is being $p$-typical a strict property? It turns out that it is not. In fact, by a theorem of Cartier, all formal group laws over a $\\Z_{(p)}$-algebra is strictly isomorphic to a $p$-typical formal group law. Hence using the ring $V$ and the universal $p$-typical formal group laws gives us some advantages over using $L\\otimes \\Z_{(p)}$ and $G_{(p)}$ as we now have nice periodic behavior and a nicely defined ring more similar to the Lazard ring. We don’t really understand yet why this periodic behavior is important, but we will see this in the future. Intuitively, if we choose some arbitrary even degree, then $L$ has incredibly many elements in that degree. Using $V$ allows us to pick out only one of these in an orderly exponential manner. This has the benefits of reducing the overall complexity of the theory immensely. Almost all cohomology theories we will work with in the future has some kind of periodic property, an it all stems from the ones just described.\nThe image of Quillen\u0026rsquo;s self map The important fact about the universal formal group law $G$ over the Lazard ring $L$ is that we know that there is a complex oriented spectrum that carries $G$ and has $L$ as its coefficient ring. This spectrum is as we know $MU$ — the spectrum representing complex cobordism cohomology. Now we have constructed a new ring $V$ and a new type of universal formal group law, $G^p$. We would like there to be a spectrum with the same properties as $MU$, i.e. a spectrum that carries $G^p$ and has $V$ as its coefficient ring. Is there such a spectrum? As the title of this post might spoil, the answer is yes. It is the spectrum $BP$, representing Brown-Peterson cohomology. As we discussed earlier, we will construct this by splitting $MU_{(p)}$ into pieces using an idempotent decomposition. So, the next thing we need to do is define this idempotent.\nTake the canonical orientation $x_{MU}$ on $MU$. When we $p$-localize we get an induced orientation $x_{MU_{(p)}}$ on $MU_{(p)}$. This orientation corresponds to a formal group law over $MU_{(p)}^\\ast (pt) \\cong L\\otimes \\Z_{(p)}$, which is a $\\Z_{(p)}$-algebra. By the theorem of Cartier mentioned above, this formal group law is isomorphic to a $p$-typical formal group law, again over $MU_{(p)}^\\ast (pt)$. This formal group law corresponds to an orientation on $MU_{(p)}$, different from $x_{MU_{(p)}}$. Orientations on $p$-local spectra are as mentioned earlier classified by maps $MU_{(p)}\\longrightarrow E$, hence this new orientation gives us our map\n$$ e: MU_{(p)}\\longrightarrow MU_{(p)}. $$\nThis map is an idempotent map, which by our intuitive reasoning in the beginning of the section corresponds to a decomposition\n$$ MU_{(p)} \\cong eMU_{(p)}\\vee (1-e)MU_{(p)}. $$\nThe image of $e$, i.e. $eMU_{(p)}$ is the spectrum we define2 to be $BP$ — the Brown-Peterson spectrum. In the original article by Brown and Peterson they defined this spectrum even more generally, not even using $p$-localization. The method we have used here, first used by Quillen, creates a spectrum that is isomorphic after $p$-localizing the original Brown-Peterson spectrum. Since the original was created not requiring a prime $p$, the notation for the spectrum $BP$ has a tradition of omitting the reference to $p$, but we should never forget that it is always there in hiding.\nThere are some other ways to construct $BP$ as well, some we can briefly describe. In the post about formal group laws we described how we get a formal group law from any complex oriented cohomology theory. We asked the natural question: Given a formal group law, ca we construct a complex oriented cohomology theory corresponding to it? We answered briefly that this was not the case, but mentioned that with some restrictions on the formal group law that this is the case. Why do we need the restriction?\nOne way of trying to construct a complex oriented cohomology theory from a formal group law is to use the universal one, $MU$. In particular, given a ring formal group law $F$ over a ring $R$ we can construct a functor $E^\\ast (-):Top\\longrightarrow GrAb$ by defining for a topological space $X$\n$$ E^\\ast (X) = R\\otimes_{MU^\\ast (pt)} MU^\\ast (X). $$\nHere we give $R$ an $MU^\\ast(pt)$-module structure via $F$, hence the tensor product makes sense and also incorporates the formal group law. This looks like it should be a cohomology theory, and we ask if this is the case? It is very close, i.e. it satisfies all but one axiom — the exactness axiom. We can\u0026rsquo;t guarantee that the functor sends cofiber sequences to long exact sequences. They are sent to complexes of modules, but they might not be exact. If we think of $E^\\ast(-)$ as the composition of the functors $MU^\\ast(-)$ and $R\\otimes (-)$ then this failure becomes apparent, as the tensor functor $R\\otimes(-)$ is not exact. If we recall some homological algebra then we can get that this functor is exact, and hence that $E^\\ast(-)$ as defined above is a cohomology theory, by requiring that the ring $R$ is flat 3.\nOk, are almost at Brown-Peterson cohomology. Let $R$ be the ring $V=\\Z_{(p)}[v_1, v_2, \\ldots]$ as defined earlier. This ring is flat, hence the functor $X\\longmapsto V\\otimes_{MU^\\ast(pt)}MU^\\ast(X)$ is a cohomology theory. By Brown\u0026rsquo;s representability theorem — yes, the same Brown — this functor is represented by a spectrum, and this spectrum is exactly $BP$.\nYou might ask: what about the other part of $MU_{(p)}$? We have now split open $MU_{(p)}$ and focused only on one of its pieces, $BP$, but what about the remaining part? It turns out that the other part is also $BP$, at least up to suspension. What we mean is that there is an equivalence\n$$ BP[x_{2i}, i\\neq (p^j-1)] \\simeq MU_{(p)}, $$\nwhich in particular means $MU_{(p)}$ is glued together from many copies of $BP$, just shifted by suspension to get the generators to be correct.\nThe coefficient ring of $BP$ The first thing we need to figure out about $BP$ is its coefficient ring, $BP^\\ast(pt)$. Due to the two constructions above we can do this in two ways. In the first construction we used the idempotent $e$ to construct a splitting of $MU_{(p)}$. This idempotent induces a map on cohomology, in particular on the cohomology of a point, i.e. on the coefficient rings:\n$$ e^\\ast(pt):MU_{(p)}^\\ast(pt)\\longrightarrow MU_{(p)}^\\ast(pt) $$\nSince $e$ is an idempotent, $e^\\ast(pt)$ will also be one. Luckily for us we have already seen this map, and it is in fact the map $\\psi$ used to create the $p$-typical Lazard ring $V$ from $L\\otimes \\Z_{(p)}$. As the coefficient ring of $BP$ is the image of $e^\\ast(pt)$, i.e. the image of $\\psi$, we have\n$$ BP^\\ast(pt) \\cong V \\cong \\Z_{(p)}[v_1, v_2, \\ldots] $$\nwhere $|v_i| = 2(p^i-1)$. Since we know $V$ has a universal $p$-typical formal group law, we get that $BP$ is the spectrum that is universal among complex oriented spectra with $p$-typical formal group laws. This means in some sense that $BP$, not $MU_{(p)}$, is the true analogue of $MU$ among $p$-local spectra.\nWe can also see that $BP$ has the $p$-typical Lazard ring as its coefficient ring by using the alternative construction mentioned above. By evaluating the functor $BP^\\ast(-)$ at a point we get\n$$ BP^\\ast(pt) = V\\otimes_{MU^\\ast(pt)}MU^\\ast(pt) \\cong V. $$\nThis is of course the case for all spectra defined using this method, i.e. that the spectrum $E$ representing the cohomology theory $E^\\ast(-) = R\\otimes_{MU^\\ast(pt)}MU^\\ast(-)$ has coefficient ring $R$.\nWhy care about $BP$? We have now constructed $BP$ and shown that it behaves like $MU$ in the category $Sp_{(p)}$ of $p$-local spectra. So if we are convinced that $MU$ is interesting, we should also be convinced that $BP$ is interesting. This is however as far as we have gotten, so lets mention some other things we can learn from studying $BP$. This will not be detailed and rigorous, but we will meet some of the ideas below in later posts.\nOne intuitive reason for why $BP$ is interesting is that it can be thought of as a midway point between the $p$-local sphere spectrum $\\mathbb{S}_ {(p)}$ and the $p$-local Eilenberg-Mac Lane spectrum $H\\Z_{(p)}$. The sphere spectrum has a terribly complicated homotopy, but a easy homology, while the Eilenberg-Mac Lane spectrum has easy homotopy and terribly complicated homology. As a middle ground $BP$ has both homotopy and homology that are managable in complexity — not easy by any stretch, but not terribly complicated either.\nThe Brown-Peterson spectrum also have nice rings of cooperations. Recall that cohomology operations of some cohomology theory $E^\\ast$ are natural transformations $E^\\ast(-)\\longrightarrow E^\\ast(-)$. These are represented by maps of spectra $E\\longrightarrow E$, hence the ring of cohomology operations of $E$ is $E^\\ast E = [E, E]$, the $E$ cohomology of $E$. Similarily we define homology cooperations of $E$ to be $E_\\ast E = \\pi_\\ast(E\\wedge E)$, the $E$ homology of $E$. These cooperations are managable for $BP$, and they have been calculated to be\n$$ BP_\\ast BP \\cong V[t_1, t_2, \\ldots] $$\nwhere the $t_i$’s are generators of degree $2(p^i-1)$ in $BP_{2(p^i-1)}BP$.\nAnother important feature is that we can use $BP$ to calculate the stable homotopy groups of spheres. It turns out that $BP_\\ast BP$ is flat over the coefficient ring of $BP$, which we from above know is $V$. This makes $BP_\\ast BP$ — by some lemmas and some constructions — into both an algebra and a coalgebra over $V$. In particular, the pair $(V, BP_\\ast BP)$ has the structure of a flat Hopf algebroid. We will come back to what this means in another post, but we can think of it as a Hopf algebra with many objects. If we take the $BP$ homology of some topological space $X$, i.e. $BP_\\ast X$ then this becomes a comodule over $BP_\\ast BP$. The category of comodules over a flat Hopf algebroid turns out to be abelian, which means we can make sense of derived functors, in particular $Ext$. By using $Ext$ we can then construct certain spectral sequences, in particular the Adams-Novikov spectral sequence\n$$ Ext^{\\ast,\\ast}_ {BP_\\ast BP}(BP_\\ast(pt), BP_\\ast(pt)) \\implies \\pi_\\ast \\mathbb{S}_{(p)} $$\nthat converges to the homotopy groups of the $p$-local sphere spectrum. This is essentially just studying the $p$-torsion part of the stable homotopy groups of spheres, so doing this for all $p$ gives us the whole stable homotopy groups.\nThis was for now all I wanted to say about Brown-Peterson cohomology and the Brown-Peterson spectrum. Next time we will use it to construct new spectra and new homology theories which are even easier to manage than $BP$. This will eventually lead us to two spectrums $E(n)$ and $K(n)$ which will be our main focus for a couple of years. My PhD project is about understanding certain relationships between these two spectra, so I think we will be very familiar with them after some time!\n  If we want to be really precise with this analogue we should use $\\mathbb{E}_\\infty$ ring spectra here, but that is a story for another day.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n We are cheating a bit here. The map is actually only an idempotent up to homotopy, so considering this splitting is a bit wrong. We can fix this by using the so-called telescopes of $e$ and $(1-e)$ instead, but this theory we have chosen to save for later.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n In fact, Landweber proved that an even weaker property is sufficient, now called Landweber exactness. The result above is then formalized in the famous Landweber exact functor theorem, often called just LEFT.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://torgeiraamboe.github.io/posts/2022/brown-peterson-cohomology/","summary":"Over the holidays sadly Edgar H. Brown passed away. He was one of the influential men behind many of the concepts this blog has featured and will feature in the future. This post is in particular focused on one of these concepts, namely Brown-Peterson cohomology and the Brown-Peterson spectrum.\nIn the last post we developed the category of $p$-local spectra, and in the post before that we explored complex cobordism cohomology.","title":"Brown-Peterson cohomology"},{"content":"Topology, particularly homotopy theory, is hard. The scenes where these kind of mathematics happen are immensely complicated; the category of topological spaces; the category of spectra. The problem is that there is simply too much information to try to capture by using simple tools that we can actually understand properly. Trying to classify topological spaces or spectra is a feat that many deem impossible, it is simply too difficult.\nSo, how can we try to fix this? We take inspiration from other fields, where similar situations occur and then try to translate into our own situation. Take for example abelian groups. We have no classification of all abelian groups, but there are certain constructions that help us study them. We have a classification of finitely generated abelian groups, where we can decompose any abelian group $A$ into understandable pieces: a free part $\\Z^r$ and a torsion part $\\Z/p_1^{k_1}\\oplus \\ldots \\oplus \\Z/p_t^{k_t}$. For all abelian groups things get more complicated, but there are nice groups that have classifications, like divisible groups, which are direct sums of copies of $\\mathbb{Q}$ and Prüfer groups $\\Z(p^\\infty)$. The general approach seems to be to split the complicated groups into smaller pieces, or to study them via some easier groups. If we just consider $\\Z$ for a moment, we can for a prime $p$ study\n $\\Z/p$, the $p$-torsion integers $\\Z_{(p)}$, the $p$-local integers $\\Z_p$, the $p$-complete integers, also called the $p$-adic integers.  All these give us various information about $\\Z$ somehow centred around or away from the prime $p$. The last two actually come from a common very general framework, called localization. This framework is what will allow us to translate these ideas into topology and spectra. The main thing we want to understand in this post is $p$-localization of spectra, so let\u0026rsquo;s first recall a bit what this means for the integers.\nGiven the ring $\\Z$ and a prime $p$ we can define the ring $\\Z_{(p)}$ by inverting every prime not equal to $p$. This is the same as normal localization $[S^{-1}]\\Z$ where $S=\\{\\text{Prime ideals }(q)\\neq (p)\\}$. The reason it is called localization is due to the corresponding geometric picture.\nHaving a module $M$ over a ring $R$ is equivalent to having a quasi-coherent sheaf $\\widetilde{M}$ over the affine scheme $Spec(R)$. Letting $R=\\Z$ we get that a module is just an abelian group $A$. Hence, any abelian group $A$ gives us a quasi-coherent sheaf $\\widetilde{A}$ over $Spec(\\Z)$. The spectrum of the integers looks as follows:\nInverting every prime not equal to $p$ in $A$ is the same as restricting the quasi-coherent sheaf $\\widetilde{A}$ to the element $(p)$ in $Spec(\\Z)$. Intuitively we \u0026ldquo;zoom in\u0026rdquo; on the sheaf over just the point $(p)$, i.e. looking at it locally at\nHence the name localization.\nDefinitions Intuitively, localization is a formal way to invert morphisms in some category. It is a very general process. All we need is a multiplicatively closed set of maps, $W$, in our category $C$, which allows us to produce a category $C[W^{-1}]$ where all maps in $W$ now are invertible. If $C[W^{-1}]$ is a subcategory of $C$ then we say the localization is reflective. In this case localization is \u0026ldquo;projection\u0026rdquo; onto this subcategory in such a way that it is a left adjoint to the fully faithful inclusion. Bousfield localization is a generalization of reflective localization where we allow certain uniquenesses to be weakened, in particular we allow contractible choice for categories that have spaces of morphisms. We can think of this as making a process for inverting maps in a category such that we get a reflective localization on the homotopy category. We will not cover all general details of localizations and Bousfield localizations, as this is not necessary for us. We are primarily interested in Bousfield localization of spectra, which makes the situation a bit simpler as the category of spectra is a stable model category. Note that we could also use stable $\\infty$-categories here. The theory is roughly the same, but in the former we have to be a bit careful with which objects we are choosing — they must often be cofibrant — while in the latter this information is hidden in the $\\infty$-structure that we will not explain in this post.\nRecall that a topological stable model category is a pointed topological model category $C$ (a model category enriched in topological spaces) with a pair of functors $\\Sigma:C\\rightleftarrows C:\\Omega$ that induces an auto-equivalence on the homotopy category $HoC$. Let $W$ be a collection of morphisms in $C$.\nThe following three definitions are the central and most important definitions when defining and working with Bousfield localization.\nDefinition:  We say an object $Y$ in $C$ is $W$-local if for all maps $w:A\\longrightarrow B$ in $W$, the induced map\n$$-\\circ w: Map_C(B, Y)\\longrightarrow Map_C(A, Y)$$\nis a weak homotopy equivalence of mapping spaces.\nDefinition:  We say a morphism $f:A\\longrightarrow B$ in $C$ is a $W$-equivalence if the induced map\n$$-\\circ f: Map_C(B, Y)\\longrightarrow Map_C(A, Y)$$\nis a weak homotopy equivalence for all $W$-local objects $Y$ in $C$.\nDefinition:  We say an object $X$ in $C$ is $W$-acyclic if it is $W$-equivalent to a point, i.e. if the unique map $0\\longrightarrow X$ induces a weak homotopy equivalence\n$$Map_C(X,Y)\\simeq Map(0, Y)\\simeq pt$$\nfor all $W$-local objects $Y$ in $C$.\nSo, what do these three things mean? The names should give a rough indication. An object $Y$ is $W$-local if any morphism in $W$ looks like an equivalence from the viewpoint of $Y$. The $W$-equivalences are a broader collection of maps than $W$ that act in the same way as $W$ on $W$-local objects. The $W$-equivalences can be thought of as generated by $W$, and we do in fact have $$W\\subseteq \\{W-equivalences\\}.$$ Finally, the $W$-acyclic objects are the objects that are \u0026ldquo;trivial\u0026rdquo; in the eyes of $W$-local objects. So if we restrict to $W$-local objects, we should get that any $W$-equivalence is a weak homotopy equivalence, and that any $W$-acyclic object is weakly equivalent to a point.\nWe are now ready for our initial definition of Bousfield localization.\nDefinition:  Let $C$ be a topological stable model category and $W$ a collection of morphisms in $C$. A Bousfield localization of $C$ on $W$, written $L_WC$, is the same underlying category $C$ with a new model structure defined by\n the weak equivalences being the $W$-equivalences, the cofibrations being the same the fibrations being induced, i.e. they are the maps satisfying the lifting property with respect to acyclic cofibrations.  Equivalently we can use its universal property, that the Bousfield localization of $C$ is a category $L_W C$ such that for any left Quillen functor $F:C\\longrightarrow D$ whose left derived functor sends $W$ to weak equivalences in $D$, then the functor factors uniquely through $C\\longrightarrow L_WC$. We can summarize with the following diagram:\nIf we remove the word \u0026ldquo;stable\u0026rdquo; in the definition we get general Bousfield localization. We have already seen an example of this construction when constructing the stable homotopy category. In that case we had a model structure on spectra consisting of level-wise morphisms. We then considered the $\\pi_\\ast$-isomorphisms as weak equivalences instead, and kept the cofibrations the same. This means that the stable model structure on spectra is nothing more than Bousfield localization at the $\\pi_\\ast$-isomorphisms of the level-wise model structure.\nBefore we move on we quickly remark that Blousfield localizations do not always exist. There are, however, certain existence theorems, putting restrictions on the size of $W$ — like requiring it to be a set —and putting certain niceness conditions on the stable model category $C$. We won\u0026rsquo;t cover these in detail, as the main examples we are interested in — localization at homology theories in spectra — are proven to always exist, but we can look at localization \u0026ldquo;objectwise\u0026rdquo; instead.\nDefinition:  Let $X$ be an object in $C$. A morphism $l:X\\longrightarrow Y$ is a $W$-localization of $X$ if:\n the object $Y$ is $W$-local and the morphism $l$ is a $W$-equivalence.  If such a map exists, then we say $X$ has a $W$-localization, and if such maps exists for all objects in $C$ then we say $C$ has all $W$-localizations. If $C$ has all $W$-localizations, then the model category $L_WC$ exists.\nImportantly, such a localization are essentially unique, in the sense that any two $W$-localizations, $X\\longrightarrow Y$ and $X\\longrightarrow Y'$ of $X$, are isomorphic in the under category of $X$ in $HoC$. Hence we can denote \u0026ldquo;the\u0026rdquo; $W$-localization as $L_WX$. This also means that $W$-localizations are the fibrant replacements in $L_WC$.\nBefore we move on we introduce a constraint on $W$. This in order to make the discussion nicer and more relevant for later. The constraint is due to the following observation: given a stable model category $C$, then its homotopy category is triangulated. Hence, we must ask the important question. Is the localization $L_WC$ of a stable model category $C$ also stable? This is not true in general, hence the restrictions on $W.$ Since we are interested in stability, i.e. invariance under $\\Sigma$ and $\\Omega$, the restrictions we must have on $W$ are to be stable under these. Let\u0026rsquo;s be a bit more precise.\nGiven a topological stable model category $C$ we have isomorphisms of homotopy mapping spaces\n$$[\\Sigma X, Y]\\cong[X, \\Omega Y]\\cong \\Omega[X, Y].$$\nIn particular this means that any collection of morphisms $W$ has the properties that:\n $W$-equivalences are closed under $\\Sigma$, because if $Map(X, f)$ is a weak homotopy equivalence, then so is $Map(X, \\Sigma f)$; $W$-local objects are closed under $\\Omega$, because if $Map(X, w)$ is a weak homotopy equivalence, then so is $Map(\\Omega(X), w)$.  These two are satisfied by any collection in a topological stable model category, but we are missing a little bit to have full stability.\nDefinition:  Let $C$ be a topological stable model category and $W$ a collection of morphisms in $C$. We say $W$ is a stable collection if either\n $W$-local objects are closed under $\\Sigma$ $W$-equivalences are closed under $\\Omega$.  We only require one or the other as they turn out to be equivalent. These stable collections are what makes sure that the Bousfield localization of $C$ on $W$ still is a stable model category. This is important for still having triangulated homotopy categories after localization. What makes this nicer for the below discussion is that Bousfield localization of stable model categories on stable collections of maps is only dependent on the homotopy category, not the model category!\nSo then, what happens to localization in the homotopy category? In the normal stable model category, the homotopy category can be identified with the subcategory of bifibrant objects and homotopy classes of morphisms. In the new localized model structure, we have more weak equivalences, meaning we get fewer objects (or isomorphism classes of objects rather). These extra objects are precisely the $W$-local ones. This means that the homotopy category $HoL_WC$ is equivalent to the full subcategory of bifibrant $W$-local objects with homotopy classes of morphisms. The inclusion $HoL_WC\\longrightarrow HoC$ has a left adjoint $HoC\\longrightarrow HoL_WC$ that factors as\n$$HoC\\longrightarrow HoC/HoA\\longrightarrow HoL_WC$$\nwhere $HoA$ is the homotopy category of the full subcategory of $W$-acyclic objects. The latter functor is an equivalence, which means we also can think about $W$-localization as killing off all the $W$-acyclic objects. Here the quotient is the Verdier quotient, which connects Bousfield localization in the stable world to \u0026ldquo;regular old\u0026rdquo; localization of triangulated categories.\nHopefully the above discussion gives some basic insight into what a Bousfield localization is, at least in the nicer stable situation. The important takeaway is that Bousfield localization is — at least on homotopy categories — the idea of restricting to only local objects, or equivalently, killing certain trivial objects.\nWe now turn to an application of the general Bousfield localization described above, namely localization at homology theories in spectra.\nLocalization at homology We have really only covered how to construct cohomology theories from spectra, but a nice fact is that we also get homology theories from spectra. Given a spectrum $E$ we can form a homology theory $E_\\ast(-)=\\pi_\\ast(E\\wedge(-))$. This is called $E$-homology and is a homology theory on the category of spectra, not just on topological spaces. The simplest example is $\\mathbb{S}$-homology, which is just homotopy groups of spectra, or \u0026ldquo;equivalently\u0026rdquo; stable homotopy groups of topological spaces. To construct a Bousfield localization in spectra from a homology theory we need a collection of maps we want to invert. These maps are the so-called $E$-isomorphisms.\nDefinition:  A morphism of spectra $f:A\\longrightarrow B$ is said to be an $E$-isomorphism if it induces an isomorphism in $E$-homology.\nThese $E$-isomorphisms form a stable collection of maps in spectra, hence the localization we do will produce a stable model category. In the general case we constructed a bigger collection of $W$-equivalences from a collection $W$, but in the case of $E$-isomorphisms we simply get back the same collection. Thus $E$-isomorphisms are usually called $E$-equivalences instead, to remind more of the general construction. Localization at this collection of maps is called localization at the homology theory $E$. We do remark that the collection of $E$-isomorphisms do not form a set, so by the above briefly mentioned existence result, localizing at these maps cant be said to exist without any argument. But, there are actual sets of maps $I$ such that the $I$-equivalences are the $E$-isomorphisms, which means in particular that Bousfield localization at an homology theory $E$ always exists.\nIn spectra we have a nice definition of being $E$-local, due to the fact that $E$-isomorphisms are the $E$-equivalences.\nDefinition:  A spectrum $X$ is said to be $E$-local if every $E$-equivalence $f:A\\longrightarrow B$ induces a homotopy equivalence $Map(f, X):Map(B, X)\\longrightarrow Map(A, X)$ on mapping spectra.\nThis means we can finally define the localization of an object $X$ at $E$.\nDefinition:  Let $X$ be a spectrum. An $E$-localization of $X$ is a morphism $f:X\\longrightarrow L_E X$ such that $f$ is an $E$-equivalence and $L_E X$ is $E$-local.\nAs in the general case we are sort of replacing the spectrum by something that is equivalent in the eyes of $E$, but not necessarily equivalent in the broader category. If we then only consider such $E$-local things, we get a simplification of the category, with a simplified notion of equivalence, at least if we choose $E$ to give us something we can understand properly.\nThe earlier mentioned example of Bousfield localization at $\\pi_\\ast$-isomorphisms is also an example of localization at a homology theory. This is because $\\mathbb{S}$-homology is precicely homotopy groups of spectra. This means in particular (if we forget that we have restricted to only stable model categories for a second) that we get the stable model category of spectra as the localization $Sp_\\mathbb{S}$ om the level-wise model category of spectra. This means that the stable model structure is really intrinsic to the category of spectra, as the sphere spectrum is the monoidal unit.\nSo we have at least one example, but as mentioned in the introduction we are in this blog post primarily interested in another localization.\n$p$-localization For the rest of this post we fix a prime number $p$.\nThe first proper example — and for now the most important — of a Bousfield localization will be so-called $p$-localization of spectra. As we above have developed the notion of localizing spectra at homology theories, we first need to define and construct a spectrum which gives us $p$-local behaviour when localizing at it. This spectrum is called the $p$-local Moore spectrum, and is a special case of the Moore spectrum of an abelian group. We quickly look at how this spectrum is constructed.\nLet $G$ be an abelian group with free presentation\n$$0\\longrightarrow F_2\\overset{r}\\longrightarrow F_1 \\longrightarrow G\\longrightarrow 0.$$\nSuch a presentation always exists. Since $F_1$ and $F_2$ are free, we can find sets $I_1$ and $I_2$ freely generating the groups. Think of $I_1$ as the the generators of $G$ and $I_2$ as the relations on these generators. Construct a map\n$$\\bigvee_{I_2}\\mathbb{S}\\overset{\\rho}\\longrightarrow \\bigvee_{I_1}\\mathbb{S}$$\nsuch that $\\pi_0(\\rho)=r$. Such a map always exists as $[\\mathbb{S}, -]$ commutes with wedges, because wedge is the coproduct in the category of pointed topological spaces. The cofiber of the map $\\rho$ is denoted $M(G)$ and is called the Moore spectrum of $G.$\nThis is exactly the analogous construction as one does for Moore spaces, except now with spectra instead. Often the first reason we meet Moore spaces in an introductory algebraic topology course is to show that there are topological spaces with any group $G$ as its singular homology, i.e. some space $M$ such that\n$$\\widetilde{H}_i(M;\\Z) = \\begin{cases}% G, i=n \\\\% 0, i\\neq n % \\end{cases}$$\nThis is also the case for the Moore spectrum, or at least the analogous thing. Recall that reduced integral singular homology is represented by the Eilenberg-Maclane spectrum $H\\Z$. If $M(G)$ is to act as Moore spaces would we would need $\\pi_0(M(G))=G$ and $H_i(M(G);\\Z) = \\pi_i(M(G)\\wedge H\\Z)=0$ for $i\u0026gt;0$. Since spectra can have negative homotopy groups, we also should also have $\\pi_i(M(G))=0$ for $i\u0026lt;0$. All these hold for the above defined spectrum $M(G)$, making them really nice to localize at, because their localization often acts on the homotopy groups as normal algebraic localization.\nThese Moore spectra are essentially unique, in the sense that changing the free presentation results in a weakly equivalent spectrum. The assignment $G\\longmapsto M(G)$ is unfortunately not functorial, but the construction is still useful due to their localization properties.\nRecall that the $p$-local integers $\\Z_{(p)}$ is the subgroup of the rationals $\\mathbb{Q}$ where all primes except $p$ are invertible. We then get a Moore spectrum $M(\\Z_{(p)})$ called the $p$-local Moore spectrum. Localization with respect to the homology theory corresponding to $M(\\Z_{(p)})$ is called $p$-localization of spectra. This is a functor $$L_{(p)}:Sp\\longrightarrow Sp_{(p)}=: Sp_{M(\\Z_{(p)})}.$$ The category $Sp_{(p)}$, called the category of $p$-local spectra, has some really remarkable properties which we will meet in later posts. We have mentioned a few of them in the outro. In certain ways it is much easier to work with, and much easier to understand. We can also get back much of the interesting information about a spectrum $X$ by looking at all of its $p$-localizations.\nSo, what are the $M(\\Z_{(p)})$-equivalences, the $M(\\Z_{(p)})$-local objects and the $M(\\Z_{(p)})$-acyclic objects? All these three can be described nicely from the following general fact.\nGiven a spectrum $X$ and a Moore spectrum $M(G)$ for some abelian group $G$, we have a homological universal coefficient theorem, i.e. a short exact sequence\n$$0\\longrightarrow G\\otimes \\pi_\\ast X\\longrightarrow \\pi_\\ast(M(G)\\wedge X)\\longrightarrow Tor^\\Z (G, \\pi_{\\ast-1}(X))\\longrightarrow 0$$\nThe middle object is the $M(G)$-homology of $X$, $M(G)_ \\ast(X)$. So, this short exact sequence related the $M(G)$-homology of a spectrum to tensoring its homotopy groups with $G$, sometimes called the $G$-homotopy groups. The group $\\Z_{(p)}$ is torsion free, which means that $Tor^\\Z(\\Z_{(p)}, \\pi_{\\ast-1}(X)) = 0$ and consequently\n$$\\pi_\\ast (M(\\Z_{(p)})\\wedge X) \\cong \\Z_{(p)}\\otimes \\pi_\\ast(X)$$\nor in words, the $M(\\Z_{(p)})$-homology of $X$ is the homotopy groups (or $\\mathbb{S}$-homology if you like) of $X$ tensored with $\\Z_{(p)}$.\nWe can then describe the equivalences and the local and acyclic objects. Recall that a map $f:A\\longrightarrow B$ is called an $E$-equivalence if it induces an isomorphism in $E$-homology. Hence a $M(\\Z_{(p)})$-equivalence $f$ is precisely a map that induces an isomorphism\n$$f_*:\\Z_{(p)}\\otimes \\pi_\\ast(X)\\longrightarrow \\Z_{(p)}\\otimes \\pi_\\ast(Y)$$\nof the $p$-local homotopy groups. In particular, multiplication by $p$ on a spectrum $X$ — defined by $p\\cdot id_X:X\\longrightarrow X$, which is well defined as $Map(X, X)$ is an abelian group, i.e. a $\\Z$-module — is an $M(\\Z_{(p)})$-equivalence.\nA spectrum $X$ is $M(\\Z_{(p)})$-acyclic if it is $M(\\Z_{(p)})$-equivalent to a point. Since $M(\\Z_{(p)})$-equivalences are the ones inducing isomorphisms on $p$-local homotopy groups, we have that $X$ is $M(\\Z_{(p)})$-acyclic precisely when all of its $p$-local homotopy groups are trivial.\nThe last part is the $M(\\Z_{(p)})$-local objects. In order to get the simplest form they take we introduce a definition, which will be very important in later posts as well. It is also connected to a famous open problem in stable homotopy theory, which we will most likely encounter later.\nDefinition:  A Bousfield localization $L_E:Sp\\longrightarrow Sp_E$ is called smashing if $L_EX \\simeq L_E\\mathbb{S}\\wedge X$.\nWe always have a map $L_E X\\longrightarrow L_E\\mathbb{S}\\wedge X$ that is an $E$-equivalence, so a we really ask wether the object $L_E\\mathbb{S}\\wedge X$ is $E$-local. This depends crucially on the localized sphere.\nWhy do we bring this definition into the story now? Because $p$-localization is smashing. Hence all $M(\\Z_{(p)})$-local objects are of the form $M(\\Z_{(p)})(\\mathbb{S})\\wedge X$ for some spectrum $X$. We denote $M(\\Z_{(p)})(\\mathbb{S}):= \\mathbb{S}_{(p)}$ and call it the $p$-local sphere spectrum. Thus, all $p$-local objects are of the form $\\mathbb{S}_{(p)}\\wedge X$.\nThe homotopy category of $p$-local spectra, $HoSp_{(p)}$, is called the $p$-local stable homotopy category. By the earlier discussion it consists of bifibrant objects (in the stable model structure on normal spectra, see this post for the construction) on the form $\\mathbb{S}_{(p)}\\wedge X$, and homotopy classes of maps. Because $p$-localization is smashing, we can also describe the category $Sp_{(p)}$ as modules over the $p$-local sphere spectrum. This is because $\\mathbb{S}_{(p)}\\wedge X$ is an $M(\\Z_{(p)})$-module together with the fact that any module over $M(\\Z_{(p)})$ is $M(\\Z_{(p)})$-local. This is true in general for any smashing localization, i.e. if $E$-localization is smashing, then $$Sp_E \\simeq L_E(\\mathbb{S})-Mod_{Sp}.$$ This can also be seen from a really cool monad argument, that we will hopefully look at in the future.\nOutro We mentioned earlier that the category of $p$-local spectra has some advantageous properties over all spectra, but we have not yet seen what these are. We wont go through these in detail yet — they require their ow posts — but we simply mention a few. One of the nice thing about $Sp_{(p)}$ is that is nicely \u0026ldquo;splits\u0026rdquo; into layers. Studying these layers allows us much better understanding of $Sp_{(p)}$ than simply studying global behaviour. How do we get these layers? In the previous post we looked at the complex cobordism spectrum, and we can now ask ourselves: How does the $p$-local complex cobordism spectrum $MU_{(p)}$ look? It turns out that this spectrum splits into a sum of more easily understandable spectra, called Brown-Peterson spectra $BP(n)$. These are some of the first instances where we can study periodic behaviour in stable homotopy theory. From the Brown-Peterson spectra we can form even simpler spectra, called Johnson-Wilson spectra $E(n)$. Localizing the category of $p$-local spectra at $E(n)$ is called chromatic localization, and is the start of chromatic homotopy theory. The categories $Sp_{E(n)}$ are the different layers in $Sp_{(p)}$. These layers also consists of smaller pieces, $Sp_{K(n)}$, sometimes called monochromatic spectra. But here the picture stops. We can localize no further. The pieces $Sp_{K(n)}$ are the smallest bits of $Sp_{(p)}$ we can study using the localization framework. The spectra $K(n)$ are called Morava $K$-theories, and feature heavily in my phd-project. Hence we need to understand them, which we will do in a blog post soon.\nAnother nice feature (really due to the same as above) is that the $p$-local stable homotopy category has a really nice tensor triangulated structure. Given a tensor triangulated category we can create something similar to the spectrum of a ring from this category by studying certain nice subcategories. Due to the similarity with the spectrum of a ring, we also call these the (Balmer) spectrum of a tensor triangulated category. The spectrum of $HoSp_{(p)}$ is neatly described by its smallest pieces, namely $K(n)$. We will also tell this story soon, as it is really fascinating. But for now, this is it. We have described the category of $p$-local spectra, which was what we set out to do.\n","permalink":"https://torgeiraamboe.github.io/posts/2021/bousfield-localization/","summary":"Topology, particularly homotopy theory, is hard. The scenes where these kind of mathematics happen are immensely complicated; the category of topological spaces; the category of spectra. The problem is that there is simply too much information to try to capture by using simple tools that we can actually understand properly. Trying to classify topological spaces or spectra is a feat that many deem impossible, it is simply too difficult.\nSo, how can we try to fix this?","title":"Bousfield localization"},{"content":"In the next couple years I will need to understand the ins and outs of different cohomology theories and the spectra that represents them. Some of the most important of these (for my research) can be described using $MU$ — the complex cobordism spectrum. We briefly met this spectrum — or at least its cohomology theory — when we discussed formal group laws. There we explained briefly a theorem of Quillen, stating that the universal formal group law over the Lazard ring corresponds to complex cobordism cohomology. We did not cover what complex cobordism actually is, so that is the plan for this post.\nLet us again quickly describe the backdrop for why this is important. We are interested in understanding Landweber exact complex oriented cohomology theories. All these are formed by taking a product with the universal such theory, i.e. the universal complex oriented cohomology theory. This theory is precisely complex cobordism cohomology. It is universal in the sense that any complex orientation on some multiplicative cohomology theory $E$ can be realized as a map $MU\\longrightarrow E$. We will describe all this during this post, but first we need to understand what $MU$ actually is.\nStably complex manifolds We have already seen cobordisms a couple of times already, and each time it has featured as a relation between two manifolds. This relation is called the cobordism relation.\nCobordism relation:  Let $M$ and $N$ be manifolds of dimension $n$. We say they are cobordant if there is a manifold $W$ of dimension $n+1$ such that $\\partial W = M\\sqcup N$, i.e. the boundary of $W$ is the disjoint union of $M$ and $N$.\nThe name of the cobordism theory we are interested in is called complex cobordism, so due to the name one might expect that we simply consider cobordisms of complex manifolds. But as you might see, if $M$ and $N$ are complex manifolds, then they have real dimension $2n$ for some $n$. A cobordism would then have dimension $2n+1$, but then it can\u0026rsquo;t have a complex structure. We can work around this by introducing so-called stably complex structures instead. These are a simple enough generalization that allow complex-like structures in odd dimensions.\nLet $Gr_k(\\mathbb{R}^n$ denote the real $k$-Grassmannian of euclidean $n$-space, i.e. the space of all $k$-dimensional subspaces of $\\mathbb{R}^n$, and denote the limit $lim Gr_k(\\mathbb{R}) = BO(k)$. As the orthogonal group $O(k)$ is the structure group of real vector bundles and $BO(k)$ is the classifying space of $O(k)$, we get that vector bundles of dimension $k$ over a manifold $M$ is classified by maps $M\\longrightarrow BO(k)$. For complex vector bundles we would get $BU(k)$ instead, the classifying space of the unitary group. But, we want something \u0026ldquo;weaker\u0026rdquo; than complex structure, which we build from something real.\nLet $M$ be an $n$-dimensional manifold and $i:M\\longrightarrow \\mathbb{R}^{n+k}$ be an embedding into some euclidean space. By the Whitney embeddign theorem such a map always exists. The normal bundle of $M$ in $\\mathbb{R}^{n+k}$ is the orthogonal complement of the tangent bundle, i.e. all vectors that are normal to $M$. We can also generalize this to embeddings into other spaces by defining the normal bundle of an embedding $i:M\\longrightarrow N$, denoted $N(i)$ to be the quotient of the tangent bundle of $N$ by the tangent bundle of $M$. These are the objects we use to define the stable complex structures. We do see that the dimension of the normal bundle is dependent on the embedding, so this must be fixed later.\nLet $i:M\\longrightarrow \\mathbb{R}^{n+k}$ be an embedding and $N(i): E(i) \\overset{\\pi}\\longrightarrow M$ the associated $k$-dimensional normal bundle. It is classified by a map $v:M\\longrightarrow BO(k)$, which is the Gauss map. A $BU(k)$ structure on $M$ is a choice of lift of $v$ through the fibration $f:BU(k)\\longrightarrow BO(k)$. Given a $BU(k)$ structure on $M$ we get by composing the embedding with the inclusion $\\mathbb{R}^k\\hookrightarrow \\mathbb{R}^{k+1}$, an essentially unique $BU(k+1)$ structure on $M$. This means that we can define an equivalence relation on $BU(k)$ structures by defining them to be equivalent if they become equivalent in a high enough dimension. This is the idea behind the term \u0026ldquo;stable\u0026rdquo;.\nDefinition:  A stable complex structure on a manifold $M$ is an equivalence class of $BU(k)$ structures under the equivalence relation described above. A stably complex manifold is then a pair $(M, v)$ where $M$ is a compact manifold and $v$ a stable complex structure on it.\nWe see that this does not depend on having even dimension, hence we have complex-like structures for manifolds in all dimensions. This is the generalization that allows us to define complex cobordism.\nDefinition:  Let $M$ and $N$ be two stably complex manifolds of dimension $n$. We say they are complex cobordant if there is a stably complex manifold $W$ of dimension $n+1$ such that $\\partial W = M\\sqcup N$.\nHere $\\sqcup$ denotes disjoint union, hence this is just the cobordism relation on stably complex manifolds. We sometimes split the boundary $\\partial W$ into an \u0026ldquo;in-boundary\u0026rdquo; and an \u0026ldquo;out-boundary\u0026rdquo;, which is simply a way to assign a direction to the cobordism. We then write $\\partial W_+ = M$ and $\\partial W_- = N$, which intuitively means that the cobordism \u0026ldquo;goes from\u0026rdquo; $M$ to $N$. A picture might help:\nCohomology from geometry Now that we know what complex cobordisms are we need to understand how we get a cohomology theory. Recall that a cohomology theory is a functor from topological spaces to graded abelian groups satisfying the generalized Eilenberg-Steenrod axioms. We have described these before, so look at this post for a more in depth recollection. There are two ways of approaching this for complex cobordism: one geometric, and one abstract. The geometric construction only works well for manifolds, hence why we also have a more general second construction. But, as it is nice with some geometry, we also present the former.\nLet $X$ be a manifold of dimension $n$, $M$ and $N$ be stably complex manifolds of dimension $(n-k)$ together with maps $f:M\\longrightarrow X$ and $g:N\\longrightarrow X$. Furthermore we require that these maps are proper — that the inverse image of a compact subset is compact — and that that the stable normal bundles, $N(f)$ and $N(g)$, are stably complex. Such maps are called complex oriented. We say two complex oriented maps are complex cobordant if there is a complex cobordism $W$ such that $\\partial W = M\\sqcup N$ and a map $h:W\\longrightarrow X\\times I$ such that $f = h_{|(h^{-1}(X\\times {0}))}$ and $g=h_{|(h^{-1}(X\\times {1}))}$, i.e. the restriction of $h$ to the fibers over the endpoints of $I$ correspond to $f$ and $g$. This relation is an equivalence relation. Hence we define the set $MU^k(X)$ to be the set of complex oriented maps modulo the cobordism relation described. This set is in fact an abelian group under disjoint union. The assignment $X\\longmapsto MU^k(X)$ is also functorial in manifolds and satisfies the generalized Eilenberg-Steenrod axioms, hence it is a cohomology theory of manifolds. The reason we cant extend this to all topological spaces is that we are using the stable normal bundles of maps. These only makes sense for manifolds, as they are the ones with defined stable normal bundles. So, to get a cohomology theory for all topological spaces we must try something more general.\nCohomology from spectra The more general approach comes from the fact that all cohomology theories are represented by a spectrum via the Brown representability theorem. We construct a nice spectrum, denoted $MU$, that naturally arises from complex cobordism and then define a cohomology theory from this spectrum. The construction that gives us the spectrum is called the Pontrjagin-Thom construction. We will explain all the steps, but let\u0026rsquo;s first establish a guide for how we get there:\n Define the complex cobordism group Under the Pontrjagin-Thom construction this group is isomorphic to the homotopy groups of some spectrum Under Brown representability this spectrum represents a cohomology theory Profit  We might not get to stage four, but we will at least describe the three first ones. The first thing we need is the complex cobordism group. You might recall that we looked at the $h$-cobordism group of the spheres in the previous post looking at stable homotopy groups of spheres. The construction of a general cobordism group is similar, but this time we don\u0026rsquo;t restrict ourselves only to the spheres. As a set, the $n$\u0026lsquo;th complex cobordism group consists of complex cobordism classes of closed stably complex $n$-manifolds, i.e.\n$$\\Omega^{U}_n = {(M, c)}/\\sim$$\nwhere two stably complex $n$-manifolds are equivalent $(M,c_M)\\sim (N, c_N)$ if there is a complex cobordism $W$ such that $\\partial W = M\\sqcup N$, i.e. they are complex cobordant. Being complex cobordant is an equivalence relation because it is\n reflexive by the cylinder cobordism, symmetric by swapping the \u0026ldquo;in\u0026rdquo; and \u0026ldquo;out\u0026rdquo; boundaries and transitive by composition of cobordisms,  which means that $\\Omega_n^U$ is well defined as a set. The group operation is given by disjoint union, where the inverses are given by\n$$-(M, c) = (N,-c)$$\nand the identity is the empty set $\\empty$ — treated as a manifold of dimension $n$. The group is even abelian because we have $(M, c_M)\\sqcup (N, c_N) \\sim (N, c_N)\\sqcup (M, c_M)$ by a twist cobordism, often visualized as:\nWe have now completed step one, and so proceed with step two — the Pontrjagin-Thom construction. We will not cover this in high detail but simply state its pieces and parts. This is because we are merely interested in some topological spaces that show up, which will be the components of the spectrum $MU$.\nLet now $M$ be some stably complex manifold of dimension $n$. It has an embedding $i:M\\hookrightarrow \\R^{n+k}$ which gives us its normal bundle $N(i)$. By the tubular neighbourhood theorem we have a an inclusion $\\tau N(i)\\hookrightarrow \\R^{n+k}$, where $\\tau N(i)$ denotes the tubular neighbourhood of the normal bundle. Define a map $\\R^{n+k}\\longrightarrow \\tau N(i)$ that is the identity on the interior of $\\tau N(i)$ and sends everything else to a point. Hence it defines a map $\\R^{n+k}\\longrightarrow \\tau N(i)/\\partial \\tau N(i)$. This is a proper map on locally compact Hausdorff spaces, hence it induces a map on the one-point compactifications. The one point compactification of $\\R^{n+k}$ is $S^{n+k}$, and we denote the one point compactification of $\\tau N(i)/\\partial \\tau N(i)$ by $T(N(i))$. Hence we have a map.\n$$S^{n+k} \\longrightarrow T(N(i))$$\nSo, from a stably complex $n$-manifold $M$ we have produced a map from a sphere to some compact nice space. This space $T(N(i))$ is called the Thom space of $N(i)$, and is a general and functorial construction. The Thom space of a vector bundle $\\xi = (V, B, \\pi)$ is constructed as the quotient bundle of the disc-bundle (the vectors of length less than one) by its boundary (the unit length vectors), i.e. $T(V) = D(V)/S(V)$. The classifying space $BU(k)$ has a universal vector bundle $\\gamma_k = (EU(k), BU(k), \\pi)$, and thus the $k$-dimensional normal bundle $N(i)$ admits a map $N(i)\\longrightarrow \\gamma_k$. This map induces a map on Thom spaces, $T(N(i))\\longrightarrow T(\\gamma_k)$. By composing this map with the above map from $S^{n+k}$ we get a map\n$$\\phi_k:S^{n+k}\\longrightarrow T(\\gamma_k),$$\nrepresenting an element in $\\pi_{n+k}(T(\\gamma_k))$. The inclusion $i:BU(k)\\hookrightarrow BU(k+1)$ gives an isomorphism $i^\\ast\\gamma_{k+1}\\cong \\gamma_k\\oplus \\mathbb{1}$ , where $\\mathbb{1}$ is the trivial complex line bundle over $BU(k)$. The Thom space of $\\gamma_k\\oplus \\mathbb{1}$ turns out to be $\\Sigma^2 T(\\gamma_k)$. This makes sense intuitively, as $T(\\gamma_k)$ is roughly the one-point compactification of a real vector bundle, i.e. a sphere, which when suspended twice should give a sphere in two dimensions higher, which again should be a one-point compactification of a vector bundle with complex dimension increased by one. This gives us maps $\\Sigma^2 T(\\gamma_k)\\longrightarrow T(\\gamma_{k+1})$. We can then finally define $MU$.\nDefinition:  The complex cobordism spectrum $MU$ consists of topological spaces $MU_{2k} = T(\\gamma_{k})$ and $MU_{2k+1}=\\Sigma T(\\gamma_k)$. The structure maps $\\sigma_n : \\Sigma MU_n \\longrightarrow MU_{n+1}$ is given by the identity for $n=2k$ and by the above described map $\\Sigma^2 MU_{2k} \\cong \\Sigma MU_{2k+1}\\longrightarrow MU_{2k+2})$ for $n=2k+1$.\nThis is the spectrum we need to define the cohomology theory, but in the interest of completing the story and the construction we mention the famous result that the Pontrjagin-Thom construction gives us. Taking the colimit of the homotopy groups $\\pi_{n+k}(T(\\gamma_k))$, we see that we get the homotopy groups of the spectrum $MU$, i.e. $colim_k \\pi_{n+k}(T(\\gamma_k)) = \\pi_n MU$. This finally means that a complex cobordism class of a stably complex $n$-manifold, i.e. an element of the abelian group $\\Omega^U_n$, now gives through the above construction an element of the abelian group $\\pi_n MU$. The remarkable thing about this construction is the fact that this association is an isomorphism of groups. Hence we have\n$$\\Omega^U_n \\cong \\pi_nBU.$$\nThis is the so-called Pontrjagin-Thom construction and it actually holds for all $B$-cobordism theories, giving several nice isomorphisms to play with. This does then conclude the second point.\nThe third point we are luckily already familiar with, as we have covered the Brown representability theorem in an earlier post. This theorem gives us for a spectrum — in our case $MU$ — a cohomology theory $MU^\\ast(-)= [-, MU^\\ast]$, i.e. homotopy classes of maps into the spectrum. Importantly, the groups $MU^k(X)$ for some manifold $X$ agrees with the earlier geometric construction of complex cobordism classes of complex oriented maps into $X$. As we have covered this theory in detail before, we instead continue to the stuff mentioned in the introduction. The important part is that we now have a spectrum $MU$ that we know how to construct, and we know how relates to geometry.\nWhat do we know about $MU$? As $MU_{2n} = T(\\gamma_n)$ we have in particular that $MU_2 = T(\\gamma_1)$ where $\\gamma_1$ is the universal complex line bundle over $BU(1)$. The topological space $BU(1)$ is modeled by a colimit of Grassmann manifolds, $Gr_1(\\mathbb{C}^k)$, as $k$ goes to infinity. The first Grassmannians is the same as complex projective space, so $BU(1)$ is modelled by $colim_k \\mathbb{C}P^k = \\mathbb{C}P^\\infty$, the infinite complex projective space.\nThe cool thing is that the Thom space of the universal complex line bundle is homotopy equivalent to the base-space, i.e. $\\mathbb{C}P^\\infty$. The homotopy equivalence is induced by the zero-section on $\\gamma_1$. Hence we get that $MU_{2} \\simeq \\mathbb{C}P^\\infty$. By convention we have $BU(0)\\simeq pt$ and by definition: a zero dimensional vector bundle over a point is still just a point. This means that a zero dimensional vector bundle over $BU(0)$ is a trivial bundle. The Thom space of a trivial bundle of dimension $n$ is the $n$\u0026lsquo;th suspension of the base-space with a disjoint basepoint. For $n=0$ the zeroth suspension is the identity, and hence we are left with $T(\\gamma_0)=pt_+$, i.e. a point with a disjoint basepoint. Such a space is just the zero-sphere, hence we have $MU_0 = S^0$.\nSince $BU$ is given by Thom spaces of universal vector bundles, we might wonder if we can use this to construct some more structure on $MU$. The direct sum of two complex vector bundles of dimension $n$ and $m$ are classified by a map $BU(n)\\times BU(m)\\longrightarrow BU(n+m)$. For universal bundles over these we get induced maps on Thom spaces\n$$T(\\gamma_n\\oplus \\gamma_m)\\longrightarrow T(\\gamma_{n+m}),$$\nand for any vector bundles the Thom space of a sum is the wedge of the Thom spaces. Hence we get a map\n$$T(\\gamma_n)\\wedge T(\\gamma_m)\\longrightarrow T(\\gamma_{n+m})$$\nwhich induces a multiplication $MU\\times MU\\longrightarrow MU$. This means in particular that $MU$ is a multiplicative spectrum, and that complex cobordism cohomology is a multiplicative cohomology theory.\nThis multiplicative structure gives us a ring structure on $\\pi_\\ast MU \\cong MU^\\ast(pt)$. Recall that for a manifold $X$, the group $MU^n(X)$ is the complex cobordism class of complex oriented maps into $X$. If we let $X=pt$ then all maps into $X$ are complex oriented, and they are cobordant precisely when their codomains are complex cobordant. Hence the group $MU^n(pt) \\cong \\Omega^U_n$. Taking the direct sum of all these we get a ring $MU^\\ast(pt)\\cong \\Omega_\\ast^U$ called the complex cobordism ring. Milnor and Novikov showed that this ring is a polynomial ring in infinitely many variables, i.e. $\\Z[v_1, v_2, \\ldots]$ where $v_i$ has degree $2i$.\nWe have already seen a bit of multiplicative cohomology theories in the earlier post about formal group laws. In that post we looked at complex oriented cohomology theories and how to get formal group laws from them. We redo this now in the light of $MU$.\nRecall that a multiplicative cohomology theory is called complex orientable if the map\n$$E^2(\\mathbb{C}P^\\infty)\\longrightarrow E^2(S^2)$$\nis surjective. A complex orientation is then a choice of an element in the preimage of the canonical generator in $E^2(S^2)$. This generator is often called the first generalized Chern class, or the first Connor-Floyd Chern class, and will be denoted by $c^E$. From the structure maps of $MU$ — those given by $\\Sigma^2 MU_{2k}\\longrightarrow MU_{2k+2}$ — we get for $k=0$ a map\n$$i:\\Sigma^2 S^0 \\simeq S^2 \\longrightarrow \\mathbb{C}P^\\infty$$\nwhich is the inclusion map. In $MU$-cohomology this induces a map\n$$i^\\ast:MU^2(\\mathbb{C}P^\\infty)\\longrightarrow MU^2(S^2)$$\nThe group $MU^2(\\mathbb{C}P^\\infty)$ is given by $[\\mathbb{C}P^\\infty, MU_2]$ — the homotopy classes of maps into the complex cobordism spectrum — which through the homotopy equivalence between $MU_2$ and $\\mathbb{C}P^\\infty$ is isomorphic to the set $[\\mathbb{C}P^\\infty, \\mathbb{C}P^\\infty]$. The class of the identity map then corresponds to an element $c^{MU}\\in MU^2(\\mathbb{C}P^\\infty)$. This element gets sent to $t$, the canonical generator of $MU^2(S^2)$ under the induced inclusion map, i.e. $i^\\ast(c^{MU})=t$. Hence $MU$ is complex oriented, and moreover, the choice of complex orientation is completely natural and engrained into the structure of the spectrum itself. It is often called the universal complex orientation of $MU$. It is universal in the sense that for any other complex oriented cohomology theory $E^\\ast$ with complex orientation $c^E$, there is a (up to homotopy) unique map of ring spectra $u:MU\\longrightarrow E$ such that the induced map in the second cohomology of $\\mathbb{C}P^\\infty$\n$$u_\\ast:MU^2(\\mathbb{C}P^\\infty)\\longrightarrow E^2(\\mathbb{C}P^\\infty)$$\nsends the universal complex orientation $c^{MU}$ to $c^{E}$, i.e. $u_\\ast(c^{MU})=c^{E}$.\nFor any complex oriented cohomology theory $E^\\ast$ with complex orientation $c^E$, we get that the $E$-cohomology ring of $\\mathbb{C}P^\\infty$ is given by $E^\\ast(\\mathbb{C}P^\\infty)\\cong \\pi_\\ast E[[c^E]]$, i.e. the power series ring over its coefficient ring. The space $\\mathbb{C}P^\\infty$ is a H-space, with a multiplication induced from the tensor product of vector bundles. In $E$-cohomology this gives a map\n$$m^\\ast :\\pi_\\ast E[[c^E]]\\cong E^\\ast(\\mathbb{C}P^\\infty)\\longrightarrow E^\\ast(\\mathbb{C}P^\\infty\\times\\mathbb{C}P^\\infty)\\cong \\pi_\\ast E[[x,y]]$$\nwhere the image of the complex orientation $c^E$ under $m^\\ast$ is some power series $f(x, y)$. This power series is a formal group law over the ring $\\pi_\\ast E$. The essentially unique map that gives $c^E$ from $c^{MU}$, i.e. the ring spectrum map $u:MU\\longrightarrow E$, induces a map\n$$u_\\ast:MU^\\ast(\\mathbb{C}P^\\infty)\\cong \\pi_\\ast MU[[c^{MU}]]\\longrightarrow E^\\ast(\\mathbb{C}P^\\infty) \\cong \\pi_\\ast E[[c^E]]$$\nthat maps the formal group law $m^\\ast(c^{MU})$ over $\\pi_\\ast MU$ to the formal group law $m^\\ast(c^E)$ over $\\pi_\\ast E$. This means that the formal group law over the complex cobordism ring acts like a universal formal group law for complex oriented cohomology theories. One can then ask, does it act as the universal formal group law among all possible formal group laws? Or equivalently, can we get every formal group law from a cohomology theory?\nIn the earlier mentioned post describing these formal group laws we looked at a remarkable theorem by Quillen, stating that this is precisely the case. The formal group law we get from complex cobordism — the image of $c^{MU}$ under the map $m^\\ast$ — is the universal formal group law $f$ over the Lazard ring $L$, the ring that classifies formal group laws. This means in particular that we have a natural isomorphism $\\pi_\\ast MU\\cong L \\cong \\Z[v_1, v_2, \\ldots]$, and $m^\\ast(c^{MU}) \\cong f$.\nRound off I think this is enough of complex cobordism for today, but we will definitely see it again. The reason we construct it in detail is because we want to use it later to construct other important cohomology theories: Brown-Peterson cohomology, Johnson-Wilson theory and Morava K-theory. The latter is especially important for my research projects, so understanding its construction properly will probably be beneficial.\n","permalink":"https://torgeiraamboe.github.io/posts/2021/complex-cobordism-cohomology/","summary":"In the next couple years I will need to understand the ins and outs of different cohomology theories and the spectra that represents them. Some of the most important of these (for my research) can be described using $MU$ — the complex cobordism spectrum. We briefly met this spectrum — or at least its cohomology theory — when we discussed formal group laws. There we explained briefly a theorem of Quillen, stating that the universal formal group law over the Lazard ring corresponds to complex cobordism cohomology.","title":"Complex cobordism cohomology"},{"content":"In the previous post we studied some \u0026ldquo;easy\u0026rdquo; cases of homotopy groups of spheres. We focused most on the group $\\pi_3(S^2)$ and its computation from the Hopf fibration. All groups calculated last time were part of the so-called unstable range, meaning that they are not invariant under suspension. Due to the Freudenthal suspension theorem we know precicely the stable range for homotopy groups of spheres, and these are given by the stable homotopy groups. These groups are what we will look at today (and what we looked at during the second part of the talk these two blog-posts are based upon). We will compute some of the low stable homotopy groups of spheres using the socalled $J$-homomorphism. But, in order to do this calculation we must cover a plethora of interesting mathematics.\nWe have already looked at stable homotopy groups, but let\u0026rsquo;s recall the definition anyway.\nDefinition:  The $k$\u0026lsquo;th stable homotopy group of the spheres is defined as\n$$\\pi_k^S=colim_n(\\pi_{k+n}(S^n))$$\nWe know that this stabilizes in finite steps due to the Freudenthal suspension theorem.\nWhen we look at a table of the homotopy groups of spheres, we find these stable groups along the diagonals, and the stable range is below the jagged line.\nFrom the table we can see what the zero\u0026rsquo;th and the first stable homotopy groups is. We have in fact already calculated the zero\u0026rsquo;th stable homotopy group last time, namely $\\pi_0^S=\\Z$, and last year we calculated $\\pi_4(S^3) = \\Z/2$, which we now see is in the stable range. Hence we actually know two stable homotopy groups of spheres. But, how do we find some of the other ones?\nThe $J$-homomorphism If you have ever studied a table of the homotopy groups of spheres, you will maybe start to see some weak patterns, in particular some repeating behaviour. One of these repeating behaviours comes precisely from the $J$-homomorphism, which is a group homomorphism from the homotopy groups of the infinite orthogonal group to the stable homotopy groups of spheres.\nDefinition:  The space $O(n)$, called the $n$\u0026lsquo;th orthogonal group, is the set of orthogonal $n\\times n$ matrices, i.e.\n$$O(n) = \\{A\\in M(n):AA^T = I = A^TA\\}$$\nIt can also be thought of as the space of distance preserving transformations of $\\R^n$, or more relevant for us, as the symmetry group of the $(n-1)$-sphere. We are not so much interested in the group structure on $O(n)$, but merely its topological properties. It is in fact a Lie group, which in particular means it is a manifold.\nSince $O(n)$ form the symmetries of the $(n-1)$-sphere, an element $a\\in O(n)$ can be thought of as a map $a:S^{n-1}\\longrightarrow S^{n-1}$. If we now consider the $k$\u0026lsquo;th homotopy group $\\pi_k(O(n))$ we can think of an element in this group as being represented by a map\n$$S^k\\longrightarrow Map(S^{n-1}, S^{n-1})$$\nor by the Hom-Tensor adjunction a map\n$$S^k\\times S^{n-1}\\longrightarrow S^{n-1}.$$\nThere is a topological construction — called the Hopf construction — that takes a map from a product $X\\times Y\\longrightarrow Z$, and creates a map $X\\star Y\\longrightarrow \\Sigma Z$, where $X\\star Y$ is the join of $X$ and $Y$. The join of two spaces is a construction we don\u0026rsquo;t use very often, but it is a constructed from $X\\times Y\\times I$ by collapsing one end to $X$ and one end to $Y$. By \u0026ldquo;end\u0026rdquo; we mean the sets $X\\times Y\\times {0}$ and $X\\times Y\\times {1}$, i.e. at the endpoints of the interval $I$. The most used example and visual for the join of two spaces is the join of two intervals, $X=I=Y$. Then we get the following space $I\\star I$:\nLet\u0026rsquo;s try to see what happens for the spheres. To be able to draw these, we must restrict ourselves to only $S^0\\star S^0$ and $S^0\\star S^1$, but hopefully this will be instructive enough. When constructing the space $S^0\\star S^0$ we first construct $S^0\\times S^0 \\times I$. The space $S^0\\times S^0$ consists of four disjoint points\nand when we take the product with $I$ we then get four disjoint copies of $I$:\nCollapsing one side to $S^0 = \\{x_1, x_2\\}$, and the other to $S^0=\\{y_1, y_2\\}$ we get\nwhich we see we can topologically deform to $S^1$. Hence, $S^0\\star S^0 \\simeq S^1$. For $S^0\\star S^1$ we start with $S^0\\times S^1$, which is just two copies of $S^1$. Then taking the product with $I$ gives us two disjoint cylinders:\nCollapsing first one side to $S^0$ and then the other to $S^1$ we get\nwhich we see we can deform into $S^2$. This happens in general for all spheres, and we do in fact have $S^n\\star S^m \\simeq S^{n+m+1}$. So, when we apply the Hopf construction to our map $S^k\\times S^{n-1}\\longrightarrow S^{n-1}$ representing an element in $\\pi_k(O(n))$, we get a map\n$$S^{k+n}\\cong S^k\\star S^{n-1} \\longrightarrow \\Sigma S^{n-1}\\cong S^n$$\nwhich is a representative for an element in $\\pi_{k+n}(S^n)$. Sending a homotopy class of a representative in $\\pi_k(O(n))$ to the homotopy class in $\\pi_{k+n}(S^n)$ given by this construction described above gives a group homomorphism\n$$J_k:\\pi_k(O(n))\\longrightarrow \\pi_{k+n}(S^n)$$\nwhich is the so-called $J$-homomorphism. We will use this homomorphism to produce subgroups of $\\pi_k^S$, but first we need to stabilize, i.e. let $n$ go to infinity. But how do we do this with $O(n)$?\nThe infinite orthogonal group The first thing to notice is that the $(n-1)$-sphere embeds into the $n$-sphere by thinking of it as the equator. For $n=2$ this looks like the following picture:\nRecall that $O(n)$ is the symmetries of the $(n-1)$-sphere, hence if we think of the symmetries of the $(n-1)$-sphere as being the symmetries of the $n$-sphere that only acts on the equator, then we can think of $O(n)$ as a subspace of $O(n+1)$. Hence we get a nested inclusion\n$$O(1)\\subset O(2)\\subset O(3)\\subset \\cdots \\subset O(n)\\subset \\cdots \\subset O(\\infty) = \\bigcup_{n=1}^\\infty O(n)$$\nThe space at the end, $O(\\infty)$ is called the infinite orthogonal group, and it is in fact the colimit of the $n$\u0026lsquo;th orthogonal groups, just as in the sequence above. Taking colimits of the $J$-homomorphism we get homomorphisms\n$$J_k:colim_n\\pi_k(O(n))\\longrightarrow colim_n\\pi_{k+n}(S^n)$$\nWe have $colim_n\\pi_k(O(n)) \\cong \\pi_k(colim_nO(n)) \\cong \\pi_k(O(\\infty))$ and by definition $colim_n\\pi_{k+n}(S^n) = \\pi_k^S$, hence we get a homomorphism\n$$J_k: \\pi_k(O(\\infty))\\longrightarrow \\pi_k^S$$\ncalled the stable $J$-homomorphism. This is a group homomorphism from the unstable homotopy groups of the infinite orthogonal group, to the stable homotopy groups of the spheres. So why is this morphism important? We do in fact completely know the homotopy groups of $O(\\infty)$, so having this map will give us calculable information about the stable homotopy groups of the spheres!\nBott periodicity The result that tells us what the homotopy groups of $O(\\infty$) are is called Bott periodicity. As the name suggests, this is a result about the periodicity of these homotopy groups. This means that if we know the groups for small $n$, we know the groups for all $n$ due to their periodic nature. The bott periodicity result can be summarized in an very short equation:\n$$\\Omega^8 O(\\infty) \\simeq O(\\infty).$$\nIn words: The eightfold loop space of the infinite orthogonal group is again homotopy equivalent to the infinite orthogonal group. This means in particular that we have homotopy groups with a periodicity of eight (because homotopy equivalent spaces have equivalent homotopy groups, and taking loop spaces just shifts the degree), i.e.\n$$\\pi_k(O(\\infty)) \\cong \\pi_{k+8}(\\Omega^8 O(\\infty))\\cong \\pi_{k+8}(O(\\infty)).$$\nSo in order to know them all we only need to list eight of them. These eight are:\n$$\\begin{aligned}% \\pi_0(O(\\infty)) \u0026amp;\\cong \\Z/2 \\\\ % \\pi_1(O(\\infty)) \u0026amp;\\cong \\Z/2 \\\\ % \\pi_2(O(\\infty)) \u0026amp;\\cong 0 \\\\ % \\pi_3(O(\\infty)) \u0026amp;\\cong \\Z \\\\ % \\pi_4(O(\\infty)) \u0026amp;\\cong 0 \\\\ % \\pi_5(O(\\infty)) \u0026amp;\\cong 0 \\\\ % \\pi_6(O(\\infty)) \u0026amp;\\cong 0 \\\\ % \\pi_7(O(\\infty)) \u0026amp;\\cong \\Z % \\end{aligned}$$\nwhich you can remember by singing them to the tune of \u0026ldquo;Twinkle, twinkle little star\u0026rdquo;. Under the stable $J$-homomorphism these groups gets sent to subgroups of the stable homotopy groups of spheres, which means that the collection of stable homotopy groups of spheres admit an eightfold periodicity. In order to use these to actually calculate some stable homotopy groups of spheres, we need to know what these subgroups are, i.e. what the image of the $J$-homomorphism is.\nThe image of the $J$-homomorphism Luckily for us, Adams described these groups in the 60\u0026rsquo;s, using a conjectured result (called the Adams conjecture) later proved by Quillen. Hence the following theorem is usually credited to them both.\nTheorem (Adams-Quillen):  Let $k\u0026gt;0$. The image of the $J$-homomorphism, $ImJ_k$ is given by\n $0$ when $k=2,4,5,6 ,(mod,8)$ and a cyclic group or order $2$ when $k= 0,1 ,(mod, 8)$. If $k=3,7 ,(mod,8)$ then $k=4r-1$. The image $ImJ_k$ is given by a cyclic group of order equal to the denominator of $B_{2r}/4r$, where $B_{r}$ is the $r$\u0026lsquo;th Bernoulli number.  The incredible part of this theorem is of-course the last point. Somehow the Bernoulli numbers, which are more commonly found in analysis and number theory, show up in the homotopy groups of spheres. The reason they show up is linked to the reason that the Bernoulli numbers show up among diffeomorphism classes of exotic spheres, due to Milnor and Kervaire. We will get to this in a bit, but first: Due to the Bernoulli numbers being related to the Riemann zeta function $\\zeta(z)$, we can write that the image of the $J$-homomorphism for $k=4r-1$ is given by a cyclic group or order $S$, where\n$$S = \\text{denominator}(\\zeta(1-2r)/2).$$\nThis is the first — and probably the last — time the Riemann zeta function is making an appearance on this blog, so we felt an obligation to include it.\nBut, as you may have noticed, the image of the $J$-homomorphism only gives us subgroups of the stable homotopy groups of spheres. It would then be interesting to know if these subgroups are actually the entire group. So we ask, does this happen? And if it does, then when? The answer to the former is yes, and the latter is complicated\u0026hellip; Knowing if $ImJ_k$ is the entire $k$\u0026lsquo;th stable homotopy group is the same as knowing wether $\\pi_k^S/ImJ_k$ is trivial. By some mathematical magic, this quotient groups can be described by another quotient group — the quotient of the group of $h$-cobordism classes of the spheres by the subgroup of manifolds that are the boundaries of a higher dimensional paralellizable manifold. Let\u0026rsquo;s define these terms.\nRecall that we have talked a bit about cobordisms before. These give a very general and weak equivalence relation between manifolds. A cobordism between two manifolds can be thought of as being a way to deform one space into the other, except we allow the deformation to be non-continuous at finitely many discrete points. More specifically, a cobordism is another smooth manifold that has the disjoint union of the two original manifolds as its boundary.\nDefinition:  Let $M$ and $N$ be smooth $n$-manifolds. A cobordism $W:M\\longrightarrow N$ is a smooth $n+1$ dimensional manifold $W$ such that $\\partial W = M\\coprod N$. We call $W$ an $h$-cobordism if the inclusions $M\\hookrightarrow W$ and $N\\hookrightarrow W$ are both homotopy equivalences. If $M$ and $N$ are smooth manifolds such that there exists an $h$-cobordism between them, we say they are $h$-cobordant.\nAn $h$-cobordism can be visualized as something like:\nWe see that a cylinder between two manifolds is an $h$-cobordism, and we can wonder wether these are the only ones. This leads to the $h$-cobordism theorem, an infamous and important result, proved by Stephen Smale in the 60\u0026rsquo;s.\nTheorem (Smale):  Let $W:M\\longrightarrow N$ be a compact $h$-cobordism between two simply connected smooth manifolds of dimension at least $5$. Then $W$ is diffeomorphic to a cylinder $M\\times I$.\nBy Donaldson we know that this theorem does not hold for smooth manifolds of dimension $4$, but it does hold in dimension $3$, as it is equivalent to the Poincaré conjecture, proved in 2003 by Perelman. It also is trivially true in dimension $2$ and $1$. Hence the $h$-cobordism theorem holds for all $n\\neq 4$.\nSince the spheres are simply connected, we see that all manifolds that are $h$-cobordant to sphere, must itself be a sphere. The $h$-cobordisms must in some way preserve the smooth structures on these spheres, meaning that for high $n$ — where there exists exotic spheres — we can get several $h$-cobordism classes of spheres. In fact, the set of $h$-cobordism classes of $n$-spheres is equivalent to the set of smooth structures on the $n$-sphere. At least for $n\\neq 4$, as for this dimension it is an open problem whether exotic spheres exists.\nThe $h$-cobordism classes of spheres form a group under disjoint union, denoted $\\Theta_n$, and (for $n\\neq 4$) the set of smooth structures on $S^n$ form a group under connected sum. The equivalence between their sets respects these group structures, so we do in fact have a group isomorphism between the group of smooth structures on $S^n$ and $\\Theta_n$.\nBy Milnor and Kervaire we know some of the dimensions that do and do not have exotic spheres. This we now know gives us the structure of the group $\\Theta_n$. In particular we know that $\\Theta_n \\cong 0$ for $n= 1,2,3,5,6$, as these dimensions have no exotic spheres. We do also in fact know that $\\Theta_4\\cong 0$, but not due to this argument based on smooth structures on spheres.\nOk, so why do we care about these complicated — but also trivial — groups. It is because of the following injective homomorphism:\n$$\\Theta_k/bP_{k+1} \\longrightarrow \\pi_k^S/ImJ_k$$\nHere $bP_{k+1}$ is the cyclic subgroup of spheres that are the boundary of a parallelizable manifold. As we are only interested in the above cases where $\\Theta_n \\cong 0$ we don\u0026rsquo;t really need to understand this subgroup. But, we will mention that this is where the Bernoulli numbers show up, namely as the order of this cyclic subgroup $bP_{k+1}$. The important part is that since the homomorphism is injective and the even more importanter part is that we know precisely when this injective group homomorphism is an isomorphism. It is an isomorphism when $k$ is an integer such that there is no $k$-manifold that has Kervaire invariant equal to $1$. If there is a manifold with Kervaire invariant one, then the image of the homomorphism is a subgroup of index $2$.\nThis blog post is already getting too long, so we will not cover the Kervaire invariant one problem in detail. We will however say that it is an invariant that measures wether a manifold can be cut up and surgically sewn together into a sphere. If such a surgery is possible then the manifold has Kervaire invariant zero, but if it is impossible it has invariant one. Finding the dimensions which have manifolds with Kervaire invariant one is an almost completely solved problem. We know there exists such manifolds in dimensions $n=2,6,14,30,62$ and possibly (still open question) in dimension $126$. Now we can finally calculate some stable homotopy groups of spheres!\nFinally some calculation We now have our tools and our results, so the only thing remaining is putting them together to form calculations on the stable homotopy groups we were after. As you might barely recall, this blog-post is about homotopy groups of spheres, even though it might not feel like it\u0026hellip; Anyway, lets start with $\\pi_1^S$.\n$$\\Large \\cdots \\pi_1^S \\cdots $$\nAs we know that $\\Theta_1 \\cong 0$ and that there is no $1$-manifold with Kervaire invariant $1$, we know that the group $\\pi_1^S/ImJ_1\\cong 0$, i.e. that the image of the $J$-homomorphism is the entire group $\\pi_1^S$. For $k = 1 ,(mod,8)$ we know that $J(\\pi_k(O(\\infty)))$ is a cyclic group of order $2$, meaning that $\\pi_1^S \\cong ImJ_1 \\cong \\Z/2.$ We did alredy know this, as we calculated $\\pi_4(S^3)$ last year which lies in the stable range, but now we have a separate proof, which is always nice to have.\n$$\\Large \\cdots \\pi_2^S \\cdots $$\nFor $k=2 ,(mod,8)$ we know that $ImJ_k =0$. Also, in dimension $2$ we have a manifold with Kervaire invariant one. This means that our injective map\n$$\\Theta_2/bP_3 \\cong 0 \\longrightarrow \\pi_2^S/ImJ_2 \\cong \\pi_2^S$$\nhas index $2$, i.e. that $\\pi_2^S$ must be a group of order $2$. Thus, $\\pi_2^S \\cong \\Z/2$.\n$$\\Large \\cdots \\pi_3^S \\cdots $$\nWe now have the interesting case that $k=3,(mod,8)$, meaning that $k=4r-1$ for $r=1$. This means that the image of the $J$-homomorphism is a cyclic group of order $\\text{denominator}(B_{2}/4)$. The second Bernoulli number $B_2$ is $1/6$, meaning that we have a cyclic group of order $6\\cdot 4=24$. The group $\\Theta_3$ is still trivial, and there is no $3$-manifold with Kervaire invariant one, meaning that we again know that $ImJ_3 \\cong \\pi_3^S$. This means that we have $\\pi_3^S \\cong \\Z/24.$ This is the first truly weird stable homotopy group in our opinion.\n$$\\Large \\cdots \\pi_4^S = \\pi_5^S \\cdots $$\nFor both these groups we have no manifolds with Kervaire invariant one, and still $\\Theta_4 \\cong \\Theta_5 \\cong 0.$ This means that the image of the $J$-homomorphisms gives the entire groups $\\pi_4^S$ and $\\pi_5^S$. But, the group $\\pi_4(O(\\infty)) \\cong 0 \\cong \\pi_5(O(\\infty))$, hence the image of the $J$-homomorphisms are trivial, which means we have $\\pi_4^S \\cong 0 \\cong \\pi_5^S$.\n$$\\Large \\cdots \\pi_6^S \\cdots $$\nThis is the last group we are going to calculate. We could have gone further, but at dimension seven we run into exotic spheres, making things more complicated.. For $k=6$ we have manifolds with Kervaire invariant one, meaning that the map\n$$\\Theta_6/bP_7 \\cong 0 \\longrightarrow \\pi_6^S/ImJ_6$$\nhas index $2$. The image of the $J$-homomorphism is trivial, because $\\pi_6(O(\\infty))\\cong 0$, hence by the same reasoning as for $\\pi_2^S$, we get $\\pi_6^S \\cong \\Z/2.$\nThis rounds up our looong post about the stable homotopy groups of the spheres. I was not this detailed in describing and defining everything in my talk (which these two twin posts are based on), but I wanted to have some proper definitions and calculations when actually putting this to the public. Calculating these groups is fun, but I think we stop here for now. Maybe some other time we will describe how we have actually just described pieces of the lowest chromatic homotopy layer of the sphere spectrum, maybe we wont\u0026hellip;\n","permalink":"https://torgeiraamboe.github.io/posts/2021/homotopy-groups-of-spheres-2/","summary":"In the previous post we studied some \u0026ldquo;easy\u0026rdquo; cases of homotopy groups of spheres. We focused most on the group $\\pi_3(S^2)$ and its computation from the Hopf fibration. All groups calculated last time were part of the so-called unstable range, meaning that they are not invariant under suspension. Due to the Freudenthal suspension theorem we know precicely the stable range for homotopy groups of spheres, and these are given by the stable homotopy groups.","title":"The homotopy groups of the spheres. Part 2"},{"content":"Recently I gave a talk about the homotopy groups of spheres, and as usual, I try to collect my thoughts on this blog before (or after) presenting. The homotopy groups of spheres have featured several times on this blog, and we have made some effort into calculating them for some small dimensions. In the talk I wanted to showcase some methods used to calculate these groups, as well as doing some of the \u0026ldquo;calculations\u0026rdquo;. We have met several of the tools before, like the long exact sequence from a fibration and the Freudenthal suspension theorem, but we will also meet some new ones, like the $J$-homomorphism and the $h$-cobordism group. These two are methods for calculating the stable homotopy groups of spheres, or at least some of their subgroups. For the low dimensional cases, these subgroups will luckily be the entire groups. Due to the length of the post I have split it into two: one covering the unstable homotopy groups, mostly focusing on the Hopf fibration, and one covering the stable groups, mostly focusing on the image of the $J$-homomorphism. Before we start we recall the definition of the homotopy groups of spheres.\nDefinition:  Let $m$\u0026lsquo;th homotopy group of the $n$\u0026lsquo;sphere is defined to be the set of homotopy classes of pointed continuous maps $S^m\\longrightarrow S^n$ , denoted $$\\pi_m(S^n)=[S^m, S^n].$$\nMotivation Before doing anything at all we should motivate why these groups are interesting to study, and why mathematicians throughout the last 120 years have spent considerable effort into trying to understand them and their related theory.\nThe main thing we want to study in homotopy theory are the sets $[Y, X]$ of homotopy classes of continuous maps between topological spaces. We can simplify a bit and consider based maps instead, as these are the ones most relevant for homotopy. Both (co)homology theory and homotopy theory can be built out from studying them on CW complexes instead of general topological spaces. These are spaces built by attaching cells of different dimensions to each other by specified attaching maps. Any topological space $X$ has a CW approximation $\\widetilde{X}$, in the sense that $\\widetilde{X}$ is a CW complex and that there is a weak homotopy equivalence $\\widetilde{X}\\longrightarrow X$. This is because the CW complexes are the cofibrant objects in the category of topological spaces with the Serre model structure, hence any topological space has a cofibrant replacement, i.e. a CW complex weakly equivalent to it. This is explained in more detail in the fibration series. Anyway.. We can build these CW complexes using categorical colimits of spheres and disks. If we allow ourselves to use more homotopical language, we can instead use just spheres and points when instead using homotopy colimits. This is because disks are contractible, and homotopy comlimits are not changed by using homotopy equivalent objects. Maps out of a homotopy colimit commute with taking homotopy classes of maps, so we can simplify studying all sets $[Y, X]$ by studying the sets of maps out of the components making up $Y$, namely spheres. Hence we can study the sets $[S^n, X]$ in order to still have a very good understanding of all homotopy classes of maps. But these are nothing less than the definition of the homotopy groups of $X$! Hence the study of homotopy theory largely relies on studying homotopy groups of spaces.\nUnfortunately, maps into a homotopy colimit does not well depend on the maps into each component, so we cant reduce this nicely into just studying the homotopy groups of spheres. So to motivate why we do that we usually say that we want to consider the homotopy groups on some nice spaces we think we understand. At least this is probably how it was motivated historically as some of the first ever examples calculated was the homotopy groups of some low dimensional spheres.\nA more modern motivation for studying homotopy groups of spheres — at least the stable ones — is that they coincide with the framed cobordism groups of manifolds by the Pontrjagin-Thom construction. Hence the homotopy groups of spheres \u0026ldquo;knows about\u0026rdquo; geometric topology and all its secrets.\nThe first examples The first example one meets is always the fundamental group of the circle, $\\pi_1(S^1)$. This can be seen to be equal to the integers $\\Z$ by defining $$S^1 = \\{z\\in \\mathbb{C} : |z|=1\\},$$ i.e. the norm one complex numbers. The fundamental group is then homotopy classes of pointed maps $S^1\\longrightarrow S^1$. One such map is defined by $z\\longmapsto z^n$ for some integer $n\\in \\Z$. This map can be thought of as winding $S^1$ around itself $n$ times. Such a map exists for any integer, at it can be shown that any map $S^1\\longrightarrow S^1$ is homotopic to one of these maps. Hence $\\pi_1(S^1)$ is in bijection with integers $n,$ i.e. $\\pi_1(S^1)\\cong \\Z$. For readers having seen some differential topology, we can also use the notion of degree to prove this. They correspond in this example, but using degrees generalizes more nicely to all dimensions. But we don\u0026rsquo;t need that as we proved in a recent post about the Freudenthal suspension theorem that we in fact have $\\pi_{i+1}(S^{i+1})\\cong \\pi_i(S^i)$, hence we now know that $\\pi_n(S^n)\\cong \\Z$ for all $n$.\nWhat about going one dimension up — to the fundamental group of the sphere, $\\pi_1(S^2)$? Intuitively, we can show that this is the trivial group by showing that any based loop on $S^2$, i.e. a pointed continuous map $S^1\\longrightarrow S^2$ representing a class in $\\pi_1(S^2)$, is contractible, i.e. homotopic to the constant map on the basepoint. We illustrate this by a drawing as a substitute for a rigorous proof:\nThis shrinking of loops to points holds in general for all spheres $S^n$ with $n\\geq 2$, hence all the higher dimensional spheres have trivial fundamental groups: $\\pi_1(S^n)\\cong 0$ for $n\\geq 2$. What one historically suspected was that the homotopy groups of the spheres were the same as the homology groups of the spheres, i.e. concentrated in their singular dimension. But, as Hopf revealed, this is not the case. Hopf found a non-trivial map (in the sense that it is not homotopic to a constant map) $\\eta:S^3\\longrightarrow S^2$, which proved the existence of non-trivial homotopy groups of spheres. We have in fact already covered this computation, as we showed that $\\pi_3(S^2)\\cong \\Z$ by using the long exact sequence of homotopy groups from a fibration. This time around I want to be more graphical, and more \u0026ldquo;true\u0026rdquo; to Hopf\u0026rsquo;s original proof. We wont be as highly detailed and rigorous of course\u0026hellip;\nThe Hopf fibration The fist thing we need to do is define the map. There are several ways to do this, but the simplest one is by thinking about $S^3$ as the unit sphere in $\\mathbb{C}^2$, i.e. the complex tuples $(z_1, z_2)$ such that $|z_1|^2+|z_2|^2 = 1$. Similarly we think of $S^2$ as the \u0026ldquo;unit sphere\u0026rdquo; in $\\mathbb{C}\\times \\mathbb{R}$, i.e. the tuples $(z, x)$ such that $|z|^2+x^2 = 1$. We can then define the Hopf fibration $\\eta$ by\n$$\\eta(z_1, z_2) = (2z_1 \\overline{z_2}, |z_1|^2-|z_2|^2)$$\nwhere $\\overline{z_2}$ denotes complex conjugation. The points in the image of this map do in fact lie on $S^2$ as we have\n$$|2z_1\\overline{z_2}|^2+(|z_2|^2-|z_2|^2)^2 = (|z_1|^2+|z_2|^2)^2 = 1.$$\nSo, how can we show — or at least motivate — that this map is not homotopic to a constant map? What Hopf did was to define an invariant, which we now call the Hopf invariant. This he showed was a homotopy invariant of a map, i.e. that all maps in a homotopy class have the same Hopf invariant. If we then show that a constant map and the Hopf fibration have different Hopf invariants, then they can\u0026rsquo;t be homotopic! This is the overall strategy. The next question is then: what is the Hopf invariant?\nLet\u0026rsquo;s study the fibers of $\\eta$. one can show that two points $(z_1, z_2)$ and $(w_1, w_2)$ on $S^3$ gets sent to the same point $(z,x)$ under $\\eta$ if and only if there is a complex number $\\alpha$ with $|\\alpha|=1$, such that $(z_1, z_2)=(\\alpha w_1, \\alpha w_2)$. Because $\\alpha$ must have unit length, they form the unit circle in the complex plane. This means that if we multiply a point on $S^3$ by a point on $S^1$ (interpreted the correct way), we still get sent to the same point on $S^2$. Another way to say this is that the fiber of a point on $S^2$ is a circle. This justifies the more classical formulation of $\\eta$:\n$$S^1\\longrightarrow S^2\\overset{\\eta}\\longrightarrow S^2.$$\nIf we now look at a circle $C$ on $S^2$ that is parallel to the equator\nthen its preimage $\\eta^{-1}(C)$ should be a torus in $S^3$. This is because we have a fiber $S^1$ for each point in $S^1$ – a circle of circles – also called a torus. We can stereographically project this torus in $S^3$ to $\\mathbb{R}^3$, giving us the normal torus that we all know and love. If we pick some point $c\\in C$, then how does the corresponding circle $\\eta^{-1}(\\{c\\})$ look inside this torus $\\eta^{-1}(C)$? These circles turn out to be Villarceau circles:\nThis means that our tori in $S^3$ are sewn together by these \u0026ldquo;diagonal\u0026rdquo; circles! If we choose two distinct points $c_1$ and $c_2$ on $C$, what can we say about their corresponding two circles $\\eta^{-1}(\\{c_1\\})$ and $\\eta^{-1}(\\{c_2\\})$? They look like this:\nOn first glance this looks just like two circles on a torus, but if we remove the torus for a moment we can recognize the two circles as forming a Hopf link!\nThis link has a non-trivial linking number $l$, namely $l=1$. This linking number is what we define to be the Hopf invariant $h$ of $\\eta$, i.e. $$h(\\eta)= l(\\eta^{-1}(\\{c_1\\}), \\eta^{-1}(\\{c_2\\}))=1.$$\nFor a general map $S^3\\longrightarrow S^2$ the preimage of a point in $S^2$ is some link (a collection of possibly knotted knots) in $S^3$. The preimage of two points is then two such links, and the Hopf invariant is the linking number of these links. Hopf\u0026rsquo;s magic was to show that this linking number is a homotopy invariant. We won\u0026rsquo;t cover this here, but this is the real meat of why the Hopf fibration is a non-trivial map. We do note that there is a more standard definition of the Hopf invariant using cohomology, but this should be equivalent. We can form a map such that its Hopf invariant is $n$ for any $n\\in \\Z$, hence the third homotopy group of the sphere, $\\pi_3(S^2)$ is in bijection with the Hopf invariants, which means that $$\\pi_3(S^2) \\cong \\Z.$$ The generator for the group is the homotopy class of the Hopf fibration, $[\\eta]$, which means that it is sort of the archetypal non-trivial map from $S^3$ to $S^2$.\nThe fact that the Hopf fibration has Hopf invariant $1$ is rather special, as this feature for maps between spheres is incredibly rare. In fact, it only happens for spheres that are the unit length vectors of a finite dimensional real division algebra, which there are only four of: $\\mathbb{R}$, $\\mathbb{C}$, $\\mathbb{H}$ and $\\mathbb{O}$. This is the result of the famous Hopf invariant one problem, solved by Adams in 1960.\nThose who have already seen images of the Hopf fibration have probably already seen the fantastic visualization video video by Niles Johnson. In the video we can clearly see the toric nature of the linked circles. One thing he shows is how preimages of different parallel circles forms nested tori, kind of like the following:\nwhich is an attempt to draw roughly the preimage of five truncated circles, like these\nGo watch the video (and Niles explanation of it) for some more excellent visualization and intuition for how the Hopf fibration works. More exploration of the Hopf fibration should probably be its own blog post, but for now this will have to do..\nPart two In another blog post we computed the fourth homotopy group of the $3$-sphere, $\\pi_4(S^3)\\cong \\Z/2$. This calculation used a wide array of techniques and side-steps, but is a nice comprehensive calculation. But, this is as far as I know how to compute properly (without handwaving so hard my hands fall off) the homotopy groups of spheres in the so-called unstable range. We can suspend the Hopf map or calculate some stuff from generalized Hopf fibrations, but I don\u0026rsquo;t think I can properly complete a calculation using these methods properly. The plan was to then leave the unstable range and move on to the $J$-homomorphism. This allows us to calculate a couple of the lower stable homotopy group of the spheres. But, I see that this post has become long enough already. We therefore split it into two parts. The next one will therefore feature only stable homotopy groups, so perhaps it is nice and natural to have a split here anyway!\n","permalink":"https://torgeiraamboe.github.io/posts/2021/homotopy-groups-of-spheres/","summary":"Recently I gave a talk about the homotopy groups of spheres, and as usual, I try to collect my thoughts on this blog before (or after) presenting. The homotopy groups of spheres have featured several times on this blog, and we have made some effort into calculating them for some small dimensions. In the talk I wanted to showcase some methods used to calculate these groups, as well as doing some of the \u0026ldquo;calculations\u0026rdquo;.","title":"The homotopy groups of the spheres. Part 1"},{"content":"A little while ago we discussed the definition of a tensor triangulated category, and in that post we mentioned an example that we didn\u0026rsquo;t explicitly define, namely the stable homotopy category. The goal for todays post is to fix this. There are many ways of defining it, and some are actually better than others. As the name suggests, the stable homotopy category is a homotopy category, which we have discussed before in the fibration series. But the question is, what is it the homotopy category of? As we remarked in the post on tensor triangulated categories, it is the homotopy category of the category of spectra, and it is here that the different approaches lie. What exactly is the category of spectra, and which spectra are we even talking about? Is it the sequential spectra? or maybe the orthogonal spectra? or perhaps the symmetric ones? maybe $S$-modules or excisive functors? All these names of course means nothing to us yet, as we haven\u0026rsquo;t properly looked at any of them. We did however meet the $\\Omega$-spectrum in an earlier post, but which of the above types does it belong to?\nWe won\u0026rsquo;t cover all the above today, and most likely never. At least not in full glorious details. When I said that some ways of constructing the stable homotopy category was better than others, what I meant was that some of the above categories of spectra comes with more nice features than the others. The category of sequential spectra — the one we are going to focus on today — is the easiest to grasp, but, it does not come equipped with a nice symmetric monoidal structure, also called tensor structure. As this is one of the two fundamental structures of a tensor triangulated category, we should perhaps be a bit worried about this. We can fix this issue by instead using what is called structured spectra, which the three other types of spectra mentioned above (orthogonal, symmetric and $S$-modules) are versions of. These come nicely equipped with a symmetric monoidal structure, but the spectra themselves are harder to define and understand, as they some equipped with certain group actions or other complicating factors.\nThe crucial fact about these different notions of spectra, is that they all come equipped with nice model structures, and to top it all off, their homotopy categories are all equivalent. This means that — from the perspective of homotopy — it does not matter which definition of a spectrum we use. This is why we focus on the simplest one today, namely the category of sequential spectra.\nSequential spectra As we have already seen when looking briefly at $\\Omega$-spectra, a spectrum should somehow be a sequence of topological spaces, all connected through certain structure maps. This is still the central idea, and we will see quickly how it related back to the $\\Omega$-spectra. As we have previously covered motivation for spectra and why they are interesting, we won\u0026rsquo;t do that here as well, so instead we just jump into the definition.\nDefinition:  A sequential spectrum $X$ is a sequence of pointed topological spaces1 ${ X_n}$ for all $n\\in \\mathbb{N}$ together with pointed continuous maps $\\sigma_n^X:\\Sigma X_n\\longrightarrow X_{n+1}$ called the structure maps. Here $\\Sigma$ denotes the reduced suspension functor on the category of pointed topological spaces, $Top_\\ast$.\nSince the functor $\\Sigma$ has a right adjoint, namely the based loop space functor $\\Omega$, we have natural isomorphisms\n$$Hom(\\Sigma X_n, X_{n+1}) \\cong Hom(X_n, \\Omega X_{n+1})$$\nfor all $n$. Hence we could alternatively define the structure maps in the sequential spectra by their adjoint maps, $\\widetilde{\\sigma} _n^X:X _n\\longrightarrow \\Omega X _{n+1}$. This is starting to look a lot like the definition we had of an $\\Omega$-spectrum last time — the only thing missing is the requirement that this adjoint structure map is a weak homotopy equivalence. So, to be precise we include the definition here as well.\nDefinition:  A sequential spectrum $X$ is called an $\\Omega$-spectrum if the adjoint structure maps $\\widetilde{\\sigma}_n^X$ are weak homotopy equivalences, meaning that they induce isomorphisms on all homotopy groups.\nLet\u0026rsquo;s see some examples. The most fundamental — and hugely important — example is the sphere spectrum $\\mathbb{S}$. This is defined by $\\mathbb{S}_n = S^n$ and the structure maps being given by the canonical homeomorphisms $\\sigma_n:\\Sigma S^n \\overset{\\simeq}\\longrightarrow S^{n+1}$. We won\u0026rsquo;t say why in this post, but the sphere spectrum acts among spectra a lot like the integers $\\mathbb{Z}$ acts among abelian groups. Stay tuned for more about this in the future as it is rather interesting! Note that the sphere spectrum is not an $\\Omega$-spectrum.\nWe see that the sphere spectrum is defined by just adding more and more suspensions, so we can generalize this construction into the class of examples called the suspension spectra. For a topological space $X$ we define its suspension spectrum, denoted $\\Sigma^\\infty X$, by letting $(\\Sigma^\\infty X)_n = \\Sigma^n X$ and defining the structure maps to be the identity.\nThe third example we have in fact already seen, namely the Eilenberg-Mac Lane spectrum. We saw this because it is the spectrum that represents singular cohomology theory through the Brown representability theorem. Given a group $G$ we define its Eilenberg-Mac Lane spectrum $HG$ by $(HG)_n= K(G, n)$, where $K(G,n)$ is the $n$\u0026lsquo;th Eilenberg-Mac Lane space of $G$. The structure maps are given as adjoint structure maps by the canonical homeomorphisms $\\widetilde{\\sigma}_n:K(G,n)\\overset{\\simeq}\\longrightarrow \\Omega K(G, n+1)$.\nOur goal is to make these sequential spectra into a category, specifically a stable model category, and to do that we need to know what maps between spectra should be.\nDefinition:  Let $X$ and $Y$ be two sequential spectra. A map $f:X\\longrightarrow Y$, sometimes also called a morphism or a homomorphism, is a collection of pointed continuous maps $f_n:X_n\\longrightarrow Y_n$ commuting with the structure maps in $X$ and $Y$, i.e.\n$$f_{n+1}\\circ \\sigma_n^X = \\sigma_n^Y\\circ f_n. $$\nWe can now define a category, $Sp$, by letting the objects be sequential spectra and the morphisms be maps of spectra.\nHomotopy groups of spectra In the introduction we said that the category of sequential spectra $Sp$ has a nice model structure, which — as we know from the fibration series — allows us to study the homotopy theory of spectra. This homotopy theory is called stable homotopy theory. In the previous post on stable homotopy groups we also met this concept of stable homotopy, and it is perhaps not clear yet why the two seemingly different notions coincide. Thus we make this clear before we delve into the model structure.\nRecall that the stable homotopy groups of a topological space $X$ is defined by\n$$\\pi_n^S(X) = colim_k \\pi_{n+k}(\\Sigma^k X).$$\nBy the Freudenthal suspension theorem this colimit actually exists. To make sense of the connection to sequential spectra we must define homotopy groups of spectra.\nDefinition:  Let $X = {X_n}$ be a sequential spectrum. We define its $n$'th homotopy group to be\n$$\\pi_n(X) = colim_k \\pi_{n+k}(X_k)$$\nNow this is starting to look similar. Recall that we have an assignment that takes a topological space and gives us a spectrum, namely the suspension spectrum. We immediately see that the homotopy groups of a suspension spectrum coincides with the stable homotopy groups of the topological space at its base, i.e.\n$$\\pi_n(\\Sigma^\\infty X) = \\pi_n^S(X)$$\nwhich justifies the naming. As an example we see that the homotopy groups of the sphere spectrum gives us the stable homotopy groups of the spheres, i.e.\n$$\\pi_n(\\mathbb{S}) = \\pi_n^S(S_0)$$\nAnother example is the homotopy groups of the Eilenberg-Mac Lane spectrum of some group $G$. As we maybe expect, we get just one homotopy group, namely the zeroth one.\n$$\\pi_n(HG) = \\begin{cases} G, n=0 \\\\ 0, n\\neq 0 \\end{cases}$$\nThis is because the Eilenberg-Mac Lane spaces are defined by their unique homotopy group. We see that the homotopy groups of spectra then generalize the stable homotopy groups of topological spaces, which is just what we want. We are after all interested in stable behaviour, and we are trying to stop using topological spaces and instead use spectra.\nThe stable model structure As we have covered model categories earlier we wont do that again here. But, we are interested in a particularly nice type of model category, namely a so-called stable model category. This we must define as we have not yet seen these.\nDefinition:  A model category $C$ is said to be stable if it has a zero-object $0$, i.e. the initial and terminal object in $C$ is the the same object, and if the induced suspension functor $\\Sigma: HoC\\longrightarrow HoC$ is an equivalence.\nIn a general model category the suspension is defined to be the following homotopy pushout\nIn order to define a model structure on $Sp$ we need to define three classes of maps: weak equivalences, fibrations and cofibrations. The natural first thing to attempt is to use the model structure on topological spaces. There we already have a nice model structure, called the Serre model structure. Since sequential spectra are built from topological spaces we can try to define a model structure on spectra by using the model structure on their building blocks, for example letting a weak equivalence of spectra be a map $w:X\\longrightarrow Y$ such that at each level $w_n:X_n\\longrightarrow Y_n$ the map of topological spaces $w_n$ is a weak equivalence, i.e. a map that induces isomorphisms on all homotopy groups. This attempt works perfectly — at least almost. We can let the weak equivalences be the \u0026ldquo;level-wise\u0026rdquo; weak equivalences and the fibrations be the \u0026ldquo;level-wise\u0026rdquo; fibrations, but we need to fix the cofibrations a bit. We could of course just let them be induced by the two other classes — as being the maps that have the left lifting property with respect to acyclic fibrations — but describing them explicitly will help us when constructing the stable model structure. It is also nicer to know what they are explicitly.\nDefinition:  We say a map $c:X\\longrightarrow Y$ between two sequential spectra $X$ and $Y$ is a level-wise cofibration if the map $c_0:X_0\\longrightarrow Y_0$ and the maps\n$$X_{n+1}\\coprod_{\\Sigma X_n} \\Sigma Y_n \\longrightarrow Y_{n+1}$$\nare relative cell retracts, i.e. cofibrations in the Serre model structure on topological spaces. The above maps are the maps we get from the pushout inside the commuting squares defining a map between sequential spectra. Maybe easier to see graphically\nwhere $P$ is the pushout $X_{n+1}\\coprod_{\\Sigma X_n} \\Sigma Y_n$\nThe collections of level-wise weak equivalences, level-wise fibrations and level-wise cofibrations form a model structure on $Sp$ creatively called the level-wise model structure. But, this is not the model structure we want, as it does not make $Sp$ into a stable model category. This means we have to alter it a bit. The precise general method for doing this is called Bousfield localization, and it is a topic we will come back to soon. This is a process for adding more weak equivalences, keeping the cofibrations the same, and thus loosing some of the fibrations. For this post however, we just define each class and call it a day.\nWe wanted to incorporate the notion of stable homotopy and this will create the new weak equivalences. We also want our fibrant objects to be the $\\Omega$-spectra, so this will determine the fibrations. Let\u0026rsquo;s define each class.\nWeak equivalences: The weak equivalences in the stable model structure on $Sp$ are often called the stable weak equivalences to distinguish them from the level-wise model structure briefly discussed above. We say a map of sequential spectra $w:X\\longrightarrow Y$ is a stable weak equivalence if it induces isomorphisms $\\pi_n(w):\\pi_n(X)\\longrightarrow \\pi_n(Y)$ on all homotopy groups. These are now the homotopy groups of spectra, not topological spaces. Such maps are often called $\\pi_\\ast$-isomorphisms.\nCofibrations: A map of sequential spectra $c:X\\longrightarrow Y$ is called a stable cofibration if it is a level-wise cofibration. These stay the same due to the stable model structure being a Bousfield localization of the level-wise model structure. The cofibrant objects turn out to be CW-spectra — spectra consisting of pointed CW-complexes where the structure maps are inclusions of sub-complexes.\nFibrations: We say a map $f:X\\longrightarrow Y$ between two sequential spectra $X$ and $Y$ is a stable fibration if it has the right lifting property with respect to stable acyclic weak equivalences, i.e. the maps that are level-wise cofibrations and $\\pi_\\ast$-isomorphisms. This is equivalent to defining stable fibrations to be the maps of sequential spectra that are level-wise fibrations, such that for each $n$ the map\n$$X_n\\longrightarrow Y_n \\prod_{\\Omega Y_{n+1}}\\Omega X_{n+1}$$\ninduced by $\\widetilde{\\sigma}_n^X$ (the adjoint structure maps) and $f$ is a level-wise weak equivalence, i.e. a weak homotopy equivalence. If we let $Y=pt$, then we see that this is equivalent to $X$ being an $\\Omega$-spectrum.\nWe will not prove that these three classes in fact give a stable model structure — not even just a model structure — as this result is a bit complicated. The important part for us is that the result is true, which means we have a zero object $0$, called the zero spectrum, and that the suspension functor $\\Sigma$ is an equivalence on the homotopy category. This homotopy category — obtained by localizing at the stable weak equivalences — is called the stable homotopy category,\n$$HoSp = SHC,$$\ni.e. the category in the title of this blog post. This category is very nice and is the natural place to study stable homotopy theory. By the general theory of model categories we have seen before the hom-sets in this category are equivalent to homotopy classes of maps from cofibrant objects to fibrant objects, i.e. from CW-spectra to $\\Omega$-spectra.\nThere is also a general fact that the homotopy category of a stable model category is always triangulated, hence $SHC$ is a triangulated category! The triangles come from the fiber sequences $F\\longrightarrow X\\longrightarrow Y$, which due to the stability of the model structure is the same as the cofiber sequences $X\\longrightarrow Y \\longrightarrow C$. The actual triangles are defined by\n$$X\\overset{f}\\longrightarrow Y\\longrightarrow C(f)\\longrightarrow \\Sigma X$$\nor alternatively as diagrams\nwhere both the left small square is a homotopy pushout, and the big square is a homotopy pushout — hence the right small square is as well.\nAs stated earlier, the tensor structure is more complicated, and requires the use of structured spectra. I\u0026rsquo;m not sure we will cover these, at least not for the moment, as I want to get to other things to write about described below. But, we now have a description of the stable homotopy category $SHC$ as the homotopy category of spectra, which is what we were after. This is a tensor-triangulated category as mentioned, hence why I study it under the project of tensor triangulated geometry for my PhD.\nForward On my list for the future is more stable homotopy theory. I want to describe spectra as an $\\infty$-category, describe Bousfield localization, look at the height of formal group laws, look into topological K-theory and complex cobordism, and much more. I am however building up do describing what I am researching for my PhD, and what my goals are for results.\nBut I think this is it for now.\n  When we say topological space here we mean based compactly generated weak Hausdorff space. This is to avoid point-set topological difficulties and pathological examples. Some places might require us to restrict to pointed CW-complexes, but we will still just call these topological spaces to make everything simple.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://torgeiraamboe.github.io/posts/2021/the-stable-homotopy-category/","summary":"A little while ago we discussed the definition of a tensor triangulated category, and in that post we mentioned an example that we didn\u0026rsquo;t explicitly define, namely the stable homotopy category. The goal for todays post is to fix this. There are many ways of defining it, and some are actually better than others. As the name suggests, the stable homotopy category is a homotopy category, which we have discussed before in the fibration series.","title":"The stable homotopy category"},{"content":"For the last few posts we have covered some theory surrounding cohomology theories, and today we want to do something else, namely again look at some homotopy theory. It\u0026rsquo;s been a long time since we have covered homotopy groups, but today we return once again. In particular I want to cover a theorem and its consequences — the Freudenthal suspension theorem. This is one of the central theorems in the homotopy theory of topological spaces, and is one of the more important theorems we left out from the fibration series. In fact, we actually used it, or at least almost when we said: \u0026ldquo;Hence the suspension functor should shift the degrees of the homotopy groups up by one\u0026rdquo; in this post. Today we make this precise, and look at a cool thing that happens as a consequence of this.\nThe first thing to note is that we will not cover the definition and elementary theory of homotopy groups of topological spaces, as we have already done so in the past. We assume forward that topological space means pointed CW-complex, because this is where we define things. We can then define things generally for all topological spaces through the CW-approximation theorem and adding a disjoint base point, but this is not that important for us today.\nMotivation and preliminaries There are several ways to motivate the Freudenthal suspension theorem, which is this posts main star. I have chosen the one below as it highlights some duality and some questions that doesn\u0026rsquo;t often get asked. It is not a standard motivation, and it shouldn\u0026rsquo;t be, because it comes from not the best and most correct place. Nonetheless I like it because it connects to some theory we did on this blog over a year ago. This means in particular that any reader should not use this as some rigorous motivation. Anyway\u0026hellip;\nRecall that a fiber sequence is a sequence $F\\overset{i}\\longrightarrow E\\overset{f}\\longrightarrow B$ of topological spaces $F, E, B$, where $f$ is a fibration and $i$ is the inclusion of the fiber of $f$. Such a sequence induces a long exact sequence of homotopy groups\n$$\\cdots\\to \\pi_{n+1}(B)\\to \\pi_n(F)\\to \\pi_n(E)\\to \\pi_n(B)\\to \\cdots$$\nIf we use the loop space fibration $\\Omega X\\longrightarrow PX\\longrightarrow X$ we get the exact sequence\n$$\\cdots\\to \\pi_{n+1}(X)\\to \\pi_n(\\Omega X)\\to 0\\to \\pi_n(X)\\to \\cdots$$\nbecause the path space $PX$ is contractible. This means in particular that we have isomorphisms\n$$\\pi_{n+1}(X)\\cong \\pi_n(\\Omega X)$$\nIn the post about cofibrations we uncovered the dual statement, using cohomology. But, we might wonder if we have even more \u0026ldquo;duality\u0026rdquo; or similarities, for example dual isomorphisms $\\pi_{n+1}(\\Sigma X)\\cong \\pi_n(X)$? I need to state firmly that this is not just the dual statement of the above isomorphisms. The dual statement really is that $H^{n+1}(\\Sigma X)\\cong H^n(X)$, and we can\u0026rsquo;t reason by duality inside the homotopy groups themselves. Asking for such an isomorphism would be dual to asking wether $H^{n}(\\Omega X) \\cong H^{n+1}(X)$, which is not at all true in general. That said, it is perhaps natural to still wonder.. And we will see that this wondering — this duality dream — is in fact true, at least if our space $X$ is highly connected. Let\u0026rsquo;s recap what this means.\nDefinition:  A topological space $X$ is called $k$-connected if $\\pi_i(X)=0$ for all $0\\leq i\\leq k$.\nThis generalizes the more standard notions of being connected and simply connected, as these now simply become $0$-connected and $1$-connected respectively.\nRecall that suspensions of spheres are again spheres, i.e. that $\\Sigma S^n \\simeq S^{n+1}$. If we now take a topological space $X$, this means that we have an isomorphism $[\\Sigma S^n, \\Sigma X]\\cong [S^{n+1}, \\Sigma X]$ between the sets of homotopy classes of maps. As we implicitly are working with pointed CW complexes, the set on the right is actually the $(n+1)$\u0026lsquo;st homotopy group of $\\Sigma X$. This means that we have a map\n$$\\pi_n(X) = [S^n, X]\\overset{\\Sigma}\\longrightarrow [\\Sigma S^n, \\Sigma X]\\cong [S^{n+1}, \\Sigma X] = \\pi_{n+1}(\\Sigma X)$$\ndefined by sending a homotopy class $[f]$ to the class $[\\Sigma f]$. Notice that this is exactly what we wanted, which means that the uncertain duality statement above at least makes some sense!\nThe Freudenthal suspension theorem Now all we need in order to have our dream pseudo-duality mentioned above, is that these maps are isomorphisms in the case of highly connected spaces, which is exactly what the Freudenthal suspension theorem tells us.\nTheorem (Freudenthal):  Let $X$ be a $k$-connected topological space. Then the above map $\\pi_n(X)\\longrightarrow \\pi_{n+1}(\\Sigma X)$ is an isomorphism for $n\u0026lt;2k+1$ and a surjection for $n=2k+1$.\nIn particular this means that the suspension of a space always has higher connectivity than the space itself, i.e. suspension increases connectivity. We won\u0026rsquo;t give a proof of the theorem here, as it would require to go into much other details, and this is not what we are interested in. We are interested in what we can use the theorem for.\nThe immediate thing to always look into when we discover some relation on homotopy groups is wether it can give us homotopy groups of spheres. This seems very much to be the case with the Freudenthal suspension theorem. For example $S^3$ is $2$-connected, so for $n\u0026lt;5$, say $n=4$ the theorem gives us an isomorphism\n$$\\pi_4(S^3)\\overset{\\cong}\\longrightarrow \\pi_5(S^4),$$\nwhere we have used the fact mentioned earlier that $\\Sigma S^3 \\simeq S^4$. Recall that we computed $\\pi_4(S^3)$ last year by a lot of machinery: long exact sequences, spectral sequences, the universal coefficient theorem and the Hurewicz theorem. In the end we got that $\\pi_4(S^3)\\cong \\mathbb{Z}/2$, which means that we now also know that $\\pi_5(S^4)\\cong \\mathbb{Z}/2$. This means that we have computed three non-trivial homotopy groups of spheres on this blog, not a bad feat considering their notoriety!\nAs the suspension increases connectivity, and $S^1$ is $0$-connected, this means that $S^{k+1}$ is $k$-connected. This allows us to compute $\\pi_k(S^k)$ for all $k$ by using the Freudenthal suspension theorem! From the theorem we get isomorphisms\n$$\\pi_k(S^k)\\overset{\\cong}\\longrightarrow \\pi_{k+1}(S^{k+1})$$\nfor all $k\u0026gt;0$. Since we know that $\\pi_1(S^1) \\cong \\mathbb{Z}$ we get that $\\pi_k(S^k)\\cong \\mathbb{Z}$ for all $k$. As the spheres are suspensions of lower spheres we can even state this in terms of $S^0$:\n$$\\pi_k(\\Sigma^k S^0)\\overset{\\cong}\\longrightarrow \\pi_{k+1}(\\Sigma^{k+1}S^0)$$\nNow that is interesting! We can even extend this further, as the Freudenthal suspension theorem actually gives us isomorphisms for all $n \u0026lt; 2k-1$ as $\\Sigma^k S^0$ is $(k-1)$-connected. Hence we have isomorphisms\n$$\\pi_n(\\Sigma^k S^0)\\overset{\\cong}\\longrightarrow \\pi_{n+1}(\\Sigma^{k+1}S^0)$$\nfor all $n\u0026lt;2k-1$. This is not a result that holds only for spheres. Notice that as long as we suspend a space $X$ enough times, say $\\Sigma^k X$, then it must be $(k-1)$-connected. Hence we have isomorphisms\n$$\\pi_n(\\Sigma^k X)\\overset{\\cong}\\longrightarrow \\pi_{n+1}(\\Sigma^{k+1}X)$$\nfor all $n\u0026lt;2k-1$ for all topological spaces $X$. This is often reformulated as the following: For any topological space and natural numbers $a, b$ such that $b\u0026lt;a-1$, we have an isomorphism\n$$\\pi_{a+b}(\\Sigma^a X)\\overset{\\cong}\\longrightarrow \\pi_{a+b+1}(\\Sigma^{a+1}X).$$\nThe stable homotopy groups The above isomorphism is very important for algebraic topology, as it allows us to define the notion of stable homotopy. If we fix the natural number $b$ in the description above and allow the natural number $a$ to slowly increase from say $0$, we see that the homotopy groups $\\pi_{a+b}(\\Sigma^a X)$ and $\\pi_{a+b+1}(\\Sigma^{a+1} X)$ can vary wildly — until $a$ passes the \u0026ldquo;critical value\u0026rdquo;. This critical point happens when $a\u0026gt; b+1$. For all natural numbers higher than this critical value, the groups are forever after isomorphic. This is called the \u0026ldquo;stable behaviour\u0026rdquo; of the homotopy groups, and motivates the following definition.\nDefinition:  Let $X$ be a topological space and $n\\in \\mathbb{N}$. The $n$'th stable homotopy group of $X$ is defined to be the group\n$$\\pi^S_n (X) := colim_a \\pi_{n+a}(\\Sigma^a X)$$\nwhich we know by the above discussion is equal to $\\pi_{2n+2}(\\Sigma^{n+2}X)$.\nThe name comes from the intuition, i.e. that if we apply enough suspensions, the homotopy groups will stabilize and become the stable homotopy groups. A second intuition for the name is that stable homotopy groups are stable under suspension, i.e. $\\pi^S_n(X) \\cong \\pi^S_{n+1}(\\Sigma X)$. A cool feature of stable homotopy groups is that because the spaces $\\Sigma^a X$ are all path connected, we don\u0026rsquo;t have to worry or bother about base points when working with stable homotopy groups. This is in stark contrast to normal homotopy groups, where they are important. But as we have hidden this feature of the homotopy groups in this blog post (as we said topological space would mean pointed CW-complex) this doesn\u0026rsquo;t really add anything for this post.\nSo, why is this even interesting? We saw above that the stable homotopy groups of the spheres are much better behaved than the general homotopy groups, so this is one reason we are interested in them as they are simply easier to calculate and often easier to understand. The second thing relates more to the several other posts we have had lately, namely trying to define the stable homotopy category as the homotopy category of spectra. From the fibration series we know that to create a homotopy category we need a model structure on our category. We want the homotopy category of this model category — the stable homotopy category — to be a tensor triangulated category, as we mentioned this category as an example in the post where we defined them. To make it so we need to have a so called stable model structure on it. Because, as a general fact, the homotopy category of a stable model category is always canonically triangulated. The tensor structure is a bit more involved and difficult, so we need to work up to it a bit, but very soon we will define the stable model category of spectra. This stable model structure actually requires the use of stable homotopy groups, hence also the interest in defining them here today.\nThe last reason we will mention today — there are of course many more — as for why these groups are interesting is that they give us very nice functors\n$$\\pi^S_n:CW_\\ast\\longrightarrow Ab.$$\nThese functors are so nice that they make up a reduced homology theory! When first encountering homology and homotopy one learns very quickly that these are similar, but still very different invariants. Normal homotopy does not satisfy all the Eilenberg-Steenrod axioms for a homology theory, but, now that we look at stable homotopy instead, it actually satisfies them all. This has some nice benefits, for example the theory of stable homotopy now corresponds to a spectrum. This spectrum is of course the sphere spectrum $\\mathbb{S}$, which we will meet again later.\nNext time we will hopefully be ready to define the stable homotopy category, and maybe even look at its triangulated structure. There are many interesting things to look at further into stable homotopy theory, which we absolutely will do, so stay tuned!\n","permalink":"https://torgeiraamboe.github.io/posts/2021/stable-homotopy/","summary":"For the last few posts we have covered some theory surrounding cohomology theories, and today we want to do something else, namely again look at some homotopy theory. It\u0026rsquo;s been a long time since we have covered homotopy groups, but today we return once again. In particular I want to cover a theorem and its consequences — the Freudenthal suspension theorem. This is one of the central theorems in the homotopy theory of topological spaces, and is one of the more important theorems we left out from the fibration series.","title":"Stable homotopy"},{"content":"Recently we have covered a lot of heavy topology and abstract mathematics, so today I thought we would cover something else — something maybe a bit easier to grasp. We will introduce the concept of formal group laws, and a bit on why they are interesting.\nIntroduction and definition To not just spew out the definition straight away, we look at a situation where formal group laws arise very naturally. Let $G$ be a one-dimensional commutative Lie group (Think here of the real numbers $\\mathbb{R}$ or the circle group $S^1$). This group has a continuous product, $m:G\\times G\\longrightarrow G$, which locally can be described by a real-valued function in two variables. This function has a Taylor expansion around the origin, which is a power series in two variables. Denote this power series by $F$. This power series satisfies some axioms because of the group structure we have on $G$, these axioms are identity, commutativity and associativity. In more mathematical terms this means that the following statements hold\n $F(u,0)=u=F(0,u)$ (identity) $F(u, v)=F(v, u)$ (commutativity) $F(F(u, v), w) = F(u, F(v, w))$ (associativity)  These axioms are not at all satisfied by all power series, so these are actually something interesting to look at. Coincidentally, such power series are exactly what we are going to look into today, because this is exactly what a formal group law is.\nDefinition:  A formal group law1 over a commutative ring $R$ is a power series $F\\in R[[u,v]]$ satisfying the above three axioms 1, 2 and 3.\nHence, we can think of formal group laws as a sort of generalization of the above case of the Lie-group, i.e. some power series with coefficients in a ring that behaves like if it was the product on a Lie group. In the Lie group case our ring was the field of real numbers $\\mathbb{R}$, but in general it could be any commutative ring. For the rest of the post any ring will be commutative with an identity.\nWe did not mention anything about inverses, which always are somewhere close when talking about groups or group like things. The reason we didn\u0026rsquo;t include it as an axiom is because it isn\u0026rsquo;t needed, due to the following result.\nProposition:  Let $F$ be a formal group law over a ring $R$. Then there is a power series $i$ in one variable, such that $F(u, i(u))=0$. This power series $i$ is often called the formal inverse of $F$, or sometimes just the inverse. By commutativity this is a two-sided inverse.\nLet\u0026rsquo;s see some examples.\nExamples There are of course infinitely many examples of formal group laws, but the following two are the most interesting for us. Why this is so will become clear later.\n The additive formula $F_a(u, v) = u+v$ over any ring $R$ is a formal group law, called the additive formal group law. The multiplicative formula $F_m(u,v)= u+v+u\\cdot v$ over any ring $R$ is a formal group law, called the multiplicative formal group law.  Just to mention a couple more; there are ways to associate to an elliptic curve a formal group law. This has nice use cases in number theory. As mentioned in the introduction, there are also formal group laws coming from the multiplication on Lie groups. There is also a formal group law coming from hyperbolic tangent addition, namely $F(u,v)= \\frac{u+v}{1+u\\cdot v}$. This is used in physics to add velocities in special relativity.\nA nice feature of formal group laws is that they naturally come with easily definable morphisms between them. These are defined as follows.\nDefinition:  Let $F$ and $G$ be formal group laws over a ring $R$. A morphism $f:F\\longrightarrow G$ is a power series $f$ in one variable with vanishing constant term, such that $f(F(u,v)) = G(f(u), f(v))$.\nWe can of course use this to define isomorphisms of formal group laws by being the morphisms with inverses. We also define a strict isomorphism $I$ to be an isomorphism where the coefficient of the variable is $1$, i.e. the derivative evaluated at $0$, $I'(u) = 1$. Morphisms of formal group laws are sometimes called substitutions and strict isomorphisms of formal group laws are also called coordinate changes, as this is essentially what they do.\nThese notions of morphisms allow us to understand how certain formal group laws behave, and how they are related. It can be shown that over the rational numbers every formal group law is strictly isomorphic to the additive formal group law, i.e. is the additive one up to a coordinate change. Over other rings this is not true, so most of the interesting theory comes from trying to understand formal group laws over more general rings or fields of positive characteristic. As these notions of strict isomorphisms to the additive formal group law is important, as is is the simplest formal group law we also make the following definition.\nDefinition:  Let $F$ be a formal group law over a ring $R$. A strict isomorphism $I$ from $F$ to $F_a$ — the additive formal group law — is called a logarithm of $F$, denoted $I(u) = log_F(u)$.\nThe name comes from the equation defining the morphism, as it becomes\n$$log_F(F(u,u))=log_F(u)+log_F(v),$$\nwhich looks like the addition formula for normal logarithms.\nWe remarked above that all formal group laws are strictly isomorphic to the additive one over the rationals, so there should for all formal group laws exist a logarithm. For example, the multiplicative formal group law has a logarithm given by\n$$log_F(u)=\\sum_{i\\geq 0} \\frac{(-1)^{i-1}u^i}{i}$$\nThis is a logarithm only over the rationals, not over for example the integers.\nThe abstract minded reader might see that the assignment of the set of formal group laws over a given ring $R$ is indeed a functor, denoted $FGL(-)$, from the category of commutative rings to the category of sets. The morphisms are the natural transformations of this functor to itself.\nReally no topology? Did you really think that we could leave behind the heavy topology and abstract mathematics? that we could just simply enjoy this concept for itself and not for its use in topology? In that case you were wrong\u0026hellip;\nAll fun and mockery aside, the reason I read about formal group laws was because of an incredible result by Quillen. This says in essence that the universal complex-oriented cohomology theory determines, and is determined by, the universal formal group law. A truly wild connection, but a connection we will see fits nicely into the picture of cohomology theory we have been studying recently.\nComplex-oriented cohomology theories Last time we studied reduced cohomology theories, but this additional adjective — reduced — implies the existence of \u0026ldquo;unreduced\u0026rdquo; cohomology theories, more often named simply cohomology theories. Luckily, these are roughly the \u0026ldquo;same\u0026rdquo;, in the sense that the category of reduced cohomology theories is equivalent to the category of unreduced cohomology theories. A difference to note is that we usually define unreduced cohomology theories on pairs $(X, A)$ of topological spaces, i.e. spaces $X$ with a designated subspace $A$. If we have a reduced cohomology theory $\\widetilde{E}^\\ast$ then we can define its corresponding cohomology theory by $E^\\ast(X, A) = \\widetilde{E}^\\ast(X_+\\cup Cone (A_+))$, where $X_+$ denotes taking the space $X$ and adding a disjoint base point. We have the following decomposition of a cohomology theory:\n$$E^\\ast(X) = \\widetilde{E}^\\ast(X)\\oplus E^\\ast(pt),$$\nwhich means that as long as we know what the unreduced cohomology of a point is, we can simply use the reduced theory if we wish. Above $E^\\ast(X) = E^\\ast(X, \\empty)$. To go from a cohomology theory $E^\\ast$ to a reduced one we can define $\\widetilde{E}^\\ast(X) = E^\\ast(X, \\{x\\})$, where $x$ is the base point of $X$.\nIn order to have a nice connection to formal group laws we need to add a bit of extra structure to our cohomology theories. Firstly, we say our cohomology theory is multiplicative if the spectrum that represents it2 has a multiplication that is unital and associative up to homotopy. We have not yet looked properly into spectra, and not at all into ring spectra, but this will come soon. For the moment just accept that there are spectra with multiplications, and that these give cohomology theories with multiplication. If we recall the guiding example of a cohomology theory, namely ordinary singular cohomology, then this has a cup product, so it is in fact a multiplicative cohomology theory. Its representing spectrum — the Eilenberg-Mac Lane spectrum — is the guiding example of a ring spectrum, but as said more on this in another post.\nJust to sure we are clear on notation going forward, we recall that\n $E^\\ast$ denotes a cohomology theory, $\\widetilde{E}^\\ast$ denotes the reduced cohomology theory and $E$ denotes the spectrum that represents them.  Ok, let\u0026rsquo;s add some more structure to our cohomology theories.\nDefinition:  We say that a multiplicative cohomology theory $E^\\ast$ is complex-orientable if there exists an element $t\\in E^2(\\mathbb{C}P^\\infty)$ such that under the map $g:\\widetilde{E}^2(\\mathbb{C}P^\\infty)\\longrightarrow \\widetilde{E}^2(S^2)$, $t$ gets sent to the canonical generator $\\bar t$ of $\\widetilde{E}^2(S^2)$. In other words, the map $E^2(\\mathbb{C}P^\\infty)\\longrightarrow E^2(S^2)$ must be surjective.\nA choice of such a $t$ is called a complex orientation, and a multiplicative cohomology theory together with a complex orientation is called a complex-oriented cohomology theory. Examples of such theories are ordinary singular cohomology and complex $K$-theory as well as other more exotic theories we will meet in the future, like complex cobordism cohomology and Morava $K$-theory. For ordinary singular cohomology the natural choice of $t$ is given by the first Chern class $c_1(O(1))$, where $O(1)$ is the universal line bundle. This prompts us to actually define this element $t$ for some general cohomology theory $E^\\ast$ to be named its first generalized Chern class, or the first Connor-Floyd Chern class. We denote it by $c_1^E$. More specifically we define for a line bundle $L$ over a space $X$, the first generalized Chern class to be $c^E_1(L) = f^\\ast t \\in E^2(X)$, where $f:L\\longrightarrow \\mathbb{C}P^\\infty$ is the map given by the fact that $\\mathbb{C}P^\\infty$ is the classifying space for complex line bundles.\nThe followup question is then, does this first generalized Chern class satisfy the same nice properties as the normal first Chern class? This turns out in general to not be the case. For example, the normal first Chern class satisfies the following property, that for two line bundles $L_1$ and $L_2$ we have $c_1(L_1\\otimes L_2) = c_1(L_1)+c_1(L_2)$. But, for example complex $K$-theory — represented by the spectrum $KU$ — does not have this property, it instead has the following relation:\n$$c_1^{KU}(L_1\\otimes L_2) = c_1^{KU}(L_1) + c_1^{KU}(L_2) + c_1^{KU}(L_1)\\cdot c_1^{KU}(L_2)$$\nIt is a bit more complicated, as it features some more elements than just the standard addition featured in the formula for singular cohomology theory. But, this more complicated formula should also look awfully familiar. These two formulas, for singular cohomology and for complex $K$-theory, are in fact the additive and the multiplicative formal group laws that we saw earlier! In fact we have the following theorem.\nTheorem:  Every complex-oriented cohomology theory $E^\\ast$ determines a formal group law $F$ over the ring $E^{\\ast}(pt)$, i.e. of the $E$-cohomology of a point.\nAs usual when we have one concepts that leads to another, we ask if the reverse holds, i.e. given a formal group law, does it determine a complex-oriented cohomology theory? This does not hold in general. We will not cover these now, but there are procedures for turning a formal group law $F$ over a ring $R$ into a functor that is almost a cohomology theory with coefficient ring $R$ and which determines the formal group law $F$. This almost part is removable by adding some restrictions.\nWe can now finally describe the brilliant result by Quillen.\nQuillen\u0026rsquo;s remarkable result We stated quite informally earlier what this result says, but in essence it says that the universal formal group law determines, and is determined by, the universal complex-oriented cohomology theory. We will not cover this result in detail, as it is highly technical and I don\u0026rsquo;t understand much of it yet, but we will give a rough overview at least.\nFirst, what do we mean by universal? By universal group law we mean the following: A group law $U$ over a ring $L$ is called universal if for any other formal group law $F$ over some ring $R$ there is a unique morphism $f:L\\longrightarrow R$ such that $F$ gets sent to $U$, i.e. $f_\\ast F=U$. Any formal group law $K$ is defined by a power series $\\sum c_{i,j}u^i v^j$. These coefficients must satisfy some polynomial relations making $K$ satisfy the formal group law axioms, like $c_{0,1} = 1 = c_{1, 0}$ due to the identity requirement and $c_{i,j}=c_{j,i}$ due to commutativity. We can then define a ring $L$ to be the ring generated by these coefficients, $\\mathbb{Z}[c_{i,j}]$ modulo the ideal $Q$ generated by the polynomial relations making them be a formal group law. This ring $L = \\mathbb{Z}[c_{i,j}]/Q$ is called the Lazard ring. There is in fact a formal group law $U$ over the Lazard ring, satisfying the universal property that for any commutative ring $R$, evaluation on $U$ determines a bijection $Hom(L, R)\\longrightarrow FGL(R)$, where $FGL(R)$ is the set of formal group laws over $R$, i.e. it is an universal formal group law. This means in particular that the Lazard ring corepresents the functor of formal group laws.\nThis ring seems at first glance horribly complicated, but Lazard actually proved that this is simply a polynomial ring in infinitely many generators\n$$L \\cong \\mathbb{Z}[b_1, b_2, \\ldots]$$\nwhere $b_i$ has degree $2i$. We grade this with even degrees just to make the comparison with the universal complex-oriented cohomology theory nicer, as this is graded in even degrees.\nBy universal complex-oriented cohomology theory we mean the following: A complex-oriented cohomology theory $MU$ is universal if for any multiplicative cohomology theory $E^\\ast$, represented by the spectrum $E$, there is a bijection between the set of complex orientations on $E$ and morphisms of ring spectra $MU \\longrightarrow E$. There is a cohomology theory satisfying this, namely the spectrum $MU$ — the spectrum representing complex cobordism cohomology theory. Hence this theory is the universal complex-oriented cohomology theory. We will not cover the details of this theory here, as we are saving it for later, but think roughly of this as assigning to a topological space $X$ the group of cobordism classes of manifolds over $X$. I think of it a bit like consisting of objects such as this, or at least isomorphism classes of such objects\u0026gt;\nSo, finally, the theorem of Quillen states the following.\nTheorem (Quillen):  There is a natural isomorphism from the coefficient ring $\\pi_\\ast MU$ of the complex cobordism cohomology theory $MU^\\ast$ to the Lazard ring $L$, such that the formal group law determined by $MU^\\ast$ is the universal group law over $L$.\nThis is a remarkable connection between algebra and number theory to topology and homotopy theory. Due to Milnor and Novikov it was known that the complex cobordism ring is also a polynomial ring in infinitely even degree variables, but that these are these two are isomorphic in some natural way, and that their formal group laws correspond is truly amazing. As formal group law structures are modelled on Lie groups, there is also some analysis in this picture. So this theorem really is a nice meeting point for a lot of interesting mathematics. This result is also often cited as the birth of the field of chromatic homotopy theory, which we will learn more about during the coming years. For now this is what I wanted to say about formal group laws and their relation to algebraic topology, but there is a lot more to explore further on this topic.\n  This definition is actually of a one-dimensional commutative formal group law, and this is why we required the Lie group to be both one-dimensional and commutative. But for the purposes we are going to use them for, these are the only ones we will consider.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n We have only talked about spectra representing reduced cohomology theories, but as reduced and unreduced cohomology theories are equivalent, also unreduced theories can be represented by spectra.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://torgeiraamboe.github.io/posts/2021/formal-group-laws/","summary":"Recently we have covered a lot of heavy topology and abstract mathematics, so today I thought we would cover something else — something maybe a bit easier to grasp. We will introduce the concept of formal group laws, and a bit on why they are interesting.\nIntroduction and definition To not just spew out the definition straight away, we look at a situation where formal group laws arise very naturally. Let $G$ be a one-dimensional commutative Lie group (Think here of the real numbers $\\mathbb{R}$ or the circle group $S^1$).","title":"Formal group laws"},{"content":"Even though this blog is not centered around a specific topic, we have during the last year looked more frequently at certain topics than others, such as (co)homology theory, homotopy theory and category theory. We will continue this trend today as we will try to find a solid reason for a particular object to exist. These objects were briefly mentioned in the earlier post on tensor triangulated categories, namely spectra. These objects are hugely important to the field of algebraic topology, one reason being that they are intimately linked to cohomology. This intimate connection is the study of todays blog post1.\nThis post also serves as my entry into Grant Sanderson\u0026rsquo;s (of 3 Blue 1 Brown) contest/request for more mathematical explainer content on the internet, so be on the lookout for the other participants as well!\nCohomology The language most of modern abstract mathematics use is category theory, which we have seen numerous times on this blog. Categories are important frameworks for studying all objects of a certain type at once, instead of studying them one-by-one. Categories consists of two things: objects and morphisms. The objects we are interested in today is topological spaces2, and to start off, the morphisms are continuous functions. These functions are dear to most mathematicians hearts because continuity is a central backbone feature of many areas of mathematics, and the topological spaces are what allows us to define continuity. Hence these are important to understand.\nOne hugely successful approach to understanding topological spaces is cohomology theory. We have only seen one such theory on this blog as of yet, called singular cohomology, but this is not the only one. We have seen hints of other theories, through vector bundles and through cobordisms, but we have not seen how to make cohomology out of these constructions. We won\u0026rsquo;t see this today either, but we will use the fact that there exists several different ones. For a nice list of different cohomology theories, see this wikipedia page.\nSo, as we will use these theories, lets define what we actually mean by \u0026ldquo;a cohomology theory\u0026rdquo;. Some of the readers have perhaps seen such theories defined through the Eilenberg-Steenrod axioms, but here we take a similar, but different and yet equivalent route. This is to use just based topological spaces instead of pairs of topological spaces. The approach is equivalent, as each cohomology theory for pairs determines, and is determined by, a reduced cohomology theory for pointed topological spaces.\nDefinition:  A reduced cohomology theory $\\widetilde{E}^\\ast$ is a contravariant functor from the category of pointed topological spaces, $Top_\\ast$, to the category of graded abelian groups, $Ab_\\ast$,satisfying the four axioms below. We let $X$ be a topological space and for simpler notation we write $f^\\ast = \\widetilde{E}^\\ast(f)$ where $f:X\\longrightarrow Y$ is a continuous map to some topological space $Y$.\n  If $f\\simeq g$ then $f^\\ast = g^\\ast$, i.e. homotopic maps get sent to equivalent homomorphisms\n  For any subspace $A\\subseteq X$ there is a map $\\partial^\\ast: \\widetilde{E}^\\ast(X/A)\\longrightarrow \\widetilde{E}^{\\ast+1}(A)$, called the coboundary, which is natural in $A$ and $X$.\n  For any subspace $A\\subseteq X$ there is a long exact sequence\n$$\\cdots\\overset{\\partial_{n-1}}\\longrightarrow \\widetilde{E}^n(A)\\overset{i_n}\\longrightarrow \\widetilde{E}^n(X)\\overset{q_n}\\longrightarrow \\widetilde{E}^n(X/A)\\overset{\\partial_n}\\longrightarrow \\widetilde{E}^{n+1}(A)\\overset{i_{n+1}}\\longrightarrow \\cdots$$\nwhere $i:A\\longrightarrow X$ is the inclusion map and $q:X\\longrightarrow X/A$ is the quotient map.\n  For a collection of spaces ${X_\\alpha}_{\\alpha\\in \\Alpha}$ the maps $i_\\alpha:X_\\alpha\\longrightarrow \\bigvee_{\\alpha\\in\\Alpha} X_\\alpha$ induces isomorphisms\n$$\\prod_{\\alpha\\in \\Alpha} (i_\\alpha)^\\ast : \\widetilde{E}^\\ast(\\bigvee_{\\alpha\\in\\Alpha} X_\\alpha)\\longrightarrow \\prod_{\\alpha\\in\\Alpha}\\widetilde{E}^\\ast(X_\\alpha).$$\n  If you don\u0026rsquo;t understand the details of the definition, don\u0026rsquo;t worry, it is not really important for us today. We have included it more for completion sake. The important part is that a reduced cohomology theory is a contravariant functor $\\widetilde{E}^\\ast : Top_\\ast\\longrightarrow Ab_\\ast$.\nAn important feature of reduced cohomology theories is the following result.\nTheorem:  Let $\\widetilde{E}^\\ast$ be a reduced cohomology theory. Then for any pointed space $X$ we have an isomorphism $\\widetilde{E}^\\ast(X)\\cong \\widetilde{E}^{\\ast+1}(\\Sigma X)$ induced by the coboundry map.\nThis is an important result for several reasons. The suspension functor is the central feature of stable homotopy theory, where the spectra — our objects of interest — is one of the main players. The above result states that reduced cohomology is stable, or invariant under suspension. Another reason for its importance will become clear soon, as we will use it as part of a construction regarding spectra.\nRepresentability For us today the most important feature of reduced cohomology theories is that they are representable. We don\u0026rsquo;t yet know what this means precisely, but intuitively it means that the functor behaves very much like regular morphisms in our category. Let\u0026rsquo;s see a bit more rigorously what this means.\nOne of the most important functors in the whole of category theory is the hom-functors. There are two kinds of such functors — the covariant and the contravariant. These functors take some object in the category, and sends it to the set of morphisms to, or from, that object. To make this work we need to fix an object $X$, and then define the covariant hom-functor to be $\\text{Hom}(X, -)$, i.e. the functor that takes an object $Y$ and sends it to the set $\\text{Hom}(X, Y)$ or morphisms from $X$ into $Y$. The contravariant hom-functor is defined similarly as $\\text{Hom}(-, X)$.\nAs morphisms are one of the fundamental ideas of category theory, having a functor that sends objects to morphisms is very important. This also allow us the following definition.\nDefinition:  A functor $F:\\mathcal{C}\\longrightarrow Set$ for some category $\\mathcal{C}$ is called representable if $F$ is naturally isomorphic to $\\text{Hom}(-, X)$ for some object $X$ in $\\mathcal{C}$. The object $X$ is called a representing object of $F$.\nAs mentioned, the central feature (for us today) of reduced cohomology theories is that they are representable. We have defined our reduced cohomology theories to be functors into the category of graded abelian groups, so for each degree $n$ we have a corresponding \u0026ldquo;part\u0026rdquo; of our functor, i.e. $\\widetilde{E}^n:Top_* \\longrightarrow Ab$. The fact that these functors are representable is due to the following famous theorem.\nTheorem (Brown representability):  Let $\\widetilde{E}^\\ast$ be a reduced cohomology theory. Then for each $n$, there is a pointed connected space $K_n$ such that for any pointed connected space $X$ there is a natural isomorphism $\\widetilde{E}^n(X)\\cong [X, K_n]$, where the set on the right is the set of homotopy classes of maps in the category of pointed topological spaces. The spaces $K_n$ are unique up to homotopy equivalence.\nWe don\u0026rsquo;t really need the connectedness criteria for this theorem to hold, but for the spaces $K_n$ to be unique, we do need it. The above result means that every degree of our reduced cohomology functor is representable, meaning that there is some space that represents it. We might wonder why we don\u0026rsquo;t see the hom-functor in the above theorem, but remember that the set $[X, K_n]$ is the set $\\text{Hom}(X, K_n)$ in the homotopy category of spaces, so this theorem in fact states that the functor is representable as defined previously.\nA first look at spectra When we see the result above we might wonder if we can determine a reduced cohomology theory simply by defining the collection $\\{K_n\\}_ {n\\in \\mathbb{Z}}$ of representing objects? The answer to this turns out to be no in general. There are no canonical way of defining the coboundary map we need in the reduced cohomology theory just by having the representing spaces. There is however a fix for this, but we need to introduce some requirements and extra structure on these collections of representing objects $\\{K_n\\}_{n\\in \\mathbb{Z}}$.\nLet $\\widetilde{E}^\\ast$ be a reduced cohomology theory, and let it be represented by the sequence of pointed connected spaces $\\{K_n\\}_{n\\in \\mathbb{Z}}$. Recall that this means that for any pointed connected space $X$, we have an isomorphism\n$$[X, K_n] \\cong \\widetilde{E}^n(X)$$\nRecall also from Thorem 1 that we have an isomorphism $\\widetilde{E}^n(X)\\cong \\widetilde{E}^{n+1}(\\Sigma X)$. By the $n+1$\u0026lsquo;st part of $\\widetilde{E}^\\ast$ also being representable, we know that we have an isomorphism $\\widetilde{E}^{n+1}(\\Sigma X)\\cong [\\Sigma X, K_{n+1}]$. A central fact from algebraic topology is the fact that on homotopy classes of pointed continuous functions the suspension functor $\\Sigma$ is adjoint to the loop space functor $\\Omega$. We encountered this adjunction in the fibration series when we constructed the Puppe sequence. This fact means that we have a last isomorphism $[\\Sigma X, K_{n+1}]\\cong [X, \\Omega K_{n+1}]$. Putting all these together we get\n$$[X, K_n]\\cong \\widetilde{E}^n(X)\\cong \\widetilde{E}^{n+1}(\\Sigma X)\\cong [X, \\Omega K_{n+1}],$$\nwhich are all natural in $X$. Hence we see that also $\\Omega K_{n+1}$ seems to be a representing object for $\\widetilde{E}^n$, hence there should be a homotopy equivalence $K_n\\longrightarrow \\Omega K_{n+1}$. Due to the fact that loop space functor does not preserve connectedness very well, this is not in general a representing object, so we should not in general expect there to be a homotopy equivalence $K_n\\longrightarrow \\Omega K_{n+1}$. But, we can get something almost so by letting $X=K_n$ which results in an isomorphism $[K_n, K_n]\\cong [K_n, \\Omega K_{n+1}]$. The image of the identity map $id:K_n\\longrightarrow K_n$ gives for all $n$ a map $$\\alpha_n:K_n\\longrightarrow \\Omega K_{n+1}$$ which we call the structure maps of the collection of spaces $\\{K_n\\}_ {n\\in \\mathbb{Z}}$. By naturality of the sequence of isomorphisms above, we get that a map $f:X\\longrightarrow K_n$ gets sent to the map $f\\circ \\alpha_n$ by the isomorphism. By now letting $X=S^m$ for, we see that $\\alpha_n$ must be a weak homotopy equivalence. This is actually what we need to define a spectrum, more specifically an $\\Omega$-spectrum.\nDefinition:  An $\\Omega$-spectrum (omega-spectrum) $K$ is a collection $\\{K_n\\}_ {n\\in\\mathbb{Z}}$ of pointed connected spaces, together with weak homotopy equivalences $\\alpha_n:K_n\\longrightarrow \\Omega K_{n+1}$.\nSuch an object can be visualized in the following manner, i.e. as an infinite sequence of spaces, together with structure maps to the loop space of the \u0026ldquo;shifted space\u0026rdquo;\nSo, what happens then to the earlier statement regarding the representation of the reduced cohomology theories? The failure of the spaces themselves to uniquely determine a cohomology theory is remedied by the following theorem.\nTheorem:  An $\\Omega$-spectrum $K$ determines a reduced cohomology theory $\\widetilde{E}^\\ast$ by defining $\\widetilde{E}^n(X) = [X, K_n]$. The coboundary maps are induced by the structure maps $\\alpha_n$.\nMoreover, if between two $\\Omega$-spectrums $K$ and $L$ representing two reduced cohomology theories $\\widetilde{E}^\\ast$ and $\\widetilde{F}^\\ast$ there are pointed weak homotopy equivalences $$f_n:K_n\\longrightarrow L_n$$ that respect the structure maps, then the maps $f_n$ induce a natural isomorphism of reduced cohomology theories $\\widetilde{E}^\\ast\\longrightarrow \\widetilde{F}^\\ast.$\nHence, a reduced cohomology theory $\\widetilde{E}^\\ast$ determines, and is determined by, a unique (up to weak homotopy equivalence) $\\Omega$-spectrum $K$.\nTo give an example perhaps some of he readers are familiar with, the standard reduced singular cohomology theory with coefficients in an abelian group $G$ is represented by the so called Eilenberg-Mac Lane spectrum. This consists of the Eilenberg-Mac Lane spaces of the group $G$, often denoted $K(G, n)$ for $n\\geq 0$ and of a singleton space for $n\u0026lt;0$. The structure maps come from an universal property of these spaces, which is that $\\Omega K(G, n)$ is an $(n-1)$-Eilenberg-Mac Lane space for $G$, hence $$\\Omega K(G, n)\\simeq K(G, n-1).$$ We did in fact already see this connection when we studied cofibrations and the coexact Puppe sequence in the fibration series! Then we also more explicitly developed the long exact sequence in singular cohomology from a cofibration sequence.\nSummary So, what have we done today? We took the important category of topological spaces and tried to understand its objects using reduced cohomology theories. These we discovered were representable, which allowed us to look at maps into certain spaces. This representation was not unique, meaning that given a sequence of spaces it didn\u0026rsquo;t uniquely determine a reduced cohomology theory, but if we added some extra structure, i.e. turned the sequence of spaces into an $\\Omega$-spectrum, then we had a one-to-one correspondence between reduced cohomology theories and $\\Omega$-spectra!\nHopefully next time we will look into spectra more generally, and try to construct a category containing them as objects. We will then hopefully see that we need to be a bit careful by how we go about doing this.\n  This introduction, and most of the theory in his post is inspired heavily by the book \u0026ldquo;Foundations of stable homotopy theory\u0026rdquo; by Barnes and Roitzheim.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Note that for simplicity we define topological space to mean CW-complex. This will not affect the theory (I think) as cohomology theories of topological spaces are determined by their restriction to CW-complexes.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://torgeiraamboe.github.io/posts/2021/a-first-look-at-spectra/","summary":"Even though this blog is not centered around a specific topic, we have during the last year looked more frequently at certain topics than others, such as (co)homology theory, homotopy theory and category theory. We will continue this trend today as we will try to find a solid reason for a particular object to exist. These objects were briefly mentioned in the earlier post on tensor triangulated categories, namely spectra. These objects are hugely important to the field of algebraic topology, one reason being that they are intimately linked to cohomology.","title":"A first look at spectra"},{"content":"Disclaimer Before starting I must say that this post will not be like the other ones so far on this blog. It will be much more conceptual, non-rigorous and \u0026ldquo;essay-ish\u0026rdquo;. This is because I want to try something new — writing less \u0026ldquo;mathy\u0026rdquo;. This means that you have to take the information presented with a grain of salt as it is not truly precise — take it to be more like intuition. The goal is to explain a complicated mathematical gadget using only a single analogy, and then to explain what the analogy is at the end. It might end up to be a failure, but it might also end up being interesting..\nThe travel ledger Imagine a world where we can once again travel. Hopefully, this world will come into fruition soon enough, as people are getting vaccinated and the world is slowly returning to normal. When we get to travel I think many of us will want to better reccord where we are traveling, as we now understand better how important these memories are to us. Maybe we also want to record everywhere we go, not only the longer vacations and bigger travels. To be able to record all information about all the places we go, I propose we all use a special travel ledger to write down all the information. I won\u0026rsquo;t yet tell you what mathematical object this travel ledger will be, or rather what it will represent, but we will do a reveal at the end.\nOk, what sort of information should be stored in such a ledger? And what sort of information do we actually care about? At the bare minimum we should record where we are. This means that we can record all the places we have been in a nice systematic way. If I find my self in my home town Trondheim and travel to Rome, then I can record both Trondheim and Rome in my ledger. This will turn into a list of all the places we have visited, but not anything more.\nA thing I would like to record is how I got somewhere, or rather which path I took to get from one place to another. Even though my destination is Rome, it would be interesting to know that I went through Copenhagen on my way there. A feature of this is that we can add paths. We can start in Trondheim, travel to Copenhagen and then travel from Copenhagen to Rome. If we only cared about the path we took then this combined path would not give us any new insight into our travels. Intuitively, traveling to Rome through Copenhagen is the same as traveling to Copenhagen and then traveling to Rome. Hence, in order to distinguish these two paths we need more information.\nOne thing we could add is which mode of transportation we used to get somewhere. If I were going from Trondheim to Rome, then traveling by plane or by train would make the most sense, but if I was taking a brake from work to travel around the block, I would prefer walking or bicycling as my mode of transportation. This also allows us a single characteristic of distinguishing paths between spaces. If I look in my ledger and see two trips from Trondheim to Rome, both traveling through Copenhagen I would like to remember which is which. If I have written in the ledger that one of the trips was by plane and the other by train, then I would have some way of distinguishing them, and know which trip is which. This also allows us to distinguish between going first to Copenhagen and then to Rome, and to Rome through Copenhagen, but only if we switch mode of transportation.\nAnother way to distinguish trips is by date. If I have two trips from Trondheim to Rome, I could also distinguish them by when the trips were taken. Perhaps I visited Rome once in my childhood, and again later in life? This also gives us another way of distinguishing paths, even if they both have the same mode of transportation. If I first went to Copenhagen and then to Rome, I would have spent some time in Copenhagen, which means that the trip from Copenhagen to Rome was done on another date. So this method is also good for distinguishing between connected travels and simply going through on our way somewhere.\nThese types of information is good to have in order to distinguish loinger trips, but fail a bit when trying to distinguish shorter ones. For example, if I were to take two brakes in a day, walking around the block each time, I would have no way of distinguishing them by the information recorded in the ledger thus far. So, in order to distinguish such trips we need more information.\nWe could of course add more specific time signatures, like hours and minutes, but this is not the only ones. We could add information about the temperature; about how long the trip lasted; about what we wore; about who we met on the trip; who we went with, et cetera. In theory we have infinitely many different characteristics we could write down, each of them allowing us a different view on the path we took. Maybe we met an old friend on the bus. Maybe we met a cute dog during our walk. It\u0026rsquo;s up to us to decide which information we write down in the ledger.\nThe point is, given an infinitely precise ledger, we can write down any possible travel path, and distinguish any two \u0026ldquo;almost equal\u0026rdquo; paths by using more and more refined information. This allows us to know which travel is which by 100% certainty, something that would be nice to have when we get old and look back at what we have done in our life.\nYou\u0026rsquo;re probably wondering what this has to do with mathematics at all, and why any mathematician would care about intensely recording information about traveling. So this is perhaps the time to begin explaining.\nThe analogy As you hopefully know we live on a sphere — or possibly a disk, there seem to be some disagreement in the scientific community. Either way, we live on a topological space. Points on this topological space are given by places one could visit. Traveling from one point of the earth to another traces a continuous path between the two points. If we chose a fixed starting point (the place we call home), and only look at (homotopy classes of) paths starting and ending in that point, together with the above-mentioned notion of adding paths together, we get a structure of a group. This group is the famous fundamental group of a topological space. But, this is sometimes very restricting. What if we want to move our start and end point? What if we move to another city? To be more general than looking at closed loops from a single starting point, we could instead consider all points and all (homotopy classes of) paths between them. This has the structure of a category, a nice type of category called a groupoid. Intuitively, a groupoid is a group \u0026ldquo;with more than one object\u0026rdquo;, or the \u0026ldquo;categorified\u0026rdquo; version of a group. This just means that it is a category where all morphisms are invertible, i.e. there are only objects and isomorphisms. There is a way to associate such a category to any topological space, called the fundamental groupoid.\nDefinition:  Let $X$ be a topological space. The fundamental groupoid of $X$, denoted $\\Pi_1 X$, is the category whos objects are the points of $X$ and morphisms are the homotopy classes of paths between those points.\nAs the composition of a path and its inverse path is homotopic to the constant path we get that this category is in fact a groupoid, i.e. a category where all morphisms are invertible.\nSo, this is where the analogy comes into play. This fundamental groupoid describes nicely the very first part of our traveling ledger, i.e. the places we visited and the paths we took to get there. But, what does all the additional information represent? In the definition of the fundamental groupoid a crucial part is that we chose homotopy classes of paths, otherwise we would not get a groupoid. So, what happens if we instead store the information about which paths are homotopic but also the homotopy itself? Then we get something that is almost a groupoid, we in fact get a $2$-groupoid. This is a $2$-category i.e. A category with two types of morphisms, paths and homotopies between paths.\nIn the ledger this homotopy is given by some choice of more information, for example the date. But we don\u0026rsquo;t need to stop there. The homotopies between the paths can again be homotopic, and if we want to remember this information as well we get a $3$-groupoid, and so on.\nChoosing to remember the entire infinite tower of information about how paths between points relate to each other, creates what is called an $\\infty$-groupoid.\nDefinition:  An $\\infty$-groupoid is an $\\infty$-category where all $k$-morphisms are invertible up to an invertible $(k+1)$-morphism, for all $k$.\nThis definition is a bit unsatisfactory as it requires the notion of an $\\infty$-category, which is not an easy feat to define. We could take the definition of an $\\infty$-category to mean quasi-category, which would make the $\\infty$-groupoids be the Kan-complexes, but this is not the only choice. We have in fact previously discussed these choices in another blog post, when we looked at the so-called Homotopy hypothesis. This very roughly states that any sufficiently good definition of an $\\infty$-groupoid should generate an $\\infty$-category, $\\infty grpd$, that is equivalent (as $\\infty$-categories) to the category of topological spaces.\nHow do we get an $\\infty$-groupoid from a topological space you may ask? This is exactly what the above traveling analogy does, as it takes a topological space — somewhere we can live — and gives us a ledger — some gadget that knows all paths and all infinitely nuanced similarities between paths. In more mathematical terms we take the $\\infty$-groupoid consisting of the points of the topological space as its objects, the paths as the $1$-morphisms, the homotopies of paths as the $2$-morphisms and so on. This $\\infty$-groupoid is called the fundamental $\\infty$-groupoid of the topological space and is denoted $\\Pi_\\infty X$. This construction is in fact a functor, and this functor is conjecturally the functor that induces the equivalence of categories in the Homotopy hypothesis.\nTo summarize: Any topological space, i.e. some place where theoretical humans could live, be it a sphere, a disk, a torus; or maybe higher dimensional beings living on the surface of our universe (if our universe has a surface); or small bacteria living in our bodies, could theoretically be associated a traveling ledger. As long as we require infinite precision — the option to distinguish any two paths by any choice of similarity — we get a ledger which is an $\\infty$-groupoid. This $\\infty$-groupoid happens to (conjecturally) be an equivalence of categories, meaning that if I pick up someone\u0026rsquo;s ledger, I can pinpoint where they live. If I know all places this creature have been — and could potentially be in the future — as well as every way to travel between these places up to infinite precision, I would \u0026ldquo;perfectly\u0026rdquo; be able to know the topological space this creature lives on. Thus anyone — or at least where they live — can be defined by how well traveled they are, a sentiment every hipster world traveler Instagrammer should agree with.\nThis is neat! Thinking about post-COVID traveling we have been able to investigate the litmus test that is the Homotopy hypothesis and (hopefully) presented some intuition on a complicated mathematical gadget. Who knew that documenting where we go and how to get there could solve open mathematical problems of the highest abstraction!\nDisclaimer 2 At the end I want to again point out that the entire above text is very hand wavy. I personally don\u0026rsquo;t understand all the nuances of the theory of $\\infty$-categories and the Homotopy hypothesis, so take all above with a grain of salt. It does however — in my opinion — feature as nice intuition and an interesting analogy.\n","permalink":"https://torgeiraamboe.github.io/posts/2021/traveling/","summary":"How can we use travel-journaling to study some highly abstract and highly complicated mathematical machinery? Can we get anything out of such an analogy? In this post we do just that, study the homotopy hypothesis and infinity groupoids through the lens of a travel ledger.","title":"Traveling"},{"content":"My five years of studying mathematics at NTNU has finally culminated in my master thesis, now handed in and defended. So, I thought I would explain my thesis, and a couple of the interesting pieces. Luckily we have already covered a lot of the background material, so I will rely on that as much as possible in order to not reproduce the thesis in its full details. I have a suspicion that this post will be long enough already\u0026hellip; Ok, lets begin.\nThe idea To get an idea of what the thesis is about I thought it would be smart to state, unpack and explain the abstract of the thesis. If I have made a good job making the abstract it should summarize the thesis well, and allow us to explore the relevant ideas through it. Ok, lets see the abstract:\nLuckily I was smart enough to highlight the four central themes in the thesis by italicizing them. As you can see from those four words, the thesis is about formal DG-algebras, Massey products and $A_\\infty$-algebras. These three are intimately linked, as we will hopefully discover throughout this post. In the most rough and short outline possible: DG-algebras are collections of topological information about a topological space, Massey products are higher order data in a DG-algebra and $A_\\infty$-algebras are collections of homotopical data about a topological space. Formal DG-algebras will be those without homotopical information, so a sort of easy to understand DG-algebra. It would then be handy to understand which DG-algebras are formal, and which are not. This is the goal of the thesis.\nFormal DG-algebras We have already learned a bit about DG-algebras when we learned about homotopy associativity. There we tried deform a DG-algebra through a homotopy equivalence and see whether the result was still a DG-algebra. It turned out not to be the case as the product was no longer associative, only associative up to a special homotopy, which we later discovered was part of an $A_\\infty$-structure. More on this later. Let\u0026rsquo;s start by recalling the definition.\nDefinition:  A DG-algebra is a graded vector space $A=\\bigoplus A^i$ over a field $k$ together with two operations, $d:A\\longrightarrow A$ called the differential and $m:A\\otimes A\\longrightarrow A$ called multiplication, such that\n $|d|=1, |m|=0$, meaning that $d$ has degree $1$ and $m$ has degree $0$ $d^2=0$, meaning that $d$ makes $\\bigoplus A^i$ into a cochain complex $m(m\\otimes 1) = m(1\\otimes m)$, meaning that $m$ is an associative product $dm=m(d\\otimes 1)+m(1\\otimes d)$, meaning that $d$ is a derivation with respect to $m$  This definition is precisely a structure that unifies cochain complexes and algebras.\nThe examples one should have in mind, at least for this blog post is the cochain complex of a topological space together with the cup product. Also, the cohomology ring of a topological space together with a differential $d=0$. These are of course intimately linked, as the cohomology ring is the graded vector space we get by taking the homology of the cochain complex with respect to the differential, which we turn into a DG-algebra using the induced cup product and trivial differential. One can also consider the de Rham algebra of a manifold, and many other more fancy examples.\nWe of course also have morphisms between DG-algebras, such that we get a category of DG-algebras, denoted $DGA_k$. These morphisms are precicely those who preserve both the product and the differential, i.e. structure preserving maps.\nNow, we need to understand what a formal DG-algebra is. The abstract states that a formal DG-algebra is a DG-algebra that contain the same homotopical information as its cohomology, so what does this really mean?\nIn the fibration series we learned about model categories and the homotopy category of model categories. As it turns out, $DGA_k$ admits a model structure. This is done by defining the fibrations to be the degreewise surjective morphisms, the weak equivalences to be the quasi-isomorphisms (the morphisms that induce isomorphisms in cohomology) and the cofibrations being induced from the other two. Its Quillen homotopy category, $HoDGA_k$, is then obtained by localizing at the weak equivalences. The \u0026ldquo;homotopical\u0026rdquo; information is stored in this homotopy category, meaning that a formal DG-algebra i.e. one that contains the same homotopical information as its cohomology, should be isomorphic to it in the homotopy category!\nRecall that localizing inverts the quasi-isomorphisms, so they become isomorphisms in the homotopy category. Hence, being isomorphic in the homotopy category is the same as being weakly equivalent in $DGA_k$. Two DG-algebras $A, B$ as weakly equivalent if there exists a span of quasi-isomorphisms $A\\longleftarrow C\\longrightarrow B$ between them. The reason this is not a single quasi-isomorphisms $A\\longrightarrow B$, is that quasi-isomorphisms are not in general homotopy-invertible. Thus, a single isomorphism in $HoDGA_k$ does not always come from a single quasi-isomorphism in $DGA_k$. This now defines what we mean by formal DG-algebras, so lets wrap the above discussion up in a nice package.\nDefinition:  A DG-algebra $A$ is said to be formal if there exists a DG-algebra $C$ forming a span $H(A)\\overset{p}\\longleftarrow C \\overset{q}\\longrightarrow A$, where $p$ and $q$ are quasi-isomorphisms.\nAs we will see in a bit, the cohomology algebra itself does not contain a whole lot of homotopical information, so formal DG-algebras are sort of simple objects, at least in the eyes of homotopy.\nMassey products We said that these formal DG-algebras were the ones that contained the same homotopical information as their cohomology, but we don\u0026rsquo;t yet know what this homotopical information is, or even what it can be. One example of such information is the Massey products. Intuitively, Massey products detect higher order linking inside the space — we will see a bit better what this means in an example soon. First of, lets define these. We will do this through what is called defining systems.\nDefinition:  Let $\\bar{x} = (-1)^{|x|}x$. A defining system for a set of cohomology classes $x_1, \\ldots, x_n$ in $H(A)$ is a collection ${ a_{i,j}}$ of cochains in $A$ such that\n $[a_{i-1, i}] = x_i$ $d(a_{i, j}) = \\displaystyle\\sum_{i\u0026lt;k\u0026lt;j}\\overline{a_{i, k}}a_{k, j}$  for all pairs $(i,j)\\neq (0,n)$ where $i\\leq j$.\nMassey products will then be a set where the elements are indexed by the possible defining systems we have available. More precisely we have the following definition.\nDefinition:  The Massey $n$-product of $n$ cohomology classes $x_1, \\ldots, x_n$, denoted $\\langle x_1, \\ldots, x_n\\rangle$, is defined to be the set of all $[a_{0,n}]$, where\n$$a_{0,n} = \\sum_{0\u0026lt;k\u0026lt;n}\\overline{a_{0, k}}a_{k, n}$$\nsuch that ${ a_{i,j} }$ is a defining system.\nWe see that the Massey product is not a single element, which we might suspect when we hear the word \u0026ldquo;product\u0026rdquo;, but a set of possible different \u0026ldquo;products\u0026rdquo;. Let us write out in a bit more detail how the Massey $n$-product might look for some small $n$.\n$\\mathbf{n=2}:$ Assume we have two cohomology classes $x_1$ and $x_2$ and a defining system ${a_{i,j} }$. The defining system will just be ${ a_{0,1}, a_{1,2}}$ such that $[a_{0,1}]=x_1$ and $[a_{1,2}] = x_2$. The element in the Massey product — given by the defining system — is then $[a_{0,2}]$, where $a_{0, 2} = \\overline{a_{0, 1}}a_{1, 2}$. This is just the cohomology class of the product in the DG-algebra up to a sign. Hence Massey $2$-products are already familiar as the induced product on the cohomology of a DG-algebra!\n$\\mathbf{n=3}:$ Let now $x_1, x_2, x_3$ be three cohomology classes and ${a_{i,j}}$ a defining system for them. The system will consist of $a_{0,1}$, $a_{1,2}$, $a_{2,3}$, $a_{0,2}$ and $a_{1,3}$ such that\n $[a_{0,1}] = x_1$ $[a_{1,2}] = x_2$ $[a_{2,3}] = x_3$ $d(a_{0,2}) = \\overline{a_{0,1}} a_{1,2}$ $d(a_{1,3}) = \\overline{a_{1,2}} a_{2,3}$  This means that the element in the Massey product $\\langle x_1, x_2, x_3 \\rangle$ defined by the defining system above is given by $[a_{0,3}]$, where\n$$a_{0,3} = \\overline{a_{0, 1}}a_{1, 3} + \\overline{a_{0, 2}}a_{2, 3}.$$\nFor those who have seen Massey products before, this is the same as the classical triple Massey product, just neatly packaged using the defining systems.\n$\\mathbf{n=4}:$ Let $x_1$, $x_2$, $x_3$, $x_4$ be cohomology classes and ${ a_{i,j} }$ be a defining system for them. It consists of nine elements $a_{0,1}$, $a_{1,2}$, $a_{2,3}$, $a_{3,4}$, $a_{0,2}$, $a_{1,3}$, $a_{2,4}$, $a_{0,3}$, $a_{1,4}$ such that\n $[a_{0,1}] = x_1$ $[a_{1,2}] = x_2$ $[a_{2,3}] = x_3$ $[a_{3,4}] = x_4$ $d(a_{0,2}) = \\overline{a_{0,1}} a_{1,2}$ $d(a_{1,3}) = \\overline{a_{1,2}} a_{2,3}$ $d(a_{2,4}) = \\overline{a_{2,3}} a_{3,4}$ $d(a_{0,3}) = \\overline{a_{0,1}} a_{1,3}+\\overline{a_{0,2}}a_{2,3}$ $d(a_{1,4}) = \\overline{a_{1,2}} a_{2,4}+\\overline{a_{1,3}}a_{3,4}$  This makes the element in $\\langle x_1, x_2, x_3, x_4\\rangle$ defined by the defining system ${a_{i,j}}$ equal to $[a_{0,4}]$, where\n$$a_{0,4} = \\overline{a_{0,1}}a_{1,4} + \\overline{a_{0,2}}a_{2,4} + \\overline{a_{0,3}}a_{3,4}.$$\nWhen we mention Massey products during the rest of this post we mean Massey $n$-products for $n\\geq 3$ — for precisely this reason that Massey $2$-products are just given by induced multiplication. When we say \u0026ldquo;all Massey products\u0026rdquo; we will mean all Massey $n$-products, for all $n\\geq 3$.\nThe guiding example for Massey products have and will most likely always use the Borromean rings. In order to keep this short I am brushing some detail under the rug, but the intuition should hopefully shine through. The Borroman rings is the following space:\nIn order to prove that these three rings can not be pulled apart we need the Massey $3$-product. The $1$-cochains can be represented by loops going around the three different rings, call these $x$, $y$, $z$. The cup-product of the cohomology classes of two such chains, for example $[x]$ and $[y]$, will contain their linking number as a factor, which means $[x]\\cup [y] = 0$ as any two rings are not linked. As the cup product is trivial in cohomology, it means that the product in the cochain DG-algebra is in the image of the differential, hence there exists $a$ such that $d(a) = x\\cup y$. The same goes for the other products, and we an element $b$ such that $d(b)=y\\cup z$. This means that we have a defining system $x, y, z, a, b$, which creates a non-trivial Massey $3$-product $\\langle x, y, z \\rangle$.\nSo, can we use these Massey products in order to understand formal DG-algebras? Yes, or at least kind of. Two things can be shown:\n The cohomology algebra of any DG-algebra has only \u0026ldquo;vanishing\u0026rdquo; Massey products. As the Massey products are sets — not only one element in general — being vanishing means that this set contains the zero class. This is the analogue of a product being trivial, i.e. being equal to zero. Massey products are preserved under quasi-isomorphisms. Meaning that the Massey product sets of two quasi-isomorphic DG-algebras are isomorphic.  Hence, formal DG-algebras — as they are quasi-isomorphic to their cohomology — can only contain vanishing Massey products! This means that if we find any non-vanishing Massey product in a DG-algebra, it cant be formal, i.e. Massey products are obstructions to formality.\nThis is good. We now have a test for recognizing non-formal DG-algebras, but is this also a test for recognizing the formal ones? Or reformulated, are Massey products the only obstructions to formality? If this was the case, checking all Massey products would be a definite proof that the DG-algebra is formal. Unfortunately, this is not the case. Massey products can sort of vanish for different reasons making it possible to have certain Massey products containing zero, but not being the homotopical information we would expect. So, we need some kind of new way of figuring out when the Massey products all vanish for the same reason, sometimes stated as being \u0026ldquo;uniformly vanishing\u0026rdquo;. This leads us to some homotopical structures we have already seen quite a bit of.\n$A_\\infty$-algebras In order for this post not to be as long as the thesis it self we will mostly outsource the information on $A_\\infty$-algebras to the 4 posts we have already made on them (1, 2, 3, 4, where number 4 is the most important for this post). We will however recall the definition, and connect it to the above story on homotopical information in DG-algebras.\nDefinition:  An $A_\\infty$*-algebra* $(A, m)$ is a graded vector space $A = \\bigoplus_{i\\in \\mathbb{Z}} A^i$ together with a family of morphisms $m={m_n}$ consisting of maps $m_n\\colon A^{\\otimes n}\\longrightarrow A$ of degree $2-n$ such that\n$$\\displaystyle\\sum_{r+s+t=n}(-1)^{r+st}m_{r+1+t}(id^{\\otimes r}\\otimes m_s \\otimes id^{\\otimes t}) = 0$$\nfor all $n, s\\geq 1$ and $r, t\\geq 0$.\nThese relations are often called the Stasheff identities or the coherence relations in $A$. We won\u0026rsquo;t recall them in detail here, as it would take a bit of time and is not so important for the story we are telling in this post, but to be brief: The first Stasheff identity makes $A$ into a cochain complex; the second one states that the product $m_2$ is a derivation with respect to $m_1$, i.e. it satisfies the Leibniz rule; the third states that $m_2$ is associative up to homotopy. To see some more detail on this, see post 4.\nAs with DG-algebras we also have morphisms between $A_\\infty$-algebras such that we get a category $\\infty Alg_k$. These maps are not structure preserving, but are structure preserving up to homotopy. This is because the structure itself is homotopical, so this notion of morphisms is more fitting. What these maps are precisely is not that important for us here. The important part is that there are morphisms, and even more importantly, that there are $A_\\infty$-quasi-isomorphisms. As $m_1$ acts as a differential we can define the cohomology of an $A_\\infty$-algebra in exactly the same way as usual. This ables us to again define $A_\\infty$-quasi-isomorphisms as those who induce isomorphisms in cohomology.\nThe whole reason we introduce $A_\\infty$-algebras in order to study DG-algebras is the following theorem.\nTheorem (Kadeishvili):  Let $A$ be a DG-algebra and $H(A)$ its cohomology. There exists an $A_\\infty$-structure ${m_i}$ on $H(A)$ such that $A$ and $H(A)$ are related by an $A_\\infty$-quasi-isomorphism $H(A)\\rightsquigarrow A$.\nIn post 3 about $A_\\infty$-algebras we constructed such an $A_\\infty$-structure by deforming a DG-algebra through a homotopy equivalence. The above theorem can be proven by constructing such a deformation retraction from $A$ onto $H(A)$.\nSo, this means that not every DG-algebra is formal, i.e. quasi-isomorphic to its cohomology, but, with the added $A_\\infty$-structure on $H(A)$ it is in fact $A_\\infty$-quasi-isomorphic! Intuitively, we have now created a homotopical structure on $H(A)$ that tells us all relevant homotopical information about $A$. What we mean by this is that passing from DG-algebras to $A_\\infty$-algebras does not create more homotopy types, just showcases the relevant information more explicitly, or in a different way. This means that two DG-algebras $A$ and $B$ are DG-quasi-isomorphic if and only if they are $A_\\infty$-quasi-isomorphic. For us this is really important, as we get the following result.\nTheorem:  Let $A$ be a DG-algebra and $H(A)$ its cohomology $A_\\infty$-algebra. Then $A$ is formal if and only in $m_i=0$ for all $i\\geq 3$, i.e. $H(A)$ is a DG-algebra.\nThis is the ultimate conclusion about formality in the thesis, as we have a clear cut way to figure out if something is formal or not. The operations $m_i$ are inductively defined, so all we need to do is check that these product are all trivial in order to have a definite proof that a DG-algebra $A$ is formal. This was the goal of the thesis after all, to understand formality, or equivalently, when a DG-algebra contains the same homotopical information as its cohomology.\nThese products behave a lot like the Massey products we discussed earlier, but there are some differences, i.e. the $m_n$\u0026rsquo;s does not always create elements in the Massey $n$-products, but when $m_n=0$ for all $n\\geq 3$ we know that $A$ is formal, and hence that all the Massey products are vanishing. This is the idea behind \u0026ldquo;uniform\u0026rdquo; vanishing of the Massey products, and this in fact shows (by definition almost) that having uniformely vanishing Massey products means that $A$ is formal. Intuitively it means that we can cherrypick the zero-class from all the Massey products, and that this choice neatly settles into a trivial $A_\\infty$-structure.\nFurther results and LS-cat 1 spaces So, the goal of the thesis is reached as we have a way of checking whether a DG-algebra is formal or not. But, after finishing up the above story I had a sort of uneasy feeling. I felt we did not use the Massey products enough in the end result. We abstracted away from them, and in a not entirely perfect way.. So, is there a way to more nicely fuse the Massey products, the $A_\\infty$-structure and formality? It turns out that this is possible, at least in a special case.\nTheorem:  Let $A$ be a DG-algebra. If the induced product on $H(A)$ is trivial, and all Massey products are vanishing, then $A$ is formal.\nThis result falls out as a corollary to the following paper, showing exactly the failures of the $A_\\infty$-structure on $H(A)$ to recover the Massey products. What I found interesting about this result is that it serves as another test of formality, and the last part of my thesis is spent on using the above result to show formality of certain DG-algebras in a new way. These algebras are the cochain algebras of some interesting topological spaces that I had never encountered before, called the Lusternik-Schnirelman category 1 spaces. We will not go into details about these spaces here, but to be brief they are spaces that can be covered by two contractible subsets. An example is the suspension of any path connected topological space, as it can be covered by two cones, each contractible.\nThis makes it so that the induced cup product on their cohomology algebras have trivial product — exactly what we need to use our above theorem. It turns out that these spaces also have only vanishing Massey products, hence their cochain algebras must be formal DG-algebras!\nSo, this is my thesis summarized — or at least the abstract somewhat explained. I tried my best to make the thesis approachable and easy to read, so any one interested is welcome to have a look at it. It can be found here).\n","permalink":"https://torgeiraamboe.github.io/posts/2021/on-formal-dg-algebras/","summary":"I have recently handed in and defended my master thesis in mathematics, so I though I would go through its abstract and try to explain what it\u0026rsquo;s all about. We look at formality of DG-algebras, Massey products, A_infinity-algebras and how we can use these to some interesting results.","title":"On formal DG-algebras"},{"content":"For the last five years mathematics has been my passion, as well as my main focus in life. This passion for mathematics will hopefully not diminish, as I am now heading into four more years of studies and research through a PhD in mathematics at NTNU. I am joining a project, called Tensor triangulated geometry in Trondheim, so today I thought I would explore the definition of one of the main players in this theory, namely tensor triangulated categories. We have already met half of this structure during our several encounters of monoidal categories, but the other half remains, as well as how to glue them together into a cohesive joint structure.\nTriangulated categories As you may guess, a tensor triangulated category has both the structure of a tensor category, and a triangulated category. The tensor structure is the one we have met before, through monoidal categories, but the triangulated structure we have not yet explored in our mathematical endeavors on this blog. So, lets change that fact.\nTo justify it\u0026rsquo;s name, triangulated categories should have something to do with triangles. The way these triangles enter the picture is maybe not as direct as one would want, but they nonetheless feature prominently enough to give its name. One way to motivate triangulated categories, is to seek to generalize two concepts into a common framework. These two things are:\n Exact sequences from homological algebra Fiber and cofiber sequences from homotopy theory  Bear in mind that the following discussion is a bit rough, but that this is in order to compare similarities in algebra and topology.\nAn exact sequence consists of three abelian groups $A, B, C$ together with group homomorphisms $f:A\\longrightarrow B$ and $g:B\\longrightarrow C$ such that $f$ is injective and $\\ker g \\cong \\text{im}f$. We usually denote such a sequence by\n$$A\\overset{f}\\longrightarrow B \\overset{g}\\longrightarrow C$$\nMore generally we can construct such sequences in any Abelian category, as in such categories we always have nicely behaved kernels and cokernels. Of particular interest is the fact that $C\\cong B/f(A).$ On the other hand, a cofiber sequence consists of three topological spaces $A, B, C$ together with maps $f:A\\longrightarrow B$ and $g:B\\longrightarrow C$, such that $f$ is a cofibration and $C$ is the mapping cone of $f.$ It is more often denoted\n$$A \\overset{f}\\longrightarrow B\\overset{g}\\longrightarrow C(f).$$\nWe covered fibrations quite extensively in the the fibration series, so look there for a more in depth review of their theory and their generalization into model categories. In said series we covered cofibrations only a little bit, but we noted in the post about cofibrations that the mapping cone $C\\simeq C(f)$ of a cofibration is homotopy equivalent to $B/f(A)$. This is the same as the above situation with abelian groups.\nOk, so how do we generalize these into a common framework? When we looked a cofibrations and cofiber sequences in the fibration series, we constructed a longer sequence of topological spaces from each cofiber sequence. We expanded the cofiber sequence into\n$$A \\overset{f}\\longrightarrow B\\longrightarrow C(f)\\longrightarrow \\Sigma A, $$\nwhere $\\Sigma A$ is the suspension of $A$. For fibrations we did this in the opposite direction, i.e. constructed the mapping fiber (homotopy fiber), and a map from the loop space into it to get a sequence\n$$\\Omega B \\longrightarrow F(f)\\longrightarrow A\\overset{f}\\longrightarrow B.$$\nIf we extend the case of abelian groups to chain complexes of Abelian groups, or chain complexes of objects in an Abelian category in general, then we can also for any morphism of chain complexes $f:A\\longrightarrow B$ construct a cone $C(f)$ to get a sequence\n$$A\\longrightarrow B\\longrightarrow C(f).$$\nThis can also be extended into a longer sequence\n$$A\\longrightarrow B\\longrightarrow C(f)\\longrightarrow A[1]$$\nwhere $A[1]$ denotes the shifted complex of $A$. These two situation look awfully similar, and this is exactly what we use to generalize into a categorical structure.\nBefore we reveal the definition of a triangulated category, we define what we mean by a triangle. Let $T$ be an additive category equipped with an additive automorphism $\\Sigma:T\\longrightarrow T$ (algebraists often write $(-)[1]$ for this functor instead). A triangle is a tuple $(A, B, C, f, g, h)$ in $T$ consisting of objects $A, B, C$ and morphisms $f:A\\longrightarrow B$, $g:B\\longrightarrow C$ and $h:C\\longrightarrow \\Sigma A$. It is often denoted simply by\n$$A \\overset{f}\\longrightarrow B\\overset{g}\\longrightarrow C\\overset{h}\\longrightarrow \\Sigma A$$\nWe now maybe see why these are called triangles, as these almost form a triangle of objects and morphisms. If the automorphism can be taken to be the identity functor, then we in fact have a triangle:\nSo our definition of a triangle is a sort of generalization of this image to allow for other automorphisms as well. I don\u0026rsquo;t know if the following image helps, but it is roughly how I visualize and think about triangles\nLets now look at the definition we are interested in.\nDefinition:  A triangulated category is an additive category $T$, together with an additive automorphism $\\Sigma:T\\longrightarrow T$ often called the shift, and a class of triangles, $\\Delta$, called the exact or sometimes distinguished triangles, such that the following four axioms are satisfied.\nThis first axiom consist of three parts.\nTC1.1: For every object $A\\in T$, the triangle\n$$A\\overset{id_A}\\longrightarrow A\\longrightarrow 0\\longrightarrow \\Sigma A$$\nis exact, i.e. is an element of $\\Delta$.\nTC1.2: Every morphism $f:A\\longrightarrow B$ in $T$ can be completed to an exact triangle, i.e. there exists an object $C(f)$—called the cone of $f$—such that\n$$A\\longrightarrow B\\longrightarrow C(f)\\longrightarrow \\Sigma A$$\nis an exact triangle.\nTC1.3: Every triangle\n$$A' \\overset{f'}\\longrightarrow B'\\overset{g'}\\longrightarrow C'\\overset{h'}\\longrightarrow \\Sigma A'$$\nthat is isomorphic to an exact triangle,\n$$A \\overset{f}\\longrightarrow B\\overset{g}\\longrightarrow C\\overset{h}\\longrightarrow \\Sigma A$$\nis again exact. Being isomorphic as triangles means that there are isomorphisms $A\\rightarrow A'$, $B\\rightarrow B'$ and $C\\rightarrow C'$ such that the resulting squares commute, i.e. a commutative diagram\nWe call such diagrams (not requiring the vertical arrows to be isomorphisms) morphisms of triangles.\nTC2: If we take an exact triangle\n$$A \\overset{f}\\longrightarrow B\\overset{g}\\longrightarrow C\\overset{h}\\longrightarrow \\Sigma A$$\nand \u0026ldquo;rotate\u0026rdquo; it, i.e. look at the following triangle\n$$B\\overset{g}\\longrightarrow C\\overset{h}\\longrightarrow \\Sigma A \\overset{-\\Sigma f}\\longrightarrow \\Sigma B $$\nthen this is again exact. The same should hold for a rotation in the other direction, i.e.\n$$\\Sigma^{-1}C\\overset{-\\Sigma^{-1}h}\\longrightarrow A \\overset{f}\\longrightarrow B\\overset{g}\\longrightarrow C$$\nis again an exact triangle. Notice here that we used the inverse $\\Sigma^{-1}$ of $\\Sigma$, which exists as it is assumed to be an automorphism. Some authors only require auto-equivalence, which means that there is only a natural transformation from the composition $\\Sigma\\circ \\Sigma^{-1}$ to the identity functor, meaning that the above axiom needs a bit more care and attention. The object $\\Sigma^{-1}C$ is called the fiber of $f$. Notice the similarity to the mapping fiber briefly mentioned above, where we had $\\Omega$ instead of $\\Sigma^{-1}$. The suspension and the loop space functors are not inverses in the normal category of topological spaces, but become so in the homotopy category of spectra, mentioned a bit later. We will do an entire post about these soon.\nTC3: Given two exact triangles,\n$$A \\overset{f}\\longrightarrow B\\overset{g}\\longrightarrow C\\overset{h}\\longrightarrow \\Sigma A$$\nand\n$$A' \\overset{f'}\\longrightarrow B'\\overset{g'}\\longrightarrow C'\\overset{h'}\\longrightarrow \\Sigma A'$$\ntogether with morphisms $A\\rightarrow A'$ and $B\\rightarrow B'$, then there exists a map $\\phi:C\\longrightarrow C'$ making the diagram\ncommute. Notice that we do not require this morphism to be unique in general. This is similar to the requirement that we can always complete a morphism into a triangle, just now that we can complete a partial morphism of triangles into an actual morphism of triangles.\nTC4: This last axiom is a little more complex than the other three, but it essentially says that we can compose exact triangles into new exact triangles, and that these behave nicely. Take the two exact triangles\n$$A \\overset{f}\\longrightarrow B\\overset{g'}\\longrightarrow C'\\overset{h'}\\longrightarrow \\Sigma A$$\nand\n$$B \\overset{g}\\longrightarrow C\\overset{h}\\longrightarrow A'\\overset{f'}\\longrightarrow \\Sigma B$$\nFrom TC1.2 we know that we can complete the map $g\\circ f:A\\longrightarrow C$ into an exact triangle\n$$A \\overset{g\\circ f}\\longrightarrow C\\overset{i}\\longrightarrow B'\\overset{j}\\longrightarrow \\Sigma A.$$\nThe fourth axiom TC4, states that also the triangle\n$$C'\\longrightarrow B'\\longrightarrow A'\\longrightarrow \\Sigma C'$$\nneeds to be exact.\nIf we for a moment interpret these exact triangles as actual exact sequences of groups, then we would have $C'\\cong B/A$, $A'\\cong C/B$ and $B'\\cong C/A$. This last exact triangle then states precisely that we would get\n$$B/C\\cong A'\\cong B'/C' \\cong (C/A)/(B/A)$$\nalso known as the third isomorphism theorem. Hence TC4 is a kind of generalization of the third isomorphism theorem to exact triangles.\nExamples Phew\u0026hellip; That is always one of the longest definitions to state and understand, and it definitively takes a while to get used to\u0026hellip; Hopefully we have explained well enough some of the intuition and connection with groups and topology, which in our opinion really should guide how to think about these categorical structures. The main examples also reflect this.\nThe first one is an example where the shift is the identity functor, i.e. $\\Sigma A = A$. This example is the category of vector spaces over some field $k$, and the distinguished triangles are any triangle isomorphic to a triangle of the form\n$$A\\overset{f}\\longrightarrow B \\overset{\\begin{bmatrix} 0 \\ \\pi \\end{bmatrix}}\\longrightarrow \\ker f\\oplus \\text{cok},f \\overset{\\begin{bmatrix} i \\ 0 \\end{bmatrix}}\\longrightarrow A$$\nwhere $\\pi$ is the projection onto the cokernel, and $i$ is the inclusion of the kernel. For a more thorough treatment of this example I recommend my friend Johan\u0026rsquo;s bachelor thesis. In this example we really get a little glimpse of why this structure is named after triangles, as the triangles are the actual diagrams we used for intuition earlier\nThe next example is the naive homotopy category of the category of chain complexes of modules over some ring $R$, i.e. $HoCh(ModR)$, or more often denoted $K(R)$. This category consists of chain complexes of modules, and the maps are homotopy classes of chain maps. By our discussion of model categories in the fibration series, we know that this category is heavily related to $D(R)$ the derived category of $R$. This category is the category of chain complexes of modules over $R$, localized at the collection of quasi-isomorphisms, i.e. the maps that induce isomorphisms in homology. If we take the subcategory of $Ch(ModR)$ consisting of the bifibrant objects in some easily defined model structure, these two categories are equivalent,\n$$HoCh(ModR^{Bif}) \\simeq D(R)$$\nThe third example is the stable homotopy category $hS$. I will go more into detail on this category in another post, as it is important for my future field of study. Its objects can be thought of as the topological equivalent of chain complexes, called spectra. These are sequences of topological spaces, together with certain structure maps, which makes us able to \u0026ldquo;shift\u0026rdquo; these sequences using the suspension functor $\\Sigma$. We have met one such object in the fibration series, namely the Eilenberg-Maclane spectrum. We used this to represent the singular cohomology functor on topological spaces. This property is in fact a general property of spectra, i.e. that generalized cohomology theory can be represented by a spectrum. This follows from the Brown representability theorem. The distinguished triangles in this category are the triangles of the form\n$$A\\overset{f}\\longrightarrow B \\longrightarrow C(f)\\longrightarrow \\Sigma A$$\nwhere $C(f)$ is the mapping cone of $f$.\nIn general, the Quillen homotopy category (the localization at the weak equivalences) of a stable model category (or even more generally a stable $(\\infty, 1)$-category) is a triangulated category. A model category is called stable if its initial and terminal object coincide, and every fiber sequence is also a cofiber sequence. Both the derived category of a ring, and the stable homotopy category are examples of this general theory. Maybe we will return to visit this again later as well, as it is rather interesting.\nThe tt-categories Ok, we now understand a tiny bit about triangulated categories, or at least some intuitive and motivating examples. This post has gotten long enough, so let us finish off by defining the joint tensor and triangulated structure. There are several versions of this structure in the literature, often adding stronger requirements to fit specific needs.\nDefinition:  A tensor triangulated category (tt-category) is a tuple $(H, \\Sigma, \\Delta, \\otimes, 1, e)$ where $H$ is an additive category, such that\n $(H, \\Sigma, \\Delta)$ is a triangulated category $(H, \\otimes, 1)$ is a symmetric monoidal category $e_{X, Y}:(\\Sigma A)\\otimes B \\longrightarrow \\Sigma(A\\otimes B)$ is a natural isomorphism for all objects $A, B$ the functors $A\\otimes -$ and $-\\otimes A$ are additive for all objects $A$ given a triangle $A\\rightarrow B\\rightarrow C\\rightarrow \\Sigma A$ in $\\Delta$, then the triangles  $$X\\otimes A\\longrightarrow X\\otimes B \\longrightarrow X\\otimes C \\longrightarrow \\Sigma(X\\otimes A)$$\nand\n$$A\\otimes X\\longrightarrow B\\otimes X \\longrightarrow C\\otimes X \\longrightarrow \\Sigma(A\\otimes X)$$\nis in $\\Delta$ for all objects $X$, i.e. the functors $X\\otimes-$ and $-\\otimes X$ preserve distinguished triangles.\nSo, there we have it, the combined structure of a tensor category and a triangulated category. This post has gone on long enough, so we wont cover any examples in detail, just mentioning that the stable homotopy category and the naive homotopy category $K(R)$ of a Noetherian ring $R$, are both tt-categories. The most important for us will be the stable homotopy category, which as said earlier we will look more into soon.\nFor now this is what I wanted to present, but there will be more posts regarding this theory during the next four years, so follow along if you are interested! I have set a goal to post at least once every month, but there will probably be no regularity in when and what the posts are about. I currently have some vacation time, and thought about making a series defining mathematically what spacetime is. Hopefully this will be a more down to earth and approachable series. I also want to post a summary of my master thesis, which will be my next post I think.\n","permalink":"https://torgeiraamboe.github.io/posts/2021/tensor-triangulated-categories/","summary":"For the last five years mathematics has been my passion, as well as my main focus in life. This passion for mathematics will hopefully not diminish, as I am now heading into four more years of studies and research through a PhD in mathematics at NTNU. I am joining a project, called Tensor triangulated geometry in Trondheim, so today I thought I would explore the definition of one of the main players in this theory, namely tensor triangulated categories.","title":"Tensor triangulated categories"},{"content":"The first post on this blog is titled \u0026ldquo;geometric intuition\u0026rdquo;, and discusses the geometry behind Noether\u0026rsquo;s normalization lemma. When I wrote it I didn\u0026rsquo;t yet understand all the pieces, as I was not very comfortable working with algebraic geometry. One year later, I\u0026rsquo;m still not comfortable, but a bit more than last year. So, I thought I would update last years post with my new knowledge, as well as generalize the intuition to schemes - which we introduced in the last post.\nNoether normalization tells us information about algebras, in particular finitely generated algebras over a field $k$. Such an algebra is not necessarily a $k$-vector space, but, Noether normalization tells us that it is a finitely generated module over a polynomial ring over $k$. As we saw in the last post, algebraic geometry is very much focused on finitely generated $k$-algebras, and polynomial rings, so the fact that geometric information arises from the result is hopefully not very surprising. We restrict ourselves to infinite fields $k$, and perhaps also algebraically closed ones.\nLemma (Noether normalization for algebras):  Let $A$ be a finitely generated commutative $k$-algebra. Then there exists a non-negative integer $d$ and algebraically independent elements $y_1, \\ldots, y_d$, such that $A$ is a finitely generated module over $k[y_1, \\ldots, y_d]$.\nThere are several ways to package this information. Being a finitely generated $k$-algebra is often called being a finite type $k$-algebra, and being a finitely generated module over a ring $B$ is often called being finite over $B$, or being an integral extension of $B$. We will encounter some of these again in various forms below.\nFor algebraic varieties Last time we covered some very introductory basics regarding algebraic varieties, and in particular we looked a bit at the correspondence between ideals in $k[X_1, \\ldots, X_n]$ and affine algebraic sets in $k^n$. We did not actually state any results about this correspondence, so before we tackle Noether normalization we need to do so.\nFirst off, Noether normalization holds for any finitely generated $k$-algebra, so it would be helpful for us to understand how all of these behave. It turns out that every finitely generated $k$-algebra is of the form $k[X_1,\\ldots,X_n]/I$, where $I$ is some ideal in $k[X_1, \\ldots, X_n]$. This is good, because these are exactly1 the algebras we can use to study algebraic varieties. This also means that any affine algebraic variety naturally lives in some affine $n$-space, as the projection $k[X_1, \\ldots, X_n]\\rightarrow k[X_1, \\ldots, X_n]/I$ induces an inclusion $V(I)\\rightarrow k^n$.\nWe know from the weak nullstellensatz that for an affine algebraic variety $V$, the points in $V$ have a one to one correspondence with the maximal ideals in $\\Gamma(V)$. We also have a one to one correspondence between prime ideals in $\\Gamma(V)$ and irreducible affine subvarieties of $V$. Here the notion of irreducible means that a subvariety $W$ can be written as a union of two closed sets. The normal nullstellensatz generalizes this picture, and states that the correspondences are special cases of another correspondence, namely the on to one correspondence between affine algebraic subvarieties of $V$, and radical ideals in $\\Gamma(V)$. This correspondence is given by the two asignments $V(-)$ and $I(-)$ that we defined last time, i.e. the zero set of an ideal, and the ideal of a variety.\nWe can use the above to prove that we have an equivalence of categories between the category of affine algebraic varieties over a field $k$, and the category of finitely generated reduced $k$-algebras. Reduced means that the $k$-algebra has no nilpotent elements. In the case of finitely generated algebras, it is enough that the ideal $I\\subseteq k[X_1, \\ldots, X_n]$ that defines the finitely generated $k$-algebra, is a radical ideal.\nTo properly understand Noether normalization for affine algebraic varieties, we must understand the concept of dimension. The (topological) dimension of a variety is defined by certain chains of certain subsets.\nDefinition:  Let $V$ be an affine algebraic variety. The topological dimension of $V$ is defined to be the length of the largest proper chain of irreducible closed subsets of $V$, i.e.\n$$\\dim V = \\sup_{d}U_1\\subsetneq U_2\\subsetneq \\cdots \\subsetneq U_d$$\nwhere $U_i$ is a closed irreducible subset of $V$.\nWe immedeatly see that this definition is only suited for topologies equal to, or similar to, the Zariski topology. If we for example look at a more normal topological space, for example a Hausdorff space, then the topological dimension is $1$, as the only closed irreducible subsets are points. But, this definition works incredibly well in algebraic geometry, due to the correspondence we mentioned above - between the prime ideals in $\\Gamma(V)$ and irreducible closed subsets of $V$. This allows us to perfectly match the topological dimension of a variety to the Krull dimension of its coordinate ring.\nDefinition:  Let $A$ be a ring. The Krull dimension of $A$, denoted $\\dim_K A$ is defined to be the longest proper chain of prime ideals in $A$, i.e.\n$$\\dim_K A = \\sup_{d}p_1\\subsetneq p_2\\subsetneq \\cdots \\subsetneq p_d$$\nwhere $p_i\\subseteq A$ is a prime ideal.\nThe above remark means that we have\n$$\\dim V = \\dim_K \\Gamma(V)$$\nfor all affine algebraic varieties $V$.\nOk, the final thing we need before looking at the result of interest, is linear subspaces of $k^n$. The first thing to figure out is what the coordinate ring of a linear subspace is. If we take one such linear subspace $L\\subseteq k^n$, then its coordinate ring is $k[X_1,\\ldots,X_n]/I(L)$, i.e. the polynomial ring in $n$ variables, modulo the ideal of $L$. This ideal consists of all the polynomials in $k[X_1,\\ldots, X_n]$ that vanish on all points in $L$. Let us first consider the linear subspace $k^d$ as the $x_1\\cdots x_d$-plane. As its ideal are the polynomials that vanish on its points, we must have $I(k^d)= (X_{d+1}, \\ldots, X_n)$. To be sure we understand this, we look at $k=\\mathbb{R}$, $d=1$ and $n=2$. We can look at $k$ being the $x$-axis as a subspace $k^2$. This space is given by $V(Y)$:\nThe polynomials that are zero on the $x$-axis can not feature any solo copy of $X$. What we mean is that such a polynomial can\u0026rsquo;t be for example $f(X,Y)=X^3+Y$ as for some point $(a,0)$ on the $x$-axis, $f(a,0) = a^3\\neq 0$. We also can\u0026rsquo;t have any constant terms, as for example $g(X,Y)=XY^2+3$ is not zero on points $(a,0)$ on the $x$-axis. Hence, we must have that all components of a polynomial that vanish on the $x$-axis, must contain a copy of $Y$. This precisely means that $I(k)=(Y)$.\nGeneralizing the above, we get that the linear subspace $k^d\\subseteq k^n$ is defined by $V(X_{d+1},\\ldots, X_n)$, which gives us that $I(k^d)=I(V(X_{d+1}, \\ldots, X_n)) = (X_{d+1}, \\ldots, X_n)$, where the last equality comes from Hilbert\u0026rsquo;s nullstellensatz, together with the fact that $(X_{d+1}, \\ldots, X_n)$ is a radical ideal.\nAny $d$-dimensional linear subspace $L$ of $k^n$ must be isomorphic to $k^d$, hence their coordinate rings will also be isomorphic. Thus we get\n$$\\Gamma(L)\\cong \\Gamma(k^d) \\cong \\frac{k[X_1, \\ldots, X_n]}{I(k^d)} \\cong \\frac{k[X_1, \\ldots, X_n]}{(X_{d+1}, \\ldots, X_n)}\\cong k[X_1, \\ldots, X_d]$$\nWe are now ready to tackle Noether normalization for affine algebraic varieties.\nLemma (Noether normalization for varieties):  Every $d$-dimensional affine algebraic variety $V\\subseteq k^n$ has a surjective morphism to a $d$-dimensional linear subspace $L$ of $k^n$.\n\u0026ldquo;Proof\u0026rdquo;: The result naturally follows from Noether normalization for algebras. Given a $d$-dimensional algebraic variety $V$ we can look at its coordinate ring $\\Gamma(V)$. This is a finitely generated $k$-algebra, and is thus subject to Noether normalization for algebras. This means that there exists elements $y_1, \\ldots, y_d$ such that $\\Gamma(V)$ is a finitely generated $k[y_1, \\ldots, y_d]$-module. This is the same as saying that the ring homomorphism $k[y_1, \\ldots, y_d] \\hookrightarrow \\Gamma(V)$ is an injective integral morphism. The ring $k[y_1, \\ldots, y_d]$ must be the coordinate ring of a $d$-dimensional linear subspace of $k^n$, which we can call $L$. Hence we have an integral extension $\\phi:\\Gamma(L)\\hookrightarrow \\Gamma(V)$ of reduced finitely generated $k$-algebras. Since we have an equivalence of categories between these algebras and affine algebraic varieties, there must exist a map $\\phi^\\ast\\colon V\\rightarrow L$. As the map $\\phi$ is injective, the map $\\phi^\\ast$ is dominant, i.e. its image is dense in $L$. Because $\\phi$ is integral, the image of $\\phi^\\ast$ is closed, which then finally means that $\\phi^\\ast$ is surjective as the closure of its image is both the whole space, and the image itself, i.e. $\\text{Im }\\phi^\\ast = \\overline{\\text{Im }\\phi^\\ast} = L$.\nThe fact that the dimensions coincide, i.e. that the dimension of the linear subspace necessarily is the same as the dimension of the algebraic variety, is due to the following result.\nTheorem:  Let $A$ be a ring with Krull dimension $d$. Then any integral extension of $A$ also has Krull dimension $d$.\nSo, if we take a finitely generated $k$-algebra - now the coordinate ring of an affine algebraic set - $\\Gamma(V)$, then Noether normalization tells us that there are algebraically independent elements $y_1, \\ldots, y_d$ such that $\\Gamma(V)$ is a finitely generated module over $k[y_1, \\ldots, y_d]$, or equivalently, that $\\Gamma(V)$ is integral over the subring $k[y_1, \\ldots, y_d]$. As $k[y_1, \\ldots, y_d]$ is a polynomial ring over $d$ independent variables, it has Krull dimension $d$. And by the result above, $\\Gamma(V)$ also has Krull dimension $d$. We also know that the dimension of $V$ is equal to the Krull dimension of $\\Gamma(V)$, hence this integer $d$ from Noether normalization really is the dimension of the affine algebraic variety that corresponds to $\\Gamma(V)$, i.e.\n$$d = \\dim_K k[y_1, \\ldots, y_d] = \\dim_K \\Gamma(V) = \\dim V$$\nwhere $\\dim_K$ denotes the Krull dimension.\nA year ago we used the example of the algebraic variety $V(XY-1)$:\nwhere we by a coordinate change found a linear subspace it surjected, and even projected to:\nWe then showed that if the projection map is not surjective, then the induced map between the coordinate rings, is not integral, meaning that we had not found a ring that the coordinate ring was a finitely generated module over. This example still shows the intuition for me at least, hence the reason we include it again.\nFor schemes Generalizing the above situation to schemes forces us to introduce some different types of morphisms, and some different types of schemes. These are direct analogues of the morphisms and the varieties we had above.\nFirst and foremost we need to know what the scheme analogue of a linear subspace is. As we defined $k^d = V(X_{d+1}, \\ldots, X_n)$ to be the standard $d$-dimensional linear subspace of $k^n$, its maybe not hard to convince ourselves that $\\text{Spec }\\Gamma(k^d)$ is the correct definition for a linear subspace for schemes. This is because points in $k^d$ correspond to maximal ideals in $\\Gamma(k^d)$ when we talk about varieties, but when passing to schemes we need to keep track of subvarieties as well. This is exactly what $\\text{Spec } \\Gamma(k^d)$ gives us. Earlier we saw that $\\Gamma(k^d)\\cong k[X_1, \\ldots, X_d]$, hence also $\\text{Spec }\\Gamma(k^d)\\cong \\text{Spec }k[X_1, \\ldots, X_d]$. Such spaces are called affine $d$-space, and is usually denoted $\\mathbb{A}_k^d$.\nNotice here that we use the same kind of dimension as we did for algebraic varieties. This is because schemes are in particular topological spaces, or \u0026ldquo;have an underlying topological space\u0026rdquo;, so the same definition of (topological) dimension apply.\nThe second thing we need is the notion of being finitely generated. In the algebraic setting, a finitely generated $k$-algebra is also called a $k$-algebra of finite type. Hence the name of the next definition. This is done through the notion of \u0026ldquo;a scheme over another scheme\u0026rdquo;, which just means that we have a morphism $X\\rightarrow Y$ for the two schemes in question.\nDefinition:  Let $X\\overset{\\phi}\\longrightarrow Y$, i.e. $X$ a scheme over $Y$. We say $X$ is of finite type over $Y$ if for an affine cover $\\{\\text{Spec }B_i\\}_ {i\\in I}$ of $Y$ then $\\phi^{-1}(\\text{Spec }B_i)$ has a finite covering by open affine subschemes $\\text{Spec }C_{ij}$, such that $C_{ij}$ is a $B_i$-algebra of finite type, i.e. a finitely generated $B_i$-algbra.\nWe can simplify a bit as we are not interested in the full generality of the above definition. We are simply interested in schemes $X$ over $\\text{Spec }k$, often called $k$-schemes. Such schemes are much simpler, as $\\text{Spec } k$ is the only affine covering of it self. Hence we only need that $X$ has a cover of open affine subschemes $\\text{Spec } C_i$ such that the $C_i$\u0026rsquo;s are finitely generated $k$-algebras. We can make it even simpler by assuming $X$ is affine, i.e. $X=\\text{Spec }A$. Then $X$ is an affine cover of it self. In this situation we have that an affine $k$-scheme $\\text{Spec }A$ is of finite type if $A$ is of finite type (finitely generated as an algebra), hence we see that this really is a geometric generalization of the notion of being of finite type for algebras.\nThe next analogue we need is the analogue to being a finitely generated module over a ring. Recall that Noether normalization for algebras gives us that any finite type $k$-algebra is injectively finite over a polynomial ring, so this is the analogue we are going for.\nDefinition:  Let $X$ be an affine scheme over $Y$, i.e. $X\\overset{\\phi}\\longrightarrow Y$. We say $X$ is finite over $Y$, or that $\\phi$ is a finite morphism, if for an affine cover $\\{\\text{Spec }B_i\\}_ {i\\in I}$ of $Y$ then $\\phi^{-1}(\\text{Spec }B_i)$ is an open affine subscheme $\\text{Spec }C_{i}$, such that the restriction of $\\phi$ to $\\text{Spec } C_i$ induces a finite ring homomorphism $B_i\\longrightarrow C_i$, i.e. it makes $C_i$ a finitely generated module over $B_i$.\nWe can again simplify the situation a bit by assuming that $X$ and $Y$ are affine, i.e. $X=\\text{Spec }A$ and $Y=\\text{Spec }B$. Then they both form an affine cover of themselves, meaning that we only need that $A$ is a finitely generated $B$-module. Notice that if we assume that $X$ is an affine $k$-scheme, we can\u0026rsquo;t reduce $Y$ to being $\\text{Spec }k$ as we did above, exactly due to Noether normalization for algebras. So, Noether normalization for algebras says \u0026ldquo;for schemes\u0026rdquo; that in general, an affine $k$-scheme of finite type, is not necessarily finite over $\\text{Spec }k$. But, we can fix this in the same way as we did for both algebras and varieties. It is not finite over $\\text{Spec }k$, but it will be finite over some linear scheme. We finally get the following.\nLemma (Noether normalization for schemes):  Every $d$-dimensional affine $k$-scheme $X$ of finite type, has a finite surjective morphism to $\\mathbb{A}_k^d$.\n\u0026ldquo;Proof\u0026rdquo;: We see that this follows again from Noether normalization for algebras. As $X$ is affine we have $X = \\text{Spec }A$, and as it is a $k$-scheme of finite type, we know that $A$ is a finitely generated $k$-algebra, or stated earlier as a $k$-algebra of finite type. By Noether normalization for algebras, we can find a polynomial ring $k[y_1, \\ldots, y_d]$ over algebraically independent elements $y_1, \\ldots, y_d$ such that $A$ is a finitely generated $k[y_1, \\ldots, y_d]$-module. This means that we have an injective finite morphism $\\phi:k[y_1, \\ldots, y_d]\\hookrightarrow A$, which uniquely corresponds to a finite morphism between their spectra, i.e. $\\phi^\\ast:\\text{Spec }A\\longrightarrow \\text{Spec }k[y_1, \\ldots, y_d]=\\mathbb{A}_k^d$. As $\\phi$ is injective, $\\phi^\\ast$ is dense, an as $\\phi$ is finite, $\\phi^\\ast$ is closed, meaning that $\\phi^\\ast$ is surjective and finite.\nI think this shows a small part of why algebraic geometry is beautiful. We get direct geometric analogues of algebraic constructs, and vice versa. I find thinking in terms of schemes really difficult, as I still find them counterintuitive and hard to grasp. These correspondences makes it a bit easier, which is probably why I focus on them.. Tomorrow is my exam, where I will present the above construction. Hope it goes well.\nI stated some time ago that I would post about a project that starts next semester, so that will probably be the next post. To spoil the story, the project is a PhD at NTNU. I am to be part of a project called \u0026ldquo;Tensor triangulated geometry in Trondheim\u0026rdquo;, backed by the Trond Mohn foundation. I am really excited to be part of it, and to test my capabilities at the highest education level possible. I thought I would do a blog post defining a tensor triangulated category, so watch out for this appearing in the near future. But first, I need to get my master thesis done..\n  For this to give us a coordinate ring of a variety, we actually need that the ideal is radical. This is due to the nullstellensatz.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://torgeiraamboe.github.io/posts/2021/updated-geometric-intuition/","summary":"The first post on this blog is titled \u0026ldquo;geometric intuition\u0026rdquo;, and discusses the geometry behind Noether\u0026rsquo;s normalization lemma. When I wrote it I didn\u0026rsquo;t yet understand all the pieces, as I was not very comfortable working with algebraic geometry. One year later, I\u0026rsquo;m still not comfortable, but a bit more than last year. So, I thought I would update last years post with my new knowledge, as well as generalize the intuition to schemes - which we introduced in the last post.","title":"Updated geometric intuition"},{"content":"The first two posts ([1],[2]) I ever did on this blog - now over a year ago - were posts about algebraic geometry. In particular we explored the geometric implications of some of the algebraic results I was learning in my commutative algebra class. Last summer I also wrote a post about sheaves, and left it off by claiming to soon write about schemes. If you scroll through the blog we have covered a bunch of different topics, but the blog post on schemes, seems to have fallen through the cracks. Today we will rectify this situation. I have my algebraic geometry exam this week, so this is both an explainer-post, and a \u0026ldquo;making sure I understand the course material\u0026rdquo;-post. These types of posts have in fact become common on this blog, but hopefully that is ok.\nThe goal of the post is to be able to understand the definition of a scheme. So in order to do that we first make a quite extensive recap on algebraic varieties in order to get some motivation and intuition, and then make sure we understand all the components of the definition. As we have done before, we start with the definition we want to understand, and then unravel it as we go along. So, here it is, the definition of a scheme.\nDefinition:  A scheme is a locally ringed space $(X, \\mathcal{O}_ X)$ that admits an open cover $\\{U_i\\}$ such that $(U_i, \\mathcal{O}_{X|U_i})$ is isomorphic to $\\text{Spec }A_i$, the spectrum of some ring $A_i$.\nThere are many ways to package the information in the above definition, so just be aware that not all definitions of a scheme will look like this, but, this is the definition an formulation we are going to cover in this post.\nAlgebraic varieties Much of algebraic geometry can be done without ever mentioning schemes. This is due to them being a generalization of another well established - easy to work with - object, called algebraic varieties. An algebraic variety consists of two things:\n A topological space $X$. In particular, this topological space needs to be cut out by certain algebraic equations. A sheaf on $X$. In particular, a sheaf of functions that lift to certain polynomial functions on a certain vector space.  We must of course explain what the above words mean more mathematically and rigorously, but this is at least some handwavy information. To be more precise, an algebraic variety will be a ringed space $(X, \\mathcal{O}_X)$, i.e. a topological space $X$, together with a sheaf of functions on $X$. It will however be a very nice ringed space.\nAffine algebraic sets The main schtick in algebraic geometry is the correspondence and correlation between algebraic and geometric information. The geometric information will be curves, surfaces and shapes in $k^n$ for some field $k$ (most often algebraically closed), while the algebraic information are prime ideals in the polynomial ring $k[X_1, \\ldots, X_n]$. In order to have this nice correspondence we have two constructions that allow us to translate back and forth between these two seemingly separate worlds.\nDefinition:  Let $S$ be a subset of $k[X_1, \\ldots, X_n]$. We define the zero-set of $S$, also called the vanishing set, to be $V(S)=\\{ x\\in k^n | f(x)=0, \\forall f\\in S \\}$.\nNotice that the set $S$ generates an ideal $(S)$, and that the zero-set of $(S)$ is the same as the zero set of $S$. This means we can restrict our selves to studying ideals instead of all sets. We call a subset $V\\subseteq k^n$ an affine algebraic set if $V=V(I)$ for some ideal $I\\subseteq k[X_1, \\ldots, X_n]$.\nFor starters we can let $k = \\mathbb{R}$, and $n=2$. This means that some polynomial in two variables, for example $F(X,Y)=X^2+Y^2-1$, generates an ideal in $k[X,Y]$. The zero-set of $F$ is the unit circle:\nAnother example is the zero-set of the ideal generated by $G(X,Y)=XY-1$, which has its zero-set equal to the graph of the function $f(x)=1/x$:\nThese affine algebraic sets, that are generated by a single polynomial, are called hypersurfaces in $k^n$.\nWe can quite easily see that the intersection and union of two affine algebraic sets is again affine algebraic sets. In fact we have $V(I)\\cap V(J) = V(I+J)$ and $V(I)\\cup V(J) = V(IJ)$. For example, the intersection of the above two affine algebraic sets is the empty set, which is the zero set of the whole ring $k[X_1, \\ldots, X_n]$.\nBut, if we for example scale the radius of the circle a bit, i.e. instead use $F(X,Y)=X^2+Y^2-\\sqrt{2}$, then we see that the two affine algebraic sets intersect in two points:\nOk, we need to be able to produce algebraic information from geometric one, so we also need the sort of \u0026ldquo;reverse\u0026rdquo; construction.\nDefinition:  Let $W$ be a subset of $k^n$. We define the ideal of $W$ to be $I(W) = \\{ f\\in k[X_1, \\ldots, X_n] | f(x) = 0, \\forall x\\in W \\}$. Note that $I(W)$ is in fact an ideal.\nIf we take some subset $W\\subseteq k^n$, then we define its coordinate ring (also called the ring of regular functions) to be $k[X_1, \\ldots, X_n]/I(W)$.\nNote that for arbitrary imagined subsets $W$, the ideal $I(W)$ usually consists only of the zero element. This is because we usually think about subsets as blobs, or at least as dictated by some standard topology on $k^n$, which have no regular algebraic information in them. However, $k^n$ does not get to have the standard topology in our situation, so closed subsets will automatically correspond to sets $W$ where $I(W)$ will be more than just the zero-polynomial.\nThe Zariski topology We already got a little sneak-peak above, by the fact that intersection and union of affine algebraic sets is again affine algebraic sets, and that the empty set is an affine algebraic set. This is already almost everything we need in order to have a topology on $k^n$. We need that $k^n$ itself is an affine algebraic set, and that we either have arbitrary unions or arbitrary intersections. The last one is only to know weather we should define the topology by its closed or its open sets. For the first one we notice that all points in $k^n$ vanish on the zero-polynomial. Since $k$ is a field, the zero-polynomial does in fact generate an ideal $(0)$, hence we must have $V((0)) = k^n$. The last step is realizing that we do in fact have arbitrary intersections, i.e. $\\bigcap_{i\\in I} V(I_i) = V(\\prod_{i\\in I} I_i)$. This means that the affine algebraic sets make up the closed sets in a topology on $k^n$. This topology is called the Zariski topology.\nAn important thing to realize is that this topology works quite a bit different than the topologies one is used to from topology. The closed sets are shaped that we get from repedeately slicing $k^n$ by polynomials, which makes them really \u0026ldquo;small\u0026rdquo;. The open sets, are then \u0026ldquo;huge\u0026rdquo;, and are almost always dense in $k^n$.\nWe have some easy to define open sets called the standard open sets, or sometimes distinguished open sets. These are defined by $D(f) = k^n\\setminus V((f))$, i.e. the complement of the hypersurface generated by $f\\in k[X_1,\\ldots,X_n]$. These open sets form a basis for the Zariski topology on $k^n$. We can use this to define the Zariski topology on any affine algebraic set $X\\subseteq k^n$ by letting the topology on $X$ be the subspace topology. Then we would instead use $f\\in \\Gamma(X)$.\nThe sheaf of regular functions As we have already covered sheaves in an earlier blog post, we will not do that here. So if the reader has not seen sheaves, it would be smart to look at that post before reading onwards.\nBut, before we construct the sheaf we need, we need to realize that defining it on a basis for the topology is enough. Usually we need to define an object - in our case a ring - for each open set in a topological space $X$, satisfying a couple conditions. A basis for the topology on $X$ allows us to construct any other open set as a colimit of sets in the basis. When we apply the sheaf, then the rings we get for the general open sets can again be constructed as colimits of the rings we get from the open sets in the basis. Thus when we only define the sheaf for the basis elements, we are simultaneously defining it for all open sets, due to colimits of rings behaving nicely.\nIf we let $X$ be an affine algebraic set, then we define the sheaf of regular functions by\n$$\\mathcal{O}_X(D(f)) = \\Gamma(X)_f$$\nThis means that for any standard open set $D(f)$, the elements in the ring associated to it by the sheaf $\\mathcal{O}_X$, looks like fractions $\\frac{a}{f^n}$, where $a\\in \\Gamma(X)$.\nWe have not covered stalks and germs of sheaves yet, but intuitively stalks are what the sheaf does really really close to a point $x\\in X$. To be more precise, the stalk of $\\mathcal{O}_ X$ at the point $x$, is defined as the colimit $colim_{x\\in U} \\mathcal{O}_ X(U)$, and is denoted by $\\mathcal{O}_{X,x}$. For the above defined sheaf, every stalk inherits a ring structure, as the colimit of rings is again a ring. Every stalk is in fact a local ring, which by the way, is the reason for why $(-)_f$ is called localization, and the reason for calling rings local in the first place. Intuitively, we \u0026ldquo;zoom in\u0026rdquo; to the smallest open set around a point $x\\in X$, and there, the regular functions looks like the ring of global regular functions $\\Gamma(X)$, localized at the maximal ideal that corresponds to the point $x$.\nVarieties This means that we can turn any affine algebraic set into a ringed space by letting the associated sheaf be the sheaf of regular functions. We can then define what an affine algebraic variety is.\nDefinition:  An affine algebraic variety is a ringed space $(X, \\mathcal{O}_X)$ that is isomorphic to $(V, \\mathcal{O}_V)$ for some affine algebraic set $V$.\nAs we above noted that the stalks of the sheaf of regular functions are in fact local rings, we call an affine algebraic variety a locally ringed space.\nThe only difference between an affine algebraic variety and a general algebraic variety is that we allow algebraic varieties to be sewn together by these affine algebraic varieties. Like manifolds, who locally look like Euclidean $n$-space, an algebraic variety locally looks like an affine algebraic variety. To be precise we include a proper formulation.\nDefinition:  An algebraic variety is a locally ringed space $(X, \\mathcal{O}_ X)$ that admits an open cover $\\{U_i\\}$ such that $(U_i, \\mathcal{O}_{X|U_i})$ is an affine algebraic variety.\nHere $\\mathcal{O}_{X|U}$ means that we restrict our sheaf to only consider open subsets of $U$, instead of open sets on all of $X$. The above definition seemingly looks very much like the definition of a scheme we introduced in the beginning, so we conclude that we are on the right track.\nSchemes One of the things that stick out as a difference between the definition of an algebraic variety, and the definition we stated in the beginning of a scheme, is the object $Spec A_i$.\nThe spectrum as a topological space This is the gadget that makes a scheme more general than an algebraic variety, so lets define it.\nDefinition:  Let $A$ be a commutative unital ring. We define the spectrum of $A$ (as a topological space) to be the set $\\text{Spec } A = \\{ p\\subseteq A | p \\text{ prime}\\}$, i.e. the set of prime ideals in $A$, together with the topology defined by letting the closed sets be of the form $V(a)=\\{ p\\in \\text{Spec } A| a\\subseteq p \\}$, where $a$ is any ideal in $A$.\nWe won\u0026rsquo;t prove that this is a topology on $\\text{Spec } A$, but it should remind us of the topology we had on an affine algebraic set, namely the Zariski topology. These are in fact the same topology, hence they also get the same name for both algebraic varieties and spectrums. As for affine algebraic varieties, we have a nice basis for this topology, defined by the sets\n$$D(f) = \\text{Spec }A\\setminus V(f)=\\{ p\\in \\text{Spec } A | f\\notin p\\}$$\nHere we start to see why using $\\text{Spec }A$ is a generalization of affine algebraic varieties. If we let $A=\\Gamma(X)$ for some affine algebraic set $X$, then by the weak nullstellensatz we know that the points in $X$ correspond to maximal ideals in its coordinate ring, $\\Gamma(X)$. All maximal ideals are prime, but not all prime ideals are maximal. Hence $\\text{Spec }\\Gamma(X)$ contains in some sense \u0026ldquo;more points\u0026rdquo; than $X$. As prime ideals in $\\Gamma(X)$ correspond to irreducible affine algebraic subsets of $X$, we get that $\\text{Spec }\\Gamma(X)$ contains both the information about the points in $X$, but also all the affine algebraic subsets.\nThe spectrum as a ringed space We saw all the way back in the introduction that a scheme was defined as a ringed space, so it should hopefully come as no surprise that we also need to give $\\text{Spec }A$ a sheaf of rings. This sheaf will hopefully look familiar.\nDefinition:  Let $A$ be a commutative unital ring and $\\text{Spec } A$ its spectrum. We define a sheaf on $\\text{Spec }A$, called its structure sheaf, by\n$$\\mathcal{O}_{\\text{Spec }A}(D(f)) = A_f$$\nThis means that we can turn any ring $A$ into a ringed space by letting the topological space be $\\text{Spec }A$, and the sheaf be the structure sheaf $\\mathcal{O}_{\\text{Spec }A}$. This ringed space is called its spectrum. As for affine algebraic varieties, these ringed spaces are in fact locally ringed spaces, i.e. ringed spaces where the stalk at every point is a local ring. To be precise, and to sum up, we give the definition properly.\nDefinition:  Let $A$ be a commutative unital ring. We define the spectrum of $A$ to be the locally ringed space $(\\text{Spec }A, \\mathcal{O}_ {\\text{Spec }A})$, where $\\mathcal{O}_{\\text{Spec }A}$ is the structure sheaf defined above. By abuse of notation we often denote this ringed space by just $\\text{Spec } A$.\nThese spaces are actually schemes, and we will see below that they are the basic building blocks for all schemes. This is maybe not surprising, as in the introduction we defined schemes to be locally ringed spaces that locally looked like these spectra of rings.\nThe definition Phew! That was a lot of construction. Luckily, we are now ready to define our objects of interest - schemes. As with algebraic varieties, we will first define an affine scheme, and then define a general scheme to be a ringed space that is locally affine. This means simply that the affine schemes are the building blocks of general schemes, just as affine algebraic varieties formed the building blocks of algebraic varieties.\nDefinition:  An affine scheme is a locally ringed space $(X, \\mathcal{O}_X)$ that is isomorphic to $\\text{Spec }A$ for some commutative unital ring $A$.\nHere we see what we stated above, i.e. that the spectra of rings actually form the building blocks we wanted. But we allow some isomorphisms in order to not be too strict in our definitions. Thus we can finally restate the definition from the introduction, and say that we understand the parts.\nDefinition:  A scheme is a locally ringed space $(X, \\mathcal{O}_ X)$ that admits an open cover $\\{U_i\\}$ such that $(U_i, \\mathcal{O}_{X|U_i})$ is an affine scheme.\nBy the definition of an affine scheme, this definition is really the definition we presented in the introduction, even though it looks slightly different. The reason we did not use the word affine scheme in the introduction is that using affine schemes to define schemes is not very enlightening without first understanding the whole affine construction.\nWe now hopefully understand what the different components of the definition are, as well as why they are defined that way. They do however look disturbingly similar to algebraic varieties, so are schemes actually useful?\nWhy the need for schemes? So why do we need this abstraction? The algebraic varieties we had earlier are most usable for rings that are algebras over an algebraically closed field $k$. In fact, big results like the general nullstellensatz only holds for algebraically closed fields. This is one place where the necessity for schemes arise, as schemes are usable for all commutative unital rings! Maybe most notably, the integers $\\mathbb{Z}$ is not a $k$-algebra. Hence, if we want to use algebro-geometric techniques in number theory - for example studying the vanishing set of $X^n+Y^n-Z^n$ over $\\mathbb{Z}$ for $n\\geq 3$- then we often need schemes to do so.\nBut, even in the world of algebraically closed fields, schemes show up as necessary. They do so for example in the study of intersections of plane curves. We have not really covered projective space and projective varieties in this blog post (maybe we will do that later), but one can study plane curves by studying homogeneous polynomials in $k[X,Y,T]$. Bezout\u0026rsquo;s theorem then tells us that the number of intersection points $V(F)\\cap V(G)$ of two homogeneous polynomials with no common components, is $s\\cdot t$, where $s$ is the degree of $F$ and $t$ the degree of $G$. This theorem only holds when we count multiplicities of intersections, which is a scheme-theoretic construction. Let us for example look at the intersection of the two plane curves we saw earlier:\nRecall that these curves are given by $F=X^2+Y^2-1$ and $G=XY-1$. These both have degree 2, but there are only 2 intersection points. As we really need these to be projective curves, we can possibly also have an intersection point \u0026ldquo;at infinity\u0026rdquo;. This is still only three possible points, so we need to have at least one intersection with \u0026ldquo;multiplicity 2\u0026rdquo;. If we were only allowed to use the structure of algebraic varieties here, then all these multiplicities will be 1, but if we allow for the intersection to admit a scheme structure, then we can \u0026ldquo;count correctly\u0026rdquo;. In this way we get the four intersection points that Bezout\u0026rsquo;s theorem tells us we should have.\nSchemes are of course useful in many other situations, where algebraic varieties turn out not to be general enough, or not the right tool. In one of the next coming days we will see a generalization of the first post i ever made, i.e. geometric intuition about Noether normalization, to these more general schemes. Maybe we\u0026rsquo;ll write a bit better what is stated in the first post as well\u0026hellip;\n","permalink":"https://torgeiraamboe.github.io/posts/2021/schemes/","summary":"The first two posts ([1],[2]) I ever did on this blog - now over a year ago - were posts about algebraic geometry. In particular we explored the geometric implications of some of the algebraic results I was learning in my commutative algebra class. Last summer I also wrote a post about sheaves, and left it off by claiming to soon write about schemes. If you scroll through the blog we have covered a bunch of different topics, but the blog post on schemes, seems to have fallen through the cracks.","title":"Schemes"},{"content":"This is part four in a sort of connected story about operations in mathematics that are associative up to homotopy. It will probably be beneficial to read part 1, part 2 and part 3 in advance of this, but it is not required in theory. These previous posts do however build up some intuition and motivation for the object we are looking at today. To quickly recap what we already seen in these previous posts we recall that we started out by looking at how to transfer a group structure on a topological space through an isomorphism. We saw it produced the same structure, so we weakened to looking at transferring it through a homotopy equivalence instead. We then got an operation that was associative only up to homotopy, which we studied a bit through the so called Stasheff associahedra. We then introduced H-spaces and saw that some of these, in particular loop spaces, had the same type of homotopy associative operation. In the latest edition we looked at a more algebraic situation, still heavily motivated by the topology we had discussed earlier. In this situation we explicitly described a ternary operation that we proved was the associating homotopy and saw that we got a certain relation involving the associator and the boundary of the associating homotopy.\n$A_\\infty$-algebras Our goal is to formalize the property of being homotopy associative in the way we have been exploring in the previous posts. Not only that, but we want to have the object being algebraic, as it will allow us to study both algebra and topology at the same time. It is, I think, easier to assign algebraic invariants to topological objects, than topological invariants to algebraic objects. The algebra also helps us formalize topological information in a very rigorous and insightful way, so studying topology through the lens of algebraic information is often not too limiting. Ok, lets jump into the definition, and then explain afterwards how it rigorizes the different things we have discussed in these previous blog posts.\nDefinition:  An $A_\\infty$*-algebra* $(A, m)$ is a graded vector space $A = \\bigoplus_{i\\in \\mathbb{Z}} A^i$ together with a family of morphisms $m={m_n}$ consisting of maps $m_n\\colon A^{\\otimes n}\\longrightarrow A$ of degree $2-n$ such that\n$$\\displaystyle\\sum_{r+s+t=n}(-1)^{r+st}m_{r+1+t}(id^{\\otimes r}\\otimes m_s \\otimes id^{\\otimes t}) = 0$$\nfor all $n, s\\geq 1$ and $r, t\\geq 0$. These relations are often called the Stasheff identities or the coherence relations in $A$.\nThis looks highly complicated and abstract, but we will see that we already are familiar with this structure and what the relations mean. To see this we investigate what happens for some low $n$‘s.\n$\\mathbf{n=1 :}$ The Stasheff identity then simply becomes\n$$0 = (-1)^{0+0}m_1 \\cdot (m_1) = m_1^2$$\n$\\mathbf{n=2 :}$ This sum is a bit more complicated, but still not too bad. We have\n$$0 = (-1)^{1}m_2\\cdot(Id\\otimes m_1)+(-1)^{0}m_1\\cdot (m_2)+(-1)^{1}m_2\\cdot (m_1\\otimes Id)$$\nwhich reduces to $m_1 m_2 = m_2(m_1\\otimes Id + Id\\otimes m_1)$.\n$\\mathbf{n=3 :}$ This sum is again going to be more complicated, but lets keep our tongues straight and our heads cold and do this one as well.\n\\begin{aligned} 0 \u0026amp;= (-1)^{2}m_3(Id\\otimes Id \\otimes m_1) \\\\\n\u0026amp;\\quad + (-1)^{2}m_3(Id\\otimes m_1 \\otimes Id) \\\\\n\u0026amp;\\quad + (-1)^{2}m_3(m_1\\otimes Id \\otimes Id) \\\\\n\u0026amp;\\quad + (-1)^{2}m_2(m_2\\otimes Id) \\\\\n\u0026amp;\\quad + (-1)^{1}m_2(Id\\otimes m_2) \\\\\n\u0026amp;\\quad + (-1)^{0}m_1(m_3) \\end{aligned}\nwhich reduces to\n$$m_2(id\\otimes m_2) - m_2(m_2\\otimes id) = m_3(m_1\\otimes id \\otimes id + id\\otimes m_1 \\otimes id+id\\otimes id \\otimes m_1) + m_1m_3.$$\nWe wont show the relation for $n = 4$ until the end, and we will not present the ones for $n\u0026gt;4$ as these get more and more complex, and less and less recognizable.\nThe first condition looks very familiar and is easily recognized as the cochain condition. This means that our graded vector space is a cochain complex with respect to $m_1$. The second one is then relatively easy understand when we interpret $m_1$ as a differential. It tells us that $m_1$ is a derivation with respect to $m_2$. If we apply this to an element $v_1\\otimes v_2$ and remember to use the Koszul grading rule we get:\n\\begin{aligned} (m_2(m_1\\otimes id)+m_2(id\\otimes m_1))(v_2 \\otimes v_1) \u0026amp;= m_2(m_1\\otimes id)(v_1\\otimes v_2) + m_2(id\\otimes m_1)(v_1\\otimes v_2) \\\\\n\u0026amp;= (-1)^{|id||v_1|}m_2(m_1(v_1)\\otimes v_2) + (-1)^{|m_1||v_1|}m_2(v_1\\otimes m_1(v_2)) \\end{aligned}\nSince the identity morphism has degree $0$ the first sign vanishes, and since $m_1$ has degree $1$ we are left with $(-1)^{|v_1|}$ as our second sign, i.e.\n$$m_2(m_1(v_1)\\otimes v_2) + (-1)^{|v_1|}m_2(v_1\\otimes m_1(v_2)).$$\nWe just figured out that $m_1$ acts as a differential, so for just a moment let it be denoted by $d$. Since $m_2$ takes two vectors and produces one vector, we can interpret this as a product. If we write $m_2(v_1\\otimes v_2)=v_1\\cdot v_2$ for this product, we now get a more familiar equation:\n$$d(v_1\\cdot v_2) = d(v_1)\\cdot v_2 + (-1)^{|v_1|}v_1\\cdot d(v_2)$$\nwhich we recognize as the graded Leibniz rule.\nThe third condition should be recognizable by the previous post in this little series. We recognize the left hand side as the associator of $m_2$ and the right hand side as the boundary of $m_3$ where now $m_1$ is the differential. Since the right hand side is not necessarily equal to zero, we see that the product is not necessarily associative, as expected by the nature of this series. If in fact $m_3 = 0$, then we see that the associator is zero, and hence the product $m_2$ is associative. As we can see, $m_2$ is also associative if $m_1$ is zero.\nAs we see by the first two relations, these look an awful lot like the dg-algebras we defined last time. In fact we have just showed that an $A_\\infty$-algebra where $m_3 = 0$ is a dg-algebra. This also means that we can view any dg-algebra $(A, m, d)$ as an $A_\\infty$-algebra, by letting the multiplication $m$ be the map $m_2$, the differential $d$ be the map $m_1$ and letting $m_i=0$ for all $i\\geq 3$. Hence, a dg-algebra is a kind of trivial, or easy version of an $A_\\infty$-algebra.\nRelationship with the boundary operator When we looked at $m_3$ being the associating homotopy of $m_2$, i.e. that $m_3$ is the homotopy that connects the two different ways of multiplying three elements two times, we defined a boundary operator\n$$\\partial (-) = d(-)-(-1)^{|-|}(-)d_{A^{\\otimes 3}} $$\non the complex $Hom(A^{\\otimes 3}, A)$ where the different graded components are given by the degrees of the maps. We can do this more generally for higher arity maps, i.e. for a map $f\\colon A^{\\otimes n}\\longrightarrow A$ we get\n$$\\partial f = df -(-1)^{|f|}d_{A^{\\otimes n}}$$\nwhere $d_{A^{\\otimes n}}= \\sum_{k=0}^{n}(id^{k}\\otimes d\\otimes id^{\\otimes n-k})$. This allows us to look at $\\partial m_n$ and its relation to the Stasheff identities in the following way: Consider the extremal decompositions of the number $n$ into $r+s+t$, i.e. the one where $s=n$ and the ones where $s=1$. The former gives us the part of the Stasheff identity given by $m_1(m_s)$ and the latter the sum\n$$\\sum_{r=0}^{n-1} (-1)^{n-1}m_n(id^{\\otimes r}\\otimes m_1\\otimes id^{\\otimes n-r-1})$$\nAs mentioned above, the differential is given by $m_1$, meaning that these two parts of the Stasheff identity perfectly matches the boundary operator applied to $m_n$! Hence if we want, we can reformulate the Stasheff identities as\n$$\\partial m_n = - \\sum_{r+s+t=n}(-1)^{r+st}m_{r+s+t}(id^{\\otimes r}\\otimes m_s\\otimes id^{\\otimes t})$$\nwhere $r,s,t\\geq 1$. If we in this case let $n=3$ we see that we get exactly the scenario we had last time with the boundary of the homotopy $m_3$. In this way, the higher arity maps $m_n$ are interpreted as homotopies between certain combinations of the lower arity maps. These combinations are exactly the topological boundaries of the Stasheff associahedra. Let\u0026rsquo;s round off by seeing this connection for $n=4$.\nRecall that the fourth Stasheff associahedra is a pentagon\nwhere we interpret the vertecies as ways to multiply four elements as follows;\nor written in more appropriate notation;\nAs we already know that $m_3$ gives a homotopy between $m_2(id\\otimes m_2)$ and $m_2(m_2\\otimes id)$, then for example $m_2(id\\otimes m_3)$ gives a homotopy between $m_2(id\\otimes m_2(id\\otimes m_2))$ and $m_2(id\\otimes m_2(m_2\\otimes id))$. We can in this exact fashion also put in the homotopies that form the edges of $K4$. We then get:\nAs we see in the picture we think of the center of $K4$, or the $2$-cell inside the boundary, as the map $m_4$. If we calculate the boundary, letting the vertices be enumerated from the left, going counter clockwise, we get\n$$\\partial m_4 = m_2(1\\otimes m_3) - m_3(1\\otimes 1\\otimes m_2) - m_3(m_2\\otimes 1\\otimes 1) + m_2(m_3\\otimes m_1)+m_3(1\\otimes m_2\\otimes 1)$$\nwhich is exactly the Stasheff identity for $n=4$ in the earlier described boundary interpretation! This means that an $A_\\infty$-algebra is really a cochain complex with a multiplication that is associative up to homotopy. This homotopy satisfies the pentagon equality up to homotopy, and so on ad infinitum. This is what gives $A_\\infty$-algebras their other name, strongly homotopy associative algebras, shortened sometimes to sha-algebras. They are not widely used throughout mathematics, but they are for example useful in stable homotopy theory, string theory (in particular open string field theory) and the deformation theory of algebras.\nThese objects feature heavily in my master thesis, which is why I have devoted these last few blog posts to them. In my project I use these to study some properties of dg-algebras. I have about a month and a half until I hand in the thesis, so after that Ill do a blog post explaining the project in more detail, as well as the results featured in it. The next post now I think will be about another project I’m starting next semester.\n","permalink":"https://torgeiraamboe.github.io/posts/2021/sha-algebras/","summary":"This is part four in a sort of connected story about operations in mathematics that are associative up to homotopy. It will probably be beneficial to read part 1, part 2 and part 3 in advance of this, but it is not required in theory. These previous posts do however build up some intuition and motivation for the object we are looking at today. To quickly recap what we already seen in these previous posts we recall that we started out by looking at how to transfer a group structure on a topological space through an isomorphism.","title":"Sha-algebras"},{"content":"In the two last posts we have been discussing operations that are associative up to homotopy, and where such operations might arise naturally in topology. One claim I made, which I later realized was maybe a bit unmotivated and in need of some clarification was how some higher arity maps actually defined (or were defined by) homotopies between combinations of the lower arity maps. We also purely looked at this in a topological setting, but in algebraic topology we often translate to algebraic structures, so I also wanted to see clearly that the same constructions hold in that setting. To be more precise I am talking about the claim that a map we denoted by $m_3$ was a homotopy between $m_2(id\\otimes m_2)$ and $m_2(m_2 \\otimes id)$, where $m_2$ was a product induced through a homotopy equivalence. Don’t worry if you don’t recall the definitions and this problem, we will go through it again shortly. Today we in fact upgrade this earlier homotopy equivalence slightly such as to have a bit more to work with. As said we also take a turn away from standard topology and make our choice of “space” for this post to be chain complexes of vector spaces. I will not cover in detail why this is a reasonable thing to do but I will mention that the de Rham complex of a manifold, the rational singular cochains on a topological space and the rational cohomology of a topological space are all such structures. So, if we believe that algebraic topology is a nice way to study spaces, then studying these should be highly relevant.\nBefore we start I want to warn that this post might be a bit long and possibly quite terse. It comes from me trying to understand the statement explained above in such detail that everyone that has written something about this in the literature seemingly does. The founder of these ideas, James Stasheff, has some nice explanations for when “space” means topological space, as we hinted at in an earlier post describing the Stasheff associahedra $K3$ as a space that parametrizes operations between the two ways of combining $m_2$ with it self. There is a brief explanation in the book Algebraic operads by Valette and Loday where they prove that $m_3$ is a homotopy in the algebraic setting as well, but I found it a bit lacking in detail for my own complete understanding. It may be just me who is slow and needs every detail to make everything click… Anyway, lets go on a unnecessarily detailed, terse and long journey exploring this rather simple question: How can we make a homotopy $m_3$ between $m_2(id\\otimes m_2)$ and $m_2(m_2 \\otimes id)$?\nPreliminaries Lets start of by defining the key players that we need. I will assume some more general theory to be known, i.e. some algebraic topology and some homological algebra. Let’s kick it off by recalling what the hell a homotopy is in our algebraic setting of chain complexes.\nDefinition:  Let $A$ and $B$ be chain complexes and $f, g\\colon A\\longrightarrow B$ be two morphisms between them. A chain homotopy between $f$ and $g$ is a degree $-1$ map $h\\colon A\\longrightarrow B$ such that $f-g = d_B\\circ h + h\\circ d_A$.\nWith this in hand we jump straight to looking at the system we will be in for the rest of the post, namely the deformation retraction.\nDefinition:  Let $(A, d_A)$ and $(B, d_B)$ be cochain complexes, and let $p\\colon A\\longrightarrow B$ and $i\\colon B\\longrightarrow A$ be morphisms between them. We call $p$ a deformation retraction if $p\\circ i = id_B$ and there exists a homotopy $i\\circ p\\overset{h}\\sim id_A$. If there exists a deformation retraction $A\\longrightarrow B$, then we say $A$ is a deformation retract of $B$. We sometimes denote a deformation retraction by $(A, B, i, p, h)$.\nNote that a deformation retraction is in particular a homotopy equivalence. In fact, it can be shown that two cochain complexes are homotopy equivalent if and only if they are both deformation retracts of another cochain complex. Hence these deformation retracts are intimately linked with the homotopy theory of complexes. In the first post we tried to transfer a product on a topological space through a homotopy equivalence, so if we want to look at the same setting in this more algebraic case we need to know what a “space” with an operation is.\nDefinition:  A differential graded algebra $A=(\\bigoplus_{i\\in \\mathbb{Z}} A_i, m, d)$, often called just a dg-algebra or a DGA, is a graded associative algebra $(A, m)$ together with a degree $+1$ map $d: A\\rightarrow A$, often called the differential, such that\n $d\\circ d = 0$ $d(a\\cdot b) = d(a)\\cdot b + (-1)^{|a|}a\\cdot d(b)$.  Alternatively we can describe it as a chain complex $A$ with a grading respecting product $m:A^n\\otimes A^m\\longrightarrow A^{m+n}$ such that the second condition above holds. Hopefully one recognizes the first condition as $A$ being a cochain complex and the second as the product $m$ in $A$ satisfying the graded Leibniz rule with respect to the differential $d$. If you do not recognize these, then take these as definitions instead.\nThe last thing we need is a rule that tells us how to combine tensor products of morphisms, called the Koszul grading rule. It is given by\n$$(f_1\\otimes f_2)\\circ(g_1\\otimes g_2) = (-1)^{|f_2||g_1|}f_1 \\circ g_1 \\otimes f_2 \\circ g_2.$$\nIt also determines how to evaluate such a morphism on elements, by\n$$(f_1\\otimes f_2)(a\\otimes b) = (-1)^{|f_2||a|}f_1(a) \\otimes f_2(b).$$\nSetup The whole scenario comes from the following problem, which should feel familiar to the reader that has ready the other two posts: If we have a dg-algebra $(A, m, d_A)$ and a deformation retraction $(A, B, i, p, h)$ onto a chain complex $(B, d_B)$, can we induce a dg-algebra structure on $B$?\nThe natural thing to try is to define $m_2:B\\otimes B\\longrightarrow B$ by $m_2 = p\\circ m\\circ i\\otimes i$, which is exactly the strategy we used last time as well. For simplicity we omit the composition symbols for the rest of today. So what about the ternary map $m_3$? We know from the topology we discussed earlier that we want it to be a homotopy, so it has to have degree $-1$. We have a map present that shifts the degree down by one, namely the homotopy $h$. So for example instead of doing $p(m(ipm\\otimes 1)(i\\otimes i\\otimes i)$ we replace $ip$ by $h$ to get something like $p(m(hm\\otimes 1)(i\\otimes i\\otimes i)$, which now has degree $-1$. There are two ways of doing this, so it is perhaps not unintuitive that we define\n$$m_3 = p(m(hm\\otimes id)-m(id\\otimes hm))(i\\otimes i\\otimes i).$$\nWe can view $m_3$ as an element in $Hom(A^{\\otimes 3}, A)$. This space can be made into a chain complex by defining the boundary operator as follows:\n$$\\partial f = d_A f - (-1)^{|f|} f d_{A^{\\otimes 3}}$$\nwhere $d_{A^{\\otimes 3}} = (d_A, id, id)+(id, d_A, id)+(id, id, d_A)$ and $f$ just some generic element in $Hom(A^{\\otimes 3}, A)$ of degree $|f|$. In particular we have that $\\partial m_3 = dm_3 + m_3 d_{A^{\\otimes 3}}$. Notice that $m_2(m_2\\otimes id)$ and $m_2(id\\otimes m_2)$ are also elements of $Hom(A^{\\otimes 3}, A)$ and are both maps of degree zero. Let’s draw them in a diagram.\nA homotopy between $m_2(id\\otimes m_2)$ and $m_2(m_2\\otimes id)$ would be a map $h\\colon A^{\\otimes 3}\\longrightarrow A$ of degree $-1$ such that\n$$d_A^{n-1}\\circ h^{n} + h^{n+1}\\circ d_{A^{\\otimes 3}}^n = m_2(id\\otimes m_2)-m_2(m_2\\otimes m_2).$$\nBut notice that this is exactly just showing that $\\partial h = m_2(id\\otimes m_2)-m_2(m_2\\otimes id)$! Hence for $m_3$ to be the homotopy we want between $m_2(id\\otimes m_2)$ and $m_2(m_2\\otimes id)$ we must show that $\\partial m_3 = m_2(id\\otimes m_2)-m_2(m_2\\otimes id)$. This is often just stated as being the case in most surveys, or the proof skips too many steps to actually figure out what’s going on. The reason we introduce this boundary operator is because it hopefully gives some flashbacks to topology, and how the boundary of standard simplices (for example one given by $K3$) is calculated.\nThis is the reason why I wanted to make this post, to actually calculate this and see that it holds. If you believe me when I say it is true, then you can stop reading now, as the rest will be mostly just calculation.\n\u0026ldquo;Shut up and calculate\u0026rdquo; - My friend Karl We denote $id$ by $1$ to make it more distinguishable from $d_A$ – which we denote by just $d$ – and eventual copies of $i\\circ d$. We also skip writing $\\circ$, and denote it instead just by concatenation, so $d\\circ m_3 = dm_3$. Since $m_3$ consists of $i, p$ – which are degree $0$ – and $h$ – which has degree $-1$, we have $|m_3|=-1$. The boundary of $m_3$ is then\n\\begin{aligned} \\partial m_3 \u0026amp;= dm_3+m_3(d,1,1)+m_3(1,d,1)+m_3(1,1,d) \\\\\n\u0026amp;= dm_3 +p((-1)^{|1||d|}m(hm(id\\otimes i)\\otimes i) -(-1)^{|hm||d|}m(id\\otimes hm(i\\otimes i))) \\\\\n\u0026amp;\\hspace{13mm} +p((-1)^{|1||1|}m(hm(i\\otimes id)\\otimes i) -(-1)^{|hm||1|}m(i\\otimes hm(id\\otimes i))) \\\\\n\u0026amp; \\hspace{13mm} +p((-1)^{|1||1|}m(hm(i\\otimes i)\\otimes id) -(-1)^{|hm||1|}m(i\\otimes hm(i\\otimes id))) \\end{aligned}\nwhere the signs appear due to the Koszul grading rule. As the identity morphism has degree $0$ most of these vanish, except for $(-1)^{|hm||d|}$. The composite map $hm$ has degree $|h|+|m| = -1+0 = -1$ and the differential $d$ has degree $1$ as we work with cohomological grading. Since $i$ is a morphism of chain complexes it commutes with the differentials, hence we can put all the $i$‘s outside together to get\n\\begin{aligned} \\partial m_3 \u0026amp;= dm_3 +p(m(hm(d\\otimes 1)\\otimes 1) +m(d\\otimes hm) \\\\\n\u0026amp; \\hspace{17mm} +m(hm(1\\otimes d)\\otimes 1) -m(1\\otimes hm(d\\otimes 1)) \\\\\n\u0026amp; \\hspace{17mm} +m(hm\\otimes d) -m(1\\otimes hm(1\\otimes d))(i\\otimes i\\otimes i) \\end{aligned}\nWe haven’t touched the $dm_3$ part yet, so lets see what this gives us. We get\n\\begin{aligned} dm_3 \u0026amp;= d(p(m(hm\\otimes 1) -m(1\\otimes hm))(i\\otimes i\\otimes i)) \\\\\n\u0026amp;= p(dm(hm\\otimes 1) -dm(1\\otimes hm))(i\\otimes i\\otimes i) \\end{aligned}\nSince $A$ is a dg-algebra we can use the graded Leibniz rule to expand $dm$ into $m(d\\otimes 1)+m(1\\otimes d)$. Doing that both places they appear above we get\n\\begin{aligned} dm_3 \u0026amp;= p((m(d\\otimes 1) +m(1\\otimes d))(hm\\otimes 1) \\\\\n\u0026amp;\\quad -(m(d\\otimes 1) +m(1\\otimes d))(1\\otimes hm))(i\\otimes i\\otimes i) \\\\\n\u0026amp;= p((m(d\\otimes 1) +m(1\\otimes d))(hm\\otimes 1) \\\\\n\u0026amp;\\quad -m(d\\otimes 1) -m(1\\otimes d)(1\\otimes hm))(i\\otimes i\\otimes i) \\end{aligned}\nTo contract this we need to apply the Koszul grading rule. For the individual pieces in the above equation we get\n\\begin{aligned} m(d\\otimes 1)(hm\\otimes 1) \u0026amp;= (-1)^{|1||hm|}m(dhm\\otimes 1) \\\\\nm(1\\otimes d)(hm\\otimes 1) \u0026amp;= (-1)^{|d||hm|}m(hm\\otimes d) \\\\\nm(d\\otimes 1)(1\\otimes hm) \u0026amp;= (-1)^{|1||1|}m(d\\otimes hm) \\\\\nm(1\\otimes d)(1\\otimes hm) \u0026amp;= (-1)^{|d||1|}m(1\\otimes dhm) \\end{aligned}\nwhere as before all signs are $1$ except $(-1)^{|d||hm|}=-1$. Thus we have\n\\begin{aligned} dm_3 \u0026amp;= p(m(dhm\\otimes 1)-m(hm\\otimes d)-m(d\\otimes hm)-m(1\\otimes dhm))(i\\otimes i\\otimes i) \\end{aligned}\nWe know that $h$ is a homotopy between $i\\circ p$ and $id_A$, and for chain complexes this means that $dh+hd=i\\circ p - id_A$. This gives us that we can replace $dh$ by $id_A-i\\circ p-hd$ in the equation above. Doing this gives us\n\\begin{aligned} dm_3 \u0026amp;= p(m((1-ip-hd)m\\otimes 1)-m(hm\\otimes d)-m(d\\otimes hm) \\\\\n\u0026amp;\\quad -m(1\\otimes (1-ip-hd)m))(i\\otimes i\\otimes i) \\\\\n\u0026amp;= p(m(m\\otimes 1)-m(ipm\\otimes 1)-m(hdm\\otimes 1) \\\\\n\u0026amp;\\quad -m(hm\\otimes d)-m(d\\otimes hm) \\\\\n\u0026amp;\\quad -m(1\\otimes m)+m(1\\otimes ipm)+m(1\\otimes hdm))(i\\otimes i\\otimes i) \\end{aligned}\nNotice that we have both $m(m\\otimes 1)$ and $m(1\\otimes m)$ present, with the opposite signs. These two are just repeated products in $A$, so their difference form the associatior $m(m\\otimes 1)-m(1\\otimes m)$ in $A$, which is of course just $0$ as we know $A$ is associative.\nAfter canceling the associator in $A$, and rearranging the terms a bit nicer, we can venture further by again applying the graded Leibniz rule to the $dm$‘s. This gives us\n\\begin{aligned} dm_3 \u0026amp;= p(m(1\\otimes ipm)-m(ipm\\otimes 1) \\\\\n\u0026amp;\\quad -m(h(m(d\\otimes 1)+m(1\\otimes d))\\otimes 1) \\\\\n\u0026amp;\\quad -m(hm\\otimes d)-m(d\\otimes hm) \\\\\n\u0026amp;\\quad +m(1\\otimes h(m(d\\otimes 1)+m(1\\otimes d))))(i\\otimes i\\otimes i) \\\\\n\u0026amp;= p(m(1\\otimes ipm)-m(ipm\\otimes 1) \\\\\n\u0026amp;\\quad - m(hm(d\\otimes 1)\\otimes 1) - m(hm(1\\otimes d)\\otimes 1) \\\\\n\u0026amp;\\quad +m(hm\\otimes d)+m(d\\otimes hm) \\\\\n\u0026amp;\\quad +m(1\\otimes hm(d\\otimes 1))+m(1\\otimes hm(1\\otimes d)))(i\\otimes i\\otimes i) \\end{aligned}\nNow we are finally ready to put everything together. Recall we wanted to find $\\partial m_3 = dm_3 + m_3d_{A^{\\otimes 3}}$. The calculation has been so long that is hard to remember what we actually were doing. We have found both parts of this equation, and putting them together we have\n\\begin{aligned} \\partial m_3 \u0026amp;= p(m(1\\otimes ipm)-m(ipm\\otimes 1) \\\\\n\u0026amp;\\quad - m(hm(d\\otimes 1)\\otimes 1) - m(hm(1\\otimes d)\\otimes 1) \\\\\n\u0026amp;\\quad -m(hm\\otimes d)-m(d\\otimes hm) \\\\\n\u0026amp;\\quad +m(1\\otimes hm(d\\otimes 1))+m(1\\otimes hm(1\\otimes d))(i\\otimes i\\otimes i) \\\\\n\u0026amp;\\quad +p(m(hm(d\\otimes 1)\\otimes 1) +m(d\\otimes hm) \\\\\n\u0026amp;\\quad +m(hm(1\\otimes d)\\otimes 1) -m(1\\otimes hm(d\\otimes 1)) \\\\\n\u0026amp;\\quad +m(hm\\otimes d) -m(1\\otimes hm(1\\otimes d))(i\\otimes i\\otimes i) \\\\\n\u0026amp;= p(m(1\\otimes ipm)-m(ipm\\otimes 1) \\\\\n\u0026amp;\\quad - m(hm(d\\otimes 1)\\otimes 1) - m(hm(1\\otimes d)\\otimes 1) \\\\\n\u0026amp;\\quad -m(hm\\otimes d)-m(d\\otimes hm) \\\\\n\u0026amp;\\quad +m(1\\otimes hm(d\\otimes 1))+m(1\\otimes hm(1\\otimes d) \\\\\n\u0026amp;\\quad +m(hm(d\\otimes 1)\\otimes 1) +m(d\\otimes hm) \\\\\n\u0026amp;\\quad +m(hm(1\\otimes d)\\otimes 1) -m(1\\otimes hm(d\\otimes 1)) \\\\\n\u0026amp;\\quad +m(hm\\otimes d) -m(1\\otimes hm(1\\otimes d))(i\\otimes i\\otimes i) \\end{aligned}\nwhere in the last equality we have just put the $p$ on the left and the $i$‘s on the right. This is just to have everything inside the same bracket, i.e. $p(\\text{all the stuff})(i\\otimes i\\otimes i)$, which we can do as they are linear. We see that almost everything on the inside cancels nicely, and we are left with\n$$\\partial m_3 = p(m(1\\otimes ipm)-m(ipm\\otimes 1))(i\\otimes i\\otimes i)$$\nExpanding this we get\n$$\\partial m_3 = pm(1\\otimes ipm)(i\\otimes i\\otimes i) - pm(ipm\\otimes 1)(i\\otimes i\\otimes i)$$\nwhich we recognize as $m_2(1\\otimes m_2) - m_2(m_2\\otimes 1)$. This means we are finally left with what we wanted to show:\n$$\\partial m_3 = m_2(1\\otimes m_2)-m_2(m_2\\otimes 1)$$\ni.e. the associator of $m_2$. All this to justify the following image:\nAs $m_3$ is the homotopy of the associator, we call it the associating homotopy of $m_2$. This does really show how cleverly the algebraic versions of topological objects are defined, and how cool the field of algebraic topology really is! We can translate back and forth between algebra and topology without any real problems, and the translations allows us to use both algebra and topology for insight into the problems. Such connections is precisely why I entered into this field some years ago.\nClosing remarks This relation will in the next post reveal itself to be one of an infinite tower of relations that define an $A_\\infty$-algebra. It will actually be the third relation, and we have already seen the first two. The first one will just give us the cochain complex rule, $d^2=0$, and the second one will give us the graded Leibniz rule. Hence we will see that the dg-algebras we defined today really are some examples of “easy” $A_\\infty$-algebras. These information packed algebraic structures will the codify what we mean by “related by higher homotopies” which we sometimes throw around willy-nilly. If you hadn’t already guessed it, this is part of what I am writing about for my master thesis! When I hand it in I hope to have explained all the parts that go into it already on this blog, in that way making a summary post will be easier and will build on established older posts.\n","permalink":"https://torgeiraamboe.github.io/posts/2021/the-associating-homotopy/","summary":"In the two last posts we have been discussing operations that are associative up to homotopy, and where such operations might arise naturally in topology. One claim I made, which I later realized was maybe a bit unmotivated and in need of some clarification was how some higher arity maps actually defined (or were defined by) homotopies between combinations of the lower arity maps. We also purely looked at this in a topological setting, but in algebraic topology we often translate to algebraic structures, so I also wanted to see clearly that the same constructions hold in that setting.","title":"The associating homotopy"},{"content":"In the most recent blog post we discussed homotopy associativity and how to transfer algebraic structures on topological spaces. There we in particular used topological groups, which are topological spaces with group structures. That said, any group is a topological group by equipping it with the discrete topology. So if we want to study some actual topology, and not just glorified group theory, we need to look at where multiplications and binary operations arise naturally in topology.\nThe first place to start could maybe be Lie groups. These are manifolds with group structures, and are “more” topological than just all topological groups. Even though these groups are incredibly useful and have a rich theory associated to them, they are not the focus of this blog post. Actually having group structure is often too strict for situations where binary operations arise more naturally in topology, so let’s look at the bare minimum that we could have.\nH-spaces In topology we are fortunate enough to have a nice notion of homotopy. This we have discussed at length in the fibration series, which resulted in exploring some theory about model categories. In the homotopy category of topological spaces we argued that we can study homotopy classes of maps instead of inverted weak equivalences. This allows us to make some nice definitions of algebraic structures in the category of topological spaces. For example we can define a H-group to be a topological space with operations such that it is a group in the homotopy category. This allows for the operations to be invertible, associative and unital up to homotopy instead of on the nose. Here the “H” stands for Hopf, as in the mathematician Heinz Hopf, as the maybe intuitive name, homotopy group, is already occupied. We said we would look at the bare minimum, so instead of a H-group, we look at an H-space.\nDefinition:  An H-space is a topological space $X$, together with a binary operation $m$, that has a unit up to homotopy. Alternatively, it can be described as a space with the operation m such that it is a unital magma in the homotopy category.\nSome of the most famous examples are the spheres $S^0$, $S^1$, $S^3$ and $S^7$. These are H-spaces as they inherit an operation from the real division algebra they are the unit-length subset of. For example $S^3$ sits as the vectors in $\\mathbb{H}$, the quaternions, with length 1, and the other ones in $\\mathbb{R}$, $\\mathbb{C}$ and $\\mathbb{O}$ respectively. The first three are actually groups, making them Lie groups, but $\\mathbb{O}$ is non-associative, and hence $S^7$ is as well, so its not a group. The interesting fact that these four spheres are the only H-spaces is related to the famous Hopf invariant one problem, solved by Frank Adams.\nWe said we wanted to stay away from groups, but here we are, back again.. Let’s actually see a non-group example. The most important one for us will be loop spaces.\nLoop spaces Definition:  Let $(X, x)$ be a pointed topological space, abusively denoted just by $X$. The loop space of $X$, denoted $\\Omega X$, is defined to be the set of continuous maps $\\Omega X = \\{ f\\colon I\\longrightarrow X \\vert f(1)=x=f(0)\\}$, where $I$ is the unit interval. As the endpoints of the interval gets mapped to the same point we get a loop, hence the name.\nWe turn this into a H-space by defining our operation to be concatenation of loops. As two elements in $\\Omega X$ are two loops starting and ending at the same point $x$, we can simply join them to be a single loop that happens to pass through $x$ in the middle. More rigorously we define\n$$(g\\ast f) (t) = \\begin{cases} f(2t), t\\in [0, 1/2] \\\\ g(2t-1), t\\in [1/2, 1] \\end{cases}$$\nThis makes $g\\ast f$ into a loop, i.e. a map from the interval to $X$ with value $x$ at the endpoints. This means that we traverse the first loop $f$ at double the speed, and then the second loop $g$ at double the speed. This is to make sure we have a map from the interval, and not from $[0, 2]$.\nSince it is supposed to be a H-space we need a (up to homotopy) unit. This is given by the constant loop at $x$, which we denote by $c_x$. As we have\n$$(c_x\\ast f) (t) = \\begin{cases} f(2t), t\\in [0, 1/2] \\\\ c_x(2t-1) = x, t\\in [1/2, 1] \\end{cases}$$\nwe get a homotopy to the loop $f$ by just reparametrizing the intervals. The homotopy is a map $h\\colon I\\times I\\longrightarrow X$ such that $h(0, t) = c_x\\ast f$ and $h(1, t)=f$, and is given by $h(s, t)= (1-s)(c_x\\ast f)(t) + sf(t)$, or drawn graphically by the following square:\nNotice that composition of three loops $f$, $g$, $h$ can be done in two different ways. We can do $h\\ast(g\\ast f)$ or $(h\\ast g)\\ast f$. These are different because\n\\begin{aligned} ((h\\ast g)\\ast f) (t) \u0026amp;= \\begin{cases} f(2t), t\\in [0, 1/2] \\\\\n(g\\ast h)(2t-1), t\\in [1/2, 1] \\end{cases} \\\\ \u0026amp;= \\begin{cases} f(2t), t\\in [0, 1/2] \\\\ g(2\\cdot(2t-1)), t\\in [1/2, 3/4] \\\\ h(2\\cdot(2t-1)-1), t\\in [3/4, 1] \\end{cases} \\\\ \u0026amp;= \\begin{cases} f(2t), t\\in [0, 1/2] \\\\ g(4t-2), t\\in [1/2, 3/4] \\\\ h(4t-3), t\\in [3/4, 1] \\end{cases} \\end{aligned}\nand\n\\begin{aligned} (h\\ast (g\\ast f)) (t) \u0026amp;= \\begin{cases} (g\\ast f)(2t), t\\in [0, 1/2] \\\\ h(2t-1), t\\in [1/2, 1] \\end{cases} \\\\\n\u0026amp;= \\begin{cases} f(2\\cdot2t), t\\in [0, 1/4] \\\\\ng(2\\cdot(2t-1)), t\\in [1/4, 1/2] \\\\\nh(2t-1), t\\in [1/2, 1] \\end{cases} \\\\\n\u0026amp;= \\begin{cases} f(4t), t\\in [0, 1/4] \\\\\ng(4t-2), t\\in [1/4, 1/2] \\\\\nh(2t-1), t\\in [1/2, 1] \\end{cases} \\end{aligned}\nwhich seem similar, but are parametrized on the interval I differently. Fear not, these can also be reparametrized by a homotopy, so the concatenation of loops is associative up to homotopy! This homotopy can be drawn as follows:\nFrom last time we maybe remember what this means. Having a homotopy between the two ways of combining three elements with a product is the same as an action from the third Stasheff associahedra, $K3$:\nBy iteratively using this homotopy as well as higher dimensional reparametrization cubes on the different ways of using concatenation of loops on bigger and bigger sets of loops, we in fact get actions from all $Kn$. This means that a loop space is an example of an $A_\\infty$-space, which we defined last post as a space with an action from the Stasheff operad.\nIn a way it is also the only example, as a space $X$ is a loop space if and only if it is an $A_\\infty$-space and its monoid $\\pi_0(X)$ of connected components is a a group. We still haven’t properly defined $A_\\infty$-spaces and $A_\\infty$ structures, and we will not do so in this post either. Not even in the next post I think. But it is coming, sometime in the future. For now, whenever someone says $A_\\infty$-space, think about loop spaces, and these actions from the Stasheff associahedra.\n","permalink":"https://torgeiraamboe.github.io/posts/2021/spaces-with-operations/","summary":"In the most recent blog post we discussed homotopy associativity and how to transfer algebraic structures on topological spaces. There we in particular used topological groups, which are topological spaces with group structures. That said, any group is a topological group by equipping it with the discrete topology. So if we want to study some actual topology, and not just glorified group theory, we need to look at where multiplications and binary operations arise naturally in topology.","title":"Spaces with operations"},{"content":"Imagine we have a system of two topological spaces $f:T\\longrightarrow G$. We are often interested in knowing if a certain property on the space $G$ can be transferred through f such that we have the same property on $T$. If f is a nice enough morphism an example could be a topological invariant of $G$, for example its Euler characteristic. In this post we are more interested in transferring other things than invariants, more specifically structures. If $G$ has an algebraic structure, for example a group structure, can we then transfer the same or some other similar structure onto $T$ through $f$?\nIsomorphic transfer Let’s assume for now that $G$ is a group and that $f$ is an isomorphism. This allows us to also make $T$ into a group by transferring the group structure through $f$. We get this by defining the multiplication on $T$ to be $t_1\\cdot t_2 = f^{-1}(f(t_1)\\cdot f(t_2))$. Let’s prove that this is a group structure on $T$.\nSince $f$ is an isomorphism, we have a unique element that gets sent to the identity element in $G$, which we define to be the identity element of $T$, i.e. $1_T = f^{-1}(1_G)$. This is in fact an identity element since\n\\begin{aligned} t\\cdot 1_T \u0026amp;= f^{-1}(f(t)\\cdot f(1_T)) \\\\\n\u0026amp;= f^{-1}(f(t)\\cdot f(f^{-1}(1_G))) \\\\\n\u0026amp;= f^{-1}(f(t)\\cdot 1_G) \\\\\n\u0026amp;= f^{-1}(f(t)) \\\\\n\u0026amp;= t . \\end{aligned}\nThe same holds for $1_T\\cdot t = t$. We define the inverse of an element to be $t^{-1} = f^{-1}((f(t)^{-1})$. Which we see is an inverse because\n\\begin{aligned} t\\cdot t^{-1} \u0026amp;= f^{-1}(f(t)\\cdot f(t^{-1})) \\\\\n\u0026amp;= f^{-1}(f(t)\\cdot f(f^{-1}((f(t))^{-1}))) \\\\\n\u0026amp;= f^{-1}(f(t)\\cdot (f(t))^{-1}) \\\\\n\u0026amp;= f^{-1}(1_G) \\\\\n\u0026amp;= 1_T, \\end{aligned}\nwhere the same also holds for $t^{-1}\\cdot t = 1_T$. The operation is associative because\n\\begin{aligned} t_1\\cdot (t_2\\cdot t_3) \u0026amp;= t_1\\cdot (f^{-1}(f(t_2)\\cdot f(t_3)))\\\\\n\u0026amp;= f^{-1}(f(t_1)\\cdot f(f^{-1}(f(t_2)\\cdot f(t_3)))) \\\\\n\u0026amp;= f^{-1}(f(t_1)\\cdot (f(t_2)\\cdot f(t_3))) \\\\\n\u0026amp;= f^{-1}((f(t_1)\\cdot f(t_2))\\cdot f(t_3)) \\\\\n\u0026amp;= f^{-1}(f(f^{-1}(f(t_1)\\cdot f(t_2)))\\cdot f(t_3)) \\\\\n\u0026amp;= (f^{-1}(f(t_1)\\cdot f(t_2))\\cdot t_3 \\\\\n\u0026amp;= (t_1\\cdot t_2)\\cdot t_3 \\end{aligned}\nwhere the equality between the third and the fourth line comes from the associativity of the product in $G$.\nHence we have a binary operation on $T$ which is associative, has an identity element and has all inverses, which makes $T$ into a group.\nHomotopy equivalent transfer A crucial part in the above proof is that $f$ is an isomorphism, so what happens when this is not the case? We need some sort of way to pass from $G$ back to $T$ in order to have an algebraic structure on $T$, so we need a morphism that has a weaker type of inverse than an isomorphism. We do this by choosing $f$ be a homotopy equivalence. This means we have an homotopy inverse, i.e. a map $g: G\\longrightarrow T$ such that $f\\circ g \\sim id_G$ and $g\\circ f \\sim id_T$. In this situation, what happens to the same kind of transferred structure on $T$? We do the same thing as last time and define our operation to be given by $m_2(t_1, t_2)=t_1\\cdot t_2 = g(f(t_1)\\cdot f(t_2))$. Why we also denote it by $m_2$ will be clearer later. This is a map $T\\times T\\longrightarrow T$. One thing we can check is weather this map is associative. We have\n\\begin{aligned} t_1\\cdot (t_2 \\cdot t_3) \u0026amp;= t_1\\cdot g(f(t_2)\\cdot f(t_3)) \\\\\n\u0026amp;= g(f(t_1)\\cdot fg(f(t_2)\\cdot f(t_3))) \\end{aligned}\nand\n\\begin{aligned} (t_1\\cdot t_2) \\cdot t_3 \u0026amp;= g(f(t_1)\\cdot f(t_2)) \\cdot t_3\\\\\n\u0026amp;= g(fg(f(t_1)\\cdot f(t_2))\\cdot f(t_3)) \\end{aligned}\nwhich because $g\\circ f \\neq id_T$, are not equal in general. Luckily they are homotopic! So instead of actual associativity, we have associativity up to homotopy. Such a homotopy between them is a map $m_3:I\\times T^3\\longrightarrow T$, where $I$ is the unit interval. This means that the interval parameterizes a space of maps $T^3\\longrightarrow T$ in such a way that on the edges of the interval we have the two ways of combining three elements by our operation $m_2$. Another way to say this is that the composition of $m_3$ with the boundary map $\\partial$ is given by\n$$m_2(id_T\\times m_2) - m_2(m_2 \\times id_T) - m_3(\\partial \\times id_T \\times id_T + id_T\\times \\partial \\times id_T + id_T\\times id_T\\times \\partial ).$$\nWe can graphically visualize the parametrization by the following diagram:\nHere the two trees at the two vertices visualize the different brackets we can put between the elements in order to get the two different operations using $m_2$. The line between them is the homotopy $m_3$.\nStasheff associahedra The line we just constructed, i.e. the space that parametrizes operations $T^3\\longrightarrow T$ is called the third Stasheff associahedra, which we denote by $K3$. A natural question to ask is if we can continue this process, i.e. to see if we have spaces that parametrize maps $T^4\\longrightarrow T$ such that the different ways of combining four elements using $m_2$ lie on its boundary. Let’s investigate what this would mean. We have five ways of combining four elements by the operation $m_2$, namely $t_1 \\cdot (t_2 \\cdot (t_3 \\cdot t_4))$, $t_1 \\cdot ((t_2 \\cdot t_3) \\cdot t_4)$, $(t_1 \\cdot t_2) \\cdot (t_3 \\cdot t_4)$, $(t_1 \\cdot (t_2 \\cdot t_3)) \\cdot t_4$ and $((t_1 \\cdot t_2) \\cdot t_3) \\cdot t_4$. All of these are homotopic to each other through repeatedly using the homotopy $m_3$ to reposition the brackets. Notice that we have two ways of getting from $t_1 \\cdot (t_2 \\cdot (t_3 \\cdot t_4))$ to $((t_1 \\cdot t_2) \\cdot t_3) \\cdot t_4$. By using diagrams to describe the rebracketing we can visualize them as follows.\nHere the vertices are the different combinations of four elements using $m_2$, the edges are the rebracketings using $m_3$. The two paths we have is the two paths we can use to get from the leftmost vertex to the rightmost one. Can we say something about how these two ways are similar? Yes, they are homotopic! This means that we can fill in the pentagon by a homotopy. We call this filled in pentagon the fourth Stasheff associahedron, denoted $K4$. This means that we now have a space that parametrizes a collection of maps $T^4\\longrightarrow T$ in such a way that it respects the $m_3$ on the boundary, i.e. a map $m_4: K4\\times T^4\\longrightarrow T$.\nIf we look back we can also define $K2$ to be just a point, as it parametrizes the one multiplication operation we chose at the beginning. Trivially we can define $K1$ to be the empty set. We can also continue this process further than $K4$, and every time these Stasheff associahedra get more complicated. We wont explain all the details of all paths and combinations, but $K5$ looks like this:\nEvery vertex correspond to one way we can combine 5 elements, every edge to homotopies between them, every surface corresponds to homotopies between paths of homotopies, and lastly the inside to a homotopy between paths of the surfaces. These shapes get more and more complicated, and grow in dimension, so visualizing $Kn$ for $n\\geq 6$ is difficult. You can see this page for an interactive 3D model of $Kn$ for $0\\leq n\\leq 10$. Be wary that $K10$ might really push your computer. What matters is that for every $n$ we get a map $m_n:Kn\\times T^n\\longrightarrow T$, that acts as a homotopy between different ways of combining $m_{n-1}$.\nAs we see in the drawings earlier we have that $K4$ is built up by five copies of $K3$, and we see that $K5$ is built up by five copies of $K4$ and three copies of $K3\\times K3$. There is a formula for knowing how many of which Stasheff associohedra that build up a higher associahedron. The formula for finding how many copies of copies of $Kr\\times Ks$ there is in $Kn$ is given as follows. For each $r, s$ such that $r+s=n+1$ there are $r$ copies of $Kr\\times Ks$ in $Kn$. For $n=4$ we get (as $K1$ is the empty set) two copies of $K2\\times K3$ and three copies of $K3\\times K2$. Since $K2$ is just a point we get five copies of $K3$, which is what we see in the picture given earlier of $K4$. There are ways to explicitly describe the attaching maps, and there is even a way to construct $Kn$ as a particular convex hull in $\\mathbb{R}^{n-2}$, but we won’t cover these here.\nSo why should we care about these? It is in general nice to have objects that classify certain operations on other objects, as much of modern mathematics is described in terms of operations on objects. These objects that parametrize operations are called operads, and in particular the set ${Kn}_ {n\\geq 1}$ we just constructed to parametrize operations $T^n\\longrightarrow T$ for topological spaces is called the Stasheff operad. A topological space with the action of the Stasheff operad is called an $A_\\infty$-space. We will come back to talking about operads and $A_\\infty$-structures in a future blog post, because they are really interesting! But for now we have done what we set out to do, i.e. understand a bit better what happens when we try to transfer a group structure through a homotopy equivalence, so let’s call it a day!\n","permalink":"https://torgeiraamboe.github.io/posts/2021/homotopy-associativity/","summary":"Imagine we have a system of two topological spaces $f:T\\longrightarrow G$. We are often interested in knowing if a certain property on the space $G$ can be transferred through f such that we have the same property on $T$. If f is a nice enough morphism an example could be a topological invariant of $G$, for example its Euler characteristic. In this post we are more interested in transferring other things than invariants, more specifically structures.","title":"Homotopy associativity"},{"content":"For those that don’t know I am a fifth year mathematics student at NTNU, meaning I am finishing my masters degree after this semester. During my time at NTNU I have had some wonderful classes, and some wonderful teachers. Since most I post about on this blog is related to topology, it is very safe to assume that some of my most memorable courses are exactly the topology courses. I very recently looked at my notes from my first topology course, or rather one of the two first, as I took two in parallel during my fourth semester. The course was focused on differential topology and the study of smooth manifolds. It was taught by my now supervisor, but on a couple of the last lectures we had some guest appearances from the other topology professors at NTNU. One of these guest lectures is the focus of todays blog post.\nThe reason I still remember this particular lecture is because I left it understanding nothing. Some lectures takes some time to process, but this was not one of those. The information contained in the lecture was just so far above my head at the time, and it has taken me until now to understand it. I remember the lecture because it was inspiring, because I realized there is no cap on mathematical knowledge, because this is a field where one can always continue learning and never understanding it all. Not all lectures need to be understandable, or even exam-relevant (this one luckily wasn’t), some lectures just need to be inspiring and forward-looking.\nAnyways, below are my notes from that lecture. I have added some text to clarify some points and to make the post more cohesive, but the message and the theory is as written in the notes. If you want to see my actual notes for reference, you can find them here. You can also read the lecturers notes here. This material was presented in a 2×45 minute lecture, so details will be a bit sparse, and knowledge will mostly be presented on a need to know basis. As this comes from a lecture, the post is also somewhat long, so you are now officially warned.\nIntroduction to topology, 19.04.18\n2-dimensional topological quantum field theories A topological quantum field theory (TQFT) is a very rich topological gadget with many use cases. These objects encode many of the fundamental invariants that we associate to manifolds. More precisely, an n-dimensional TQFT is a symmetric monoidal functor $Z:nCob\\longrightarrow Vect_{\\mathbb{C}}$. Here the category $nCob$ is the category of $n$-dimensional manifolds and cobordisms, and the category $Vect_\\mathbb{C}$ is the category of complex vector spaces. The latter can be substituted by another linear category if wanted. When $n=2$ we have the following theorem.\nTheorem:  There is an equivalence of categories $2TQFT\\simeq cFA_{\\mathbb{C}}$, where $2TQFT$ is the category of 2-dimensional TQFTs and $cFA_\\mathbb{C}$ is the category of commutative Frobenius algebras.\nThe goal of the lecture, and hence this blog post, will be to understand the statement of this theorem. We will not present a proof. To make sense of the statement of the theorem we will need to do two things.\n Understand the formalism we use to present the statement, in this case categories, functors, symmetric monoidal categories, and equivalences of categories. Understand the presented objects and the statement itself, in this case cobordisms and commutative frobenius algebras.  Categorical preliminaries We begin with understanding the formalism used to present the theorem, namely category theory. We only present the few bits we actually need, but a proper understanding of this theory would probably be useful for all readers.\nDefinition:  A category $\\mathcal{C}$ consists of objects $A, B, C, \\ldots$ , and morphisms $A\\rightarrow B$. We write $A\\in \\mathcal{C}$ for objects and $f\\in \\mathcal{C}(A, B)$ or $f\\in Hom_{\\mathcal{C}}(A, B)$ alternatively for morphisms. These objects and morphisms must subject to the following axioms:\n Given $A\\rightarrow B$, $B\\rightarrow C$ we can compose them to get $A\\rightarrow C$ Composition is associative, i.e. for morphisms $A\\rightarrow B\\rightarrow C\\rightarrow D$ we have $h\\circ(g\\circ f) = (h\\circ g)\\circ f$ For every $A\\in \\mathcal{C}$ there is an identity morphism $id_A:A\\rightarrow A$, such that for any morphism $f:A\\rightarrow B$ we have $f\\circ id_A = f = id_B \\circ f$  Examples are $Vect_\\mathbb{C}$, the category of vector spaces over $\\mathbb{C}$ with linear maps and $Top$, the category of topological spaces with continuous maps.\nIn mathematics we are often, or almost always more interested in maps between things instead of the things themselves. Hence we need maps between categories, which are called functors.\nDefinition:  A functor $F:\\mathcal{C}\\longrightarrow \\mathcal{D}$ between two categories, consists of a map from the objects of $\\mathcal{C}$ to the objects of $\\mathcal{D}$, and a map $F_{A, B}: \\mathcal{C}(A, B)\\longrightarrow \\mathcal{D}(A, B)$, such that:\n Given $A\\rightarrow B\\rightarrow C$ in $\\mathcal{C}$, then $F_{A, C}(g\\circ f) = F_{B,C}(g)\\circ F_{A, B}(f)$ For every $A\\in \\mathcal{C}$ we have $F_{A,A}(id_A) = id_{F(A)}$.  As said, we are often interested in maps instead of objects, and the wonderful thing about category theory is that we can make sense of maps between other maps. If you are interested in such things I have a couple blog posts about higher category theory that flesches out this idea. Here we define maps between functors, which are called natural transformations.\nDefinition:  Let $F, G: \\mathcal{C}\\longrightarrow \\mathcal{D}$ be two functors. A natural transformation $\\eta:F\\Longrightarrow G$ assigns to each object $A\\in \\mathcal{C}$ a morphism $\\eta(A):F(A)\\longrightarrow G(A)$ in $\\mathcal{D}$, such that for each morphism $f:A\\longrightarrow B$ in $\\mathcal{C}$, we have $G_{A, B}(f)\\circ \\eta(A) = \\eta(B)\\circ F_{A,B}(f)$. We say $\\eta$ is a natural isomorphism if $\\eta(A)$ is an isomorphism for all $A$.\nThe reason we introduce these maps between maps, is because we want a way to compare categories to see if they are similar. In other fields of mathematics we usually define isomorphisms between objects to satisfy this need. These are usually defined to be maps $f:A\\longrightarrow B$ such that there exists a two sided inverse. In category theory however, it turns out that such isomorphisms between categories is a too strong notion of comparison, as they leave out categories we intuitively want to consider “the same”. In topology we also run into this problem, and we then can define homotopy equivalences instead. The following definition will hopefully be reminiscent of such types of “weaker” equivalences.\nWe say two categories\n$\\mathcal{C}$ and $\\mathcal{D}$ are equivalent if there exists two functors $F:\\mathcal{C}\\longrightarrow \\mathcal{D}$ and $G:\\mathcal{D}\\longrightarrow \\mathcal{C}$ such that $G\\circ F\\simeq id_\\mathcal{C}$ and $F\\circ G \\simeq id_\\mathcal{D}$.\nIf you want some more information on equivalences of categories I also have a post going into more details explaining why they are “more correct” than isomorphisms of categories.\nWe now have the basics covered, and will now start to add on more structure which we want later. We said that a TQFT was a symmetric monoidal functor, so we need to explain what we mean by that.\nDefinition:  A strict monoidal category $(\\mathcal{C}, \\otimes , I)$ is a category $\\mathcal{C}$ together with a functor $\\otimes:\\mathcal{C}\\times \\mathcal{C}\\longrightarrow \\mathcal{C}$ and an object $I\\in \\mathcal{C}$, such that $\\otimes$ is associative and $I$ is a left and a right unit for $\\otimes.$\nThis should be thought of as a not necessarily commutative product on the category. To make it nicer, i.e. introduce a notion of commutativity, we need the following definition.\nDefinition:  We say a strict monoidal category is symmetric if for each pair $A, B\\in \\mathcal{C}$ there is a twist map (also sometimes called a braid map) $\\tau_{A, B}:A\\otimes B\\longrightarrow B\\otimes A$ such that\n for any two maps $f:A\\longrightarrow A'$ and $g:B\\longrightarrow B'$ we have $g\\otimes f \\circ \\tau_{A. B} = \\tau_{A', B'}\\circ f\\otimes g$ for any triple $A, B, C \\in \\mathcal{C}$ we have $\\tau_{A, B\\otimes C} = \\tau_{A, B}\\otimes id_C \\circ id_B\\otimes \\tau_{A, C}$ for any pair $A, B\\in \\mathcal{C}$ we have $\\tau_{A, B}\\circ\\tau_{A, B} = id_{A\\otimes B}$.  As said above, this should be thought of as a commutative product on the category.\nThe last part of this categorical puzzle is to define a symmetric monoidal functor to be a functor between two symmetric monoidal categories such that the product structure is preserved. This can be thought of as being similar to group homomorphisms between abelian groups.\nCobordisms The next part of the puzzle is to define the different stuff used in the theorem we want to state. From here on out we will assume that all manifolds mentioned are smooth and compact. To define TQFTs we need two things; cobordisms and vector spaces. We assume the reader is familiar with vector spaces, so the remaining part are the cobordisms. We will however note that the category of vector spaces form a symmetric monoidal category with the tensor product operation on vector spaces. This is required for us to have a symmetric monoidal functor after all. Ok, over to the topology.\nLet $M, N$ be two oriented manifolds of dimension $n$. For example:\nA cobodism $W:M\\longrightarrow N$ is an oriented manifold $W$ of dimension $n+1$ such that $\\partial W = M\\coprod N$, for example\nCobordisms can be though of as evolving a manifold over time. It turns one manifold into another by some continuous, but somehow non-continuous process. If we chop the cobordism into slices we can play them after each other from start to finish and get a little movie for how the one manifolds twists, turns, bends, wobbles, splits, merges and deforms into another manifold. If you have ever seen the slice-images from scanning a brain from top to bottom you will hopefully get the picture.\nWe define $2Cob$ to be the category which has objects being closed oriented 1-dimensional manifolds and morphisms being orientation preserving boundary extending diffeomorphism classes of 2-dimensional cobordisms. This means that we consider two cobordisms $W_1, W_2: M\\longrightarrow N$ to be equivalent if there exists an orientation preserving diffeomorphism (smooth isomorphism) $f:W_1\\longrightarrow W_2$ that extends the isomorphism $\\partial W_1 \\cong M\\coprod N \\cong \\partial W_2$.\nFor any $M \\in 2Cob$, the identity morphism $id_M$ is given by $M\\times I$, where $I$ is the unit interval. Think about this a just a tube between the two manifolds. Composition of $W_1:M_1\\longrightarrow M_2$ and $W_2:M_2\\longrightarrow M_3$ is given by $W_1 \\coprod_{M_2} W_2$, i.e. gluing the two cobordisms together along their shared boundary $M_2$. Gluing together the following two cobordisms\nand\ngives us the new cobordism\nbetween $M_1$ and $M_3$. It is important to note that it is not trivial to give the composition the structure of a smooth manifold. It can be done in many different ways, but luckily for us they all produce equivalent cobordisms.\nWith this we have shown that $2Cob$ is in fact a category. If we let $\\otimes = \\coprod$, i.e. the normal disjoint union, then $(2Cob, \\coprod, \\emptyset )$ is a monoidal category, where $\\emptyset$ is the empty set. There is a diffeomorphism $M_1\\coprod M_2 \\longrightarrow M_2\\coprod M_1$. This diffeomorphism induces a cobordism $T: M_1\\coprod M_2 \\longrightarrow M_2\\coprod M_1$, which we call the twist cobordism. It can be visualized as\nRecall that all closed connected oriented 1-dimensional manifolds are equivalent to the circle. Hence the different manifolds, i.e. the objects in $2Cob$ are essentially just different amount of copies of the circle. This can be made more precise, but we will not need the entire formalism today. Instead we define a skeleton for $2Cob$ to be the full subcategory ${ 0, 1, 2, 3, \\ldots, n, \\ldots }$ with $n=\\coprod_n S^1$. By abuse of notation, we denote this category onwards by $2Cob$. It is important to note that the skeleton is equivalent as categories to the original category, but this new one is smaller and makes everything nicer and very much easier to draw!\nIn the drawings we have presented we notice that all the cobordisms seem to be built up from similar parts. They mostly seem to consist of tubes, splitting into more tubes or joining into fewer tubes. We will see that this is actually the case, but first we need a precise formulation of what this means.\nDefinition:  A generating set for a monoidal category $(\\mathcal{C}, \\otimes, I)$ is a set $S$ such that all morphisms in $\\mathcal{C}$ can be obtained from the elements in $S$ by composition or by $\\otimes$. If $S$ is a generating set, then we say $\\mathcal{C}$ is generated by $S$.\nThe point of the discussion we now go into is the fact that we can use the classification of surfaces to give an explicit description of $2Cob$ by generators and relations. This will allow us to say explicitly how the image of a functor $2Cob\\rightarrow Vect_\\mathbb{C}$ behaves.\nTheorem:  The category $2Cob$ is generated by the following six cobordisms, often called the basic cobordisms.\nThis means that we can build any cobordism from these easy to handle pieces! This also extends to the following definition, which just described a decomposition of a cobordism into elements of the generating set above. For simplicity of notation we say a cobordism $W:m\\longrightarrow n$ has $m$ in-boundaries, and $n$ out-boundaries. From a drawing standpoint this just means we have $m$ circles as boundaries on the left, and $n$ circles as boundaries on the right.\nDefinition:  The normal form of a connected surface with $m$ in-boundaries, $n$ out-boundaries and genus $g$, is the decomposition of the surface into a number of basic cobordisms. We can for example decompose the following cobordism\ninto the following union of basic cobordisms\nNotice that it has the same number of in-boundaries, out-boundaries and the same genus.\nThe relations we need to have our explicit description of $2Cob$ are called identity, unit and counit, associativity and coassociativity, commutativity and cocommutativity, Frobenius and twisting. Since the category is generated by six cobordisms, we only need to see what happens on combinations of these. Visually, these are the relations we need.\nThe identity relation says that composing with the identity cobordism, i.e. the cylinder $S^1\\times I$ does nothing. i.e.\nThe unit and counit relation looks like:\nHopefully the associativity relation (top) is somewhat recognizable, and the coassociativity (bottom) relation is just the dual of it, i.e.\nThe same goes for the commutativity relation (top) and the cocommutativity relation (bottom):\nThe last two are maybe a bit less common. The Frobenius relation looks like:\nAnd the twisting looks like:\nTogether the six basic cobordisms and the above relations make $2Cob$ into a really nice category to work with, as we can just draw everything we want.\n2-dim TQFT\u0026rsquo;s and $cFA_\\mathbb{C}$ We have now almost arrived at the statement of the theorem. To remind ourselves we again state the definitions of the main components in the theorem.\nDefinition:  A 2-dimentional topological quantum field theory (2-dim TQFT) is a symmetric monoidal functor $Z: 2Cob\\longrightarrow Vect_{\\mathbb{C}}$.\nThese functors form a category where the objects are the 2-dim TQFTs and the morphisms are natural transformations between them. Denote this category by $2TQFT$. The other category we need is the category of commutative Frobenius algebras. We haven’t actually defined what we mean by this yet, so lets do that.\nDefinition:  A commutative Frobenius algebra consists of a complex vector space $A$ together with a commutative and associative product $m:A\\times A\\longrightarrow A$ and a non-degenerate bilinear form $\\mu: A\\times A\\longrightarrow \\mathcal{C}$ such that $\\mu(m(a, b), c) = \\mu(a, m(b, c))$. We often write $m(a, b)$ as just $a\\cdot b$, and then the relation becomes $\\mu(a\\cdot b, c)=\\mu(a, b\\cdot c)$.\nThe most used examples of such algebras are matrix algebras $M_n(\\mathbb{C})$ where $\\mu(a, b)$ is the trace of their product, i.e. $\\mu(a, b)=tr(a\\cdot b)$.\nTo at least justify some part of the theorem, and see where the Frobenius algebras come into play we look at the following. Let $Z$ be a 2-dim TQFT. Then the image of the object $1=S^1$ in $2Cob$ hits some complex vector space, which we denote by $A$, i.e. $Z(S^1) = A$. Then $Z(n) = A^{\\otimes n} = A\\otimes \\cdots \\otimes A$ because $Z$ is symmetric monoidal. This also means that $Z(\\emptyset)=\\mathbb{C}$.\nFurther we have that $Z$ applied to morphisms in $2Cob$, i.e. the cobordisms, must produce morphisms between the different tensor products of $A$. For example:\nis a map between $A\\otimes A$ and $A$, because the cobordism is a morphism between $2$ and $1$. By the above relations this map is commutative and associative product, which makes $A$ into a commutative algebra with identity element given by\nThis is in fact the identity of the algebra product defined above, because of the unit relation. Moreover we have a map $A\\longrightarrow \\mathbb{C}$ given by\nand that the composition\nwhich we can denote by $\\mu$, is non-degenerate bilinear form on $A$. This means that we have a commutative associative product and a non-degenerate bilinear form on our vector space. The last piece of the puzzle comes from the Frobenius relation. This makes it so that $\\mu(a\\cdot b, c) = \\mu(a, b\\cdot c)$.\nHence $A$ is a commutative Frobenius algebra! This means that any vector space in the image of our 2-dim TQFT is in fact a commutative Frobenius algebra, and that we have a functor $F: 2TQFT\\longrightarrow cFA_\\mathbb{C}$ given by $F(Z) = Z(S^1$). The fact that every commutative Frobenius algebra arises this way is a lot harder to show and we will not cover it here. But it can be done, and once it is, we finally have our theorem:\nTheorem:  The category of 2-dimentional topological quantum field theories, $2TQFT$, is equivalent to the category of commutative Frobenius algebras, i.e.\n$$2TQFT \\simeq cFA_\\mathbb{C}.$$\n","permalink":"https://torgeiraamboe.github.io/posts/2021/a-lecture-in-my-second-year/","summary":"For those that don’t know I am a fifth year mathematics student at NTNU, meaning I am finishing my masters degree after this semester. During my time at NTNU I have had some wonderful classes, and some wonderful teachers. Since most I post about on this blog is related to topology, it is very safe to assume that some of my most memorable courses are exactly the topology courses. I very recently looked at my notes from my first topology course, or rather one of the two first, as I took two in parallel during my fourth semester.","title":"A lecture in my second year"},{"content":"Last year I posted a blog post where we looked at a way to use elementary homotopy theory to hang a picture on the wall in a stupid way. The task was to hang a picture on two nails in such a way that if we pull one of the nails out, the picture falls down. “That is stupid” I hear you say, but premise is as premise does, or something similar quoted from Forrest Gump. I remarked then that I had seen the problem a couple years earlier, and I actually recently found were, which is how this blog post got made. I initially came across the problem from a video by a YouTube channel called GoldPlatedGoof. I watched the video again recently and decided to look around math-YouTube for other videos on the problem. There I came across one similar, and a bit less rigorous video by Matt Parker and Steve Mould. They solved it similarly to the original one, i.e. by using commutators, which is formalized by using the fundamental groups we did last time when posting about this. More interestingly I came across a video by Tom Scott and Jade Tan-Holmes which used a completely different (yet actually the same) method for solving it. Jade used knots and braid diagrams to produce a solution for the problem, which inspired me to make this post. We are also going to solve the problem using knots. The overall tactic will be roughly the same as Jades, but the method and the proof will be a bit different. The post has turned out to be quite long, but there are many pictures, and not that much text!\nTo solve the problem we have to go a bit further than knots. We have to introduce a bit more complicated theory, called links. These mathematical objects are essentially multiple knots together in a system, possibly linked together, hence the name. Lets see an example. Last time we visually represented knots by their knot diagrams, and similarly we visualize links by their link diagrams, which are just several interplaying knot diagrams.\nThis link is called the Hopf-link, and consists of two unknots, ie. just two circles, linked together. A bit more complicated link is\nwhich is just a scribble, and does not have a name (that I know of). The different parts of the link is called the link components. The Hopf-link then has two components, both being the unknot, while the scribble has three components.\nSo, how can we use links to solve our problem? Lets remind our selves of the problem visually.\nWe need some way to create a link from the system consisting of the painting, the string and the two nails, i.e. a reformulation of the problem into link-theory. The way we are going to do this is to remove the non-important part of the system, as well as replacing some other parts by something equivalent. The only irrelevant part is actually the painting. It contributes nothing to the problem. If we hang a closed loop on the two nails, the problem is equivalent. A solution to one of them is automatically a solution to the other, hence we can remove the painting and just use the closed loop, i.e.\nThis produces one component of our link, but we still need more. An important insight here is that the closed loop can be wound either clockwise or anti-clockwise around each of the nails. Is there another objects that allows for two different ways to interact? There is, and it is in fact another closed loop, i.e. the unknot! We can understand this by seeing that a string can pass through the unknot either from below, or from above in the link diagram, like in the following pictures\nWhen winding a string around a nail we have the property that a clockwise followed by an anti-clockwise turn cancels each other out, similarly for the other way around. In passing a string in and out of an unknot we also have this property. If we first pass over, and then under we cancel out, and the result is no linking. This is maybe a bit hard to think about, so lets see it visually.\nHence we can replace the two nails in the original problem by two more unknots. To have a totally equivalent problem we need one more restriction. The two nails in the original problem have no way of interacting with each other, and hence we must require this from the two unknots we replaced them with as well. This means that without the closed loop initially holding the picture, the two remaining loops are unlinked, i.e.\nNow we finally have our equivalent system; three unknots where at least two of them are unlinked. Lets visualize what one attempt of hanging the picture would be in this equivalent reformulated system.\nOk, so how does this new system affect the statement of the problem? The reformulated problem becomes; Can we find a link consisting of three unknots such that if we remove one of them the two others are unlinked? Notice that this formulation satisfies the restriction we gave, as removing the loop originally holding the painting results in two unlinked unknots. It also means that if we remove one of the loops that used to be a nail, the two other loops, i.e. the painting-hanging loop and the other nail-loop are unlinked. This means that in the original formulation the picture would not be hanging on the remaining nail, and hence the picture would fall down. So, finding such a link would indeed solve the original problem.\nThere is in fact a famous link which satisfy this property. It is named after a medieval family who used the link as their family sigil. This is of course the Borromean link.\nWhen we looked at knots last time we spent some time on tricolorability to prove that there exists knots that are not the unknot. The same theory applies to links. We can color the strands of each component in the link diagram, and the property of being tricolorable is invariant under the Reidemeister moves we can apply to the link. To quickly recap, a knot (or link) is tricolorable if we can color each strand in such a way that minimum two colors are used, and at every crossing, either all three colors are represented, or just one color is. We gave the following example last time of a tricolorable knot:\nSo, lets use this to prove that the Borromean links are linked, and that removing one components results in two unlinked unknots. This will show that the Borromean link is an answer to the problem. Lets first see that three unknots, is tricolorable. This is easy to se as we can simply color each of them by one color each.\nFor the Borromean link to not be equivalent to the three unknots we must show that it is not tricolorable. This will mean that there is no set of Reidemeister moves we can do to turn the Borromean link into the three unknots, meaning that it is in fact linked. Lets try to tricolor it. It is actually a nice exercise to prove this, so if you want to try it your self I would recommend it before continuing.\nWe start by randomly assigning a color to a strand, for example\nThis strand will be one of the two strands that make up one of the unknots in the link. If we color the other part of the same unknot with the same color, we see immediately by following the tricolorability rules that every strand must be the same color. This does not produce a tricoloring as we must use at least two colors. Hence we must chose some other color for the second part of that circle.\nNow we have two crossings where we have two colors represented, meaning that the last strand in the crossings must be the last color. We are then left with the following\nBy the crossing furthest to the right we see that the biggest strand that is left must be green, but by the left-most crossing that is not colored, we see that the smallest strand must also be green, i.e.\nBut this does not make a tricoloring of the link. This happens no matter which strand we started with, and no matter the color. Hence the Borromean link is not tricolorable, and can not be equivalent to the three unknots. What remains is to see what happens when we remove one of the loops from the link. We get\nThese we can easily see are all respectively equivalent to two unknots.\nWe have shown that the Borromean link satisfies being a linked link, such that removing any component results in two unlinked unknots. Hence it is a solution to the translated problem! We are not going to translate back to the original problem, because this produces the same commutator solution we did last time and hence is not very much fun. This post has already been long enough…\nFurther remarks This problem has many interesting related concepts to it from many different fields of mathematics and other fields outside it. These two blog-posts have been focused on topology and a bit on algebra, but it shows up other places as well. For example in complex analysis, where it is related to the Pochhammer contour. This contour is just the curve we got last time by using the commutator in the fundamental group. I forgot to mention it last time, but the commutator path is homologous to the trivial path, but not homotopic to it, so this problem also serves as an insight into the differences between homology and homotopy.\nThe Borromean link we used today is also intimately connected with this problem. It is also connected to several other things, like balanced tournaments (rock, paper, scissors), higher linked atoms in physics and more. This interesting article sheds some relatively easily digestible light on the connection with rock, paper, scissors.\n","permalink":"https://torgeiraamboe.github.io/posts/2021/hanging-pictures-with-knots/","summary":"Last year I posted a blog post where we looked at a way to use elementary homotopy theory to hang a picture on the wall in a stupid way. The task was to hang a picture on two nails in such a way that if we pull one of the nails out, the picture falls down. “That is stupid” I hear you say, but premise is as premise does, or something similar quoted from Forrest Gump.","title":"Hanging pictures with knots"},{"content":"Something I have been looking into a bit lately, due to it sadly not being taught at my university is knot theory. This is something I have always known to be a part of topology, and have known to have interesting applications in physics, medicine, chemistry and more. So to rectify the situation I thought I would prove that knots exist. It was also nice to take a brake from all the higher category theory we have been looking into lately!\nA knot is defined to be an embedding of the circle $S^1$ into $\\mathbb{R}^3$, so immediately we have proven our statement since the identity is an embedding. Hence we at least have one knot, called the unknot or the trivial knot, being just the circle itself. This is of course trivial, so the question “are there knots?” is better phrased as “are there other knots than the unknot?”. This question is not trivial and requires a proof, which is what we are doing today. We say two knots are the same, or are equivalent, if we can transform one into the other by transforming the space $\\mathbb{R}^3$ they are embedded in. These transformations are called ambient isotopies, and corresponds to manipulating the knot without cutting or letting parts of the knot pass through itself.\nReidemeister moves A nice property of knot theory is that it is a very graphical and visual theory. Everything (at least for us) happens in a low dimension, so we can always draw what we mean. We defined a knot to be an embedding of the circle into Euclidean three-space, but a nice way to draw them are called knot projections, or knot diagrams. This is just the projection of the knot into the plane, where we keep track of the crossings. Lets give an example. The following knot is called the figure-eight knot (maybe you can see why).\nWhen we talk about a knot for the rest of this post, we will mean the knot diagram of a knot. Even though we call it a knot, we still don’t know if we can deform, twist and turn this so that it becomes the unknot. A first attempt at distinguishing any knot from the unknot might be to try to count the crossings in its knot diagram. The unknot has no crossings, so any knot with crossings should be a different knot right? Sadly its not that easy. Notice that we can also have something equivalent to the unknot with any number of crossings, by simply twisting the unknot as many times as we need. Since, this simple twisting does not change the knot, we can’t use it to distinguish them either. We call this twisting the type-1 Reidemeister move, and it can be depicted by the drawing below. Remember here that we are only looking at a section of a knot, and not the whole knot.\nThere are two more of these moves that does not change the knot. We call these the type-2 and type-3 Reidemeister moves. The type-2 Reidemeister move can be though of as pulling back a strand that lies over another, and can be visualized as below.\nThe type-3 Reidemeister move can be thought of as pulling a strand over another crossing. This is maybe the most difficult move to intuitively agree that does not change the type of the knot. It can be visualized as below.\nOk, so how does these moves help us? Since they do not change the type of the knot, we can use them to get from one knot to another equivalent knot. Hence, two knots are equivalent is there is a sequence of Reidemeister moves connecting them. This fact is a famous theorem by the man Kurt Reidemeister himself.\nTricolorability You maybe notices that I used a word we haven’t yet defined, i.e. a strand. A strand is defined to be the part of a knot diagram going from one under-crossing to the next. This is again best seen by a drawing. I have colored one of the four strands in the figure-eight knot seen earlier.\nThere are an equal number of strands as there are crossings. We are now ready to define the machinery that will allow us to prove that there is a knot that is not the unknot. This machinery is called tricolorability. We say a knot can be tricolored, or is tricolorable, if we can color all its strands using three colors, such that at least two colors are used and such that at each crossing, either all colors are present, or only one is present. Lets check if our only two knots, the unknot and the figure-eight knot are tricolorable. In its simplest form, i.e. just the circle, we se that the unknot is not tricolorable, as a coloring of its unique strand only has one color. We will get back to the fact that all possible knots that are equal to the unknot must also be not tricolorable. What about the figure-eight knot? We start by trying to fill it in after the rules. We chose the same color orange for the middle strand that we colored earlier. Now, to follow the rules, either all three strands present in the central crossing must be orange, or two more must be present. If we try all orange we get\nand we see that the last strand also has to be orange, which means we failed to use at least two colors. Ok, lets try to have three different colors present at the central crossing. We then get\nwhere we see that if we must follow the second rule, the last strand must be all three colors at once. This is because it must be orange at its upper end, green at the blue-orange upper crossing, and blue at the bottom crossing. We are only allowed to color each strand once so we have actually proven that the figure-eight knot is not tricolorable.\nThere is something we have swept under the rug here so far, and that is showing that the Reidemeister moves doesn’t affect a knots tricolorability. If it did, then tricolorability wouldn’t be an invariant of the knot type, which is bad for showing two thing are the same or that two things are different.\nSince these moves are performed “inside” a knot, we must require that the beginnings and ends of the drawn strands have the same color both before and after the move. This is to make sure that we are only looking at the actual move affecting tricolorablity, and not changing something else about the knot colorwise. For the type-1 Reidemeister move, notice that we can only use one color both before and after the move, i.e.\nHence, if a knot is tricolorable, performing a type-1 Reidemeister move will not change that fact. For the Type-2 Reidemeister move, we notice that after we perform the move, we must have two separate strands, which means we can either have two different colors, or only one color. If we let both have the same color we assume that there is some other color elsewhere in the knot, not being affected by the move. We can them color the system with all same color before doing the move, so that case is fine. If we chose the two different colors, we get\nwhich shows that the tricolorability is preserved. For the type-3 Reidemeister move we can also choose the same color everywhere, in the same way as for the type-2 move. But, if we choose to tricolor the system using different colors, we get\nwhich still preserves the tricolorability! We have shown that Reidemeister moves does not affect the tricolorability of a knot, and hence that tricolorability is a knot invariant. This means that any knot equivalent to the unknot or the figure-eight knot is not tricolorable. This means that we cant use this machinery to show that the figure-eight knot is not the unknot, as they both are not tricolorable. But, it also mean that all we have to do to prove that knots different from the unknot exist, is to prove that there exists knots that are tricolorable! And this we can prove by example. I wont go for the standard example of a tricolorable knot, and we will instead show that the so-called Granny knot, is tricolorable. The Granny knot is the following knot:\nAnd all we have to do to prove that it is tricolorable is to find a tricoloring. This is as easy as just picking a strand to color in some color and following the rules. I then got the following coloring of the Granny knot\nwhich by inspection satisfies all the rules of a tricoloring of the knot. Hence, we have finally showed that there are knots! So the answer to the question in the title is yes.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/there-are-knots/","summary":"Something I have been looking into a bit lately, due to it sadly not being taught at my university is knot theory. This is something I have always known to be a part of topology, and have known to have interesting applications in physics, medicine, chemistry and more. So to rectify the situation I thought I would prove that knots exist. It was also nice to take a brake from all the higher category theory we have been looking into lately!","title":"Are there knots?"},{"content":"A couple weeks ago I held a talk on introductory higher category theory. Most of the talk was based upon thing we already have discussed on this blog, such as the strict $2$-category $Cat$, bicategories, and why strictness fails for the category of topological spaces. The inly thing I talked about which I haven’t yet featured on this blog is the notion of quasi-categories, so I though that I would do that today. So, to see where we are headed, I just define it right away.\nDefinition (quasi-category): A quasi-category is a simplicial set where every inner horn has a filler.\nThis definition is incredibly short and sweet, but packs a serious punch once we unravel it. It is also often stated as a quasi-category being a simplicial set satisfying the weak Kan condition. There are many ways to intuitively justify the existence of quasi-categories, and one of them we almost already know. We have previously discussed $\\infty$-groupoids as just topological spaces through the homotopy hypothesis. From Quillen we know that the homotopy theory of topological spaces and the homotopy theory of simplicial sets are equivalent. More precisely, the category of topological spaces is Quillen equivalent to the category of simplicial sets. Instead of $\\infty$-groupoids—which are $(\\infty, 0)$-categories as every morphism of every degree is invertible up to a coherent homotopy—we can talk about $(\\infty, 1)$-categories. These are intuitively a collection of objects and morphisms such that all homsets are $\\infty$-groupoids. The most classical example being just the category of topological spaces, or more generally categories enriched in topological spaces, often called topological categories. Now we maybe start to see an idea of why quasi-categories are defined through simplicial sets. We can pass over to categories enriched in simplicial spaces, which gets us a bit closer to the definition, but not quite.\nI want to remark that the above section is only for broad intuition, and that I’m both shoving an incredible load of details under the rug, and lack a solid understanding of the technicalities. But, for me at least, it gives a picture of why we care about introducing simplicial sets into higher category theory, without going through the whole nerve of a category business.\nSimplicial sets Time to start unraveling the definition. I said a quasi-category was a simplicial set, so this is probably a good place to start. To define a simplicial set we first need to define the simplex category $\\Delta$.\nDefinition (the simplex category): The simplex category $\\Delta$ is the category consisting of all finite totally ordered sets with (non-strict) order preserving maps. We write the objects as $[n] = {0,1,2,3, \\ldots}$.\nThe category $\\Delta$ is generated by two important classes of maps, called the face maps and the degeneracy maps. The $i$‘th face map $\\delta_n^i$ is defined as the unique order preserving injection $\\delta_n^i: [n-1]\\longrightarrow [n]$ that misses $i$ and the $i$‘th degeneracy map $\\sigma_n^i$ is defined as the unique surjection $\\sigma_n^i:[n]\\longrightarrow [n-1]$ that hits $i$ twice.\nDefinition (simplicial set): A simplicial set is a functor $X: \\Delta^{op} \\longrightarrow Set$. We write $X_n = X([n])$ and call it the $n$-simplicies of $X$.\nThese again form a category, $sSet$ where the morphisms are the natural transformations between the simplicial sets.\nThe most important examples of simplicial sets are the so-called standard $n$-simplexes $\\Delta^n$. These are defined to be $\\Delta^n = Hom([n], -)$, where the functor $Hom([n], – )$ is on the opposite category, so we can use it as $Hom(-, [n])$ on the normal simplex category. These standard simplexes are the simplest ones to think about and the simplest to visualize. This is because we can apply the geometric realization functor, and these become the familiar $n$-simplexes we use in topology! Hence we can think of for example $\\Delta^3$ as\nDue to the Yoneda lemma, the $n$-simplicies of a simplicial set $X$ are in one to one correspondence with maps $\\Delta^n \\longrightarrow X$ in the category of simplicial sets.\nWe have now covered what a quasi-category consists of, namely a simplicial set. So, next we need to understand the condition we put on that simplicial set.\nHorns and fillers The condition we asked for included another simplicial set we need to define, namely the the simplicial $k$-horns. These are very similar to the standard simplices, but are missing one of the sides. To be rigorous we define the $i$‘th side of $\\delta^n$ to be the image of $\\Delta^{n-1}$ under the inclusion $\\iota_i$ onto the side of $\\Delta^n$ opposite to $i$. The $0$‘th side of $\\Delta^3$ under the geometric realization functor would then be the orange side in the following picture.\nWe then use these sides to construct what we call simplicial horns.\nDefinition (The simplicial k-horn): The simplicial $k$-horn is the union of all sides of $\\Delta^n$ except the $k$‘th one, i.e.\n$$\\Lambda_k^n = \\bigcup_{i\\neq k} Im(\\iota_i:\\Delta^{n-1}\\longrightarrow \\Delta^n). $$\nA $k$-horn in a simplicial set $X$ is then a map $\\Lambda_k^n \\longrightarrow X$. We call it an inner horn if $0\u0026lt;k\u0026lt;n$.\nWe wanted these $k$-horns in our simplicial set to satisfy a condition, which we called the weak Kan condition. This condition tells us that certain lifts of maps related to the $k$-horns in a simplicial set $X$ exists. We have a canonical inclusion from the simplicial $k$-horn into $\\Delta^n$ and we want there to exist a lift through this map for every inner horn in $X$, i.e. that the dotted map exists\nIf such a lift exists for all inner horns in a simplicial set $X$ we say it satisfies the weak Kan condition. We have now unrolled the definition, and we can state it with a bit more insight.\nDefinition (quasi-category): A quasi-category is a simplicial set $X$ such that every horn $\\Lambda_k^n \\longrightarrow X$ lifts to a map $\\Delta^n\\longrightarrow X$ through the canonical inclusion $\\Lambda_k^n\\subset \\Delta^n$.\nSo what does this definition really mean? What does this even have to do with categories? The connecting piece is interpreting horns as composable morphisms in a category. The easiest to visualize is the lift of the horn $\\Lambda_1^2$. If we draw it it looks like\nand an existing lift means there exists a dotted map\nmaking the triangle commute up to a higher morphism. In other words, we have some weaker form of composition of composable morphisms in the quasi-category. There may be many different ways to compose the morphisms, to we can’t talk about “the” composition, but all of the different compositions are related by higher morphisms. In this way we can view a quasi-category as a weaker notion of category, where we have morphisms that compose non-uniquely, and have an infinite tower of morphisms between morphisms to relate the compositions and higher relations. If we insist that the lift in the weak Kan condition is unique, we actually have an object we can use as a definition for a category, hence quasi-categories generalize categories, which is what we wanted, and justifies the word “quasi” being put in front.\nThat was all I wanted to say today, but we will definitely revisit quasi-categories later as the theory built by Lurie and Joyal around these objects are too interesting to not look deeper into!\n","permalink":"https://torgeiraamboe.github.io/posts/2020/quasi-categories/","summary":"A couple weeks ago I held a talk on introductory higher category theory. Most of the talk was based upon thing we already have discussed on this blog, such as the strict $2$-category $Cat$, bicategories, and why strictness fails for the category of topological spaces. The inly thing I talked about which I haven’t yet featured on this blog is the notion of quasi-categories, so I though that I would do that today.","title":"Quasi-categories"},{"content":"You may be thinking, what the heck is a monoid, and why the heck is it vertical? To explain this we will need some insight into classical categories and $2$-categories, which we luckily have been developing for the last few posts. First off, to let the familiar readers know, the objects of study today is called monads, not vertical monoids. But, I like to visualize them and think about them as somehow vertical, or at least something not strictly horizontal or one-dimensional.\nNot everyone is familiar with monoids, so to set the stage for the rest of the post we define a monoid to be a set $M$ together with a map $\\mu:M\\times M\\longrightarrow M$ and a distinguished element $1 \\in M$ such that $m(a, 1) = a = m(1, a)$ and $m(m(a, b), c) = m(a, m(b, c))$ for all $a, b, c \\in M$. This makes m an associative multiplication on $M$ with a two-sided unit $1$. We can kind of think about a monoid as a group without inverses, but pulling all intuition from groups might turn out bad.\nWe can define more general versions of monoids by using category theory. This makes use of monoidal categories, which we have talked about a little while ago. A monoid in a monoidal category $(\\mathcal{C}, \\otimes, I)$ is an object $M$ together with a map $\\mu:M\\otimes M\\longrightarrow M$, called multiplication, and a map $\\eta: I\\longrightarrow M$, called the unit, such that the associative law and left and right unit laws hold.\nHere $\\alpha$ is the associator in the monoidal category and $\\lambda$, $\\rho$ are the unitors. These are described a bit in the previously mentioned post. We see that this notion of monoid in a monoidal category is essentially equal to the one previously stated using sets, in fact the first definition is the same as a monoid in the monoidal category of sets, $Set$.\nIf we recall back to the discussion about $2$-categories in the earlier post about the homotopy hypothesis, we defined what we called vertical composition of $2$-morphisms. This notion of vertical is the reason for saying that monads are somehow vertical monoids. If we draw $1$-morphisms horizontally, as we usually do, then we can draw $2$-morphisms vertically.\nWhich makes this whole notion of vertical composition a bit more graphical. In a $2$-category $\\mathcal{C}$ we always have a category $B(X, Y)$ of morphisms between objects. If we restrict ourselves to $1$-endomorphisms we can define a monoid in the monoidal category $B(X, X)$. Here the monoidal structure comes from composition of $1$-endomorphisms. If we recall what we need in order to have a monoidal category, we need a product (which here is horizonal composition), a unit (which here is the identity $1$-morphism $id_X$ at an object $X$), an associator and two unitors, that respectively satisfy the pentagon identity and the triangle identity. This is already ingrained into the definition of a $2$-category, and is made very explicit in the model we presented, i.e. bicategories. A monoid in this monoidal category of $1$-endomorphisms is the definition of a monad in a $2$-category. To make this even more explicit, and to summarize a kind of wild paragraph, we present a rigorous definition.\nDefinition (Monad): A monad $(X, T, \\mu, \\eta)$ consists of an object $X$, a $1$-endomorphism $T$, i.e. an object in the category of endomorphisms $B(X, X)$ together with two $2$-morphisms $\\mu: T\\circ T\\longrightarrow T$ and $\\eta: Id_X\\longrightarrow T$, such that the diagrams\nand\ncommute.\nIn the more classical setting, the definition of a monad comes from endofunctors of categories, i.e. $1$-endomorphisms in the category of categories, $Cat$. The most important, or at least some important examples of such monads comes from adjunctions. In fact every adjunction pair $(F, G)$ defines a monad. Here $G\\circ F$ defines an endofunctor $T=G\\circ F: \\mathcal{C}\\longrightarrow \\mathcal{C}$, the adjunction unit is a natural transformation $\\eta: Id_{\\mathcal{C}}\\longrightarrow G\\circ F$ and the monad multiplication comes from the adjunction counit $\\epsilon$ by\n$$\\mu: T\\circ T = G\\circ F\\circ G\\circ F \\overset{id_G \\circ \\epsilon \\circ id_F}\\longrightarrow G\\circ F = T$$\nThis monad kind of measures the failure of the adjoint pair $(F, G)$ to be an equivalence of categories.\nThe classical definition of a monoid i.e. the one using just sets can also be reformulated in this setting by letting our $2$-category have only one object, letting $1$-morphisms be sets where composition of sets is the cartesian product, and the $2$-morphisms be morphisms of sets. A monad in this category is then just a monoid. This idea is from John Baez, who also talks about connections to Feynman diagrams in physics in his posts. I don’t know enough physics to explore this now, but maybe another time.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/vertical-monoids/","summary":"You may be thinking, what the heck is a monoid, and why the heck is it vertical? To explain this we will need some insight into classical categories and $2$-categories, which we luckily have been developing for the last few posts. First off, to let the familiar readers know, the objects of study today is called monads, not vertical monoids. But, I like to visualize them and think about them as somehow vertical, or at least something not strictly horizontal or one-dimensional.","title":"Vertical monoids"},{"content":"Last fall I held a talk about functors, natural transformations and equivalences of categories. This talk was part two of five in a student seminar on introductory category theory. There was mostly second year students attending but also a couple more experienced students. To make the talk a bit interesting for them as well I said that an equivalence of categories is the correct notion of “sameness” of categories, and not isomorphisms due to the fact that categories naturally lie in a $2$-category. An isomorphism of categories would be the correct notion of sameness if the category of categories had only trivial $2$-categorical structure, and we didn’t have to worry about higher morphisms. In this post I want to look at this statement and show that it is true.\nMotivation and hand waving Last post we talked a bit about $2$-categories and the differences between strict and weak $2$-categories. We introduced these through $Cat$, the category of (small) categories, which we discovered was a strict $2$-category. We also defined a bicategory, which is a way to explicitly describe a weak $2$-category. It can be smart to read that post to have some familiarity with the notion of $2$-categories. Since strict $2$-categories are special cases of weak $2$-categories, I will for simply use the term $2$-category instead of explicitly referring to one of them for most of this post.\nIn normal category theory we have for long understood that objects are not to be classified using equality, but some weaker notion of equivalence, usually called isomorphisms. For example in the category of abelian groups we want to use the first isomorphism theorem. This says that the image of a group homomorphism $f:G\\longrightarrow H$, is isomorphic to the domain modulo the kernel of the homomorphism. These two groups are essentially the same, i.e. the induced morphism on the quotient $\\overline{f}:G/Ker(f)\\longrightarrow Im(f)$ is an isomorphism. If we were only allowed to talk about groups being equal, this would not be a useful theorem, and our theory in general would not be as rich. So, we have learned that equality of objects is a bad notion in a standard category.\nClassical theory To understand what equivalences and isomorphisms of categories are, and how they relate to this higher $2$-categorical structure, we need to look at their classical definitions.\nDefinition (Isomorphism of categories): A functor $F:\\mathcal{C}\\longrightarrow \\mathcal{D}$ is called an isomorphism of categories if there exists a functor $G:\\mathcal{D}\\longrightarrow \\mathcal{C}$ such that $G\\circ F= id_{\\mathcal{C}}$ and $F\\circ G = id_{\\mathcal{D}}$.\nTo use a very suggesting notation, we let $=$ denote that the diagram commutes. Then we can express the definition as the two following diagrams.\nNote in particular that we have equalities $G\\circ F = Id_{\\mathcal{C}}$ and $F\\circ G = Id_{\\mathcal{D}}$. This is of course just because of composition, but remember that existence of composition is an axiom in the definition of a category. A priori, if we didn’t know we lived in a category, composition may not be defined. We could of course do two things in succession, but this does not a priori define a map. For example, if our objects are the points on a topological space, and the maps are paths parametrized by the unit interval, then composition of two paths is no longer a morphism, since it requires a twice as long interval. This can be fixed by a homotopy, but if we don\u0026rsquo;t pass to homotopy-classes if paths we will have undefined composition. This remark will become more important in a bit. Similarly we state the classical definition of an equivalence of categories.\nDefinition (Equivalence of categories): A functor $F:\\mathcal{C}\\longrightarrow \\mathcal{D}$ is called an equivalence of categories if there exists a functor $G:\\mathcal{D}\\longrightarrow \\mathcal{C}$ and two natural isomorphisms $\\eta$ and $\\epsilon$, such that $G\\circ F \\overset{\\eta}\\implies id_{\\mathcal{C}}$ and $F\\circ G \\overset{\\epsilon}\\implies id_{\\mathcal{D}}$.\nTo again use very leading diagram drawings, we can express the definition through the following two diagrams.\nIf we recall back to last post, we said that the category of (small) categories, $Cat$, naturally had the structure of a strict $2$-category, but a $2$-category nevertheless. This structure came from letting the objects be the categories, the $1$-morphisms be the functors and the $2$-morphisms be the natural transformations. But, we can also have another $2$-category structure on $Cat$, namely the trivial one. Any category is trivially a strict $2$-category, just by letting all $2$-morphisms be trivial, i.e. equalities. This is of course strict since composition of $1$-morphisms, i.e. normal morphisms in the category are associative by definition. Now we are starting to form the full picture of the statement, namely that the difference between equivalences of categories and isomorphisms is the choice of the canonical or the trivial $2$-category structure on $Cat$.\nEquivalences in 2-categories The last piece of the puzzle is the following discussion. In a general $2$-category, say described by a bicategory, we have objects, i.e. $0$-cells, and categories of morphisms between them. Thus, as we have learned in the hand waving part, it is bad to talk about equality between the $1$-cells in a bicategory, as they themselves are objects in a category. So what would we then want to describe very similar $1$-cells? Since the $1$-cells and $2$-cells are respectively objects and morphisms in a category, we have the notion of a $2$-cell being an isomorphism. This means that it is invertible on the nose. Since $2$-cells aren’t the objects in some category, we can easily talk about equality between them, and invertible then means that we have an actual inverse. Hence we can define very similar $2$-cells to be the $2$-cells that are invertible up to a $2$-cell isomorphism. This is called an equivalence in a $2$-category.\nDefinition (Equivalence in a 2-category): Let $A, B$ be $0$-cells in a bicategory $\\mathcal{C}$. A $1$-cell in $\\mathcal{C}$, i.e. an object $f:A\\longrightarrow B$ in the category $\\mathcal{C}(A, B)$, is called an equivalence if there exists a $1$-cell in $\\mathcal{C}(B, A)$, $g:B\\longrightarrow A$ and two isomorphism $2$-cells $\\alpha: g\\circ f\\implies id_A$ and $\\beta f\\circ g \\implies id_B$.\nMaybe a “new” cool drawing makes things simpler, more intuitive and hopefully more familiar.\nThese diagrams mysteriously look very similar to the ones defining equivalences of categories. The diagrams also visualize a bit better why we call the different pieces $0$, $1$ and $2$-cells, as they operate in the same way n-cells do in topology, especially simplicial sets. If we let our $2$-category be $Cat$ with the trivial $2$-morphisms, we see that an equivalence in that $2$-category is nothing but an isomorphism, since the $2$-isomorphism connecting the composition and the identity is the “equality morphism”. In the canonical $2$-category structure on $Cat$ we see that an equivalence in that $2$-category is an equivalence of categories, since the composition is connected to the identity functors by a $2$-isomorphism, also called a natural isomorphism in the classical setting.\nThis is the full picture, and we have explained what we set out to do!\n","permalink":"https://torgeiraamboe.github.io/posts/2020/equivalences-of-categories/","summary":"Last fall I held a talk about functors, natural transformations and equivalences of categories. This talk was part two of five in a student seminar on introductory category theory. There was mostly second year students attending but also a couple more experienced students. To make the talk a bit interesting for them as well I said that an equivalence of categories is the correct notion of “sameness” of categories, and not isomorphisms due to the fact that categories naturally lie in a $2$-category.","title":"Equivalence of categories"},{"content":"A litmus test is a question asked in politics to a potential candidate for high office in which the answer determines if the person gets nominated or not. If a person or a committee holds the power of nominating candidates, they can use that power to make sure that a potential candidate holds their view on a certain matter. So, what does this have to do with mathematics, or especially with homotopy theory? There is a question worth asking certain objects to check if they should be allowed to be a suitable “definition” for a certain nice structure. The question, or test, which we will look more closely at soon, first started as a conjecture by Grothendieck, named later “the homotopy hypothesis”. This conjecture is still open in the way formulated by Grothendieck, but it can be turned on its head to form this test instead. The reason this is possible is because of ambiguity in a certain definition in higher category theory, and because there is seemingly many inequivalent “definitions” for the same object. Before exploring any theory at all, the conjecture states that $\\infty$-groupoids are equivalent to topological spaces. The litmus test then becomes; $X$ is considered a definition of $\\infty$-groupoids if and only if all $X$s’ are equivalent to topological spaces.\nMotivation Before jumping into definitions and theory, I wanted to first give a little motivation to why we are going past normal categories, and why stuff with the $\\infty$ prefix are interesting to study. As I understand it, the main reason to do $\\infty$ -stuff is to make “less strict” versions of our familiar objects from normal abstract algebra, and it turns out that the correct definition of “less strict” kind of means “up to homotopy”. This will hopefully become apparent throughout this post. The main $\\infty$ -object in this post will be $\\infty$ -groupoids, and it acts as one of the fundamental higher objects in homotopy theory, and it is of course the star of the beforementioned litmus test.\nThe motivating example for studying so-called higher categories is the category of categories, denoted $Cat$. Or, to avoid nasty set theoretic Russel paradox business, we actually define it as the category of small categories. Here the objects are (small) categories, and the morphisms are functors. As we have learned in regular category theory, there also exists morphisms between functors, called natural transformations. Hence we have more types of things in this new type of category. We have two types of morphisms, which we simply call $1$-morphisms, which are the functors in this case, and $2$-morphisms, which are the natural transformations. Since $2$ is the highest we have in this setting, we call it a $2$-category. From normal category theory we also know that the collection of functors between two categories form a category themselves, so we can also think about a $2$-category as a category where all the homsets are themselves categories. When we discussed cosmoi, we defined what we called an enriched category, and this is exactly what a $2$-category is, a category enriched over $Cat$. We can do this because $Cat$ is monoidal under the Cartesian product. This definition actually makes what we define as strict $2$-categories. These are categories where composition of $1$-morphisms has to be associative on the nose, because they are the morphisms of a category, i.e. strictly associative. This also means that strict $2$-categories actually also are normal categories with more information. We can then iteratively define a strict $n$-category to be a category enriched in a strict $(n-1)$-category. These strict versions are easy to define, and are nice to work with, but turns out to rarely show up in nature. As we mentioned, we want to have less strict versions of algebraic objects, not keep going with the same stuff.\nWeak higher categories The question then becomes; how do we define a non-strict, or more often called a weak $2$-category? This is not obvious, and require us to choose how to do it. Intuitively we want a $2$-category to be a collection of objects together with $1$-morphisms and $2$-morphisms, such that compositions of $1$-morphisms are associative up to invertible $2$-morphisms, but formalizing this in an exact definition is not trivial. One solution is called bicategories. These are created by weakening the notion of enrichment, and calling a bicategory a category weakly enriched in $Cat$. This is the oldest, and most used definition of a weak $2$-category.\nDefinition (Bicategory): A bicategory is a structure consisting of\n a collection of objects, often called $0$-cells for each pair of $0$-cells $x, y$, a category $B(x, y)$, whose objects are called $1$-cells and whose morphisms are called $2$-cells for each $0$-cell $x$ there is a distinguished $1$-cell $1_x \\in B(x,x)$ called the identity $1$-cell at $x$ for each triple of $0$-cells $x,y,z$ a functor $C_{x, y, z}: B(x, y)\\times B(y, z)\\longrightarrow B(x, z)$ which sends a pair of $1$-cells $(g, f) \\longmapsto g\\circ f$, called horizontal composition, and pairs of $2$-cells $(\\epsilon, \\eta )\\longmapsto \\epsilon \\ast \\eta$, called vertical composition for each pair of $0$-cells $x, y$ natural isomorphisms $l: f\\circ 1_x \\longrightarrow f$ and $r: 1_y \\circ f \\longrightarrow f$ called the left and right unitor respectively for each quadruple of $0$-cells $w, x, y, z$ a natural isomorphism $\\alpha: B(y, z)\\times B(x, y)\\times B(w, x) \\longrightarrow B(w, z)$ built from the functor $\\circ$, called the associator  such that the unitors satisfy the triangle identity\nand the associators satisfy the pentagon identity\nThis definition is a mouthful, but it shows how intricate the definitions of these higher objects can become. And remember, this is only a weak $2$-category. Imagine how many relations there are for even higher structures. The good thing is that we don’t have to imagine. We simply have to find another way of representing these objects with more familiar terms. We have to model them by something else. So for example for an $(\\infty, 1)$-category, there are already objects that behave in the way we want, and we just have to use the already well defined structure. We wont go through these in detail in this post, as I am saving them for a bit later. But, to mention one and the most used model for an $(\\infty, 1)$-category, which is an $\\infty$-category where all $k$-morphisms are weakly invertible for $k\\geq 2$, is called quasi-categories. These are special types of simplicial sets, and can be defined with little trouble. The theory of higher categories mainly consists of theory for $(\\infty, 1)$-categories, and mainly through the model of quasi-categories. We can define an $(\\infty, n)$-category sort of to be a category weakly enriched in $(\\infty, n-1)$-categories, which means that to understand $(\\infty, 1)$-categories, we need to understand $(\\infty, 0)$-categories, which are the $\\infty$-groupoids.\n$\\infty$-groupoids To describe the litmus test, we luckily only need one of the simpler $\\infty$-categories. For normal categories, one of the simplest types is the ones where all morphisms are invertible, i.e. groupoids. If we carry this logic over to our new setting, an $\\infty$-groupoid should be an $\\infty$-category where all of the $k$-morphisms are invertible up to an invertible $(k+1)$-morphism, which makes sense since we said they were the $(\\infty, 0)$-categories.\nAs we have seen, having all these higher morphisms comes with a lot of troubles, the most prominent one being how we are supposed to make a proper definition when we are required to make infinite choices for composition laws. So here we want to model $\\infty$-groupoids using other more familiar objects. We started by saying that “less strict” roughly means “up to homotopy” which hinted at the fact that we can use topological spaces and their homotopy theory to help us on the way.\nIf we take a topological space $X$, it has a category associated to it, namely the fundamental groupoid $\\Pi_1 X$. This is a category where the objects are all the points in $X$ and the morphisms are homotopy classes of paths between points. If we instead of homotopy classes use just paths as morphisms, the composition, i.e. concatenation of paths, becomes invertible up to homotopy. And this homotopy is invertible up to homotopy, and so we can continue ad infinitum. This category is called the fundamental $\\infty$-groupoid of $X$. So, if we define $1$-morphisms to be paths, $2$-morphisms to be homotopies of paths, $3$-morphisms to be homotopies of homotopies of paths etc, we get that topological spaces satisfy the intuitive definition we had of an $\\infty$-groupoid.\nThis is where the litmus test finally comes into play. This description of $\\infty$-groupoids as topological spaces is very nice, but there could be other models that serve other purposes. The litmus test then tells us that any suitable definition of $\\infty$-groupoids, i.e. any chosen model, should produce a category $\\infty grpd$, which is equivalent to $Top$, the category of topological spaces, i.e. $\\infty grpd \\simeq Top$. Any notion of $\\infty$-groupoids can then be interpreted as just drawing diagrams between dots by using paths and homotopies on a topological space, and the geometry of the topological space determines which paths can have homotopies between them etc.\nThis also tells us that any definition, or model of $\\infty$-groupoids will produce our familiar homotopy theory, which gives us many different views on the already familiar classical theory.\nThere are already many such models, and they are used for different things. One of the more used ones are Kan complexes, which are simplicial sets where every horn has a filler. There are also globular sets, marked simplicial sets, algebraic Kan complexes, etc. We will maybe see some of these later when we discuss $(\\infty, 1)$-categories. But, for now this is what I wanted to say about the homotopy hypothesis.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/the-homotopy-litmus-test/","summary":"A litmus test is a question asked in politics to a potential candidate for high office in which the answer determines if the person gets nominated or not. If a person or a committee holds the power of nominating candidates, they can use that power to make sure that a potential candidate holds their view on a certain matter. So, what does this have to do with mathematics, or especially with homotopy theory?","title":"The homotopy litmus test"},{"content":"Since one of my main mathematical interests is homotopy theory, im bound to often bump into things that require the use of base-points. This has long been the classical way to study spaces, especially in terms of homotopy groups. When I was introduced to these so-called pointed spaces, I couldn’t help but feel that these we less natural, or more ad hoc, than regular spaces. I didn’t know much about categories then, but have since learned it is usually in this context that some form of naturality occur. It turns out that pointed spaces actually come from a very nice natural categorical construction, which of course is the focus of this post. I will assume introductory knowledge of categories, and I will try to keep this short for once.\nDefinition As the name implies, we will have something like “a category under some object”, but we will have to make this precise of course. Under categories are also sometimes called coslice categories, and they are in fact a special case of a construction called comma categories, which we will not cover today. The idea is roughly to fix an object, and study morphisms out of said fixed object instead the object itself. This will hopefully be clear from the definition.\nDefinition (Under category): Let $\\mathcal{C}$ be a category, and $c$ an object in it. The under category $c\\downarrow \\mathcal{C}$ is a category whose objects are all morphisms $f_A: c\\rightarrow A$ that start at $c$, and whose morphisms are commuting triangles of the form\nIt then (at least for me) makes intuitively sense that we call it the under category, since it consists off all things happening “under” an object $c$ in some nice way. It is in fact a category, since it has identity morphisms\nfor any object $f:c\\rightarrow A$ in the category, and composition of morphisms are associative because the commutivity of the inner triangles in the following diagram imply the commutivity of the outer triangle.\nThis is all we need in order to call $c\\downarrow \\mathcal{C}$ a category.\nExamples Our motivation was to create pointed topological spaces, so how do we get these as an under category? The category of pointed topological spaces with base-point preserving maps, is precisely the category $\\ast \\downarrow Top$ of topological spaces under a one point space! How can we see this? Any object in the under category is a map $b_A$ from a point to a space $A$. Call the image $x=b_A(\\ast)$ of this map the base-point of the space $X$. This information is exactly the same as having a space with a specified point $(X, x)$, i.e. an object in the category of pointed topological spaces. Also, maps in this under category are maps that commute with the formation of these base-points, i.e. diagrams\nwhich in terms of just the pointed spaces are maps that preserve the chosen base-points in the two spaces $A$ and $B$, because $f(b_A(\\ast))=b_B(\\ast)$, i.e. base-point preserving maps. Hence we have a nice categorical description of pointed spaces, and they are an example of a very natural construction. Neat!\nAnother example is the category of algebras over a ring. To recap the definition, an algebra over a ring $R$, also called an $R$-algebra, is a ring $A$ together with a ring map $s_A: R\\rightarrow A$, making it into an $R$-module in a compatible way. This is maybe starting to look familiar to the previous example. An $R$-algebra morphism is, now not surprisingly, a ring map between two $R$-algebras, such that it commutes with their respective map from $R$, i.e. a map such that\ncommutes. Hence, the category of $R$-algebras, is the under category $R\\downarrow Rings$ in the category of rings.\nIt said I would keep this short, so I wont say anything more for now. I will mention that the semester has started again, so not much time to write on the blog… But, I have started writing my master thesis, so maybe Ill do some writing here about what I write about there, or some progress updates etc. Time will tell.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/under-category/","summary":"Since one of my main mathematical interests is homotopy theory, im bound to often bump into things that require the use of base-points. This has long been the classical way to study spaces, especially in terms of homotopy groups. When I was introduced to these so-called pointed spaces, I couldn’t help but feel that these we less natural, or more ad hoc, than regular spaces. I didn’t know much about categories then, but have since learned it is usually in this context that some form of naturality occur.","title":"Under category"},{"content":"This post is part two of a little two-part miniseries about defining the cosmos. To learn what a cosmos is in mathematics, or rather what we want it to be, you can read the first part. There we described a cosmos as a nice place to enrich a category, or a nice place to do enriched category theory, and to quickly recap, an enriched category is a category where we have objects of morphisms instead of just a collection of them, and these objects come from some monoidal category. In this post we will continue the story, and focus more on the definition rather than the setup.\nOk, since we have already decided we want to do enriched category theory, and a cosmos is supposed to be a nice category to enrich over, we already know at least two properties a cosmos must have.\n It must be a category That category must be monoidal  Now we at least have some base line for what a cosmos is! We began the introduction to a cosmos by comparing it to its brother in physics, and maybe it would be fun to continue this path. In physics one wants to be able to study the smallest building blocks, and the largest structures. We would kind of like to be able to “zoom in” and “zoom out” as much as we want, and both see the small local picture and the bigger picture.\nThe big, and the small The above analogy is maybe a bit of a stretch, but I think the intuition still kind of holds if we still want to pretend that we are using motivation from physics. In mathematics, and especially in this kind of abstract algebra, looking at the small and looking at the big is called limits and colimits. As said, this analogy is not perfect, as limits and colimits capture much more than just zooming in and out. They kind of capture the structure of seing the smaller and bigger picture, and they do so in every way possible. They are also somewhat difficult to grasp, but we will try our best.\nA diagam in a category $\\mathcal{C}$ can be thought of as a functor $D$ from a category $J$ to $\\mathcal{C}$, where we think of $J$ as a sort of indexing category, or a “shape” category. This means that $J$ determines the indexing, and where we have arrows in our diagram in $\\mathcal{C}$. Hence we sometimes reffer to such a diagram to have shape $J$. The diagram is then a collection of objects in $\\mathcal{C}$, that are indexed by the objects in $J$, and also has the same “pattern” or “shape” as $J$. If $J$ is a small category, i.e. both the collection of objects form a set, and all the collections of morphisms form sets, then we call $D$ a small diagram.\nDefinition (Cone and cocone): Let $D$ be a diagram in $\\mathcal{C}$ with the shape of $J$. A cone $(N, \\psi)$ to $D$ is an object $N$ in $\\mathcal{C}$ together with a collection of morphisms $\\psi_X : N\\longrightarrow D(X)$ indexed by the objects $X$ in $J$, such that for every morphism $f:X\\longrightarrow Y$ in $J$, we have $D(f) \\circ \\psi_X = \\psi_Y$, i.e. the diagram\ncommutes for all such $f$. Dually, a cocone $(M, \\mu)$ to $D$ is an object $M$ together with a collection of morphisms $\\mu_X : D(X)\\longrightarrow M$ indexed by the objects $J$, such that for every morphism $f:X\\longrightarrow Y$ in $J$, we have $\\mu_Y \\circ D(f) = \\mu_X$, i.e. the diagram\ncommutes for all such $f$.\nUnderstanding these cones and cocones is often the difficult part of understanding limits and colimits. There exists weird diagrams, and understanding the cone of one of these weird diagrams as an object itself is in my opinion often difficult. We wont dwelwe too much on these objects, but the reader should look at some examples like products, direct sums, disjoint unions, terminal and initial objects, and check that these are cones or cocones (ther are actually also limits or colimits). This also hints at the fact that limits are cones, and colimits are cocones, which will show up in the definition. They are kind of the biggest cones, and smallest cocones. This will also hopefully become clear from the definition.\nDefinition (Limit): A limit of a diagram $D$ in a category $\\mathcal{C}$ in the shape of $J$ is a universal cone $(L, \\phi)$ to $D$. This means that every other cone $(N, \\psi)$ uniquely factors through it, i.e. there exists a unique morphism $u: N\\longrightarrow L$ such that $\\phi_X \\circ u = \\psi_X$ for all $X$ in $J$. Or in a diagram form:\nIf the diagram is small, we call the limit a small limit.\nDefintion (Colimit): Similarily, a colimit of a diagram $D$ in a category $\\mathcal{C}$ in the shape of $J$ is a universal cocone $(L, \\phi)$ to $D$. In the same way as for the limit, this means that any other cocone factors uniquely through it. Or in a diagram form:\nIf the diagram is small we call the colimit a small colimit.\nIt is important to note that limits and colimits of a diagram need not always exist in a given category, but in the nice ones we usually work in, most likely they exist. A category where all small limits exists is called a complete category, and dually, a category where all small colimits exists is called cocomplete. Some authors call a category bicomplete if the category is both complete and cocomplete. In fact we did this when discussing model categories, which are bicomplete categories with a model structure.\nClosed categories We are actually almost done, but we are missing one final property, and that is a property called closedness. For a category to be closed, we need that everything regarding the category is a part of the category. This is a bit vague, but the simple intuitive definition is that not only the objects in the category are objects, but the collections of morphisms also are objects in the category. We can also think of this as the category being enriched over it self, which if we remember back to the examples of enriched categories, was something that a couple nice categories had, like Abelian groups and vector spaces. These are often categories one would like to mimic, or at least have categories that act as nicely as them. Since the game we are playing is enriched category theory, it might be smart that the category we enrich over, i.e. a cosmos, is also a kind of trivial enriched category, and this is exactly the case because of this property.\nClosedness is formalized by the notion of internal homs. From the intuitive definition, this should be some sort of way to compare the collections of morphisms to objects in the category. More precisely, an internal hom is a functor $[-,-]: \\mathcal{C}^{op} \\times \\mathcal{C} \\longrightarrow \\mathcal{C}$, that kind of works as a collection of morphisms. Every locally small category that has an internal hom functor has a forgetful functor to the category of sets, that sends the internal hom to the actual set of morphisms.\nDefinition (Closed category): A closed category is a category $\\mathcal{C}$ together with an unit object $I$ and an internal hom functor $[-,-]$, such that there are nice morphisms $L: [B, C]\\rightarrow [[A, B], [A, C]]$, $i_A: A\\rightarrow [I, A]$ and $j_A: I\\rightarrow [A, A]$, for three different definitions of nice respectively. What exactly the different “nice” morphisms are will not be covered here, because we wont need them for our definition of a cosmos. This is because when uniting the different structures we have, these nice maps becomes apart of a more known structure.\nWe have now defined all the structures that we need to state the definition of a cosmos. But, since we now have several structures at the same time, we need to make sure that these structures play nice together. As a recap, we recall that the structures we have are, category, monoidal, symmetry, complete, cocomplete and closedness. Luckily for us, the limits and colimits are not actually a structure of the category, but more like a property that we have internally. It says something about which objects exists, but not about structure. So these fit together with the other ones for free!\nFrom both the monoidal structure and from the closedness, we have a unit object, $I$. If we want a nice category that makes sense these two unit objects should of course be the same. Some of the structure is motivated, or at least inspired from the category of sets, where we have $[X,Y]={ f:X\\rightarrow Y}$ and\n$$Hom(S, [X, Y])\\cong Hom(S\\times X, Y).$$\nSo to carry this motivation further, we require that the internal hom functor $[X,-]$ is right adjoint to the monoidal product functor $-\\otimes X$ . Hence, in a closed and monoidal category we have a bijection $Hom(A, [X, Y])\\rightarrow Hom(A\\otimes X, Y)$, that is natural in all three variables. This map is often called “currying”, and is used in for example $\\lambda$-calculus, type theory and categorical logic. When this is the case, we concatenate the two structures and call the category a closed monoidal category, or sometimes a monoidal closed category.\nDefinition So, we have now defined everything, and united the structures. The journey has been long, and the concepts plenty, but we have finally arrived. To sum up the entire discussion, we will finally define a cosmos, more specifically Bénabou\u0026rsquo;s definition of a cosmos. This definition shows that a one sentence definition can take a long time to formulate, and a long time to process.\nDefinition (Cosmos): A cosmos is a bicomplete closed symmetric monoidal category $\\mathcal{C}$.\nWe havent really explored why this definition satisfies what we claimed at the introduction last time, i.e. that cosmoi are nice places to do enriched category theory, but trying to study it has made me realize it may be out of my reach as of now. I find the subject really interesting, so Ill try to visit back at this theory at a later time. Hopefully then we can explore how enriched categories over a cosmos behaves like normal category theory. Anyway, for now, this is it.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/defining-the-cosmos-2/","summary":"This post is part two of a little two-part miniseries about defining the cosmos. To learn what a cosmos is in mathematics, or rather what we want it to be, you can read the first part. There we described a cosmos as a nice place to enrich a category, or a nice place to do enriched category theory, and to quickly recap, an enriched category is a category where we have objects of morphisms instead of just a collection of them, and these objects come from some monoidal category.","title":"Defining the cosmos: Properties and definition"},{"content":"I think there are many parts of physics worth studying for mathematicians, and the physical notion of a cosmos may be one of them, but, this post is not about physics. Even though the usual field of study one thinks of when hearing the word “cosmos” is physics, there is also a type of mathematical object with the same name. This type of object does have that name for a reason, which is not clear maybe from the object it self, but from what one can do with and in such an object. In physics, the cosmos is a word for the universe, but it includes also the universes structure. The cosmos is not just “all the stuff that exists”, but also their relations and complex interactions. It is therefore kind of the background, or the playing field of physics.\nA cosmos in mathematics is also a kind of nice playing field for mathematics. More specifically ncatlab says it is “a nice place to do category theory”. But what does this mean? Well, it is kind of complicated, but we will try to understand some of it. To be more precise without explaining anything more, one could say the idea is that the theory of categories enriched over a cosmos behave similarly to standard category theory itself. Much of this theory is still way above my head, so Ill try to keep it grounded. That said, we need to understand what an enriched category is to tell the story of the cosmos properly. This is the goal for this post, and next time we will come back to looking at what properties a cosmos should have for our above statement to be true. Throughout we will try our best to pretend that the definition is motivated by physics.\nMore structure Often when doing category theory or homological algebra we often find that we need some restrictions on our category to make it nicer to work with, or to have more nice properties. First of all we often note that it is usually enough to work in locally small categories, i.e. categories where the collection of morphisms between two objects always form a set. Many authors even require this for their definition of a category. Sets in themselves are not always exciting enough, so we often require that these sets of morphisms have some structure, often an algebraic one. This is intuitively exactly what an enriched category is, i.e. some category where all sets of morphisms are actually objects in some other fixed category, i.e. we have objects of morphisms. Hence we can talk about categories “enriched over” another category, or sometimes authors use “enriched in” instead.\nWe see quite quickly that the category from where we steal our objects of morphisms needs to have at least one property. In a category we need to be able to compose morphisms, and when these morphisms come from an object, their composition also must come from an object, and hence we need some way to take the product of objects. This is formalized by the category being a monoidal category, i.e. a category where we have some sort of product that behave nicely. This is easier said than done, and the following long definition reflects that.\nDefinition (Monoidal category): A monoidal category is a category $\\mathcal{C}$ equipped with a functor $\\otimes : \\mathcal{C} \\times \\mathcal{C} \\rightarrow \\mathcal{C},$ called the monoidal product, a unit object $1\\in \\mathcal{C}$ and three natural isomorphisms $\\lambda_A : 1\\otimes A \\rightarrow A$, $\\rho_A : A\\otimes 1\\rightarrow A$ and $\\alpha_{A,B,C} : (A\\otimes B)\\otimes C \\rightarrow A\\otimes (B\\otimes C)$ called the left unitor, right unitor and associator respectively, such that the following diagrams\ncalled the triangle identity, and\ncalled the pentagon identity, both commute.\nThe definition seems very difficult, and has a lot of moving parts, but in reality it is quite simple. We are using the symbol for the tensor product, $\\otimes$ for the monoidal product because the tensor product is usually the product we are using. So any intuition we have from using the tensor product can usually be applied to monoidal categories. If the three natural isomorphisms $\\lambda, \\rho, \\alpha$ are identities, then $\\mathcal{C}$ is called a strict monoidal category. These do rarely come up in nature, but every monoidal category is in fact equivalent to a strict monoidal category.\nA version of the monoidal category we will be using is actually a bit nicer, and comes with an extra bit of information, namely symmetry.\nDefinition (Symmetric monoidal category): Let $\\mathcal{C}$ be a monoidal category. We say $\\mathcal{C}$ is a symmetric monoidal category if there is a natural isomorphism $\\beta_{X,Y}: X\\otimes Y \\rightarrow Y \\otimes X$, called the braid isomorphism, such that $\\beta_{X,Y}\\circ \\beta_{Y,X} = id_{X\\otimes Y}$ and the following diagrams\ncalled the unit coherence, and\ncalled the associativity coherence, both commute.\nJust to mention it, there is a version of this type of category where we relax the definition a bit, such that the composition $\\beta_{X,Y}\\circ \\beta_{Y,X}$ is not the identity. This is then called a braided monoidal category, and is often used in knot theory.\nTo have some quick examples, most categories that appear in the wild are symmetric monoidal. For example the category of sets with the regular cartesian product is symmetric monoidal, the category of groups with the cartesian product is symmetric monoidal, and the category of finite dimensional vector spaces with the tensor product is symmetric monoidal.\nEnriched categories So, with that definition under our belt, we are ready to tackle the next definition, which is really what we want to understand, namely enriched categories.\nDefinition (Enriched category): Let $\\mathcal{V}$ be a monoidal category. A $\\mathcal{V}$-category $\\mathcal{C}$, or a category enriched over $\\mathcal{V}$, consists of a collection of objects, denoted $Ob\\mathcal{C}$, and for every pair $A,B$ of objects in $\\mathcal{C}$ we have an object $C(A,B) \\in \\mathcal{V}$, called the hom object, or the object of morphisms. These collections must satisfy that for any object $A$ in $\\mathcal{C}$ there is a morphism $j_A : 1\\rightarrow C(A,A)$ called the identity element, and for every triple of objects $A, B, C$ in $\\mathcal{C}$ there is a morphism $\\circ_{A,B,C}: C(B,C)\\otimes C(A,B)\\rightarrow C(A,C)$ called composition such that the following three diagrams commute.\nWhich expresses the associativity of composition,\nand\nwhere the latter two replace our standard notion of identity morphism with a more appropriate one when using the identity object 1 from our monoidal category $\\mathcal{V}$.\nWe see that our intuitive notion of an enriched category took quite a long time to explain, and had a lot of bits and pieces that needs to be correct. But, our intuitive explanation, i.e. a category where we have objects of morphisms instead of just collections of morphisms is still the nice way of thinking about these abstract complicated mathematical structures. To have a couple examples, we first look at the part we mentioned in the introduction, that we usually require our category to be locally small. Here our potential class of morphisms that usually define a category is required to be sets. So, we have taken sets, which form a monoidal category $Set$ under the cartesian product, and stolen them for our hom objects, i.e. a locally small category is just a $Set$-category, or a category enriched in Set. This is the first stepping stone to realizing that maybe enriched categories are nice to work with after all!\nIf we want some algebraic structures on these sets, we can instead enrich our category over the category of abelian groups, which is monoidal under the tensor product when viewing them as $\\mathbb{Z}$-modules. These categories are the pre-additive categories. Familiar examples such as the category of abelian groups, the category of modules over a commutative ring and the category of vector spaces are actually all enriched over themselves, as their morphisms all form objects in the category. There are of course some more wacky examples, such as viewing a generalized type of metric space as a category enriched over the poset $([0,\\infty], \\geq)$ of extended real numbers, where the monoidal product is just standard addition. An example related to this is a recent paper by (among others) of one of my favorite math-bloggers Math3ma, which used a similar idea to try to understand language as a category enriched over the unit interval with multiplication as the monoidal product. She and her collaborator did this by having the hom-objects be the conditional probability $p(s'|s)$ that $s$ is a subsequence of the sequence $s'$, and use this to understand something which I didn’t understand.\nAs you can tell, the possibilities, and the examples are many and diverse. But we are not merely interested in these enriched categories. We are interested in which objects it is nice to enrich over. This will be done in part 2 of this mini series, where we explore the remaining pieces to defining a cosmos, and at the end hopefully define it in all its glory. To hint a bit at where we are heading, we want to define $\\mathcal{V}-Cat$ of categories enriched over $\\mathcal{V}$, and that this category behaves like a standard category, i.e. we have nice morphisms, natural transformations, a Yoneda lemma, equivalences and adjunctions etc. We will not prove that all of these have an enriched version, but interested readers can study “Basic concepts of enriched category theory” by G.M. Kelly.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/defining-the-cosmos-1/","summary":"I think there are many parts of physics worth studying for mathematicians, and the physical notion of a cosmos may be one of them, but, this post is not about physics. Even though the usual field of study one thinks of when hearing the word “cosmos” is physics, there is also a type of mathematical object with the same name. This type of object does have that name for a reason, which is not clear maybe from the object it self, but from what one can do with and in such an object.","title":"Defining the cosmos: Enriched category theory"},{"content":"The last few posts have all been of relatively long length and have all taken some time to construct and write. I initially also wanted to produce shorter posts just discussing an example or a calculation etc, and today I tried to do just that, but failed. The post became somewhat longer than intended, but it is really informal and intuitive, so its fine in my opinion.\nIn a previous post we discussed both weak homotopy equivalences and regular homotopy equivalences, and we have also encountered the Whitehead theorem, which says that any weak homotopy equivalence between CW-complexes is in fact a regular homotopy equivalence. But, we did not discuss their differences, which is what we do in this post.\nAnyone who have studied some topology has encountered the classical counter-example used to prove that not all connected topological spaces are path connected, namely the “topologist sine curve”. We can use this space to construct a space which is weakly contractible, i.e. weakly homotopy equivalent to a point, but not contractible, i.e. homotopy equivalent to a point. Hence this space is a counter example to Whiteheads theorem for non-CW-complexes, and shows that that assumption is crucial for the theorem to hold. Recall that a map is called a weak homotopy equivalence if it induces an isomorphism on every homotopy group, and that it is called a homotopy equivalence if there exists a homotopy inverse, i.e. some map such that their composition both ways is homotopic to the respecive identity maps.\nThe what circle? The counter-example we will construct is called the Warsaw circle, and intuitively, it is a topologist sine curve sewn together to form something similar to a circle. Or equivalently, taking a circle, removing a segment, and replacing it with the topologist sine curve.\nTo have a formal mathematical construction, we can construct it as\n$$S_W = { (x, sin(\\pi/x)) , | , 0 \u0026lt; x \\leq 1 } \\cup {(0,y) , | , -1 \\leq y \\leq 1 } \\cup C $$\nwhere $C$ is a continuous curve in the plane connecting $(1,0)$ to $(0,0)$ without intersecting the other parts of the Warsaw circle. The curious thing about this construction is that the Warsaw circle, $S_W$ is actually path connected, which the topologist sine curve is not. The problem on the topologist sine curve is that a non-zero point can’t be connected to $(0,0)$ in the curve, but on the Warsaw circle, you can just go around the other way.\nNow, choose a map that sends the one-point space into the Warsaw circle. Since they are both path-connected spaces, they both have a trivial zeroth homotopy group, or equivalently just one path component. The one-point space has the rest of its homotopy groups trivial as well, and it is hopefully clear that the only possible non-zero homotopy group of the Warsaw sircle is its fundamental group.\nA shitty intro to shape theory To show (rather non-rigouously) that the fundamental group of the Warsaw circle is trivial, we are going to use shape theory, invented (I think) by Karol Borsuk in the 60’s. One more modern interpretation of shape theory is that it is to Čech homology the same as homotopy theory is to singular homology. As such, it is sometimes called Čech homotopy theory instead of shape theory. Čech homotopy has been developed a bit further, and is a bit more general to my understanding, but still this view holds strong if we don\u0026rsquo;t care about their relationship to cohomology. Anyway… Shape theory is the study of spaces that can be embedded in the Hilbert cube\n$$Q = \\prod \\left[-\\frac{1}{n}, \\frac{1}{n} \\right] $$\nand special maps called shape maps between them. Essentially, two spaces are shape equivalent if they are homotopy equivalent when we “thicken” them by some amount. If we thicken the Warsaw circle, it does no longer have that weird topological sine curve bit. This is because that whole infinitely tight together mess is now just a nice blob, and the thickened Warsaw circle is hence homotopy equivalent to the thickened normal circle, which is homotopy equivalent to the standard sircle $S^1$.\nSince the Warsaw circle it is not shape equivalent to a point, it cannot be homotopy equivalent to a point. To relate back to the theory hinted at, this shape equivalence says that both the Warsaw circle and the normal circle both have a non trivial first Čech homotopy group, and that they are isomorphic in the Borsuk shape category.\nThis is all very imprecise and non-rigorous, but if we think about what an element in the fundamental group would be if it was not trivial, it would be a path from the basepoint (the image of the one-point space) to itself, which is not the constant path. For such a path to exist, it has to travel through the topologist sine curve, which we know it cant do, since the topologist sine curve is not path connected. Hence it makes sense intuitively that there should be no such path, and hence that the fundamental group of the Warsaw circle is trivial.\nThis post became a bit longer than expected, and was maybe a bit less precise than I intended, but I think it was still fun and valuable.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/the-warsaw-circle/","summary":"The last few posts have all been of relatively long length and have all taken some time to construct and write. I initially also wanted to produce shorter posts just discussing an example or a calculation etc, and today I tried to do just that, but failed. The post became somewhat longer than intended, but it is really informal and intuitive, so its fine in my opinion.\nIn a previous post we discussed both weak homotopy equivalences and regular homotopy equivalences, and we have also encountered the Whitehead theorem, which says that any weak homotopy equivalence between CW-complexes is in fact a regular homotopy equivalence.","title":"The Warsaw circle"},{"content":"For quite some time I have occasionally stumbled onto the Wikipedia page for orbifolds while looking at topology related mathematics. I have always been fascinated by them, and always though that they certainly will come up during studies at university, but they never have (at least not yet). On said wikipedia page it says that the word orbifold is short for “orbit manifold” and that these orbifolds are in fact a generalization of manifolds.\nIn this post we will focus on smooth orbifolds as these are nicer to draw, and are a nicer introduction to the objects. These will then be generalizations or smooth manifolds. So, one of first things to ask is maybe why smooth manifolds need generalizing at all? Smooth manifolds in them selves are very nice objects and are used all over mathematics, physics, robotics and more, but they can be a bit restrictive. Many natural objects have so-called singularities, or singular point. Take for example a pillow case. It has four such singular points, namely the four corners.\nThese types of points are not allowed on a smooth manifold, because there has to be a neighborhood around every point that looks like euclidean space. Smooth orbifolds however, allow these types of points and several other types of “irregularities” that are not allowed on smooth manifolds. They are actually much more general than this, and their full generality is to me still not understood. Orbifolds have been abstracted and made “nicer” by using heavier mathematical machinery (étale Lie groupoids or Deligne-Mumford stacks), but the classical definition is still worth discussing and learning, which is what we will attempt today.\nSo, the two questions I want to answer today is; What is a smooth orbifold? And how do they generalize smooth manifolds? Maybe sometime in the future we will study them closer and ask more nuanced questions.\nPreliminaries Recall that a manifold is a nice topological space that locally looks like Euclidean space. More precisely, around every point, there exists and open subset around it and a homeomorphism, called a chart, from that open subset to an open subset of Euclidean space. If all these homeomorphisms are in fact smooth maps, i.e. diffeomorphisms, then the manifold is called a smooth manifold. To motivate the future definition of a smooth orbifold a bit, we look at what can happen to Euclidean space when taking quotients by a group action. Don’t worry if you don’t know these terms yet, they will be explained later, but try to understand what is happening by looking at the pictures.\nLet $\\mathcal{M}=\\mathbb{R}^2$ and let $G=\\mathbb{Z}\\times \\mathbb{Z}$ act on $\\mathcal{M}$ by $(n, m) \\cdot (a, b) = (a+n, b+m)$, i.e. as a lattice. If we take their quotient, $\\mathcal{M}/G$ we get something that still has a smooth structure. In fact we get the torus. This is quite easy to think through, but it is maybe even easier by a visual “guide”.\nThe torus is a smooth manifold, so we have produces a nice object that is locally diffeomorphic to the object we started with. If we instead let $G = \\mathbb{Z}_4$ and let it act on $\\mathcal{M}$ by rotation around origin, we suddenly get something that does not have a smooth structure. We get a cone.\nThese are both examples of orbifolds, and they also hint at the fact that orbifolds generalize manifolds. To have a nice intuitive definition, akin that of the intuitive definition of a manifold, we can say that an orbifold is a nice topological space that locally looks like Euclidean space modulo some linear action from a finite group (or more general, a group acting properly discontinuously).\nWe have already used terms like “a group acting on a space” and “quotient by a group action”. To make sure we understand these before delving into the technicalities, we do some repetitions on a couple definitions.\nDefinition (group action): Let $X$ be a set and $G$ a group. A group action from $G$ on $X$ is a map $\\alpha : G\\times X\\rightarrow X$ such that $\\alpha (e,x)=x$ and $\\alpha (g,\\alpha (h,x)) = \\alpha (gh,x)$ for all $g,h\\in G$ and $x\\in X$. The action is also often just denoted $gx$. If $X$ is a topological space, a group action is called properly discontinuous if for every $x\\in X$ there exists an open neighborhood around $x$ such that $\\alpha (g, U) \\cap U \\neq \\emptyset$ for only a finite number of $g\\in G$. This holds trivially true for all finite groups.\nDefinition (quotient space): Let $X$ be a set and $G$ a group acting on $X$. We call the set $G_x = { gx\\in X , | , g\\in G}$ the orbit of $x$. We can form an equivalence relation on $X$ by saying two elements are equivalent if they are in the same orbit. The quotient of $X$ by that relation is called the orbit space, or the quotient space $X/G$. When $X$ is a topological space, the orbit space has a natural topology given by the quotient topology, and hence it is also a topological space.\nSo, the orbit space of a topological space is always a topological space. But, is the orbit space of a smooth manifold always a smooth manifold? No, we saw that in the examples with the cone, but the orbit space of a smooth manifold is always an orbifold!\nWhat is an orbifold? We have already made an intuitive definition, along the lines of the intuitive definition of a manifold. But, as all who have done manifold theory properly, there are some small details needed to make the intuitive definition precise, like charts and atlases. The same holds for orbifolds.\nDefinition (Smooth orbifold): A smooth orbifold $\\mathcal{O}$ is a Hausdorff topological space $X_{\\mathcal{O}}$ together with a covering ${U_k}$ such that for any element $U_i$ in the cover, there is a diffeomorphism $\\phi_i: U_i \\rightarrow V_i/\\Gamma_i$, where $V_i$ is a subset of $\\mathbb{R}^n$ and $\\Gamma_i$ is a finite group acting on $V_i$. Also, for any $U_j \\subset U_i$ there is an embedding $\\phi_{ji}: V_j \\rightarrow V_i$ and an injective group homomorphism $f_{ji}:U_j\\rightarrow U_i$, such that for any $\\gamma \\in \\Gamma_i$ we have $\\phi_{ji}(\\gamma x) = f_{ji}(\\gamma)\\phi_{ji}(x)$, and such that the following diagram commutes\nOk, that definition is a mouthful and a half, but it is just as precise as it needs to be to give us how we intuitively think about the informal definition we gave earlier. The covering makes sure that all points on the underlying topological space is part of one of these sets that look like a quotient, and the whole subset business makes sure that “zooming” in, or looking a bit closer around a point, does not reveal something wildly different.\nA nice class of examples comes from something similar to the two motivational examples we saw earlier, namely global quotients. The space we are taking the quotient of does not have to be the Euclidean plane, or even a Euclidean space, but can be any smooth manifold. Let\u0026rsquo;s formalize this class of examples by a lemma.\nLemma: Let $\\mathcal{M}$ be a smooth manifold and $G$ a group acting properly discontinuously on $\\mathcal{M}$. Then their quotient $\\mathcal{M}/G$ is a smooth orbifold.\nIt is important to note that not all orbifolds arise as such quotients of smooth manifolds. But these are nice for intuition, and make some nice examples, such as the example from the beginning, namely the pillow case. Take the smooth manifold $\\mathcal{M}$ to be the torus. Let this torus be constructed from rotating a circle of radius 1 around the origin in $\\mathbb{R}^3$, with the axis of rotation being the $z$-axis.\nIf we act on the torus by rotating $\\pi$ radians around the $y$-axis, we get a symmetry transformation, or equivalently a $\\mathbb{Z}_2$-action.\nIf we then take the quotient by this action, i.e. $\\mathcal{M}/ \\mathbb{Z}_2$, we get our wanted pillowcase. How can we see this? If we poke a stick into the torus, in the direction of the $y$-axis, we see that it penetrates the torus at four points. When we take the quotient, it is roughly the same as folding the torus in two, with the fold being around the stick.\nThe important bit here is that it is not just a fold, but a kind of merger after folding. The result looks something like this.\nWhich we can see, after a bit of delicious topological deformation, is the pillowcase we were after.\nAnother way of viewing it is to look first at only the points not in the $yz$-plane. After taking the quotient, we see that all the points not in the $yz$-plane form a cylinder. At the edges of this cylinder are the points that were on the $yz$-plane. These points formed two circles on the torus. The orbits of the points on these circles are just two points symmetrically above the $y$-axis, except at the four points that lie exactly on the $y$-axis. These four points are their own orbits, which means that the orbit space of the two circles is diffeomorphic to two disjoint lines. These two lines are then gluing shut the cylinder of all the other points. The following drawing is not at all mathematically precise, but it kind of illustrates the process I’m describing.\nThere are more than one way of constructing the pillowcase as a smooth orbifold, but I though this one made everything quite clear. It is also a relatively easy, but not too easy example of a smooth orbifold. There is many more examples that are worth looking into, and maybe I will some time, but for now I think this post is long enough.\nMotivation for further reading The theory around orbifolds seem to be very rich and interesting. The definitions I mentioned earlier, i.e. étale Lie groupoids and Deligne-Mumford stacks are objects that require some more deep insight then I have currently, but maybe they are cool to look at in the future some time. There is also a whole theory of algebraic topology, homotopy theory and differential geometry developed for orbifolds (both from the classical definition we have discussed here and from the fancy new definitions). To have such a theories one needs special definitions for orbifold coverings, orbifold fundamental groups and more generally orbifold homotopy groups, tangent orbibundles or more general orbibundles, orbifold Euler characteristics and many more. It may be fun to try to go through some of these in the future as well.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/orbifolds/","summary":"For quite some time I have occasionally stumbled onto the Wikipedia page for orbifolds while looking at topology related mathematics. I have always been fascinated by them, and always though that they certainly will come up during studies at university, but they never have (at least not yet). On said wikipedia page it says that the word orbifold is short for “orbit manifold” and that these orbifolds are in fact a generalization of manifolds.","title":"Orbifolds"},{"content":"This summer I’m participating in Ravi Vakils pseudocourse on algebraic geometry, AGITTOC. Hence this summer serves as a wonderful opportunity to learn and write about cool mathematics. For long I have wanted to dive deeper into this abstract topic after just dipping my toes in during my bachelor thesis, and now it is time. Ravi though us in the first lecture that we shouldn’t study abstract objects without a cause, i.e. we need to ask ourselves why we want to learn about the objects, or the mathematics that lies ahead. I want to study algebraic geometry because I really like algebraic topology, and a lot of the concepts and notions of algebraic topology are abstracted in algebraic geometry, and several concepts gets a new viewpoint or gets some new tools to use to study them. I thought I would start off by discussing one of the fundamental objects of study in algebraic geometry, namely sheaves. These objects abstract, concretize and formalize several other mathematical notions, some of which we already know. One of these in particular is sheaf cohomology which can be viewed to generalize both singular, deRham and Cech cohomology. We are going to look into this cohomology theory in a later post.\nWhen studying topology, it becomes clear pretty early that local information sewn together is often more interesting than global information. Manifolds are more interesting than Euclidean space, local sections of a vector bundle are more interesting global sections and fiber bundles are more interesting than the Cartesian product of spaces. By “more interesting” I mean more complicated, less restrictive and a more “rich” theory. Sheaves are a very good way of describing such types of local information and how this information relates to the local information elsewhere and the global information. They do not inherently describe spaces parameterized by other spaces like the vector and fiber bundles, but instead abstracts and concretizes the study of functions on a space.\nPre sheaves The main meat of the definition of a sheaf is formalized in the notion of a pre-sheaf. A pre-sheaf concerns the local information on a space we talked about previously, and how the information relate to information even more locally. Sheaves will then incorporate two additional descriptions about how the information related across local areas, and how we can glue local information together, but more on that a bit later.\nBefore we get to the proper definition, we consider an example, or a kind of motivating story. Many of the sheaves and pre-sheaves we will care about in algebraic geometry will be about functions on spaces as mentioned in the introduction. Thus this will be our motivating example. We consider continuous real-valued functions on some subset of the real line. Let $U\\subset \\mathbb{R}$ and $C(U)$ be the set of continuous functions on $U$. Since they take value in the real numbers we can express these functions by their graphs in the real plane. Let $f \\in C(U)$, for example the following graph.\nIf we restrict $f$ to a smaller subset $V\\subset U$ it is still a continuous function on that subset, i.e. $f_{|V}\\in C(V)$.\nBut, if we have a non-continuous function on U, this function could still be continuous on V\\subset U, i.e. $f\\notin C(U) \\nRightarrow f\\notin C(V)$. We can see this by the following picture.\nSince together with the above property, non-continuous functions on $V$ are also non-continuous on $U$ we get a well defined restriction map $(-)_ {|V}: C(U) \\rightarrow C(V)$. If we restrict to the same subset $U\\subset U$ we see that the restriction map $(-)_{|U}$ is actually the identity map $id_U$. If we instead continue this process one more time, i.e. with a set $W\\subset V\\subset U$, then we would get restriction maps $C(U)\\rightarrow C(V) \\rightarrow C(W)$. If we have a continuous function on $U$, say f, then we know $(f_{|V})_ {|W} = f_{|W}$, and hence we know that the following triangle commutes\nThese are actually all the properties we want to mimic when defining a pre-sheaf. So when you now read the definition, you have a concrete example in your intuition-bank! Since we said that pre-sheaves abstract the notion of functions on a space, we could form an intuitive definition of a pre-sheaf to be sets of elements associated to a topological space that behave similarly to the sets of continuous functions on the space. This is actually not very far from the precise definition which we now finally have arrived at.\nDefinition (pre-sheaf): Let $X$ be a topological space, and $\\mathscr{C}$ some category. A $\\mathscr{C}$-valued pre-sheaf $\\mathcal{F}$ on $X$ is an assignment of an object $A$ in $\\mathscr{C}$ to every open subset $U\\subset X$, i.e. $\\mathcal{F}(U) = A \\in \\mathscr{C}$, such that for every inclusion $V \\hookrightarrow U$ there is a morphism $res_{V\\subset U}: \\mathcal{F}(U)\\rightarrow \\mathcal{F}(V)$, called the restriction, satisfying the following two axioms.\n The restriction $res_{U\\subset U} = id_U$ If we have subsets $W\\subset V\\subset U$, then $res_{W\\subset V} \\circ res_{V\\subset U} = res_{W\\subset U}$, i.e. a commutative diagram  The sets $\\mathcal{F}(U)$ are called the sections of $\\mathcal{F}$ over $U$.\nThis construction looks and feels very functorial in nature, but how can we discuss $\\mathcal{F}$ as a functor if our domain is just a topological space? Well, it turns out that every topological space has the structure of a category in exactly the way we need. Recall that a topological space is a set $X$ together with a topology $T$ on $X$. This topology determines which subsets we decide to be open in $X$. We let these open sets be the objects of our category. For the morphisms, we let there be a single arrow $V\\rightarrow U$ between two open sets, if and only if $V\\subset U$. We then automatically have an identity morphism for every object, and composition is well defined and is associative. We call this category $O(X)$, for the category of open sets on $X$.\nWe can then equivalently define a $\\mathscr{C}$-valued pre-sheaf on a topological space $X$ to be a contravariant functor $\\mathcal{F}:O(X)\\rightarrow \\mathscr{C}$. Usually $\\mathscr{C}$ will be the category of sets, the category of Abelian groups, the category of rings or the category of modules over a ring. When we have these more specific categories, we call a pre-sheaf for example a pre-sheaf of Abelian groups on $X$, instead of an $Ab$-valued pre-sheaf. The same goes for case with rings and modules. Pre-sheaves, and sheaves of rings will be especially important when we later are going to study schemes.\nSheaves As said earlier, sheaves are like pre-sheaves that incorporate two additional descriptions about how information relates across local areas, and how we can glue local information together. To motivate these additional axioms, we again use the motivating example that we used before the definition of a pre-scheme, namely the continuous functions on a subset $U$ of the real line $\\mathbb{R}$.\nIf we have an open cover ${U_i}$ of $U$ we want to study how functions on each of the sets in the cover can give us information about functions on the whole of $U$, and how restricting the functions can tell us information about the function globally. Let $f, g \\in C(U)$ such that their restriction to the sets in the cover are equal, i.e. $f_{|U_i} = g_{U_i}$ for all sets $U_i$ in the cover.\nThen we can see that the functions must be equal on the entire set $U$, i.e. if $f_{|U_i} = g_{U_i}$ for all $U_i$, then $f=g$ on $U$. This property, that the function is determined by it’s restrictions to an open cover, is called the uniqueness axiom and will be one of the extra features of a sheaf. What about the other direction? If we have a function on every set in the cover that agrees on their overlaps, do we then have a function on the entire set? For these continuous functions the answer is yes.\nIf we just put all the functions together, we still get a continuous function. The key piece for this working is that the functions agree on the overlaps, i.e. they are equal on every intersection. More formally, if we have functions ${f_i}$ on the $U_i$‘s such that $(f_i){|U_i , \\cap U_j} = (f_j){|U_i, \\cap U_j}$ for all $i$ and $j$, then there is a continuous function $f$ on $U$ such that $f_{|U_i} = f_i$. This property, that we can put together functions defined locally to form functions globally, is called the glueability axiom, and will be the second extra feature of a sheaf.\nIn the definition of a pre-sheaf, we could be very general, and allow values in every category $\\mathscr{C}$. As we have seen in the example of the two extra axioms above, it looks almost unavoidable to actually use elements to talk about the axioms, and hence we need to have that $\\mathscr{C}$ is a concrete category, i.e. a category in which the objects consists of elements. It is possible to do this more generally without discussing elements, but I don’t quite understand it yet. The categories we are interested in are all concrete anyway, and I find the definition using elements to be more intuitive, and more in sync with the motivating intuition-building example we just gave. Hence this is the definition we focus on.\nDefinition (sheaf): Let $X$ be a topological space. A $\\mathscr{C}$-valued sheaf $\\mathcal{F}$ of $X$ is a $\\mathscr{C}$-valued pre-sheaf such that the two additional following axioms hold:\n (Uniqueness). Let ${U_i}$ be an open cover of $U$ and $f,g \\in \\mathcal{F}(U)$. If $res_{U_i , \\subset U}(f) = res_{U_i , \\subset U}(g)$ for all $U_i$ in the cover, then $f=g$. The application of the restriction morphism $res_{V \\subset U}$ to the element f is often instead written as $f_{|V}$ to be more familiar. In that notation, we have if $f_{|U_i} = g_{|U_i}$ for all $U_i$ in the cover, then $f=g$. (Glueability). Let ${U_i}$ be an open cover of $U$ and $f_i \\in \\mathcal{F}(U_i)$ such that $res_{U_i ,\\cap U_j\\subset U_i}(f_i) = res_{U_i ,\\cap U_j \\subset U_j}(f_j)$ for all of the functions $f_i$ and all of the open sets $U_i$ in the cover. Then there exists an element $f\\in \\mathcal{F}(U)$ such that $res_{U_i , \\subset U}(f)=f_i$ for all functions $f_i$ and open sets $U_i$ in the covering. In the alternative notation, we have that if $(f_i)_{|U_i\\cap U_j} = (f_j)_{|U_i\\cap U_j}$ for all of the functions and all sets in the cover, then there exists a function $f\\in \\mathcal{F}(U)$ such that $f_{|U_i} = f_i$.  Here we quite clearly see the two extra properties we discussed above in the motivating example. We also see that sheaves exactly capture the information needed to move between local information and global information. We can also see that we can actually define a sheaf to be a pre-sheaf with only one extra axiom, namely unique glueability. Here we only use the last of the two axioms, i.e. glueability, but require the existence of a unique map on $U$ instead of just some map. As with the pre-sheaves, the usual categories we use are sets, Abelian groups, rings and modules. The same naming conventions apply for sheaves, so an $R$-mod-valued sheaf on $X$ will instead be called a sheaf of $R$-modules on $X$.\nNext time we will study more examples of sheaves to build our intuition about them. Then we will study an alternative way of viewing sheaves, through étale spaces, or in proper french fashion, espace étale. This will require us to look at germs, stalks and sheafification which will be fun!\n","permalink":"https://torgeiraamboe.github.io/posts/2020/sheaves/","summary":"This summer I’m participating in Ravi Vakils pseudocourse on algebraic geometry, AGITTOC. Hence this summer serves as a wonderful opportunity to learn and write about cool mathematics. For long I have wanted to dive deeper into this abstract topic after just dipping my toes in during my bachelor thesis, and now it is time. Ravi though us in the first lecture that we shouldn’t study abstract objects without a cause, i.","title":"Sheaves"},{"content":"A part of mathematics I really an starting to enjoy more is mathematics that explain or develop connections between geometry or topology, and algebra. The first two posts on this blog was focused on developing some geometrical insight to two lemmas from commutative algebra, namely Noether’s normalization lemma and Zariski’s lemma. There are many more such connections worth discussing and exploring, and today I want to focus on one of these “bridges” between geometry and algebra, namely Swan’s theorem. This theorem tells us how nice objects “over” another object in geometry relate to nice objects “over” another object in algebra.\nBefore we reveal the connection we are discussing, we go through some preliminaries for stating the theorem precisely. In the informal statement above the object in geometry will be a compact Hausdorff space, and nice objects over it will be vector bundles, while the object in algebra will be a ring and objects over it will be projective modules. I will assume knowledge about rings and point-set topology, but we will develop the notion of projective modules and vector bundles to get a sense of how they are similar and relate to each other.\nVector bundles In the fibration series we have developed the notion of a fiber bundle, and a vector bundle will be such an object such that all of the fibers are vector spaced instead of arbitrary topological spaces. We developed an intuition that bundles over a space is a map that is locally a projection, and the space above it consists of similar fibers glued together possibly non-trivially.\nDefinition (vector bundle): Let $X$ be a topological space. A real vector bundle $(E,p)$ over $X$ is a space $E$, called the total space, together with a map $p:E\\rightarrow X$ such that for any point $x\\in X$, $p^{-1}(x)$ has the structure of a finite dimensional real vector space. In addition we need the bundle to satisfy the local trivialization condition, which says that for every point $y\\in X$ there is: an open neighborhood $U\\subset X$ containing $y$; a natural number $n$; a homeomorphism $\\phi : U\\times \\mathbb{R}^n \\rightarrow p^{-1}(U)$, such that for any point $x\\in U$ we have $p\\circ \\phi (x, v) = x$ for all $v\\in \\mathbb{R}^n$ and that the map $v\\mapsto \\phi(x,v)$ is a vector space isomorphism.\nThe topological space $X$ in the context of a vector bundle is referred to as the base space. If we can choose $U=X$ in the local trivialization, i.e. a global trivialization, we call $(E,p)$ a trivial bundle because we have $E\\cong X\\times \\mathbb{R}^n$ for some $n$. An example would be the trivial one dimensional real vector bundle over the circle, which would be an infinitely tall cylinder, or if we draw the real line as a finite line segment just a normal cylinder.\nAn important question when studying objects over another object, i.e. some sort of system $p:E\\rightarrow B$ where $p$ is at least surjective, is the question of when do we have an inverse map, or even more generally a one sided inverse. If we have a vector bundle $p:E\\rightarrow B$, we define a section of the bundle to be a continuous map $s:B\\rightarrow E$ such that $p\\circ s = id_B$. Such a map always exists when we are discussing vector bundles since we can send a point on the base space to the zero-vector in the vector space that is the fiber over it. This is called the zero section. If our vector bundle is the tangent bundle, then a section is just a vector field on the base space. A graphic example is an embedding of the circle into the trivial bundle we discussed previously.\nThese maps will be important for proving the theorem as they will function as the way we define the algebraic information by the topological information. Note that there exists a notion of local sections which are exactly the same but is a one sided inverse only on an open neighborhood $U$ instead of on the whole space $X$. Hence sections are also called global seqtions.\nThe last piece we need about vector bundles are maps between them. If we have two vector bundles $(E,p)$ and $(F,q)$ over the same base space $X$ then a map between them $\\tau: (E,p)\\rightarrow (F,q)$ is a map $\\tau: E\\rightarrow F$ such that the following triangle commutes.\nProjective modules The other nice object over another one which will be important for stating the theorem is a projective module over a ring. Recall that a module is an Abelian group together with an action from a ring often called the scalar product. A projective module is characterized by a certain lifting property.\nDefinition (projective module): Let $R$ be a ring. An $R$-module $P$ is called projective if for every surjective module homomorphism $f: N\\rightarrow M$ and every module homomorphism $g:P\\rightarrow M$ there exists a lift $h:N\\rightarrow P$ such that $g\\circ h = f$, i.e. the following diagram commutes.\nNotice that we don’t require the lift to be unique, and hence the lifting property is not a universal property. Recall that maps between modules are maps that respect both the additive group structure and the scalar product from the ring.\nAn example of projective modules are free modules. These modules behave very similar to vector spaces since they always have a basis which makes maps between them describable by matrices. Recall that if a module is generated by a finite set of elements, called its generators, then we call the module finitely generated. In fact projective modules and free modules have a lot in common. By using some commutative algebra one can show that all projective modules are locally free, meaning there exists a cover of ideals such that localization at every ideal in the cover is a free module. We can also define a projective module by being a summand of a free module. This is because there always exists a surjective module morphism from a free module $R^n$ onto any finitely generated module $M$, and by the lifting property the sequence $0\\rightarrow ker(f)\\rightarrow R^n \\rightarrow M\\rightarrow 0$ splits, and hence $R^n\\cong M\\bigoplus ker(F)$, i.e. $M$ is a direct summand of a free module.\nRight away, even before discussing the statement of the theorem we can notice that projective modules are locally free modules, and that vector bundles are locally trivial bundles. Since free modules behave very similarly to vector spaces, this hints at a connection between the two notions.\nSwan\u0026rsquo;s theorem So, we have now defined the objects needed to formulate the theorem. As stated in the introduction, the theorem will relate the objects discussed to each other. To understand how this relation occurs we need a good way of translating topological or geometric objects to algebraic objects, and the way we are going to do that in this theorem is through functions on the objects. If we take some nice topological space we can study the set of continuous real-valued functions on that topological space. Since the codomain, $\\mathbb{R}$, is a ring, we can define addition and multiplication of these continuous functions by the addition and multiplication of the real numbers that elements of the topological space map to, i.e. define the operations pointwise. Hence for a nice topological space $X$ we always have a corresponding ring, $C(X)$ of real-valued continuous functions on $X$. This is the correspondence that Swan’s theorem focuses on. The theorem tells us that nice geometric objects over nice topological spaces are the same as nice projective objects over the corresponding nice algebraic objects, or more precisely that real vector bundles over a compact Hausdorff space $X$ are the same as finitely generated projective modules over the ring of real-valued continuous functions $C(X)$. The precise formulation for the theorem encapsulates what I mean by “the same as” in a categorical language, but the information is the same.\nTheorem (Swan): The category of real vector bundles over a compact Hausdorff space $X$ is equivalent to the category of finitely generated projective modules over the ring of continuous real functions on $X$.\nJust as a quick disclaimer, I won’t cover the entirety of the proof, but we will look at the important pieces and the general idea. Since we have two categories we want to show are equivalent, we should find a fully faithful, essentially surjective functor , in other words an equivalence of categories, that shows that these categories are the same. Let $Vect(X)$ be the category of vector bundles over $X$ and $pmod(C(X))$ be the category of finitely generated projective modules over $C(X)$. If we let $p\\in Vect(X)$, i.e. $p$ is a vector bundle $E\\overset{p}\\rightarrow X$ then we denote the set of all sections of $p$ by $\\Gamma(p)$. Notice that $s\\in \\Gamma(p)$ is a map $s:X\\rightarrow E$, and since every point in the image lies in a vector space, we can define addition of sections by adding their images pointwise. We can also define scaling of the sections by continuous real-valued functions on $X$ by letting $f\\circ s (x) = f(x)\\cdot s(x)$. This in fact makes $\\Gamma(p)$ into a $C(X)$-module! If we have a map between two vector bundles over $X$, say $\\tau:p\\rightarrow q$ then we can define a map between their $C(X)$-modules of sections by post composition, i.e. sending a section $s\\in \\Gamma(p)$ to $\\tau \\circ s$. This is a section of $q$ because $q\\circ (\\tau \\circ s)=(q\\circ \\tau) \\circ s = p \\circ s = id_X$. These two together form a functor $\\Gamma : Vect(X)\\rightarrow mod(C(X))$ sending a vector bundle p to its $C(X)$-module of sections $\\Gamma(p)$ and a vector bundle map $\\tau$ to the $C(X)$–module map $\\Gamma(\\tau)=\\tau\\circ (-)$.\nTo see that this is in fact a functor only to projective finitely generated $C(X)$-modules we first note that trivial vector bundles, i.e. bundles of the form $X\\times \\mathbb{R}^n \\overset{p}\\rightarrow X$, correspond to free $C(X)$-modules under the defined functor $\\Gamma$. This is because a trivial vector bundle has a finite global basis, i.e. a finite set of sections of which the image of each point in $X$ is a basis for $p^{-1}(x)$, which determines a free basis for the module of sections. The next step is then to prove that every vector bundle is a direct summand of a trivial vector bundle. This only holds for vector bundles over compact Hausdorff spaces, hence the assumption in the theorem. This can be shown through the existence of an inner product on the vector bundle if the base space is paracompact Hausdorff, and hence allowing us to form inner orthogonal complement bundles, i.e. for any subbundle of the original bundle a vector bundle such that their direct sum bundle is the original bundle. If our base space is compact we can do this for every set in a finite trivialization and glue them together by partitions of unity. Our functor, i.e. taking the module of sections does in fact preserve direct sums, hence every $C(X)$-module is a direct summand of a free module, which we saw earlier is the same as being a projective module. Hence, every finite dimensional real vector bundle over $X$ in fact maps to a projective $C(X)$-module. The remaining part is to show that every $C(X)$-module homomorphism between projective modules actually comes from a unique map of vector bundles, i.e. that for every map $F:P\\rightarrow Q$ of projective modules there is a unique map $f:p\\rightarrow q$ between two vector bundles over $X$ such that $\\Gamma(f)=F$. This is a bit tricky to show, but comes mainly from the fact that any compact Hausdorff space is normal, and that we can extend local sections to global on normal spaces.\nThis is as far as I’ll go into the proof, but we have at least covered the basic elements. The whole proof revolves exactly around showing that the functor $\\Gamma$ is an equivalence of categories.\nClosing remarks There are a couple facts that should be mentioned when discussing this theorem. First, the theorem also hold if we instead of real vector bundles use complex vector bundles, and complex-valued continuous functions instead of real-valued ones. It does not however work if we use totally disconnected fields, like the rational numbers $\\mathbb{Q}$. Secondly, if we replace every “continuous” by “smooth”, i.e. try to have a version in differential geometry then the theorem still holds. This means replacing our topological space by a smooth manifold, the vector bundle by a smooth vector bundle, continuous functions by smooth functions and sections by smooth sections. Thirdly, there is an earlier version of the theorem in algebraic geometry instead of algebraic topology due to Serre, so the theorem is often named the Serre-Swan theorem. Serre proved that finite dimensional vector bundles over algebraic varieties are also the same as finitely generated projective modules over the similar ring of continuous functions in algebraic geometry. I am following Ravi Vakils summer course on algebraic geometry, so maybe I will cover that version of the theorem after learning some more algebraic geometry.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/swans-theorem/","summary":"A part of mathematics I really an starting to enjoy more is mathematics that explain or develop connections between geometry or topology, and algebra. The first two posts on this blog was focused on developing some geometrical insight to two lemmas from commutative algebra, namely Noether’s normalization lemma and Zariski’s lemma. There are many more such connections worth discussing and exploring, and today I want to focus on one of these “bridges” between geometry and algebra, namely Swan’s theorem.","title":"Swan's theorem"},{"content":"This is part 9 of a series leading up to and exploring model categories. For the other parts see the series overview.\nLast time we ended by giving a definition of a homotopy between maps on the collection of bifibrant objects in a model category. Today we are going to expand further upon this idea, and try to build the theory we are familiar with for topological spaces but in the general setting. The goal is to have a well defined workable notion of a homotopy category, and understand what it consists of.\nMotivation In topological spaces, there are two ways to make a homotopy category. The first one is called the naive homotopy category and is made by having the same objects, i.e. all topological spaces, but instead of all maps we have homotopy classes of maps. As the name implies, the resulting category isn’t very well behaved in the way we want it to. Quillen introduced a better definition which is made through localization. Localization is defined by formally inverting a class of maps such that they become isomorphisms. The resulting category after localizing at the class of weak homotopy equivalences is called the Quillen homotopy category of topological spaces, or just the homotopy category. When actually working with the naive homotopy category, there are some alterations we can do to make the situation better. If we encounter a bad object that does not play nice, we replace it by a CW-approximation via a weak homotopy equivalence, which by the CW-approximation theorem always exists. There is also a famous theorem by Whitehead, called naturally the Whitehead theorem, which states that “two CW-complexes are weakly homotopy equivalent if and only if they are homotopy equivalent”. Hence, when we take homotopy classes of maps, every weak homotopy equivalence between CW-complexes will end up in the same equivalence class as an isomorphism, which makes weakly homotopy equivalent spaces isomorphic. Now we have two categories that are very similar, and these will be our motivation throughout.\nThe homotopy category Before we do anything else we define the homotopy category of a model category in the general setting, not just for topological spaces.\nDefinition (homotopy category): The homotopy category of a model category $\\mathscr{C}$ is defined to be the Quillen homotopy category of $\\mathscr{C}$, i.e. $Ho(\\mathscr{C})= W^{-1}\\mathscr{C}$ where $W$ is the collection of weak equivalences in the model structure.\nThis definition does not give us much in terms of workability. Even though we called it naive, we really like homotopy classes of maps, and this definition of a homotopy category does not reflect the definition we gave of homotopy at all. As we see, the homotopy category is purely dependent on the class of weak equivalences and doesn’t on the surface have anything to do with homotopy. But, as we will see soon, homotopy classes of maps do play a role here, but we got to do some work to show it.\nAs said earlier, we left of with the definition of homotopy in a model category. To mimic topological spaces we need this definition of homotopy to satisfy some properties, at least working nice with composition, having a notion of homotopy equivalence between objects and hopefully have some abstracted version of the Whitehead theorem to tell us we are one the right track. We didn’t show that left and right homotopies work nicely with composition, but I don’t think it is that hard to imagine, hence we leave it out to focus on the more important bits.\nDefinition (homotopy equivalence): We say two bifibrant spaces $X$ and $Y$ are homotopy equivalent if there exists morphisms $f:X\\rightarrow Y$ and $g:Y\\rightarrow X$ such that $g\\circ f \\sim id_X$ and $f\\circ g \\sim id_Y$.\nIn the Serre model structure on topological spaces the cofibrant objects are exactly the CW-complexes, and any object is fibrant. Hence, we can reformulate the Whitehead theorem as “two bifibrant objects are weakly homotopy equivalent if and only if they are homotopy equivalent”. This is starting to look like a general theorem that tells us that a nice definition of homotopy which leads to a nice notion of homotopy equivalence will in fact coincide with the pre-chosen class of weak equivalences when restricted to the class of “homotopy-nice” objects. This is the theorem that tells us we are on the right track towards a workable version of the naive homotopy category, because when we localize at the weak equivalences in the Quillen homotopy category, the homotopy equivalent objects will turn into isomorphic objects.\nThe generalized Whitehead theorem: Any two bifibrant objects in a model category $\\mathscr{C}$ are weakly equivalent if and only if they are homotopy equivalent.\nNow we are getting somewhere! Localizing at the weak equivalences also turns homotopy equivalences of bifibrant objects into isomorphisms! We are getting closer to a workable nice category. Now we have a subcategory of bifibrant objects, which we denote $\\mathscr{C}_ {b}$ or more standard $\\mathscr{C}_{cf}$, with a notion of homotopy being an equivalence relation, denoted $\\sim$. Hence we can form its naive homotopy category $\\mathscr{C}_b\\rightarrow \\mathscr{C}_b/\\sim$. By the generalized Whitehead theorem the map sends weak equivalences to isomorphisms, and hence it has to factor through its Quillen homotopy category $Ho(\\mathscr{C}_b)$. We also have an inclusion $\\mathscr{C}_b \\rightarrow \\mathscr{C}$ which induces a map on their Quillen homotopy categories, i.e. $Ho(\\mathscr{C}_b)\\rightarrow Ho(\\mathscr{C})$. The final piece of the puzzle of having a workable homotopy category will come from the fact that those maps form an equivalence of categories $Ho(\\mathscr{C})\\cong \\mathscr{C}_b/\\sim$, which means we have both a nice definition, and a nice way to work with it. I must admit I don’t fully understand the proof yet, hence I leave it out for now, but I will hopefully post an update with just this proof in the future.\nThis final theorem also means that we have isomorphisms\nwhere $A^{cf}$ means we have taken both a cofibrant followed by a fibrant replacement of $X$. I include this as a picture since this article had none, and I need a coverphoto… Also pictures are more fun.\nThe reader might be confused as to why the naive homotopy category of topological spaces exists, and why we don’t really need to pass down to only CW complexes. Recall that in the Strøm model structure on the category of topological spaces, all objects are both fibrant and cofibrant, hence localization at the homotopy equivalences results in the same category as just taking homotopy classes of maps. Hence, the naive homotopy category is the Quillen homotopy category of topological spaces with the Strøm model structure, while the “true” homotopy category is the Quillen homotopy category of topological spaces with the Serre model structure. This shows in my opinion that the Serre model structure is a bit nicer, but also more restrictive.\nDerived categories The algebraically inclined reader familiar with homological algebra will recognize the definition of the Quillen homotopy category as very similar to the derived category of a ring, or in general the derived category of an abelian category. As mentioned in part 7, an example of a model category is the category of chain complexes of modules over some ring, and localizing this category at its weak equivalences, namely the quasi isomorphisms gives the derived category of the ring, i.e. $D(R)=Q^{-1}C(ModR)$ where $Q$ is the class of quasi isomorphisms. Usually the reason for introducing the derived category in homological algebra is that working with chain homotopy classes of maps in chain complexes does not work nicely with the triangulated structure that naturally arises. In particular, a short exact sequence in the category of chain complexes may not be a distinguished triangle in the “homotopy category”. By homotopy category I here mean the category of chain complexes of modules over a ring with maps being chain homotopy classes of chain maps. This should rather be called the naive homotopy category, since it is exactly the same construction that we did for topological spaces. Passing to the derived category rectifies this, since every exact sequence gives a distinguished triangle. We will probably explore triangulated categories more in the fall, as I am going to follow a course focusing on them.\nIn the model structure on chain complexes of modules over a ring, the injective and projective resolutions are the fibrant and cofibrant replacements. We have showed that homotopy classes of maps between bifibrant objects gives an equivalent naive homotopy category to the Quillen homotopy category of the entire category, hence if we take an Abelian category with enough projectives and enough injectives, all objects have nice replacements that we can work with, and if we restrict ourselves to just these projective and injective chain complexes we have an equivalent category to the derived category that is more workable.\nNext time we will study functors between model categories, and what it means to preserve the model structure. We will also study what type of functor we need to make sure that both model categories have an equivalent homotopy category. As a teaser, derived functors will be an example of functors between model categories.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/the-homotopy-category/","summary":"This is part 9 of a series leading up to and exploring model categories. For the other parts see the series overview.\nLast time we ended by giving a definition of a homotopy between maps on the collection of bifibrant objects in a model category. Today we are going to expand further upon this idea, and try to build the theory we are familiar with for topological spaces but in the general setting.","title":"The homotopy category"},{"content":"This is part 8 of a series leading up to and exploring model categories. For the other parts see the series overview.\nLast time we finally defined the model category, gave some examples and tried (kind of) to give a motivation to why they are interesting and how they set the stage for homotopy theory. The first time I read the definition I was a bit confused about the lack of mention of homotopy, or at least some prototype of it that I could connect with. This structure on a category is supposed to embody where homotopy theory works, but failed to immediately convey that to me. But, that said, we will today go through the construction of homotopy, and prove that it is an equivalence relation on maps in nice cases. These cases we mentioned in the previous part, and will be maps between objects that are both fibrant and cofibrant, which I will refer to as bifibrant.\nAbstract homotopies We know from topology that homotopy requires some sort of interval or paths, and the abstract definition will in a way reflect that. What we are going to construct are so called cylinder objects, that imitates taking the product with the interval in regular topological homotopy. Dualy, we are going to define path objects, which will mimic the path space in topology. These two will respectively define left and right homotopies, which will be equivalence classes only on fibrant and cofibrant objects respectively. These two notions of homotopy will coincide and give the same equivalence relation on bifibrant objects. Note that in the definition we are using products $\\prod$ and coproducts $\\coprod$. Since we work in a model category these always exists because the product is a special case of a limit, and the coproduct is a special case of a colimit, which both exists because a model category is bicomplete.\nDefinition (cylinder object): Given an object $X$ in a model category $C$ we define the cylinder object of $X$, denoted $Cyl(X)$ to be factorization of the codiagonal map $X \\coprod X \\rightarrow X$ into $$X \\coprod X \\overset{i_1+i_2} \\rightarrow Cyl(X) \\overset{p} \\rightarrow X,$$ where $p$ is a weak equivalence. If $X\\coprod X\\overset{i_1 + i_2}\\rightarrow Cyl(X)$ is a cofibration, we call $Cyl(X)$ a good cylinder object, and if in addition $p$ is an acyclic fibration, we call $Cyl(X)$ a very good cylinder object.\nDefinition (path object): Given an object $X$ in a model category $C$ we define the path object of $X$, denoted $Path(X)$ to be factorization of the diagonal map $X \\rightarrow X\\prod X$ into $$X \\overset{i}\\rightarrow Path(X) \\overset{(p_1,p_2)}\\rightarrow X \\prod X,$$ where $i$ is a weak equivalence. Similarily to the cylinder object, if $Path(X)\\overset{p}\\rightarrow X\\prod X$ is a fibration, we call $Path(X)$ a good path object, and if in addition i is an acyclic cobration, we call $Path(X)$ a very good path object.\nBy the factorization axiom for model categories (MC4) every object has at least one very good cylinder object and one very good path object. It can be useful to use these in some cases, but in other cases we can actually be interested in cylinder and path objects that aren’t necessarily good, or very good. For example, in the Serre model structure on topological spaces, the standard cylinder object $Cyl(X)=X\\times I$ is only good when $X$ is a CW-complex.\nWe now have objects that behave in some of the same ways as the objects used to define homotopy of topological spaces. In topological spaces, the cylinder object is as mentioned the product with the unit interval. When we then define a topological homotopy from this cylinder, we require that the homotopy restricts to the maps we are constructing a homotopy between on each end of the cylinder, and this will be what motivates how we define it in the general setting as well.\nDefinition (left homotopy): Given two maps $f,g: X\\rightarrow Y$ we define a left homotopy $h:f\\sim_L g$ from $f$ to $g$ to be a map $h: Cyl(X)\\rightarrow Y$ such that the following diagram commutes\nDefinition (right homotopy): Given two maps $f,g: X\\rightarrow Y$ we define a right homotopy $h:f\\sim_R g$ from $f$ to $g$ to be a map $h: X\\rightarrow Path(Y)$ such that the following diagram commutes\nIf the cylinder object used to define the left homotopy is a good cylinder object then we call the homotopy a good left homotopy, and similarly if it is a very good cylinder object we call the homotopy a very good left homotopy. The same goes for the path object used to define the right homotopy, which gives us good right homotopies and very good right homotopies.\nEquivalence relation That homotopy is an equivalence relation is one of the most important and fundamental properties that homotopy has in the category of topological spaces, and hence it should also be important in the general setting. Before we do that, we note that we can upgrade any left homotopy $h$ to a good left homotopy by factoring the map $X\\rightarrow Cyl(X)$ into $X\\rightarrow Cyl(X)' \\overset{\\sigma}\\rightarrow Cyl(X)$ by the fourth axiom for model categories (MC4). Then $h\\circ \\sigma$ will be a good homotopy. If $Y$ is fibrant, then we can upgrade it further to a very good left homotopy by using the other factorization on $Cyl(X)\\rightarrow X$ to get $Cyl(X)\\rightarrow Cyl(X)'\\rightarrow X$. Since we assumed $Y$ was fibrant, we have a commutative diagram\nwhere $T$ is a terminal object. The lift comes from the third axiom for model categories and gives the very good left homotopy we wanted. Ok, so we have the opportunity to choose good left homotopies in general, and very good homotopies for fibrant objects. We will use this to prove the following lemma.\nLemma: Let $X$ be a cofibrant object. Then left homotopy defines an equivalence relation on $Hom(X,Y)$.\nProof: Using $X$ itself as a cylinder object together with the map $f:Cyl(X)=X\\rightarrow Y$ as a left homotopy shows that any map $f:X\\rightarrow Y$ is left homotopic to itself. It is symmetric since we can compose with the swithing map $X\\coprod X \\rightarrow X\\coprod X$ that just switches the components. This gives a homotopy “in the other direction”. Lastly, let $f_1\\sim_L f_2$ and $f_2\\sim_L f_3$ be good homotopies with cylinder objects being $Cyl(X)$ and $Cyl(X)'$ respectively. Then the pushout of the diagram $Cyl(X)' \\leftarrow X \\rightarrow Cyl(X)$ defines a new cylinder object and a homotopy $f_1\\sim f_3$. Hence the relation is reflexive, symmetric and transitive which is the definition of an equivalence relation.\nSomething I have not mentioned yet is that the opposite category of a model category is again a model category. The opposite category has the same weak equivalences, and switches the fibrations and cofibrations. Hence, many proofs in model categories are easier, since we can appeal to duality. For example, since cofibrations are fibrations, fibrant objects are cofibrant and the diagonal is the codiagonal and vice versa in the opposite category, left homotopy is a right homotopy in the opposite category. Hence the same proof as above in the opposite category shows that we can upgrade to a good homotopy and that right homotopy is an equivalence relation on $Hom(X,Y)$ when $Y$ is fibrant. By the way, this duality is the Eckman-Hilton duality in the category of topological spaces, which I referenced in part 3 of the fibration series. Recall that we then switched between loop spaces and suspensions, which are related to these path objects and cylinder objects and hence are dual to each other through the opposite category.\nRelations between the two types of homotopy When I first worked through this I was a bit uneased by the two different notions of homotopy that does not seem to be immediately identifiable with each other. But, when working with topological homotopy there is a good reason as to why we never see the two different concepts, because in both the Serre and the Strøm model structure, all objects are fibrant. Hence, by the next lemma, the existence of right homotopies always implies the existence of left homotopies in the category of topological spaces, hence we don’t ever need to bother with making the distinction.\nLemma: Let $f,g:X\\rightarrow Y$ be two maps. If $X$ is cofibrant and $f,g$ are left homotopic then they are right homotopic. Dually, if $Y$ is fibrant and $f,g$ are right homotopic, then they are left homotopic.\nProof: Choose a good cylinder object $X\\coprod X \\overset{i_1 + i_2}\\rightarrow Cyl(X) \\overset{j}\\rightarrow X$ and let $h:Cyl(X)\\rightarrow Y$ be a left homotopy between $f$ and $g$. Choose also a good path object $Y\\overset{q}\\rightarrow Path(Y) \\overset{(p_1, p_2)}\\rightarrow Y\\prod Y.$ We then have a commutative diagram\nwhich has a lift $\\overline{h}$ by the third axiom of model categories (MC3). Note here that we used the fact that $i_1$ is an acyclic cofibration which we have not proved, but it can be seen by the two out of three property since $X$ is assumed to be cofibrant together with the fact that it is a composition of two cofibrations. The composition $h\\circ i_2:X\\rightarrow Path(X)$ gives a right homotopy between $f$ and $g$ as desired. The dual statement has a dual proof.\nDefinition (homotopy): We say two maps $f,g:X\\rightarrow Y$ are homotopic, denoted $f\\sim g$ if they are both left homotopic and right homotopic.\nIf we then restrict our attention to just the bifibrant objects we have a well defined notion of homotopy that is an equivalence relation for all of the morphisms between the bifibrant objects. This will allow us next time to look at homotopy equivalences of objects, homotopy classes of maps and finally the homotopy category of a model category.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/homotopy-in-model-categories/","summary":"This is part 8 of a series leading up to and exploring model categories. For the other parts see the series overview.\nLast time we finally defined the model category, gave some examples and tried (kind of) to give a motivation to why they are interesting and how they set the stage for homotopy theory. The first time I read the definition I was a bit confused about the lack of mention of homotopy, or at least some prototype of it that I could connect with.","title":"Homotopy in model categories"},{"content":"This is part 7 of a series leading up to and exploring model categories. For the other parts see the series overview.\nFinally we have made it to the destination we set, namely, more abstraction. This post is focused on the definition and intuition on model categories, which abstracts the objects we have been studying for some weeks, namely fibrations and cofibrations. The main definition is that of a model structure on a category, which together with a nice category will form the definition of a model category. So, why do we want this? There are more than one reason.\n Homotopy theory is not only useful for topological spaces, and can be done in other settings, for example in chain complexes. Model categories tells us when we have a category that is suitable for homotopy. We often talk about different homology theories or cohomology theories, but can we also have different homotopy theories? When working in some category, we would like to invert a nice class of morphisms, but doing so arbitrarily is not certain to give a nice result. The result will be a zig-zag of morphisms, which we in full generality have no control over. If we invert the nice morphisms in a model category however, we have nice control.  Preliminaries As we can see, a model category is in a way a category such that its homotopy category exists and is well behaved. We will discuss this further and try to make it more precise, but before we state the definition, we need a couple preliminaries.\nDefinition (retraction): A map $f$ is called a retract, or a retraction of a map $g$ if there exists a diagram\nsuch that the horizontal maps compose to the identity map.\nDefinition (bicomplete category): A bicomplete category is a category where all of its small limits and small colimits exists. A small limit is a universal cone over a diagram where the index category is a set. A small colimit is similarly a universal cocone over a diagram where the index category is a set. The important feature for us will be that pullbacks and pushouts exists, and that terminal and initial objects exists. The last two will be explained better later.\nRecall also that a fibration is a map that satisfies the homotopy lifting property, and that a cofibration is a map that satisfies the homotopy extension property. When we explored them earlier, it was in the setting of topological spaces, hence we could use homotopies and intervals and the like in our constructions. When we define a model category soon we can’t rely on topological spaces, since we want to obtain a general theory, not just an axiomatization of the theory of topological homotopy that we already know. But these are classes of maps that we like, and that have nice properties. Hence we want to imitate these properties in the general setting. In the formal definition, there is one more class of maps that we like, and that is called weak equivalences. We haven’t discussed these yet, but they will kind of be the isomorphisms in the homotopy theory. Think about weak homotopy equivalences, which are maps that induce isomorphisms on all homotopy groups, and quasi isomorphisms as the motivating examples.\nModel categories We now have enough backstory and preliminaries to make a precise definition of a model structure on a category. Our goal is to generalize the stage for homotopy theory, but in the definition it will not however be intrinsically clear how we are going to define homotopy, because to be general, there are no reference to a unit interval or something similar. For me it is helpful to think about the motivating example, being the category of topological spaces, when reading the definition.\nDefinition (model structure): A model structure on a category $\\mathscr{C}$ consists of three classes of maps called fibrations, cofibrations and weak equivalences, such that the following axioms hold. To make some of the axioms easier, we call a fibration that is also a weak equivalence an acyclic fibration, and similarly we call a cofibration that is also a weak equivalence an acyclic cofibration.\nMC1: Any retraction of a map in one of the three classes is again in the same class. The classes are called retraction closed.\nMC2: The class of weak equivalences has the “two out of 3” property, i.e. if two out of $f, g, g\\circ f$ is a weak equivalence, then the last of them is also a weak equivalence.\nMC3: If we have a commutative square\nwhere either $i$ is a cofibration and $p$ is an acyclic fibration, or $i$ is an acyclic cofibration and $p$ a fibration, then there exists a map $h: B \\rightarrow X$ making both subdiagrams commute. This is often referred to as fibrations having the right lifting property with respect to acyclic cofibrations, and cofibrations having the left lifting property with respect to acyclic fibrations.\nMC4: Any map $f:X\\rightarrow Y$ has two factorizations $f=p\\circ i$ where $i$ is a cofibration and $p$ is an acyclic fibration, and $f=p\\circ i$ where $p$ is a fibration and $i$ is an acyclic cofibration.\nDefinition (Model category): A model category is a bicomplete category $\\mathscr{C}$ together with a model structure.\nThe definition seems a bit weird, and as mentioned, it has no reference to any homotopy going on, and does not give us anything extra for free. But, as time have shown since the first definition of a model category by Quillen in the 60’s, this is the correct definition. The definition we have given is a bit stricter than the original definition by Quillen, but the one presented here is equivalent to Quillens definition of a closed model category. Also, in the original formulation, the acyclic fibrations and acyclic cofibrations were called trivial fibrations and trivial cofibrations. These have been changed to avoid confusion between another term often referred to as trivial fibrations, namely fibrations where the total space is the product of the base space and the fiber. The name maybe also sound a bit weird, but it is kind of short for “the category of models”, which might make some sense. It consists of the models for where we can do homotopy, and “models” the homotopy category.\nBecause a model category is complete and cocomplete it has an initial object $I$ and a terminal object $T$. These are objects such that there exists an unique morphism out of, and into them respectively. If the unique morphism from an object $X\\rightarrow T$ is a fibration, then $X$ is called fibrant, and if the unique morphism $T\\rightarrow Y$ is a cofibration, then $Y$ is called cofibrant. We are going to define homotopy in a model category next time, but it will turn out that a proper homotopy theory will only work for a subclass of objects in the category, which are the objects that are both fibrant and cofibrant.\nExamples As I mentioned before, the important image to have in your head is the category of topological spaces, and this will also be our first example. This is complete and cocomplete, since the forgetful functor lifts both limits and colimits uniquely from the category of sets. It has more than one model structure, but the most familiar one has Serre fibrations as its fibrations and weak homotopy equivalences as its equivalences. We did not have a similar definition of cofibrations only with respect to CW complexes, so the cofibrations are not the ones we already know unfortunately. The cofibrations in this model structure is best described by being retracts of relative cell complexes, i.e. a retraction of a map $X\\rightarrow Y$ where $Y$ is made from $X$ by attaching cells. Weak homotopy equivalences are the maps we mentioned earlier, that induce isomorphisms on all homotopy groups. This historically was also the motivating example.\nAnother model structure on the category of topological spaces comes from Hurewicz fibrations, closed Hurewicz cofibrations and regular homotopy equivalences as the weak equivalences. This was proven by Arne Strøm, and is called the Strøm model structure on topological spaces. The unique thing about this model structure, that is certainly not the usual situation, is that every object is both fibrant and cofibrant.\nAnother example is the category of chain complexes of modules over some ring. Here the model structure consists of quasi isomorphisms as the weak equivalences, the fibrations are degreewise projections and the cofibrations are degreewise injections with projective cokernel. The homotopy theory in this setting is the same as regular homological algebra.\nThose who know homological algebra will know about projective and injective resolutions. These objects are what is called quasi isomorphic replacements, and this can also be defined in the general setting. Any morphism in the category can be factorized, so if we factorize the unique map into the terminal object $X\\rightarrow T$, into a weak equivalence and a fibration. This will make a space which is weakly equivalent to $X$ and is a fibrant object. This is called a fibrant replacement of $X$. The same can be done with the unique morphism out of the initial object, which will result in a cofibrant replacement. In the example of the category of chain complexes over a ring a projective resolution is an example of a cofibrant replacement, and an injective resolution is an example of a fibrant replacement.\nThe notions of fibrant and cofibrant replacements will be important when we introduce homotopy in a model category and the homotopy category of a model category. There are two ways to do this, and we will explore them both. One comes from constructing homotopy classes of maps, and the other by localization at the weak equivalences. But, we will save this for next time.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/model-categories/","summary":"This is part 7 of a series leading up to and exploring model categories. For the other parts see the series overview.\nFinally we have made it to the destination we set, namely, more abstraction. This post is focused on the definition and intuition on model categories, which abstracts the objects we have been studying for some weeks, namely fibrations and cofibrations. The main definition is that of a model structure on a category, which together with a nice category will form the definition of a model category.","title":"Model categories"},{"content":"This is part 6 of a series leading up to and exploring model categories. For the other parts see the series overview.\nThrough the series so far we have covered the basic uses of fibrations and related things, like the long exact sequence of homotopy groups, the Serre spectral sequence, fiber bundles and homotopy groups of spheres. But, we have not mentioned that fibrations has a dual construct, namely cofibrations. The road we are heading with this series, as mentioned before, is to define Model categories, and discover how to use them. Up until now, and including this post, I have been pretty comfortable with the objects of study, and I feel i know them quite well. After this post tho, I think I’m entering unknown territory for me, which is good!\nCofibrations We first defined fibrations through the homotopy lifting property. So if cofibrations are dual to fibrations, there should be a dual notion to homotopy lifting. So, what is the dual to a lift? It is an extension. So, the cofibrations will be defined in terms of the homotopy extension property. Intuitively, we can think of this as “any homotopy defined on a subspace can be extended to the entire space”. This lacks some precision, but is a good intuitive start. Notice also here the use of subspaces. We remarked that fibrations kind of looked like projections, so the dual object should intuitively kind of look like an inclusion. Hence, instead of lifting a homotopy through a projection, we extend a homotopy through an inclusion. This is at least how I think about it. As said, this is not precise, and rigorous mathematics require precise definitions, so we need to give one.\nDefinition (cofibration): A map $f:X\\rightarrow Y$ is called a Hurewicz cofibration if for any space $A$ and every map $g:Y\\rightarrow A$ and homotopy $h: X\\times I \\rightarrow A$ such that $h(-,0)= g\\circ f$, there exists a homotopy $\\overline{h}:Y\\times I\\rightarrow A$ such that $\\overline{h}\\circ (f\\times id_I) = h$. This is better summarized by the following diagram.\nIf the image of $X$ in $Y$ is a closed subspace, we call f a closed Hurewicz cofibration. From now on, if i say cofibration, i will mean closed Hurewicz cofibration.\nUnfortunately, cofibrations don’t have as good of a geometric interpretation that their dual has (at least that i know of). The algebraic duality, and the duality in the definition is clear, but I often thrive of geometric interpretation, which I haven’t yet succeeded in with cofibrations. But, we can ask some of the same questions to try to dually mimic the behavior of fibrations, and the first step is the long exact sequence. We have already seen that extensions are the dual to loop spaces, so if we try to develop a sequence similar to the Puppe sequence we developed in part 3, then we should expect to instead continue towards the right and use iterated suspensions.\nThe coexact Puppe sequence In the case of fibrations we did this by introducing the homotopy fiber, and this time we do the same by introducing the homotopy cofiber. Given a map $f: X\\rightarrow Y$, the homotopy cofiber is often better known as the mapping cone of $f$. The mapping cone $C(f)$ can be thought of as the homotopy version of a quotient space, but more precisely it is defined to be the gluing of $X\\times I$ to $Y$ along the image of $X$ under $f$ modulo the relation $(x,0)\\sim (x',0)$. This is written mathematically as $C(f)= ((X\\times I)\\coprod_f Y) /(x,0)\\sim (x',0)$. Here $(X\\times I)\\coprod_f Y$ means $((X\\times I)\\coprod Y)/(x,1)\\sim f(x)$, i.e. gluing $X$ to its image in $Y$. The whole construction is maybe more visually understandable with the following picture.\nOne important thing for us is that the mapping cone of a closed cofibration is homotopy equivalent to the quotient space $Y/f(X)$. Now, the sequence $X\\rightarrow Y\\rightarrow C(f)$ is a cofiber sequence, or also called a coexact sequence. This is a feature of a sequence that we have not encountered yet. We have a nice notion of when a sequence $A\\rightarrow B\\rightarrow C$ is exact, which is when the kernel of the second map is equal to the image of the first map. A natural question that arises is when does such an exact sequence induce an exact sequence of homotopy classes of maps. If the induced sequence $[-, A]\\rightarrow [-, B] \\rightarrow [-, C]$ is exact, we call the sequence a fiber sequence. If the induced sequence $[A, -]\\leftarrow [B, -] \\leftarrow [C, -]$ is exact, we call it a cofiber sequence, or a coexact sequence. The sequence of functors being exact means it the resulting sequence after evaluating at an object is always exact, i.e. $[A, X]\\leftarrow [B, X] \\leftarrow [C, X]$ exact for all $X$.\nSince the suspension is a functor we get from $X\\rightarrow Y \\rightarrow C(f)$ sequence $\\Sigma X \\rightarrow \\Sigma Y \\rightarrow C(\\Sigma f)$, which turns out is also coexact. We can see this by passing to Hom functors and applying the isomorphism to the adjoint, which is the loop functor. In the picture above, we can see that $Y$ sits nicely inside the mapping cone as a copy. Hence we can include $Y$ into it to joint the two sequences. This inclusion is a cofibration, and hence its mapping cone is homotopy equivalent to the quotient $C(f)/Y$, which is the same as the suspension of $X$. Recall from earlier that the suspension is defined as $\\Sigma X = (X\\times I)/(x,0)\\sim (x',0), (x,1)\\sim (x',1)$. A picture might help.\nWe then have the coexact sequence $X\\rightarrow Y \\rightarrow C(f) \\rightarrow \\Sigma X \\rightarrow \\Sigma Y \\rightarrow \\Sigma C(f)$. Iterating this construction, we get a long coexact sequence called the coexact Puppe sequence, or the topological cofiber sequence. There are a few details that I fave glossed over, and there maybe some cases that we should be careful about, but at least for CW complexes this should hold.\nOk, we know this is a coexact sequence, which means that if we apply a contravariant Hom functor on it, we will have a long exact sequence. What object should we use? In the case for the regular Puppe sequence, we used the homotopy Hom functor $[S^0, -]$, so what is the dual to this functor? It is $[-, K(\\mathbb{Z},k)]$. I think the reason this is true will become clear in a little bit, but to give a short note, recall that we used the adjointness between loop spaces and suspensions, and using $S^0$ was a good choice because the suspension of spheres is again a sphere in one dimension higher. So now, we also want to use this adjointness, but then we have iterated loop functors, and what spaces do we know that when used the loop functor on is again the same kind of space, but one dimension lower? You guessed it, its the Eilenberg-MacLane spaces we developed in part 5! Recall that we used that $\\Omega K(\\mathbb{Z},k) \\cong K(\\mathbb{Z}, k-1)$. Ok, so we then get the long exact sequence\n$$\\leftarrow [\\Sigma^n X, K(\\mathbb{Z}, k)] \\leftarrow [\\Sigma^n Y, K(\\mathbb{Z}, k)] \\leftarrow [\\Sigma^n C(f), K(\\mathbb{Z}, k)] \\leftarrow [\\Sigma^{n+1} X, K(\\mathbb{Z}, k)] \\leftarrow ,$$\nand since loops and suspensions is adjoint, we get\n$$\\leftarrow [X, \\Omega^n K(\\mathbb{Z}, k)] \\leftarrow [Y, \\Omega^n K(\\mathbb{Z}, k)] \\leftarrow [C(f), \\Omega^n K(\\mathbb{Z}, k)] \\leftarrow [X, \\Omega^{n+1} K(\\mathbb{Z}, k)] \\leftarrow ,$$\nwhich we know, as noted above, is the long exact sequence\n$$\\leftarrow [X, K(\\mathbb{Z}, k-n)] \\leftarrow [Y, K(\\mathbb{Z}, k-n)] \\leftarrow [C(f), K(\\mathbb{Z}, k-n)] \\leftarrow [X, K(\\mathbb{Z}, k-(n+1)] \\leftarrow .$$\nOk, now what? How does this help us at all? We are maybe expecting to find some dual notion of homotopy here, and in a way, that is what we get. There is a construction called cohomotopy (which we may explore in a later post), but this is not the construction we have here. What we have created is actually the long exact sequence in cohomology!\nCohomology The first time i learned this, I was surprised. How do we see this? Recall that a $K(\\mathbb{Z}, n)$ space in $(n-1)$-connected. Hence, by the Hurewicz theorem discussed in part 5, we have\n$$H_n(K(\\mathbb{Z}, n)) \\cong \\pi_n(K(\\mathbb{Z}, n))\\cong \\mathbb{Z},$$\nand\n$$Ext(H_{n-1}(K(\\mathbb{Z}, n)), \\mathbb{Z}) \\cong Ext(0, \\mathbb{Z}) \\cong 0,$$\nso by the cohomological universal coefficient theorem (cUCT) we have\n$$H^n(K(\\mathbb{Z}, n)) \\cong Hom(H_n(K(\\mathbb{Z}, n)), \\mathbb{Z}) \\cong Hom(\\mathbb{Z}, \\mathbb{Z}) \\cong \\mathbb{Z}.$$\nThis means that there is a canonical class in $H^n(K(\\mathbb{Z}, n))$ corresponding to the identity element $1\\in \\mathbb{Z}$, call this $\\iota$. Hence we have a natural map $[X, K(\\mathbb{Z}, n)] \\rightarrow H^n(X;\\mathbb{Z})$ given by evaluating the induced map in cohomology from a homotopy class of maps in $[X, K(\\mathbb{Z}, n)]$ on the canonical class, i.e. $[ f ]\\mapsto f_*(\\iota)$. This map is in fact an isomorphism of Abelian groups. We can see this by first confirming for spheres, and then for a bouquet of spheres, and use the skeleton structure of $X$ as a CW-complex, which gives the cofibration $X^{k-1}\\rightarrow X^k \\rightarrow \\bigvee S^k$ to get the result through induction on the degree of the skeleton, and lastly union over them all to get the result for $X$. Finally we are left with $[X, K(\\mathbb{Z}, n)] \\cong H^n(X;\\mathbb{Z})$, for all CW complexes $X$. If we assume the map f to be a cofibration, then the cohomology of the mapping cone is the same as the relative cohomology $H^n(Y,X)$. Finally, from the sequence\n$$\\leftarrow [X, K(\\mathbb{Z}, n)] \\leftarrow [Y, K(\\mathbb{Z}, n)] \\leftarrow [C(f), K(\\mathbb{Z}, n)] \\leftarrow [X, K(\\mathbb{Z}, n-1)] \\leftarrow ,$$\nwe have, under the isomorphisms discussed above, the long exact sequence\n$$\\leftarrow H^n(X;\\mathbb{Z}) \\leftarrow H^n(Y;\\mathbb{Z}) \\leftarrow H^n(Y,X;\\mathbb{Z}) \\leftarrow H^{n-1}(X;\\mathbb{Z}) \\leftarrow .$$\nThis is not the standard, and should not be the standard way to produce this exact sequence, but I still find it cool that it works this way. Cohomology doesn’t feel dual to homotopy, but in a way, this construction shows that they are, at least for some notion of dual. Maybe thinking of them as adjoint constructions is better, I don’t know. This was all I wanted to do for this post. There is another way to characterize cofibrations, namely through neighbourhood deformation retracts. The only reason i mention this is to have a relevant artwork by Fomenko to end the article with, so here is “A retraction of a space onto a subspace of it“.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/cofibrations/","summary":"This is part 6 of a series leading up to and exploring model categories. For the other parts see the series overview.\nThrough the series so far we have covered the basic uses of fibrations and related things, like the long exact sequence of homotopy groups, the Serre spectral sequence, fiber bundles and homotopy groups of spheres. But, we have not mentioned that fibrations has a dual construct, namely cofibrations. The road we are heading with this series, as mentioned before, is to define Model categories, and discover how to use them.","title":"Cofibrations"},{"content":"Some time ago I saw this problem of hanging a picture on the wall using a string and two nails in such a way that if you remove one of the nails from the wall, the picture falls down. This is a bad way to hang pictures you immediately say, and I would agree. I saw some solution to the problem, and didn’t think about it for many years, until this week when I figured out that we need homotopy, in particular the fundamental group, to do it! Finally a real world practical useful application of homotopy theory! Take that society.\nAnyway. What is this connection between hanging pictures on the wall and homotopy? Well, we are tasked to hang it with a string, and this string together with the picture forms a loop, which gives us a connection to homotopy groups. In particular it gives us a relation to the fundamental group, which is the first and simplest homotopy group. To be rigorous, lets define it properly.\nDefinition (fundamental group): Let $X$ be a path connected topological space with base point x. The fundamental group of $X$ at the point x, denoted $\\pi_1(X,x)$ is the set of loops in $X$ that start and end at $x$, modulo deformation. That means that we say two loops are the same if we can continuously deform them into each other. We define a group operation on this set by the concatenation of loops, i.e. we do one loop and then the other in succession. Since we can do a loop both one way and do the same loop backwards (which for the group inverses) we have a group. The identity element is just the constant loop at the basepoint.\nSince we are going to hang the pictures on the wall, this is equivalent to looking at the plane $\\mathbb{R}^2$ as our space to do homotopy. When we hammer two nails into the wall, this is the same as punching two holes into our plane, like in the picture below. Lets call these points $a$ and $b$. Then finally the space we are interested in is $\\mathbb{R}^2-{a,b}$, i.e. the plane but with the two points removed.\nRemoving one of the nails correspond to filling one of the holes. If we forget about the requirement described in the introduction, then to hang the picture on the wall we need to twist and turn the string around the two nails in some way. We will soon describe a particular way that meets the requirements, but first, we just look at any way to do this. Choose the basepoint in the space to be where the string is connected to the picture. Since the picture has to actually hang on the wall and not fall down, this must correspond to a non-zero element of the fundamental group $\\pi_1(\\mathbb{R}^2-{a,b}, x)$, i.e. some loop around the two nails that we can’t “pull away” or equivalently, can’t be deformed to the constant loop. If we could deform it to a constant loop, it would mean that the string really wasn’t well enough put around the two nails, and the picture falls down.\nAbove you can see a non-zero element in the homotopy group represented by a way to hang a picture on the wall. We will later call this particular way for $a^2b^{-1}ab^{-2}$, but more on the naming schemes in a little bit.\nOk, so we have figured out that any way to make the picture hang on the wall using the two nails correspond to a non-zero element in the group $\\pi_1(\\mathbb{R}^2-{a,b}, x)$. Can we describe this group in a more relatable simpler way? It turns out that we can, but not too simple. This description comes from a cool theorem in algebraic topology called the Seifert-van Kampen theorem. This theorem tells us that if we can decompose a space $X$ into two pieces, $U$ and $V$ such that the intersection of these two pieces is contractible and the base point lies in this intersection, then the fundamental group of the entire space is equal to the free product of the fundamental groups of the two pieces, i.e. $\\pi_1(X,x) = \\pi_1(U,x)\\ast \\pi_1(V,x)$. What the free product is will be explained soon, but first we need to know what this theorem can do for us? We can split $\\mathbb{R}^2-{a,b}$ into two pieces, each one containing just one of the points, and leaving a little overlap.\nThe basepoint already lies nicely in the intersection, and the intersection is just a infinite tall column, which is contractible. The fundamental group of each of the two pieces we can figure out, since each piece is homeomorphic to $\\mathbb{R}^2-{a}$ and $\\mathbb{R}^2-{b}$ respectively, which we know retracts to the sircle $S^1$, which have a fundamental group $\\pi_1(S^1)=\\mathbb{Z}$. Ok, this is maybe a bit heavy and complex looking, but think of it this way. If we were to hang the picture using only one nail, then all we could do was either wind the string around the nail in one direction, or in the opposite direction. Winding it first three times clockwise, then one more time clockwise is the same as winding it four times clockwise, and winding it three times clockwise then one time counterclockwise is the same as winding it just two times clockwise. You can maybe tell that this is the same as counting how many times we wind clockwise and counterclockwise, hence the group is the same as the integers. The identity element is just winding zero times around the nail, hence in our case, this means that the picture falls down.\nSo what have we learned? We now know that $\\pi_1(\\mathbb{R}^2-{a}) = \\pi_1(\\mathbb{R}^2-{b}) = \\mathbb{Z}$ and that $\\pi_1(\\mathbb{R}^2-{a, b}) = \\mathbb{Z}\\ast \\mathbb{Z}$ which is the notation for the free product of the groups. To understand this free product, it will be easier to describe the fundamental groups as the infinite cyclic group generated by one generator, i.e. $\\pi_1(\\mathbb{R}^2-{a}) = \\langle a \\rangle$ and $\\pi_1(\\mathbb{R}^2-{b}) = \\langle b \\rangle$. For simplicity we denoted the generator by the name of the point in which it represents the fundamental group of. Hence, $b^2$ now means winding two times clockwise around the point $b$, and $a^{-4}$ means winding four times counterclockwise around the point $a$, and so on. The free product is a bit tricky product, but in this situation we have described now, it consists of all finite lists of combinations of $a$ and $b$ where we multiply the $a$‘s and $b$‘s where we can. An example of an element would then be $a^2b^3a^{-6}ba^2b^{-2}$, and all other combinations you could think of. Multiplication of elements is just writing them after each other and contracting the elements that can be contracted. Inverse elements comes from writing the list of elements backwards and replacing all positive degrees with negative and vice versa. So for example, $a^2b^{-3}$ is the inverse of $b^3a^{-2}$ because their multiplication (concatenation of lists) is $a^2b^{-3}b^3a^{-2} = a^2b^0a^{-2} = a^2a^{-2} = a^0 = id$.\nOk, we now have algebraic descriptions of the fundamental groups, and we can use this to describe a way to hang the picture in the way we wanted. To recall the problem, we want to hang a picture on the wall using a string and two nails such that if we remove any of the two nails from the wall, the picture falls down. My guess is the following picture.\nIn the algebraic language we developed just prior, this would be called $aba^{-1}b^{-1}$. Anyone having done some abstract algebra, or especially some Lie theory would immediately recognize this as the so called commutator of $a$ and $b$. In the free product this commutator is not equal to the identity element, as we can see in the picture and since the group is non-Abelian. In an Abelian group however (like the fundamental group of the plane with just one point removed), all commutators are trivially equal to the identity element, and this is what we will use to make the picture fall down.\nSo, lets prove that my guess satisfies the requirement. Notice that removing the nail at the point $b$, or equivalently filling the hole b corresponds to a group homomorphism that sends an element of the free product group to the cyclic group on $a$, i.e. a homomorphism $f_a: \\langle a\\rangle \\ast \\langle b\\rangle \\rightarrow \\langle a\\rangle$ that is the identity on the elements of $\\langle a\\rangle$ and is the trivial homomorphism that sends everything to the identity on all elements of $\\langle b\\rangle$. For example,\n$$f_a(a^5b^{-3}a^{-3}b^2) = f_a(a^5)f_a(b^{-3})f_a(a^{-3})f_a(b^2)=a^5 \\cdot id_a \\cdot a^{-3}\\cdot id_a = a^5\\cdot a^{-3} = a^2.$$\nThe act of removing the nail at point a corresponds to the exact same construction, just for the group $\\langle b\\rangle$. Call this map $f_b$. Now, what happens when we use the maps that corresponds to removing nails on the commutator we designed earlier? We get\n$$f_a(aba^{-1}b^{-1})=f_a(a)f_a(b)f_a(a^{-1})f_a(b^{-1})) = a\\cdot id_a \\cdot a^{-1} \\cdot id_a = id_a$$\nand\n$$f_b(aba^{-1}b^{-1})=f_b(a)f_b(b)f_b(a^{-1})f_b(b^{-1})) = id_b\\cdot b \\cdot id_b \\cdot b^{-1} = id_b,$$\nand hence, removing any of the nails means that the loop no longer hangs on any of the nails, since for it to hang on one of the nails it has to have been wound around at least one time clockwise or counterclockwise! This is equivalent to saying that the picture falls to the ground, which proves that our guess actually fits the criteria. There are as you may notice very many other ways to do this, but i think the commutator way is the most simple and easiest to visualize. And by that we have successfully made a shitty way to hang a picture on a wall, but, we used homotopy, which makes it cool!\n","permalink":"https://torgeiraamboe.github.io/posts/2020/hanging-pictures-with-homotopy/","summary":"Some time ago I saw this problem of hanging a picture on the wall using a string and two nails in such a way that if you remove one of the nails from the wall, the picture falls down. This is a bad way to hang pictures you immediately say, and I would agree. I saw some solution to the problem, and didn’t think about it for many years, until this week when I figured out that we need homotopy, in particular the fundamental group, to do it!","title":"Hanging pictures with homotopy"},{"content":"This is part 5 of a series leading up to and exploring model categories. For the other parts see the series overview.\nAs promised in the previous part, we are going to calculate $\\pi_4(S^3)$. I think we will have to use all of the machinery (plus some new) that we have been through during this series to do the calculation. What more could we possibly need you ask? Last time we developed the machinery to calculate the cohomology of the total space of a fibration, but we want to compute homotopy. Hence we need a method for translating cohmological information into homotopical information, which is what we are missing to be able to do the calculation. There may be other processes that I haven’t learned, but the process I know goes through two steps. First we must translate cohomology into homology. This is done through the so called cohomological universal coefficient theorem (cUCT). Then we need to translate from homology to homotopy. This is done through the Hurewicz theorem. I think of these two theorems together as sort of a Rosetta stone for algebraic topology. It makes us able (with some computation and restrictions of course) to move between the three fundamental theories of invariants we have in algebraic topology, which I find beautiful. There is one more thing we need, which is a starting point for our calculation. We need a good fibration to extract the information we want which we are able to translate into homotopy afterwards. Therefore we need a space in the fibration that does not complicate things when we translate into homotopy, i.e. we need a space in which we completely understand its homotopy groups. The “homotopy-easy” spaces I’m describing are called Eilenberg-MacLane spaces. In cohomology (and homology) theory we have the easy spaces being spheres because we completely understand their cohomological structure. They cam be thought of as the building blocks for (co)homology. The same type of space for homotopy is exactly theese Eilenberg-MacLane spaces, and they form the building blocks for homotopy groups in the same way as the spheres for (co)homology. Hence we can combine these spaces and spheres in a fibration and use that to compute cohomology and then relatively easily translate this to homotopy, which is exactly our plan for computing $\\pi_4(S^3)$.\nExpanding our tool belt The first new tool, which we briefly mentioned above is called the Hurewicz theorem and allows us to move between homology and homotopy in certain nice cases. These nice cases happen when the topological space we are studying is very connected, i.e. at least both path connected and simply connected and often even the higher dimensional analog called n-connected. The level of connectedness can be formulated though the homotopy groups of the space, in particular we call a space $X$ for $n$–connected if $\\pi_k(X) = 0$ for all $k\\leq n$, here path connected corresponds to 0-connected, and simply connected corresponds to 1-connected.\nTheorem (Hurewicz): Let $n\\geq 2$. and $X$ be $(n-1)$-connected. Then $H_k(X) = 0$ for all $ 0 \u0026lt; k \u0026lt; n $ and the Hurewicz homomorphism $h_*: \\pi_n(X) \\rightarrow H_n(X)$ is an isomorphism.\nWe see that the absence of low degree homotopy groups also gives an absence of lower degree homology groups. The Hurewicz homomorphism is given by evaluating the induced map on homology from a homotopy class of a map $f:S^n\\rightarrow X$ in the fundamental class of $S^n$, i.e. the choice of a generator for the group $H_n(S^n)\\cong \\mathbb{Z}$. If we denote the fundamental class by $[S^n]$, then it is given by $h_*([f])=f_([S^n])$. What exactly the maps are will not be important for us, but the fact that it is an isomorphism in nice cases is very useful.\nTheorem (cUCT): Let $X$ be a topological space and $G$ an Abelian group. Then for any $i$ we have a short exact sequence\n$$0\\rightarrow Ext_{\\mathbb{Z}}(H_{i-1}(X;\\mathbb{Z}), G)\\rightarrow H^i(X;G) \\rightarrow Hom_{\\mathbb{Z}}(H_i(X;\\mathbb{Z}), G)\\rightarrow 0.$$\nThis tells us that cohomology is almost just maps from homology into the coefficients, except we might be a little bit off, but in a manner we understand, i.e. up to some extension. We are going to rely quite heavily on this theorem in the calculation later, but there are a few extra bits we need. There is a theorem by Serre that says that the homology groups of a simply connected space are finitely generated if and only if the homotopy groups are finitely generated. We know that the homology groups of spheres are finitely generated, hence all of the homotopy groups are also finitely generated. In the short exact sequence in cUCT, we also need to know a little bit about when there are no homomorphisms between two groups, and how the Ext group works. If we have a finite group $A$, then the group group $Hom(A,\\mathbb{Z})=0$. To have the converse statement we also need to know that A is finitely generated, i.e. if $A$ finitely generated then $Hom(A,\\mathbb{Z})$ is a free group. Hence if $Hom(A,\\mathbb{Z})=0$ then $A$ is a finite group. What we need to know about $Ext(A,\\mathbb{Z})$ is that $Ext(\\mathbb{Z}/2,\\mathbb{Z})\\cong \\mathbb{Z}/2$, and that the converse holds if we have a finiteness condition, i.e. if $A$ is a finite group and $Ext(A,\\mathbb{Z})=\\mathbb{Z}/2$, then $A\\cong \\mathbb{Z}/2 .$\nDefinition: A topological space $X$ is called an Eilenberg-MacLane space of type $K(G,n)$, or just a $K(G,n)$-space for short, if we have $\\pi_n(X) = G$ and all of its other homotopy groups are trivial.\nThe important cases for us in this computation is a $K(\\mathbb{Z}, 3)$ space and a $K(\\mathbb{Z}, 2)$ space. How do these spaces look? We know the simplest case, namely that the sircle $S^1$ is a $K(\\mathbb{Z}, 1)$ space. This we know because it has the integers as a fundamental group, and as discussed in part 3, it can have no maps from higher dimensional spheres, hence all higher homotopy groups are trivial, and this is our definition of a $K(\\mathbb{Z}, 1)$-space. In the computation later we need an explicit description of a $K(\\mathbb{Z}, 2)$-space, so before we jump to computation, we remark that $\\mathbb{C}P^{\\infty}$ is in fact a $K(\\mathbb{Z}, 2)$-space! This space is the space consisting of all complex lines passing through the origin in the infinite dimensional complex vector space $\\mathbb{C}^{\\infty}$. I’m not going to explain much about this space, but we will use it’s cohomology groups and it’s cohomology ring later.\nCalculation of $\\pi_4(S^3)$ I didn’t expect the preliminaries to be that long, but now the hard part is over (not really) and we are finally ready to compute! Lets start with the fibration $X\\rightarrow S^3 \\rightarrow K(\\mathbb{Z},3)$. This fibration is not super easy to get, but the idea is to iteratively attach higher dimensional cells to $S^3$ in order to kill off higher homotopy groups in degrees higher than 3. When we kill off all the higher homotopy groups, we are only left with a homotopy group in degree three, which is the integers since it is “made” from the 3-sphere, and this is our definition of a $K(\\mathbb{Z},3)$. This is sometimes referred to as “capping” of a space, giving a “capped” space. It is dual to the notion of a “killing space”, which is a cool name i thought i would mention. When we pass to the long exact sequence for this fibration we get\n$$\\cdots \\rightarrow \\pi_4(K(\\mathbb{Z},3)) \\rightarrow \\pi_3(X) \\rightarrow \\pi_3(S^3) \\rightarrow \\pi_3(K(\\mathbb{Z},3)) \\rightarrow \\pi_2(X) \\rightarrow \\pi_2(S^3) \\rightarrow \\cdots,$$\nin which we know several of the groups. We know that $K(\\mathbb{Z},3)$ only has homotopy in degree 3 and that $\\pi_2(S^3) = 0$. We also know that the map $\\pi_3(S^3) \\rightarrow \\pi_3(K(\\mathbb{Z},3))$ is an isomorphism, since that is the way we constructed the space $K(\\mathbb{Z},3)$. Further to the right we only have trivial groups. Hence we get\n$$\\pi_3(X) \\cong \\pi_2(X) \\cong \\pi_1(X) \\cong \\pi_0(X) \\cong 0.$$\nFurther to the right we have that all of the homotopy groups of $K(\\mathbb{Z},3)$ are trivial, and because we know that the long sequence is exact, we get that $0 \\rightarrow \\pi_n(X) \\rightarrow \\pi_n(S^3) \\rightarrow 0$ is exact, hence the homotopy groups are isomorphic for all $n\u0026gt;3$. In particular we have $\\pi_4(X) \\cong \\pi_4(S^3)$ which is what we are going to use in order to calculate it. As mentioned earlier, all homotopy groups of spheres are finitely generated, and hence all of the homotopy groups of $X$ are as well. We see that we have to compute the homotopy groups of $X$, and to do this we are going to use the Rosetta stone we described in the introduction, by first computing its cohomology, and then translating through homology and then finally into homotopy.\nAs we did in the Puppe sequence in part 3, we can extend the inclusion of the fibers into the total space to a fibration with fibers being the loop space of the base space in the original fibration, i.e. $\\Omega K(\\mathbb{Z},3)\\rightarrow X \\rightarrow S^3$. Have we made things even more complicated? How does the loop space of an Eilenberg-MacLane space look? We have actually made it simpler. In part 3 we discussed the suspension functor, and noticed that the suspension of a sphere is a new sphere in one dimension higher. Hence the suspension functor should shift the degrees of the homotopy groups up by one. We mentioned that the loop space functor is adjoint to the suspension, and hence is shifts the degrees of the homotopy groups down by one. We can also see this by the fibration $\\Omega X\\rightarrow PX \\rightarrow X$, where $PX$ is the path space of $X$. The path space is contractible, and hence from it has only trivial homotopy groups, so when we pass to the long exact sequence of homotopy groups from the fibration we get that $\\pi_{n+1}(X) \\cong \\pi_{n}(\\Omega X)$. Because of this we get that $\\pi_n(\\Omega K(\\mathbb{Z},3)) = 0$ for $n\\geq 3$ and $\\pi_2(\\Omega K(\\mathbb{Z},3)) = \\mathbb{Z}$.\nHey, look at that, the loop space of the Eilenberg-MacLane space has only one non-trivial homotopy group, and thus by our definition it is an Eilenberg-MacLane space itself, namely a $K(\\mathbb{Z}, 2)$-space. Luckily for us we already know a $K(\\mathbb{Z}, 2)$-space, namely $\\mathbb{C}P^{\\infty}$. To summarize, our new fibration looks like $\\mathbb{C}P^{\\infty}\\rightarrow X \\rightarrow S^3$. Now we have something to put into a spectral sequence which we know computes the cohomology of $X$ from the cohomology of the base and the cohomology of the fibers. And, since $\\mathbb{C}P^{\\infty}$ is a nice CW-complex with one cell in each even degree, we know how its cohomology looks like, and even more important, we know how its cohomology ring looks like. We have $H^*(\\mathbb{C}P^{\\infty})\\cong \\mathbb{Z}[a_2]$, i.e. a polynomial ring with the generator in degree two. Lets throw all this information into the Serre spectral sequence. We get\nSince our base space is a sphere, we naturally get two columns, and since $\\mathbb{C}P^{\\infty}$ has cohomology in every even degree, these two columns continue all the way up to infinity. Luckily for us, we only care about a small portion of the spectral sequence. Since there are 3 “steps” between the two columns, all of the differentials on the second page has a trivial group as either it’s domain or it’s codomain. Hence nothing happens at the second page. When we flip to the third page, the differentials are “long” enough to connect our two columns. We know that the spectral sequence computes the cohomology of the topological space $X$, and since there are only one group along each of the diagonals, i.e. either $\\bigoplus_{p+q=n}E_r^{p,q} = E_r^{0,n}$ or $\\bigoplus_{p+q=n}E_r^{p,q} = E_r^{3,n}$. By this we know that the n‘th cohomology group of $X$ is actually the group showing up in the spectral sequence along the n‘th diagonal. From the computation of the homotopy groups of $X$ earlier, we know that $\\pi_3(X) = \\pi_2(X)=0$ and by the Hurewicz theorem we know that this implies that $H_3(X) = H_2(X) = 0$, which by cUCT implies that $H^3(X) = 0$. We have a group on the third diagonal, namely $E_3^{3,0}$, and it is hit by only one single differential, which is the differential $d:E_3^{0,2}\\rightarrow E_3^{3,0}$. Since all other differentials at the later pages are too long, we know that this differential is in fact the only differential hitting this group throughout the entire spectral sequence. Thus, we know that it has to be an isomorphism. Since the cohomology ring of $\\mathbb{C}P^{\\infty}$ has a generator a in the second degree, it lives in $E_3^{0,2}$ and it maps through $d_2$ to some generator of $E_3^{3,0}$, call this $x$, i.e. $d_2(a)=x$. The generator a lives in degree 2, so its square in the cohomology ring $a^2$ lives in degree 4, and hence lives in $E_3^{0,4}$. By the Leibniz rule that the differentials satisfy, we get that $d_4(a^2)= ax$ and that the map is multiplication by two. The cube of the generator $a^3$ lives in $E_3^{0,6}$ and maps to $a^2 x$ by multiplication by three and so on upwards. We can draw the information into the spectral sequence, just for a better visualization.\nWhen we flip to the fourth page, all of the differentials are too long to pass between the columns, and hence we get that $E_4 = E_{\\infty}$ which means that $H^4(X)=Ker(d_4)=Ker(\\cdot 2) = 0$ and latex $H^5(X) = Cok(d_4)= Cok(\\cdot 2) = \\mathbb{Z}/2$. Now we’re getting somewhere! We see the first evidence of what is to become $\\pi_4(S^3)$ after translating with the Rosetta stone. As described earlier, we need to translate into homology first, which we do by cUCT. We get the short exact sequence\n$$0\\rightarrow Ext_{\\mathbb{Z}}(H_{3}(X), \\mathbb{Z})\\rightarrow H^4(X) \\rightarrow Hom_{\\mathbb{Z}}(H_4(X), \\mathbb{Z})\\rightarrow 0.$$\nWe figured out that $H^4(X) = 0$ and $H_3(X)=0$, and therefore we get $Ext_{\\mathbb{Z}}(H_3(X),\\mathbb{Z}) = Ext_{\\mathbb{Z}}(0,\\mathbb{Z}) = 0$. Since the sequence is exact we must have $0 = H^4(X;\\mathbb{Z}) \\cong Hom_{\\mathbb{Z}}(H_4(X),\\mathbb{Z})$. Then $Hom_{\\mathbb{Z}}(H_4(X),\\mathbb{Z}) = 0$ which implies that $H_4(X)$ is a finite group. This we know since the homotopy groups of $X$ are finitely generated (discussed previously), hence the homology groups of $X$ are as well which gives us that it is a finite group by the discussion in the paragraph about cUCT. In one degree higher we also get a short exact sequence from cUCT, namely the sequence\n$$0\\rightarrow Ext_{\\mathbb{Z}}(H_{4}(X), \\mathbb{Z})\\rightarrow H^5(X) \\rightarrow Hom_{\\mathbb{Z}}(H_5(X), \\mathbb{Z})\\rightarrow 0.$$\nSince $H_4(X)$ is finitely generated we know $Hom_{\\mathbb{Z}}(H_5(X), \\mathbb{Z}) = 0$, because it is either this or it is equal to $\\mathbb{Z}/2$ and that option disappears since it is free. Now this means that $Ext_{\\mathbb{Z}}(H_{4}(X), \\mathbb{Z}) \\cong H^5(X) \\cong \\mathbb{Z}/2$ and since we know that $H_4(X)$ is a finite group, we get that $H_4(X)\\cong \\mathbb{Z}/2$. Phew… Almost done now.\nThankfully, the last part of the translation from homology to homotopy is easier in this case. Recall that we figured out that $\\pi_3(X) \\cong \\pi_2(X) \\cong \\pi_1(X) \\cong \\pi_0(X) \\cong 0$ in the beginning when constructing our fibrations. Hence we know that X is 3-connected, and by the Hurewicz theorem we have an isomorphism $H_4(X)\\cong \\pi_4(X)$ which means that we have $\\pi_4(X) \\cong \\mathbb{Z}/2$. Our whole reason for doing this calculation with the space $X$ was that we figured out from the long exact sequence from the fibration that $\\pi_4(X) \\cong \\pi_4(S^3)$, and by this we finally have our result, $\\mathbb{Z}/2\\cong H_4(X)\\cong \\pi_4(X) \\cong \\pi_4(S^3)$, or in short\n$$\\pi_4(S^3) \\cong \\mathbb{Z}/2 .$$\nI really like this computation because it is rather difficult, and has a lot of moving parts, which makes it more fun! I don’t think the next posts will be this long and detailed, because this is maybe a bit much information in one post, even though it is just one computation in essence. Onward we will discuss cofibrations and weak equivalences, and then move into model category territory. I think my goal will be to show that the homotopy category of topological spaces is equivalent to the homotopy category of simplicial sets, which also enables me to finally start reading May’s book “Simplicial objects in algebraic topology”. Anyway, as usual I will leave off with an artwork by Anatoly Fomenko, this time his piece called “The method of killing spaces in homotopic topology”, which is dually relevant.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/a-homotopy-group-of-a-sphere/","summary":"This is part 5 of a series leading up to and exploring model categories. For the other parts see the series overview.\nAs promised in the previous part, we are going to calculate $\\pi_4(S^3)$. I think we will have to use all of the machinery (plus some new) that we have been through during this series to do the calculation. What more could we possibly need you ask? Last time we developed the machinery to calculate the cohomology of the total space of a fibration, but we want to compute homotopy.","title":"A homotopy group of a sphere"},{"content":"This is part 4 of a series leading up to and exploring model categories. For the other parts see the series overview.\nMy personal favorite part about fibrations is that they come equipped with a natural way to compute the cohomology of the total space from the cohomology of the base and the cohomology of the fibers. This process is encoded in a structure called a spectral sequence, and is a complicated object in its full generality. It consists of layers upon layers of intertwined cohomology groups, all sewn together by homomorphisms. But when I first learned their computing power, and learned how to use them, I fell in love with the structure. If you visit my homepage you will find several small write ups using spectral sequences to prove theorems and do computations of cohomology rings etc. Therefore, I want to create a nice introduction to how to use them, given a fibration. Technicalities of the structure of the spectral sequences will be omitted, but the definitions will of course be given.\nSpectral sequences A spectral sequence can be thought of as a book, with possibly infinite pages. Every page consists of multiple complexes of cohomology groups, each being the cohomology of one of the complexes on the previous page. The maps on a page will be “longer” than the maps on the previous page, and all of them will be almost diagonal. We will make all this more precise in a little bit, but it can be helpful to have this information in the back of the head will reading and exploring the definition. With that said we first remind ourselves of some basic definitions from homological algebra to be able to formulate and be precise with the spectral sequence afterwards.\nDefinition (chain complex): A sequence of abelian groups (or more generally modules, or even more generally objects in some abelian category)\n$$\\cdots \\rightarrow A_{n-1} \\overset{d_{n-1}}\\rightarrow A_n \\overset{d_n}\\rightarrow A_{n+1} \\rightarrow \\cdots $$\nis called a cochain complex if the composition of two arrows is zero, i.e. if $d^2 = 0$. This is equivalent to saying that $\\text{Im}(d_{n-1})\\subset \\text{Ker}(d_n)$.\nDefinition (cohomology): Let C be a cochain complex. We define the n‘th cohomology group of $C$ to be $H^n(C) = \\text{Ker}(d_n)/\\text{Im}(d_{n-1})$. This is often verbally stated as “cocycles modulo coboundaries”.\nThe most important cases for us is the use of cohomology of topological spaces. From a topological space $X$ we can define a cochain complex called the singular cochain complex on $X$. When we take the cohomology groups of this singular cochain complex, we get a lot of information about the topological structure of $X$. When we discuss cohomology groups from here on out, we will always mean this type of cohomology.\nDefinition (Spectral sequence): A spectral sequence is a tri-graded object, or a list of bi-graded objects $E^{p,q}_ r$ together with morphisms $d^r: E^{p,q}_ r \\rightarrow E^{p+r, q-r+1}_ r$ for all $r\u0026gt;0$ ,$p,q\\in \\mathbb{Z}$, and isomorphisms $E^{p,q}_{r+1}\\cong H(E^{p,q}_{r})$. The spectral sequence is called a first quadrant spectral sequence if $E^{p,q}_r = 0$ when $p\u0026lt; 0$ or $q\u0026lt;0$ .\nRemark: In the way we have developed the spectral sequence, it computes cohomology. I just want to mention that there is a completely analog version that computes homology. If we go through the same construction, just reversing all the arrows, and changing coefficients by tensoring instead of taking dual groups, we get a spectral sequence of homological type.\nThe first time I saw this definition, i didn’t understand anything. It was through a graduate course in algebraic topology, and roughly half the course focused on the use of spectral sequences. The problem with trying to introduce this abstract structure in this short of a text is that we don’t have enough time to explore it properly, and not even explain the definition properly with the care and precision it really deserves. That said, I feel the importance of the spectral sequence is not the understanding of the nitty gritty details, but how we can use it. The spectral sequence in all of its generality is for me not very nice, but there are special cases of them that pop up from different places, most important for us, from a fibration. This special case makes it relatively easy to depict what happens, and how topological spaces relate to each other through the fibrations. The proof that we in fact get a spectral sequence from a fibration is rather long and difficult, and I don’t want to go through it here (at least for now), so just trust me when i say that it works. If you don’t, I recommend Weibel’s book “An introduction to homological algebra” where the construction is explained further, or Hatcher’s book “Algebraic topology”.\nTo be more precise about how the spectral sequence from a fibration looks, we give a proper definition.\nDefinition (Serre spectral sequence): Given a fibration $F\\rightarrow X\\rightarrow B$ we get a first quadrant spectral sequence $E$ such that $E_r^{p,q}\\Rightarrow H^{p+q}(X, \\mathbb{Z})$ .\nThis spectral sequence starts at the second page which is given by $E_2^{p,q}\\cong H^p(B;H^q(F;\\mathbb{Z}))$.\nHere the \u0026lsquo;'$\\Rightarrow$\u0026rsquo;' means that it computes or “converges” to the cohomology of the total space. This roughly translates to taking the direct sum of all of the groups on the diagonal, i.e. $H^n(E) \\cong \\bigoplus_{p+q=n}E_{\\infty}^{p,q}$. This is not always completely correct, and we have to be a bit careful when doing this, but in the case of first quadrant bounded spectral sequences I think it holds. In the examples I will try to be more graphical, and use pictures of the spectral sequences to make the math clearer. Whenever I say spectral sequence from now, I will mean (unless otherwise stated) the Serre spectral sequence. Before we look at some examples lets look at a general picture for how the second page of the spectral sequence of a fibration $F\\rightarrow X\\rightarrow B$ looks like.\nHere we can quite clearly see the almost diagonal maps on the second page, and we also see the bi-graded grid of cohomology groups that is described in the definition. If I had drawn a bigger diagram, we would start to see to of the orange arrows after one another. The sequence of groups with these arrows called differentials form chain complexes as we mentioned in earlier, i.e. their composition will always be zero. I will not draw a general picture of the third page, but it would consist of the cohomology of the complexes formed by the orange differentials. The maps on the third page would go two down and three to the right, instead of one down and two to the right as in the second page we see depicted. Note that the maps being called differentials here are not because they are maps in the spectral sequence, but because they are differentials in the chain complexes, meaning they compose to zero and satisfy the generalized Leibniz rule. We will not need this, but it is important to know the naming conventions.\nComputing some examples To see that it actually works, it is maybe good to have a trivial example first, namely when the fibration $F \\rightarrow E \\rightarrow B$ comes from a trivial fiber bundle, also called the product, i.e. $E\\cong B\\times F$. Lets take a concrete example, say $S^2 \\rightarrow E= S^1\\times S^2 \\rightarrow S^1$. The spectral sequence associated to this fibration should in theory compute that the cohomology $H^n(S^1\\times S^2)$ is the same as the product of the cohomologies $H^n(S^1)\\times H^n(S^2)$. Let’s see how it pans out. We know that the cohomology groups of $S^1$ looks like the integers in degree zero and in degree one, i.e. $H^0(S^1;\\mathbb{Z}) \\cong \\mathbb{Z} \\cong H^1(S^1;\\mathbb{Z})$. We also know that the cohomology groups of $S^2$ looks like the integers in degree zero and in degree two, i.e. $H^0(S^2;\\mathbb{Z}) \\cong \\mathbb{Z} \\cong H^2(S^2;\\mathbb{Z})$, hence we get\nAs we see, the differentials miss all of the available groups, and every one of them is therefore the zero homomorphism, since remember that the sequences of objects they form are in fact complexes. Hence nothing changes when we flip to the next page, and the next after that, and we have $E_2 = E_{\\infty}$. Because of this the cohomology of the product is the sum along the diagonal and we get $H^0(S^1\\times S^2) \\cong \\mathbb{Z}$, $H^1(S^1\\times S^2) \\cong \\mathbb{Z}$ and $H^2(S^1\\times S^2)\\cong \\mathbb{Z}$, just as we expected.\nLet’s do another example. In part 3 of this fibration series we computed the third homotopy group of the sphere by using the long exact sequence of homotopy groups from the Hopf fibration. What happens in the spectral sequence associated to the Hopf fibration then? On the second page we get four cohomology groups as shown here:\nWe only have one non-zero differential, namely the morphism between $E_2^{0,1}$ and $E_2^{2,0}$. Hence, when we flip to the third page, we have\nOn the third page we see that all of the possible differentials are too long to hit any of the groups, hence we know that the third page is the last page, i.e. all pages after has to look exactly the same. We are lucky to already know how the cohomology of the spheres look, and since we know that the spectral sequence computes the cohomology of $S^3$ we know that the differential has to be an isomorphism, since it has to have both a trivial kernel and a trivial cokernel. To explain a bit better, if we were to sum along the diagonals to compute the cohomology of $S^3$, we would see $H^1(S^3)=Ker(d)$, but as mentioned we know that $H^1(S^3)=0$, thus we must have $Ker(d)= 0$. The exact same argument holds for $Cok(d)$, and since they are both zero, d has to be an isomorphism.\nFuture of the series Next time in the fibration series we will use the machinery we developed in here, together with some theorems to compute one more of the non-trivial homotopy groups of the spheres. We will show that $\\pi_4(S^3) \\cong \\mathbb{Z}/2$ which i think historically was the first computed homotopy group of a sphere that was non-trivial and also not just the integers, but a finite cyclic group. A tentative plan for this series is to introduce enough material so that I can start to learn about model categories properly. There is also loads more fun calculations to do and more theorems and concepts to study. Also, recently Eric Weinstein published a lecture describing his proposed theory of everything, i.e. a theory that unifies general relativity and quantum mechanics. In this theory he uses a generalized version of the universe as a manifold and constructs a certain fiber bundle over this manifold which he calls the Observerse. It would be cool to try to construct this bundle, and a related bundle which he calls the Chimeric bundle, to dip my toes into mathematical physics. The summer vacation is long, and corona makes sure that I have plenty of time at home to study. For reading to the end I last time left off with an incredible art piece by my favorite Russian mathematician and artist Anatoly Fomenko, picturing his vision on homotopy groups of spheres. I will leave off this time with yet another artwork by Fomenko, this time it naturally fits to leave off with his work “A spectral sequence“.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/the-serre-spectral-sequence/","summary":"This is part 4 of a series leading up to and exploring model categories. For the other parts see the series overview.\nMy personal favorite part about fibrations is that they come equipped with a natural way to compute the cohomology of the total space from the cohomology of the base and the cohomology of the fibers. This process is encoded in a structure called a spectral sequence, and is a complicated object in its full generality.","title":"The Serre spectral sequence"},{"content":"This is part 3 of a series leading up to and exploring model categories. For the other parts see the series overview.\nFor an introduction to the material, the definitions, motivation and some examples, please read part 1 and part 2 about fibrations and fiber bundles. This and the the following parts of this series will be about their usefulness, especially in computing homology and homotopy groups. This will be done through two different techniques, namely the long exact sequence of homotopy groups, and the spectral sequence associated to a fibration. In this this part, we look at the long exact sequence. This is a tool that will let us relate the homotopy groups of different kinds of spaces to each other, and ultimately, will help us compute the homotopy groups of fiberbundles from the homotopy groups of the base space, and the homotopy groups of the fibers. Forward, we always have pointed spaces, and the base spaces of our fibrations are simply connected. To be a bit more self contained, we remind ourselves what a long exact sequence is.\nDefinition (l.e.s): A long sequence of objects (in our case usually groups or pointed spaces)\n$$\\cdots \\longrightarrow A_{n+1} \\overset{d_{n+1}} \\longrightarrow A_n \\overset{d_n} \\longrightarrow A_{n-1} \\longrightarrow \\cdots $$\nis called exact at $A_n$ if $\\text{Ker}(d_n)=\\text{Im}(d_{n+1})$ . The sequence is called exact if it is exact for every $n.$\nThe Puppe sequence There are several ways to develop the long exact sequence of homotopy groups, but we will do it through the Puppe sequence, and for that we first need to look at the loop space $\\Omega X$ of a topological space $X$. This is, as the name says, the topological space consisting of all loops in $X$ , i.e. the space of all pointed maps from the pointed sircle $(S^1, \\infty)$ to $X$ . We also need the notion of the homotopy fiber of a map $f: X\\rightarrow Y$ . Intuitively, this is the fiber of $f$ , except we are allowed to move thing around by a homotopy. To be more precise, the homotopy fiber of a point $y\\in Y$ consists of pairs $(x,\\omega)$ such that $\\omega$ is a path from $f(x)$ to $y$ in $Y$ . We call the collection of the fibers of all the points for the homotopy fiber of $f$, denoted $hofib(f)$.\nNow, let $f:X\\longrightarrow Y$ be a map of topological spaces. We can turn this into an exact sequence by including the homotopy fiber into the picture, namely $hofib(f)\\rightarrow X\\rightarrow Y$ . The loop space of $Y$ injects nicely into the homotopy fiber, because it consists of the paths that both start and end at the same points. We can even include $\\Omega X$ , and get a sequence\n$$\\Omega X \\rightarrow \\Omega Y \\rightarrow hofib(f)\\rightarrow X\\rightarrow Y.$$\nIterating this process further by doing the same construction on the map $\\Omega X \\rightarrow \\Omega Y$ , we get a long sequence consisting of iterated loop spaces $\\Omega^n X, \\Omega^n Y$ and homotopy fibers. This long sequence is called the Puppe sequence, and as you may have guessed, it is going to give us the exact sequence of homotopy groups that we are after.\nThe long exact sequence in homotopy If we assume that the map in the Puppe sequence is a fibration, say $p: E\\rightarrow B$ , then we get a sequence\n$$\\cdots \\rightarrow \\Omega^n X \\rightarrow \\Omega^n Y \\rightarrow \\Omega^{n-1} hofib(p) \\rightarrow \\cdots .$$\nTaking homotopy classes of pointed maps from the zero sphere $S^0$ , we get a long exact sequence\n$$\\cdots \\rightarrow [S^0, \\Omega^n X] \\rightarrow [S^0, \\Omega^n Y] \\rightarrow [S^0, \\Omega^{n-1} hofib(p)] \\rightarrow \\cdots$$\nOn homotopy classes of pointed maps, the loop space functor $\\Omega (-)$ is adjoint to the suspension functor $\\Sigma (-)$. This is part of Eckmann-Hilton duality and takes some time to explain, so I will not do that here. Hence we get the sequence\n$$\\cdots \\rightarrow [\\Sigma^n S^0, X] \\rightarrow [\\Sigma^n S^0, Y] \\rightarrow [\\Sigma^{n-1} S^0, hofib(p)] \\rightarrow \\cdots .$$\nThe suspension of a space is defined to be the cartesian product with the unit interval modulo the relation that all points are equivalent at the endpoint at the interval. This is maybe more clear with a drawing of the suspension of $S^0$ , where we can see that it is in fact equal to $S^1$ .\nBecause it is fun to draw, I also include a drawing of the suspension of $S^1$ , to see that it is equal to $S^2$ .\nThis phenomenon continues, and we see that an $n$ -sphere is just the suspension of an $(n-1)$ -sphere. Hence, we have that the iterated suspension $\\Sigma^n S^0 \\simeq S^n$ and we get the sequence\n$$\\cdots \\rightarrow [S^n, X] \\rightarrow [S^n, Y] \\rightarrow [S^{n-1}, hofib(p)] \\rightarrow \\cdots .$$\nSince our map is a fibration, the homotopy fiber $hofib(p)$ has the same homotopy type as the usual fiber, and we can replace $[S^n, hofib(p)]$ by just $[S^n, F]$ . By this, we are done, since these spaces are the definitions of the higher homotopy groups, i.e. $\\pi_n(X)\\cong [S^n, X]$, thus we finally have our long exact sequence of homotopy groups\n$$\\cdots \\rightarrow \\pi_n(X) \\rightarrow \\pi_n(Y) \\rightarrow \\pi_{n-1}(F) \\rightarrow \\cdots .$$\nComputing some homotopy groups Our goal for introducing this long exact sequence was to be able to compute homotopy groups of spaces, so that is what we will do. We start by computing both of the examples of fiber bundles we discussed yesterday, namely the cylinder and the Möbius band. For the cylinder we have the fiber bundle $I \\rightarrow S^1\\times I \\rightarrow S^1$ , which gives us the exact sequence\n$$0 \\rightarrow \\pi_1 I \\rightarrow \\pi_1 S^1\\times I \\rightarrow \\pi_1 S^1 \\rightarrow 0$$\nSince $I$ is path connected, and $\\pi_2 S^1 =0$ since the circle has the real line as it’s universal cover and any map would then extend to the universal cover since the sphere is simply connected. Since $I$ is contractible, we get that $\\pi_1 I =0$ as well, which gives us that the fundamental group of the cylinder $\\pi_1 S^1\\times I$ is $\\mathbb{Z}$ . Since the cylinder is homotopy equivalent to the circle, this is maybe no surprise. For the Möbius band, we get the exact same sequence, and then the exact same fundamental group, no surprises.\nHistorically, the most sought after examples were the homotopy groups of the higher dimensional spheres, since (as an understatement) both homotopy and homology are devices for counting mathematical holes. The spheres have almost all trivial homology groups, and is they would have almost all trivial homotopy groups, then these invariants would be a lot more similar. But, as shown by Hopf, this was not the case. He did so by introducing the now-called Hopf fibration, $S^1 \\rightarrow S^3 \\rightarrow S^2$ . This can be seen geometrically since the 3-sphere is a double cover of the space $SO(3)$ which acts on the 2-sphere by rotation. This fibration produces the exact sequence\n$$\\pi_3 S^1 \\rightarrow \\pi_3 S^3 \\rightarrow \\pi_3 S^2 \\rightarrow \\pi_2 S^1$$\nwhere $\\pi_2 S^1$ is trivial as mentioned above, and for the same reason, $\\pi_3 S^1 =0$ . Hence we have an exact sequence $0 \\rightarrow \\pi_3 S^3 \\rightarrow \\pi_3 S^2 \\rightarrow 0$ , which means that $\\pi_3 S^3 \\cong \\pi_3 S^2$ , and since every group $\\pi_n S^n \\cong \\mathbb{Z}$ , we have the first non-trivial example for homotopy groups of spheres, namely $\\pi_3 S^2 \\cong \\mathbb{Z}$ .\nNext time we introduce the Serre spectral sequence, and use it to compute cohomology groups of some interesting spaces. If we get far enough, we compute another non-trivial example of homotopy groups of spheres, namely $\\pi_4 S^3$ . As a gift for bothering to read, I link an amazing artwork by my favorite Russian mathematical artist Anatoly Fomenko, called “Homotopy groups of spheres”.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/homotopy-groups/","summary":"This is part 3 of a series leading up to and exploring model categories. For the other parts see the series overview.\nFor an introduction to the material, the definitions, motivation and some examples, please read part 1 and part 2 about fibrations and fiber bundles. This and the the following parts of this series will be about their usefulness, especially in computing homology and homotopy groups. This will be done through two different techniques, namely the long exact sequence of homotopy groups, and the spectral sequence associated to a fibration.","title":"Homotopy groups"},{"content":"This is part 2 of a series leading up to and exploring model categories. For the other parts see the series overview.\nYesterday we discussed the standard definition of a fibration by the homotopy lifting property, and today we are continuing that discussion, but in a more visual manner. This we will do by first looking at fiber bundles, and then generalizing them. Since fibrations are generalized fiber bundles, every fiber bundle is an example of a fibration, and they have been the most important examples for me, as they help me visualize and get intuition into the fibrations without having to really use the full generality of the definition. The main idea of a fiber bundle is that of a family of topological spaces parameterized by another topological space. This family will again form a topological space usually called the total space of the fiber bundle, while the space that parameterizes it is called the base space. Before we get rigorous and technical with definitions, we explore an example.\nExamples and intuition The best two “starter examples” for me at least is the cylinder, and the Möbius band. How are these a family of topological spaces parameterized by another space you ask? They can both can be thought of as a collection of intervals parameterized by a circle. The following picture of the cylinder might make it more clear.\nFor every point on the circle $S^1$ we have an interval $F$ “above” that point. The map $\\pi_1$ from the cylinder to the circle is just the projection map $\\pi_1:S^1\\times I \\rightarrow S^1$, which then gives us our first example of a fibration, namely projections. We call the cylinder a fiber bundle over $S^1$ with typical fiber $F$ , or sometime an $F$ -bundle over $S^1$ . If we instead look at the Möbius band it is a bit more complicated, but not much. We again give a picture.\nWe see the same phenomenon as with the cylinder. Above every point on the circle we have a copy of the interval $F$ , but the difference is that this is no longer just the usual projection. We have a twist, which makes it a bit weirder, hence the Möbius band is equal to the twisted product $M= S^1\\times_t F$ . But, we see that can make it into the projection locally, and this is the key to understand fiber bundles. Now, what does it mean that a map is a projection locally? It means that on the inverse image of open sets in $B$, the map $p$ restricted to that inverse image is just the projection.\nDefinition and relation to fibrations In fact, in a fiber bundle we allow slightly more, we allow that it is locally a projection up to a homeomorphism. This is just saying that we allow some topological variation of the fibers, and that a fiber bundle is a topological object and not totally rigid because we allow deformations and continuous “disturbances” in $E$ . This is also reflected in the proper definition.\nDefinition (fiber bundle): A map $p:E\\rightarrow B$ is called a fiber bundle with typical fiber $F$ if for every point $b\\in B$ , there exists an open set $U$ around $b$ and a homeomorphism $h:p^{-1}(U)\\rightarrow U\\times F$ such that $p_{|p^{-1}(U)}= \\pi_1 \\circ h$ , where $\\pi_1$ is the projection onto the first component.\nNow that we have an ok understanding of fiber bundles we can ask how they relate to fibrations. I said last time that in a fibration, every fiber is homotopy equivalent, and this is the generalization. In a fiber bundle, all fibers are homeomorphic. We can see this because $\\pi_1^{-1}({b}) \\simeq F$ , and hence $p^{-1}({b}) \\simeq F$. If we instead require this to be a homotopy equivalence we get a fibration. Since all homeomorphisms are homotopy equivalences, all fiber bundles are fibrations.\nNow we know both the standard technical definition of a fibration, and we know how to visualize them and think about them. What remains is to learn how to use them, and this we will do in the upcoming posts. I will have one post for the long exact sequence of homotopy groups, and one for the spectral sequence associated to a fibration.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/fiber-bundles/","summary":"This is part 2 of a series leading up to and exploring model categories. For the other parts see the series overview.\nYesterday we discussed the standard definition of a fibration by the homotopy lifting property, and today we are continuing that discussion, but in a more visual manner. This we will do by first looking at fiber bundles, and then generalizing them. Since fibrations are generalized fiber bundles, every fiber bundle is an example of a fibration, and they have been the most important examples for me, as they help me visualize and get intuition into the fibrations without having to really use the full generality of the definition.","title":"Fiber bundles"},{"content":"This is part 1 of a series leading up to and exploring model categories. For the other parts see the series overview.\nMy main mathematical interest for the last couple years has been algebraic topology. I feel it suits my needs for intuition, and graphical picturing of what happens. A concept I have been learning more rigorously recently is fibrations, and how to use them in computing homotopy groups and homology groups of different spaces. There is something fun and exciting about computing the homology and homotopy groups of new spaces, as it usually requires different techniques and insight every time, and fibrations have certainly presented some new tools for my calculation toolbox. Since fibrations gives us nice tools, it would be nice to understand them better, and that is my plan for this post. As a remark, all spaces used and mentioned will be topological spaces, and all maps will be continuous.\nAs a short motivation to why we bother studying fibrations at all we recall one of the standard tools one usually learns in an introductory course in algebraic topology, namely the long exact sequence of relative homology groups from a pair of topological spaces $(X, A)$, where $A\\subset X$. This can be thought of as coming from an injection $A \\hookrightarrow X$ . Now, what map between spaces do we need in order to get a long exact sequence of homotopy groups? It turns out that we need a fibration $E \\rightarrow B$ . Unfortunately fibrations do not, in my opinion, have a very clear, intuitive, and easy definition. That said, I will try my best in two different ways. The first one, which we will discuss today is as a map having a certain property. The second one, which is maybe not really a definition, but certainly paints a nice geometric picture, will be as a generalization of certain families of topological spaces parameterized by another topological space. The latter will be discussed tomorrow, as to not make the post too long.\nDefinition 1 Recall that a homotopy between two functions $f,g: X \\rightarrow Y$ is a map $h: X\\times I \\rightarrow Y$ such that $h(x,0)=f(x)$ and $h(x,1)=g(x)$ for all $x\\in X$ , i.e. it is a continuous deformation between the functions. Let $p: E \\rightarrow B$ be the map we are studying. The property we want the map to have for it to be a fibration is the so-called homotopy lifting property. This roughly says that given a homotopy in $B$, where we can lift one of the endpoints in the homotopy through $p$ to $E$ , then we can lift the entire homotopy up to $E$ . This is at least the picture I have when thinking about fibrations. The proper definition is of course a bit more technical, but I find it helpful to have this rough picture in mind.\nDefinition (Hurewicz fibration): A map $p:E\\rightarrow B$ is called a Hurewicz fibration if for any space $X$ with a homotopy $f: X\\times I \\rightarrow B$ and for any map $\\overline{f}_0: X\\rightarrow E$ lifting $f$ at the start of the homotopy, i.e. $f(x,0)=p\\circ \\overline{f}_0$, there exixts a homotopy $\\overline{f}:X\\times I \\rightarrow E$ that lifts f in the same manner as above, i.e. such that $\\overline{f}_0 = \\overline{f} _{|X\\times {0}}$ .\nOk, that was a mouthful. But we see the idea of being able to pull the homotopy up to $E$ when we can lift an endpoint. It is easier visualized as a diagram:\nThe property described as you maybe have guessed is called “the homotopy lifting property”, and a Hurewicz fibration is exactly a map that satisfies this property for all topological spaces $X$ . A bit more general notion is that of a Serre fibration, which satisfies this property for all CW-complexes instead of all topological spaces, and this is what I will refer to as a fibration. A fact about fibrations that i will not prove today atleast, is that the fibers over any point in the basespace all have the same homotopy type. Hence we usually include this when writing a fibration, i.e. we write $F\\rightarrow E \\overset{p}\\rightarrow B$ , where $F$ denotes the fiber.\nThis fact that all of the fibers have the same homotopy type is the foundation of the next way to think about fibrations. But this exposition is getting quite long, and we have a lot to present to get to the next formulation, so I will save that formulation, and some examples for tomorrow. The definition given here is the standard and most general one, but for me at least, the one we are discussing tomorrow gives this definition a much clearer picture and more intuition.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/fibrations/","summary":"This is part 1 of a series leading up to and exploring model categories. For the other parts see the series overview.\nMy main mathematical interest for the last couple years has been algebraic topology. I feel it suits my needs for intuition, and graphical picturing of what happens. A concept I have been learning more rigorously recently is fibrations, and how to use them in computing homotopy groups and homology groups of different spaces.","title":"Fibrations"},{"content":"Yesterday I wrote a geometric explanation of Noether’s normalization lemma, which you can find here. I’m going to use the geometric machinery developed in that post, so it can be useful to read that first.\nOne useful result that is often stated as a corollary to Noether’s normalization lemma is Zariski’s lemma. It is a corollary of the algebraic form of the normalization lemma, so i thought there ought to be a geometric version of it as well, which I think I have found. Zariski’s lemma holds true even for non algebraically closed fields, but I think the geometric picture becomes much clearer for algebraically closed fields.\nLemma (Zariski): Let $k$ be an algebraically closed field, and $A$ a finitely generated $k$-algebra which is also a field. Then $A$ is a finite field extension of $k$.\nThat $A $ is a finite field extension of $k $ is the same as saying that $A $ is an integral extension of $k $. Now this is starting to sound similar to our situation in Noether’s normalization lemma. This algebra $A$ is the coordinate ring of an affine algebraic variety $X $ in $k^n$ , and if that ring is in fact a field, then the ideal $I(X)$ associated to that variety must be maximal.\nThe weak nullstellensatz Now, we haven’t been through this yet, but we know precisely which varieties that have associated ideals which are maximal, namely varieties that are just points in $k^n$ . How do we see this? It is explained by the weak form of Hilbert’s nullstellensatz. Usually, if we don’t assume that our field is algebraically closed, then the weak form of Hilbert’s nullstellensatz is usually stated as a corollary to Zariski’s lemma by letting the field be algebraically closed, but today we flip the picture a little.\nThe weak Hilbert’s nullstellensatz: All maximal ideals $\\mathfrak{m}$ in the ring $k[x_1, \\cdots, x_n] $ where $k$ is an algebraically closed field are of the form $\\mathfrak{m}=\\mathfrak{m}_a=(x_1-a_1, \\cdots , x_n-a_n) $, where $a = (a_1, \\cdots, a_n)$ denotes a point in $k^n $.\nFor a detailed proof you can read my write up on the strong version on the nullstellensatz, where I also prove the weak one. You can find that here. For a geometric (and a big bit handwavy) approach, we note that prime ideals in $k[x_1, \\cdots, x_n]$ correspond to affine algebraic varieties $X$ in $k^n$ , and prime ideals in the coordinate ring of $X$ , i.e. $k[x_1, \\cdots, x_n]/I(X) = k[x_1, \\cdots, x_n]/ \\mathfrak{p}$ , then translates to affine subvarieties of $X$ because prime ideals in $k[x_1, \\cdots, x_n]/\\mathfrak{p}$ are exactly the prime ideals in $k[x_1, \\cdots, x_n] $ that contains $\\mathfrak{p}$ . All maximal ideals are also prime, so maximal ideals in $k[x_1, \\cdots, x_n] $ should translate to affine algebraic varieties that contain no affine algebraic subvarieties, i.e. points in $k^n$ .\nGeometric Zariski\u0026rsquo;s lemma Ok, we now know which affine algebraic varieties that have associated maximal ideals. Last time we translated certain integral extensions to certain surjective projections of varieties onto linear subspaces of $k^n$ . In fact, we showed that if we have a surjective projection from our affine algebraic variety to a linear subspace $L $ of $k^n$ we know that the coordinate ring of the variety is integral over the coordinate ring of the linear subspace. Now the trick to proving Zariski’s lemma becomes to find a suitable linear subspace. Since we have shown that our variety associated to the maximal ideal is a point, we only have one choice of linear subspace to surject to, namely the zero-dimensional linear subspace, $k^0 $. This is certainly a projection, and certainly surjective, hence our coordinate ring (or coordinate field really) $A$ is integral over the coordinate ring of the zero dimensional linear subspace of $k^n$ .\nNow, what is this ring? It is the ring $k[x_1, \\cdots, x_n]/I(k^0)$ , where $I(k^0)$ is the ideal of all polynomials in $k[x_1, \\cdots, x_n]$ that vanish on every point in $k^0$ which is only $0$ . Hence it is the ideal generated by all the variables, i.e. $I(k^0) = (x_1, \\cdots, x_n) $. Then we have $k[x_1, \\cdots, x_n]/(x_1, \\cdots, x_n)$ which is isomorphic to just $k$ . Hence, by Noether’s normalization lemma $A $ is an integral extension over the field $k $, hence it is a finite field extension of $k$ , which proves what we were after.\nTomorrow is the oral exam, and hopefully i get a chance to ramble on about geometric interpretations of these algebraic lemmas. Later, some day, I want to make a post about the duality between algebra and geometry in commutative algebra by interpreting the strong nullstellensatz in both an algebraic and a geometric way.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/more-geometric-intuition/","summary":"Yesterday I wrote a geometric explanation of Noether’s normalization lemma, which you can find here. I’m going to use the geometric machinery developed in that post, so it can be useful to read that first.\nOne useful result that is often stated as a corollary to Noether’s normalization lemma is Zariski’s lemma. It is a corollary of the algebraic form of the normalization lemma, so i thought there ought to be a geometric version of it as well, which I think I have found.","title":"More geometric intuition"},{"content":"Introduction This spring I have been taking a graduate class in commutative algebra, and I have yet to do algebraic geometry in a proper way, and have only gotten a small taste while writing my bachelor thesis. So this entire semester, I have felt this hinting at a geometric picture from the algebra itself, but i didn\u0026rsquo;t have the insight to figure it out. That said, I now think I have the geometric picture for Noether normalization, which in term implies a geometric picture of Hilbert nullstellensatz and some other results. It took a long time to convert the algebra into geometry for me, and i still have much to learn regarding this. What i have started to figure out is the close relationship between ideals and varieties. I have for a while known that this is one of the main reasons to introduce commutative algebra into algebraic geometry, but i couldn\u0026rsquo;t see the picture myself. Anyway, lets start with some introductory stuff.\nAn affine algebraic variety $X$ in $k^n$ is a subset of $k^n$ cut out by a collection of polynomials $F=\\{ f_i\\}_ {i\\in I}$, i.e. $X = \\{ x\\in k^n \\vert f_i(x)=0, \\forall f_i \\in F\\}$. The set $F$ of polynomials generate a prime ideal of $k[x_1, \\cdots, x_n]$, which we denote by $I(X)$. We can also start by taking a prime ideal $\\mathfrak{p}$ in $k[x_1, \\cdots, x_n]$ and generate its vanishing set $V(\\mathfrak{p})$, which will be it\u0026rsquo;s corresponding affine algebraic variety. More explicitly $V(\\mathfrak{p})= \\{ x\\in k^n \\vert f(x)=0, \\forall f\\in \\mathfrak{p}\\}$. The ring $P(X)=k[x_1, \\cdots, x_n]/I(X)$ is called the coordinate ring of the variety. This correspondence is the key bridge between the geometric picture and the algebra, and the full relation is described by Hilbert\u0026rsquo;s nullstellensatz.\nGeometry of normalization Before I explain the geometric meaning i have learned, I want to formulate the lemma in the regular algebraic way it is usually presented.\nLemma (Noether): Let $k$ be an algebraically closed infinite field and $A$ a finitely generated $k$-algebra. Then there exists an integer $d $ and algebraically independent generators $y_1, \\cdots ,y_d $ such that $A $ is a finitely generated module over $k[y_1, \\cdots, y_d] $.\nIt is often useful to know weather an affine algebraic variety $X$ projects onto a linear subspace of $k^n$. This can for example tell us information on the dimension of the variety, which again tells us other useful stuff. I have not yet explored dimension theory, hence the motivation behind this is maybe still a bit vague to me. This projection induces an injection on the cordinate rings. Let $A$ be the coordinate ring of an affine algebraic variety $X$ and $B$ the coordinate ring of a linear subspace $L$ of $k^n.$ By a coordinate change, $L \\cong k^d$, hence $I(L)$ is the zero ideal, because it consists of all polynomials in $d$ variables who vanish on every point in $k^d$, which is only the zero polynomial. Hence the coordinate ring $B$ is isomorphic to $k[x_1, \\cdots x_d] $.\nA given projection $X \\longrightarrow L$ then induces an injection $k[x_1, \\cdots, x_d]\\longrightarrow P(X) $, and a natural question that arises (somehow) is when is this injection a finite morphism. By definition this is the same as asking when $P(X) $ is a finitely generated module over $k[x_1, \\cdots, x_d] $ or when $P(X) $ is an integral extension of $k[x_1, \\cdots, x_d] $. Noether\u0026rsquo;s normalization lemma tells us that this is the case when the projection $X \\longrightarrow L $ is surjective.\nI\u0026rsquo;m not going to prove the lemma, but i will instead present an explicit example. Let $k=\\mathbb{R} $ and let $X $ be the variety defined by $x\\cdot y = 1$ in $\\mathbb{R}^2 $. This is a hyperbola with asymptotes along the $x$ and $y $ lines. If we take $L$ to be the linear subspace generated by $x$, i.e. the $x$-axis, then the canonical \u0026ldquo;straight down\u0026rdquo; and \u0026ldquo;straight up\u0026rdquo; projection hits the whole line except the origin.\nNow, what does this mean for our induced injection? The coordinate ring of $L$ is just $\\mathbb{R}[x]$ while the coordinate ring of $X$ is $P(X) = \\mathbb{R}[x, y]/(xy-1)$, hence we have the injection $\\mathbb{R}[x] \\longrightarrow \\mathbb{R}[x, y]/(xy-1) $. If this was an integral extension, then every prime ideal of $\\mathbb{R}[x] $ would have a prime ideal of $\\mathbb{R}[x, y]/(xy-1)$ laying over it, but there is no prime ideal in $\\mathbb{R}[x, y]/(xy-1)$ over the ideal generated by $x$, since all ideals in $\\mathbb{R}[x, y]/(xy-1)$ that contain $x $ must be the whole ring. Hence it can\u0026rsquo;t be an integral extension.\nBut, notice here that we in fact can do a linear coordinate change by rotating our axis $45^\\circ $, i.e. $x' = x+y $ and $y' = x-y $. Now the same projection is a surjection which in theory should make the injection an integral extension.\nThe coordinate change gives us $x = \\frac{x'+y'}{2} $ and $y = \\frac{x'-y'}{2} $, thus we get $0 = xy-1 = \\frac{(x'-y')(x'+y')}{4} -1 = x'^2 - y'^2 - 4 $. Hence our coordinate ring in the new generators is $\\mathbb{R}[x', y']/(x'^2 - y'^2 - 4) $. Now we see that this ring is integral over $\\mathbb{R}[x'] $ since we have a monic polynomial $f(t) = t^2 - (\\overline{x'}^2+4) $ which is zero at $y'$. Here $\\overline{x'} $ is the image of $x' $ in the ring $\\mathbb{R}[x', y']/(x'^2 - y'^2 - 4) $. Hence we have confirmed the lemma by an example. We made the integralness of $P(X) $ over $P(L) $ dependent of the projection, which is what we wanted.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/geometric-intuition/","summary":"Introduction This spring I have been taking a graduate class in commutative algebra, and I have yet to do algebraic geometry in a proper way, and have only gotten a small taste while writing my bachelor thesis. So this entire semester, I have felt this hinting at a geometric picture from the algebra itself, but i didn\u0026rsquo;t have the insight to figure it out. That said, I now think I have the geometric picture for Noether normalization, which in term implies a geometric picture of Hilbert nullstellensatz and some other results.","title":"Geometric intuition"}]