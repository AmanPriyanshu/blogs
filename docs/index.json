[{"content":"Synaptic Sparks: Why I\u0026rsquo;m Wiring My Thoughts into a Neural Blogosphere Hey there, fellow AI enthusiasts and curious minds! ðŸ§ ðŸ¤– Today, I just want to document what\u0026rsquo;s leading to this new adventure in regular blogging.\nThe Knowledge Synapse Picture me back in 2019, a wide-eyed novice bouncing around the vast landscape of machine learning. I was devouring every GitHub gist, Medium post, and arXiv paper I could find, growing and learning at a dizzying pace. Fast forward to today, and it feels like I\u0026rsquo;ve stepped into an alternate universe. So much of that knowledge that shaped me is now locked behind paywalls, long arduous youtube playlists, feeling almost alien to the very person who spent countless hours absorbing it.\nThat\u0026rsquo;s why I\u0026rsquo;m stepping up to the plate. This blog is my way of paying it forward, creating a freely accessible hub of AI insights on GitHub Pages. It\u0026rsquo;s for that version of me from 2019, and for anyone else out there hungry for knowledge but hitting walls of subscription prompts. Let\u0026rsquo;s keep the neurons firing and the information flowing!\nThe Memory Engram: Documenting the Journey The AI world moves fast. Sometimes, it\u0026rsquo;s hard to remember what I learned last month, let alone last year. That\u0026rsquo;s why I\u0026rsquo;m starting this blog. It\u0026rsquo;s not about big breakthroughs or fancy ideas â€“ it\u0026rsquo;s just my online diary for AI stuff. Here, I\u0026rsquo;ll write down the little \u0026ldquo;oh, I get it!\u0026rdquo; moments, the times I got stuck, and the cool things I think might be possible. It\u0026rsquo;s like leaving notes for myself along the way.\nThis isn\u0026rsquo;t for AI experts or future scientists â€“ it\u0026rsquo;s just for me. But who knows? Maybe one day I\u0026rsquo;ll read these posts and think, \u0026ldquo;Wow, I\u0026rsquo;ve really learned a lot since then!\u0026rdquo; That would be pretty cool (hopefully also true).\nThe Dopamine Circuit: Chasing the Thrill of Discovery You know that rush when your code finally compiles without errors? That\u0026rsquo;s the good stuff. By blogging about the topics that get my neurons firing, I\u0026rsquo;m creating a positive feedback loop of curiosity and creation. It\u0026rsquo;s like training a reinforcement learning agent, but the agent is me!\nThe Bio-Inspired Architecture: Small, Fast, and Evolved I\u0026rsquo;ve always been fascinated by how nature solves problems. Lately, I\u0026rsquo;ve been really interested in AI systems that try to learn from biology. There\u0026rsquo;s something exciting about compact neural networks that work a bit like animal brains or evolutionary processes or even behaviors. I\u0026rsquo;m not an expert, but I\u0026rsquo;m eager to learn and share what I discover about these smaller, nature-inspired AI approaches. It\u0026rsquo;s a big field, and I\u0026rsquo;m just starting to scratch the surface, but I hope to grow my understanding as I go along.\nThe Human-AI Interface: Building for People During my summer internship in the silicon jungle of San Francisco, I had an epiphany: the real magic happens when you build for people, not just for projects or hackathons. It\u0026rsquo;s time to shift my focus from hackathons to real-world problems. I want to bridge the gap between silicon and synapse!\nThe Output Layer: Wrapping It Up So, there you have it â€“ the reasons why I\u0026rsquo;m starting this blog. It\u0026rsquo;s not because I have all the answers, but because I have so many questions. This is my little corner of the internet where I\u0026rsquo;ll be thinking out loud about AI, learning as I go, and maybe stumbling upon some interesting ideas along the way.\nI\u0026rsquo;m excited to see where this journey takes me, and I hope that by documenting my thoughts and discoveries, I\u0026rsquo;ll be able to look back one day and see how far I\u0026rsquo;ve come. If you happen to find any of this useful or interesting, that\u0026rsquo;s great! But mostly, this is for future me, a breadcrumb trail through the fascinating world of AI.\nHere\u0026rsquo;s to the adventure ahead â€“ may it be full of learning, growth, and maybe a few \u0026ldquo;aha!\u0026rdquo; moments. Let\u0026rsquo;s see what we can figure out together! ðŸ§ ðŸ’»ðŸš€\nP.S. If you found this blog post intriguing (or at least mildly entertaining), buckle up! There\u0026rsquo;s plenty more where this came from. And hey, if you want to geek out about the latest in AI or collaborate on a mind-bending project, don\u0026rsquo;t hesitate to reach out. My email is: amanpriyanshusms2001[at]gmail[dot]com ðŸ”¬\n","permalink":"https://amanpriyanshu.github.io/blogs/posts/2024/synaptic-sparks/","summary":"Synaptic Sparks: Why I\u0026rsquo;m Wiring My Thoughts into a Neural Blogosphere Hey there, fellow AI enthusiasts and curious minds! ðŸ§ ðŸ¤– Today, I just want to document what\u0026rsquo;s leading to this new adventure in regular blogging.\nThe Knowledge Synapse Picture me back in 2019, a wide-eyed novice bouncing around the vast landscape of machine learning. I was devouring every GitHub gist, Medium post, and arXiv paper I could find, growing and learning at a dizzying pace.","title":"Synaptic Sparks: Why I'm Wiring My Thoughts into a Neural Blogosphere"},{"content":"FRACTURED-SORRY-Bench: When Decomposition Meets AI Safety Hello, fellow AI enthusiasts! ðŸ¤– Today, I wanted to dive into the FRACTURED-SORRY-Bench framework and dataset we just released. Check out the dataset, website, and github for the dataset!\nThe FRACTURED-SORRY Saga: A Tale of Adaptation and Decomposition Picture this: you\u0026rsquo;re wandering through the lush collection of prompt-injection and llm-red-teaming papers, marveling at some of the weird and some of the crazier attack mechanisms that have been released recently. When suddenly, you realize that there aren\u0026rsquo;t many Proof-of-Concept resources for multi-shot red-teaming. That\u0026rsquo;s essentially the story behind creating FRACTURED-SORRY-Bench.\nWhat\u0026rsquo;s in a Name? FRACTURED-SORRY-Bench isn\u0026rsquo;t just a mouthful; it\u0026rsquo;s a clever acronym we probably spent the most time on. It stands for:\nFramework for Revealing Attacks in Conversational Turns Undermining Refusal Efficacy and Defenses over SORRY-Bench The FRACTURED Approach: Divide and Conquer Vanilla Responses:\nModel Harmful \u0026amp; Relevant Harmful but Irrelevant Harmless ASR (%) GPT-4o 52 3 395 11.56 GPT-3.5 21 4 425 4.67 GPT-4o-mini 58 2 390 12.89 GPT-4 45 3 402 10.00 Decomposed Responses:\nModel Harmful \u0026amp; Relevant Harmful but Irrelevant Harmless ASR (%) GPT-4o 223 103 124 49.56 GPT-3.5 229 106 115 50.89 GPT-4o-mini 226 106 118 50.22 GPT-4 221 104 125 49.11 The FRACTURED-SORRY-Bench framework takes a page out of our everyday conversations playbook by breaking down complex problems into simpler, more manageable pieces. Just like how we breakdown complex sometimes malicious instructions into simpler manageable chunks so as to not reveal true intentions, this framework dissects AI vulnerabilities by:\nDecomposing potentially harmful queries into seemingly innocuous sub-questions Presenting these sub-questions sequentially in a conversational format Analyzing the cumulative response to determine if the original harmful intent was fulfilled Exploiting the AI\u0026rsquo;s inability to recognize malicious intent spread across multiple interactions From Theory to Practice: The Jailbreak Jamboree Now, let\u0026rsquo;s get to the juicy part â€“ the jailbreaks! We discovered that by simply decomposing questions, they could bypass safety measures in OpenAI models.\nHere\u0026rsquo;s a taste of what we found:\nA significant increase in Attack Success Rate (ASR) on average 6x Simple exploits that are zero-shot effective in communicating harmful intent in 49% of cases through decomposition During my summer internship at Robust Intelligence, I got a firsthand look at how these kinds of vulnerabilities are discovered and addressed Media Coverage, Jailbreak Meta\u0026rsquo;s Prompt-Guard LLaMA3.1 Family within 24 hours, and Jailbreaking OpenAI\u0026rsquo;s structured response within 3 hours. Now, back at CMU, I\u0026rsquo;m excited to continue exploring this fascinating field.\nThe Moral of the Story: Stay FRACTURED, My Friends So, what can we learn from this decomposed madness? A few key takeaways:\nSimplicity is key: We have a long way before we begin exploring complex jailbreaks as options for red-teaming, there\u0026rsquo;s still opportunity for lots of smaller \u0026amp; simpler attacks. Protection against multi-shot attacks: There\u0026rsquo;s a need to explore and defend against multi-shot attacks. Conclusion: The Adventure Continues As we wrap up this whirlwind tour of FRACTURED-SORRY-Bench, remember that the quest for AI safety is an ongoing journey!!\nAlso, thanks a tonne to my co-author Supriti Vijay!!\nP.S. If you found this blog post helpful (or at least mildly entertaining), I\u0026rsquo;ll be releasing quite a few more so do on-board for this adventure. Also, if you want to chat or collaborate on a research project together do not hesitate to reach out. My email is: amanpriyanshusms2001[at]gmail[dot]com ðŸ”¬\n","permalink":"https://amanpriyanshu.github.io/blogs/posts/2024/fractured-sorry-bench/","summary":"FRACTURED-SORRY-Bench: When Decomposition Meets AI Safety Hello, fellow AI enthusiasts! ðŸ¤– Today, I wanted to dive into the FRACTURED-SORRY-Bench framework and dataset we just released. Check out the dataset, website, and github for the dataset!\nThe FRACTURED-SORRY Saga: A Tale of Adaptation and Decomposition Picture this: you\u0026rsquo;re wandering through the lush collection of prompt-injection and llm-red-teaming papers, marveling at some of the weird and some of the crazier attack mechanisms that have been released recently.","title":"FRACTURED-SORRY-Bench: Unraveling AI Safety through Decomposing Malicious Intents"}]