<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Topic Extraction on Decoding AI&#39;s Evolution</title>
    <link>https://amanpriyanshu.github.io/blogs/tags/topic-extraction/</link>
    <description>Recent content in Topic Extraction on Decoding AI&#39;s Evolution</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright> </copyright>
    <lastBuildDate>Wed, 06 Nov 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://amanpriyanshu.github.io/blogs/tags/topic-extraction/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Contra-Topic-bottleneck-t5: Efficient Topic Extraction Without the Computational Overhead</title>
      <link>https://amanpriyanshu.github.io/blogs/posts/2024/contra-topic/</link>
      <pubDate>Wed, 06 Nov 2024 00:00:00 +0000</pubDate>
      
      <guid>https://amanpriyanshu.github.io/blogs/posts/2024/contra-topic/</guid>
      <description>Quick Links: Model on HuggingFace | Interactive Demo
When it comes to topic extraction, the AI world seems fixated on massive models and expensive compute. But what if there was a simpler way? ðŸ¤”
The Genesis: Simplicity Through Linear Transformation Picture this: There I was, looking for an open-source solution to extract topics from text at scale. The available options were either massive language models or complex fine-tuning pipelines. That&amp;rsquo;s when it hit me â€“ what if we could leverage the semantic structure of existing embeddings with just a linear transformation?</description>
    </item>
    
  </channel>
</rss>
