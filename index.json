[{"content":"The first post on this blog is titled \u0026ldquo;geometric intuition\u0026rdquo;, and discusses the geometry behind Noether\u0026rsquo;s normalization lemma. When I wrote it I didn\u0026rsquo;t yet understand all the pieces, as I was not very comfortable working with algebraic geometry. One year later, I\u0026rsquo;m still not comfortable, but a bit more than last year. So, I thought I would update last years post with my new knowledge, as well as generalize the intuition to schemes - which we introduced in the last post.\nNoether normalization tells us information about algebras, in particular finitely generated algebras over a field $k$. Such an algebra is not necessarily a $k$-vector space, but, Noether normalization tells us that it is a finitely generated module over a polynomial ring over $k$. As we saw in the last post, algebraic geometry is very much focused on finitely generated $k$-algebras, and polynomial rings, so the fact that geometric information arises from the result is hopefully not very surprising. We restrict ourselves to infinite fields $k$, and perhaps also algebraically closed ones.\nLemma (Noether normalization for algebras): Let $A$ be a finitely generated commutative $k$-algebra. Then there exists a non-negative integer $d$ and algebraically independent elements $y_1, \\ldots, y_d$, such that $A$ is a finitely generated module over $k[y_1, \\ldots, y_d]$.\nThere are several ways to package this information. Being a finitely generated $k$-algebra is often called being a finite type $k$-algebra, and being a finitely generated module over a ring $B$ is often called being finite over $B$, or being an integral extension of $B$. We will encounter some of these again in various forms below.\nFor algebraic varieties Last time we covered some very introductory basics regarding algebraic varieties, and in particular we looked a bit at the correspondence between ideals in $k[X_1, \\ldots, X_n]$ and affine algebraic sets in $k^n$. We did not actually state any results about this correspondence, so before we tackle Noether normalization we need to do so.\nFirst off, Noether normalization holds for any finitely generated $k$-algebra, so it would be helpful for us to understand how all of these behave. It turns out that every finitely generated $k$-algebra is of the form $k[X_1,\\ldots,X_n]/I$, where $I$ is some ideal in $k[X_1, \\ldots, X_n]$. This is good, because these are exactly1 the algebras we can use to study algebraic varieties. This also means that any affine algebraic variety naturally lives in some affine $n$-space, as the projection $k[X_1, \\ldots, X_n]\\rightarrow k[X_1, \\ldots, X_n]/I$ induces an inclusion $V(I)\\rightarrow k^n$.\nWe know from the weak nullstellensatz that for an affine algebraic variety $V$, the points in $V$ have a one to one correspondence with the maximal ideals in $\\Gamma(V)$. We also have a one to one correspondence between prime ideals in $\\Gamma(V)$ and irreducible affine subvarieties of $V$. Here the notion of irreducible means that a subvariety $W$ can be written as a union of two closed sets. The normal nullstellensatz generalizes this picture, and states that the correspondences are special cases of another correspondence, namely the on to one correspondence between affine algebraic subvarieties of $V$, and radical ideals in $\\Gamma(V)$. This correspondence is given by the two asignments $V(-)$ and $I(-)$ that we defined last time, i.e. the zero set of an ideal, and the ideal of a variety.\nWe can use the above to prove that we have an equivalence of categories between the category of affine algebraic varieties over a field $k$, and the category of finitely generated reduced $k$-algebras. Reduced means that the $k$-algebra has no nilpotent elements. In the case of finitely generated algebras, it is enough that the ideal $I\\subseteq k[X_1, \\ldots, X_n]$ that defines the finitely generated $k$-algebra, is a radical ideal.\nTo properly understand Noether normalization for affine algebraic varieties, we must understand the concept of dimension. The (topological) dimension of a variety is defined by certain chains of certain subsets.\nDefinition (Topological dimension): Let $V$ be an affine algebraic variety. The dimension of $V$ is defined to be the length of the largest proper chain of irreducible closed subsets of $V$, i.e.\n$$\\dim V = \\sup_{d}U_1\\subsetneq U_2\\subsetneq \\cdots \\subsetneq U_d$$\nwhere $U_i$ is a closed irreducible subset of $V$.\nWe immedeatly see that this definition is only suited for topologies equal to, or similar to, the Zariski topology. If we for example look at a more normal topological space, for example a Hausdorff space, then the topological dimension is $1$, as the only closed irreducible subsets are points. But, this definition works incredibly well in algebraic geometry, due to the correspondence we mentioned above - between the prime ideals in $\\Gamma(V)$ and irreducible closed subsets of $V$. This allows us to perfectly match the topological dimension of a variety to the Krull dimension of its coordinate ring.\nDefinition (Krull dimension): Let $A$ be a ring. The Krull dimension of $A$, denoted $\\dim_K A$ is defined to be the longest proper chain of prime ideals in $A$, i.e.\n$$\\dim_K A = \\sup_{d}p_1\\subsetneq p_2\\subsetneq \\cdots \\subsetneq p_d$$\nwhere $p_i\\subseteq A$ is a prime ideal.\nThe above remark means that we have\n$$\\dim V = \\dim_K \\Gamma(V)$$\nfor all affine algebraic varieties $V$.\nOk, the final thing we need before looking at the result of interest, is linear subspaces of $k^n$. The first thing to figure out is what the coordinate ring of a linear subspace is. If we take one such linear subspace $L\\subseteq k^n$, then its coordinate ring is $k[X_1,\\ldots,X_n]/I(L)$, i.e. the polynomial ring in $n$ variables, modulo the ideal of $L$. This ideal consists of all the polynomials in $k[X_1,\\ldots, X_n]$ that vanish on all points in $L$. Let us first consider the linear subspace $k^d$ as the $x_1\\cdots x_d$-plane. As its ideal are the polynomials that vanish on its points, we must have $I(k^d)= (X_{d+1}, \\ldots, X_n)$. To be sure we understand this, we look at $k=\\mathbb{R}$, $d=1$ and $n=2$. We can look at $k$ being the $x$-axis as a subspace $k^2$. This space is given by $V(Y)$:\nThe polynomials that are zero on the $x$-axis can not feature any solo copy of $X$. What we mean is that such a polynomial can\u0026rsquo;t be for example $f(X,Y)=X^3+Y$ as for some point $(a,0)$ on the $x$-axis, $f(a,0) = a^3\\neq 0$. We also can\u0026rsquo;t have any constant terms, as for example $g(X,Y)=XY^2+3$ is not zero on points $(a,0)$ on the $x$-axis. Hence, we must have that all components of a polynomial that vanish on the $x$-axis, must contain a copy of $Y$. This precisely means that $I(k)=(Y)$.\nGeneralizing the above, we get that the linear subspace $k^d\\subseteq k^n$ is defined by $V(X_{d+1},\\ldots, X_n)$, which gives us that $I(k^d)=I(V(X_{d+1}, \\ldots, X_n)) = (X_{d+1}, \\ldots, X_n)$, where the last equality comes from Hilbert\u0026rsquo;s nullstellensatz, together with the fact that $(X_{d+1}, \\ldots, X_n)$ is a radical ideal.\nAny $d$-dimensional linear subspace $L$ of $k^n$ must be isomorphic to $k^d$, hence their coordinate rings will also be isomorphic. Thus we get\n$$\\Gamma(L)\\cong \\Gamma(k^d) \\cong \\frac{k[X_1, \\ldots, X_n]}{I(k^d)} \\cong \\frac{k[X_1, \\ldots, X_n]}{(X_{d+1}, \\ldots, X_n)}\\cong k[X_1, \\ldots, X_d]$$\nWe are now ready to tackle Noether normalization for affine algebraic varieties.\nLemma (Noether normalization for varieties): Every $d$-dimensional affine algebraic variety $V\\subseteq k^n$ has a surjective morphism to a $d$-dimensional linear subspace $L$ of $k^n$.\n\u0026ldquo;Proof\u0026rdquo;: The result naturally follows from Noether normalization for algebras. Given a $d$-dimensional algebraic variety $V$ we can look at its coordinate ring $\\Gamma(V)$. This is a finitely generated $k$-algebra, and is thus subject to Noether normalization for algebras. This means that there exists elements $y_1, \\ldots, y_d$ such that $\\Gamma(V)$ is a finitely generated $k[y_1, \\ldots, y_d]$-module. This is the same as saying that the ring homomorphism $k[y_1, \\ldots, y_d] \\hookrightarrow \\Gamma(V)$ is an injective integral morphism. The ring $k[y_1, \\ldots, y_d]$ must be the coordinate ring of a $d$-dimensional linear subspace of $k^n$, which we can call $L$. Hence we have an integral extension $\\phi:\\Gamma(L)\\hookrightarrow \\Gamma(V)$ of reduced finitely generated $k$-algebras. Since we have an equivalence of categories between these algebras and affine algebraic varieties, there must exist a map $\\phi^\\ast\\colon V\\rightarrow L$. As the map $\\phi$ is injective, the map $\\phi^\\ast$ is dominant, i.e. its image is dense in $L$. Because $\\phi$ is integral, the image of $\\phi^\\ast$ is closed, which then finally means that $\\phi^\\ast$ is surjective as the closure of its image is both the whole space, and the image itself, i.e. $\\text{Im }\\phi^\\ast = \\overline{\\text{Im }\\phi^\\ast} = L$.\nThe fact that the dimensions coincide, i.e. that the dimension of the linear subspace necessarily is the same as the dimension of the algebraic variety, is due to the following result.\nTheorem: Let $A$ be a ring with Krull dimension $d$. Then any integral extension of $A$ also has Krull dimension $d$.\nSo, if we take a finitely generated $k$-algebra - now the coordinate ring of an affine algebraic set - $\\Gamma(V)$, then Noether normalization tells us that there are algebraically independent elements $y_1, \\ldots, y_d$ such that $\\Gamma(V)$ is a finitely generated module over $k[y_1, \\ldots, y_d]$, or equivalently, that $\\Gamma(V)$ is integral over the subring $k[y_1, \\ldots, y_d]$. As $k[y_1, \\ldots, y_d]$ is a polynomial ring over $d$ independent variables, it has Krull dimension $d$. And by the result above, $\\Gamma(V)$ also has Krull dimension $d$. We also know that the dimension of $V$ is equal to the Krull dimension of $\\Gamma(V)$, hence this integer $d$ from Noether normalization really is the dimension of the affine algebraic variety that corresponds to $\\Gamma(V)$, i.e.\n$$d = \\dim_K k[y_1, \\ldots, y_d] = \\dim_K \\Gamma(V) = \\dim V$$\nwhere $\\dim_K$ denotes the Krull dimension.\nA year ago we used the example of the algebraic variety $V(XY-1)$:\nwhere we by a coordinate change found a linear subspace it surjected, and even projected to:\nWe then showed that if the projection map is not surjective, then the induced map between the coordinate rings, is not integral, meaning that we had not found a ring that the coordinate ring was a finitely generated module over. This example still shows the intuition for me at least, hence the reason we include it again.\nFor schemes Generalizing the above situation to schemes forces us to introduce some different types of morphisms, and some different types of schemes. These are direct analogues of the morphisms and the varieties we had above.\nFirst and foremost we need to know what the scheme analogue of a linear subspace is. As we defined $k^d = V(X_{d+1}, \\ldots, X_n)$ to be the standard $d$-dimensional linear subspace of $k^n$, its maybe not hard to convince ourselves that $\\text{Spec }\\Gamma(k^d)$ is the correct definition for a linear subspace for schemes. This is because points in $k^d$ correspond to maximal ideals in $\\Gamma(k^d)$ when we talk about varieties, but when passing to schemes we need to keep track of subvarieties as well. This is exactly what $\\text{Spec } \\Gamma(k^d)$ gives us. Earlier we saw that $\\Gamma(k^d)\\cong k[X_1, \\ldots, X_d]$, hence also $\\text{Spec }\\Gamma(k^d)\\cong \\text{Spec }k[X_1, \\ldots, X_d]$. Such spaces are called affine $d$-space, and is usually denoted $\\mathbb{A}_k^d$.\nNotice here that we use the same kind of dimension as we did for algebraic varieties. This is because schemes are in particular topological spaces, or \u0026ldquo;have an underlying topological space\u0026rdquo;, so the same definition of (topological) dimension apply.\nThe second thing we need is the notion of being finitely generated. In the algebraic setting, a finitely generated $k$-algebra is also called a $k$-algebra of finite type. Hence the name of the next definition. This is done through the notion of \u0026ldquo;a scheme over another scheme\u0026rdquo;, which just means that we have a morphism $X\\rightarrow Y$ for the two schemes in question.\nDefinition (Finite type): Let $X\\overset{\\phi}\\longrightarrow Y$, i.e. $X$ a scheme over $Y$. We say $X$ is of finite type over $Y$ if for an affine cover $\\{\\text{Spec }B_i\\}_ {i\\in I}$ of $Y$ then $\\phi^{-1}(\\text{Spec }B_i)$ has a finite covering by open affine subschemes $\\text{Spec }C_{ij}$, such that $C_{ij}$ is a $B_i$-algebra of finite type, i.e. a finitely generated $B_i$-algbra.\nWe can simplify a bit as we are not interested in the full generality of the above definition. We are simply interested in schemes $X$ over $\\text{Spec }k$, often called $k$-schemes. Such schemes are much simpler, as $\\text{Spec } k$ is the only affine covering of it self. Hence we only need that $X$ has a cover of open affine subschemes $\\text{Spec } C_i$ such that the $C_i$\u0026rsquo;s are finitely generated $k$-algebras. We can make it even simpler by assuming $X$ is affine, i.e. $X=\\text{Spec }A$. Then $X$ is an affine cover of it self. In this situation we have that an affine $k$-scheme $\\text{Spec }A$ is of finite type if $A$ is of finite type (finitely generated as an algebra), hence we see that this really is a geometric generalization of the notion of being of finite type for algebras.\nThe next analogue we need is the analogue to being a finitely generated module over a ring. Recall that Noether normalization for algebras gives us that any finite type $k$-algebra is injectively finite over a polynomial ring, so this is the analogue we are going for.\nDefinition (Finite): Let $X$ be an affine scheme over $Y$, i.e. $X\\overset{\\phi}\\longrightarrow Y$. We say $X$ is finite over $Y$, or that $\\phi$ is a finite morphism, if for an affine cover $\\{\\text{Spec }B_i\\}_ {i\\in I}$ of $Y$ then $\\phi^{-1}(\\text{Spec }B_i)$ is an open affine subscheme $\\text{Spec }C_{i}$, such that the restriction of $\\phi$ to $\\text{Spec } C_i$ induces a finite ring homomorphism $B_i\\longrightarrow C_i$, i.e. it makes $C_i$ a finitely generated module over $B_i$.\nWe can again simplify the situation a bit by assuming that $X$ and $Y$ are affine, i.e. $X=\\text{Spec }A$ and $Y=\\text{Spec }B$. Then they both form an affine cover of themselves, meaning that we only need that $A$ is a finitely generated $B$-module. Notice that if we assume that $X$ is an affine $k$-scheme, we can\u0026rsquo;t reduce $Y$ to being $\\text{Spec }k$ as we did above, exactly due to Noether normalization for algebras. So, Noether normalization for algebras says \u0026ldquo;for schemes\u0026rdquo; that in general, an affine $k$-scheme of finite type, is not necessarily finite over $\\text{Spec }k$. But, we can fix this in the same way as we did for both algebras and varieties. It is not finite over $\\text{Spec }k$, but it will be finite over some linear scheme. We finally get the following.\nLemma (Noether normalization for schemes): Every $d$-dimensional affine $k$-scheme $X$ of finite type, has a finite surjective morphism to $\\mathbb{A}_k^d$.\n\u0026ldquo;Proof\u0026rdquo;: We see that this follows again from Noether normalization for algebras. As $X$ is affine we have $X = \\text{Spec }A$, and as it is a $k$-scheme of finite type, we know that $A$ is a finitely generated $k$-algebra, or stated earlier as a $k$-algebra of finite type. By Noether normalization for algebras, we can find a polynomial ring $k[y_1, \\ldots, y_d]$ over algebraically independent elements $y_1, \\ldots, y_d$ such that $A$ is a finitely generated $k[y_1, \\ldots, y_d]$-module. This means that we have an injective finite morphism $\\phi:k[y_1, \\ldots, y_d]\\hookrightarrow A$, which uniquely corresponds to a finite morphism between their spectra, i.e. $\\phi^\\ast:\\text{Spec }A\\longrightarrow \\text{Spec }k[y_1, \\ldots, y_d]=\\mathbb{A}_k^d$. As $\\phi$ is injective, $\\phi^\\ast$ is dense, an as $\\phi$ is finite, $\\phi^\\ast$ is closed, meaning that $\\phi^\\ast$ is surjective and finite.\nI think this shows a small part of why algebraic geometry is beautiful. We get direct geometric analogues of algebraic constructs, and vice versa. I find thinking in terms of schemes really difficult, as I still find them counterintuitive and hard to grasp. These correspondences makes it a bit easier, which is probably why I focus on them.. Tomorrow is my exam, where I will present the above construction. Hope it goes well.\nI stated some time ago that I would post about a project that starts next semester, so that will probably be the next post. To spoil the story, the project is a PhD at NTNU. I am to be part of a project called \u0026ldquo;Tensor triangulated geometry in Trondheim\u0026rdquo;, backed by the Trond Mohn foundation. I am really excited to be part of it, and to test my capabilities at the highest education level possible. I thought I would do a blog post defining a tensor triangulated category, so watch out for this appearing in the near future. But first, I need to get my master thesis done..\n  For this to give us a coordinate ring of a variety, we actually need that the ideal is radical. This is due to the nullstellensatz. \u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://torgeiraamboe.github.io/posts/2021/updated-geometric-intuition/","summary":"The first post on this blog is titled \u0026ldquo;geometric intuition\u0026rdquo;, and discusses the geometry behind Noether\u0026rsquo;s normalization lemma. When I wrote it I didn\u0026rsquo;t yet understand all the pieces, as I was not very comfortable working with algebraic geometry. One year later, I\u0026rsquo;m still not comfortable, but a bit more than last year. So, I thought I would update last years post with my new knowledge, as well as generalize the intuition to schemes - which we introduced in the last post.","title":"Updated geometric intuition"},{"content":"The first two posts ([1],[2]) I ever did on this blog - now over a year ago - were posts about algebraic geometry. In particular we explored the geometric implications of some of the algebraic results I was learning in my commutative algebra class. Last summer I also wrote a post about sheaves, and left it off by claiming to soon write about schemes. If you scroll through the blog we have covered a bunch of different topics, but the blog post on schemes, seems to have fallen through the cracks. Today we will rectify this situation. I have my algebraic geometry exam this week, so this is both an explainer-post, and a \u0026ldquo;making sure I understand the course material\u0026rdquo;-post. These types of posts have in fact become common on this blog, but hopefully that is ok.\nThe goal of the post is to be able to understand the definition of a scheme. So in order to do that we first make a quite extensive recap on algebraic varieties in order to get some motivation and intuition, and then make sure we understand all the components of the definition. As we have done before, we start with the definition we want to understand, and then unravel it as we go along. So, here it is, the definition of a scheme.\nDefinition (Scheme): A scheme is a locally ringed space $(X, \\mathcal{O}_ X)$ that admits an open cover $\\{U_i\\}$ such that $(U_i, \\mathcal{O}_{X|U_i})$ is isomorphic to $\\text{Spec }A_i$, the spectrum of some ring $A_i$.\nThere are many ways to package the information in the above definition, so just be aware that not all definitions of a scheme will look like this, but, this is the definition an formulation we are going to cover in this post.\nAlgebraic varieties Much of algebraic geometry can be done without ever mentioning schemes. This is due to them being a generalization of another well established - easy to work with - object, called algebraic varieties. An algebraic variety consists of two things:\n A topological space $X$. In particular, this topological space needs to be cut out by certain algebraic equations. A sheaf on $X$. In particular, a sheaf of functions that lift to certain polynomial functions on a certain vector space.  We must of course explain what the above words mean more mathematically and rigorously, but this is at least some handwavy information. To be more precise, an algebraic variety will be a ringed space $(X, \\mathcal{O}_X)$, i.e. a topological space $X$, together with a sheaf of functions on $X$. It will however be a very nice ringed space.\nAffine algebraic sets The main schtick in algebraic geometry is the correspondence and correlation between algebraic and geometric information. The geometric information will be curves, surfaces and shapes in $k^n$ for some field $k$ (most often algebraically closed), while the algebraic information are prime ideals in the polynomial ring $k[X_1, \\ldots, X_n]$. In order to have this nice correspondence we have two constructions that allow us to translate back and forth between these two seemingly separate worlds.\nDefinition: Let $S$ be a subset of $k[X_1, \\ldots, X_n]$. We define the zero-set of $S$, also called the vanishing set, to be $V(S)=\\{ x\\in k^n | f(x)=0, \\forall f\\in S \\}$.\nNotice that the set $S$ generates an ideal $(S)$, and that the zero-set of $(S)$ is the same as the zero set of $S$. This means we can restrict our selves to studying ideals instead of all sets. We call a subset $V\\subseteq k^n$ an affine algebraic set if $V=V(I)$ for some ideal $I\\subseteq k[X_1, \\ldots, X_n]$.\nFor starters we can let $k = \\mathbb{R}$, and $n=2$. This means that some polynomial in two variables, for example $F(X,Y)=X^2+Y^2-1$, generates an ideal in $k[X,Y]$. The zero-set of $F$ is the unit circle:\nAnother example is the zero-set of the ideal generated by $G(X,Y)=XY-1$, which has its zero-set equal to the graph of the function $f(x)=1/x$:\nThese affine algebraic sets, that are generated by a single polynomial, are called hypersurfaces in $k^n$.\nWe can quite easily see that the intersection and union of two affine algebraic sets is again affine algebraic sets. In fact we have $V(I)\\cap V(J) = V(I+J)$ and $V(I)\\cup V(J) = V(IJ)$. For example, the intersection of the above two affine algebraic sets is the empty set, which is the zero set of the whole ring $k[X_1, \\ldots, X_n]$.\nBut, if we for example scale the radius of the circle a bit, i.e. instead use $F(X,Y)=X^2+Y^2-\\sqrt{2}$, then we see that the two affine algebraic sets intersect in two points:\nOk, we need to be able to produce algebraic information from geometric one, so we also need the sort of \u0026ldquo;reverse\u0026rdquo; construction.\nDefinition: Let $W$ be a subset of $k^n$. We define the ideal of $W$ to be $I(W) = \\{ f\\in k[X_1, \\ldots, X_n] | f(x) = 0, \\forall x\\in W \\}$. Note that $I(W)$ is in fact an ideal.\nIf we take some subset $W\\subseteq k^n$, then we define its coordinate ring (also called the ring of regular functions) to be $k[X_1, \\ldots, X_n]/I(W)$.\nNote that for arbitrary imagined subsets $W$, the ideal $I(W)$ usually consists only of the zero element. This is because we usually think about subsets as blobs, or at least as dictated by some standard topology on $k^n$, which have no regular algebraic information in them. However, $k^n$ does not get to have the standard topology in our situation, so closed subsets will automatically correspond to sets $W$ where $I(W)$ will be more than just the zero-polynomial.\nThe Zariski topology We already got a little sneak-peak above, by the fact that intersection and union of affine algebraic sets is again affine algebraic sets, and that the empty set is an affine algebraic set. This is already almost everything we need in order to have a topology on $k^n$. We need that $k^n$ itself is an affine algebraic set, and that we either have arbitrary unions or arbitrary intersections. The last one is only to know weather we should define the topology by its closed or its open sets. For the first one we notice that all points in $k^n$ vanish on the zero-polynomial. Since $k$ is a field, the zero-polynomial does in fact generate an ideal $(0)$, hence we must have $V((0)) = k^n$. The last step is realizing that we do in fact have arbitrary intersections, i.e. $\\bigcap_{i\\in I} V(I_i) = V(\\prod_{i\\in I} I_i)$. This means that the affine algebraic sets make up the closed sets in a topology on $k^n$. This topology is called the Zariski topology.\nAn important thing to realize is that this topology works quite a bit different than the topologies one is used to from topology. The closed sets are shaped that we get from repedeately slicing $k^n$ by polynomials, which makes them really \u0026ldquo;small\u0026rdquo;. The open sets, are then \u0026ldquo;huge\u0026rdquo;, and are almost always dense in $k^n$.\nWe have some easy to define open sets called the standard open sets, or sometimes distinguished open sets. These are defined by $D(f) = k^n\\setminus V((f))$, i.e. the complement of the hypersurface generated by $f\\in k[X_1,\\ldots,X_n]$. These open sets form a basis for the Zariski topology on $k^n$. We can use this to define the Zariski topology on any affine algebraic set $X\\subseteq k^n$ by letting the topology on $X$ be the subspace topology. Then we would instead use $f\\in \\Gamma(X)$.\nThe sheaf of regular functions As we have already covered sheaves in an earlier blog post, we will not do that here. So if the reader has not seen sheaves, it would be smart to look at that post before reading onwards.\nBut, before we construct the sheaf we need, we need to realize that defining it on a basis for the topology is enough. Usually we need to define an object - in our case a ring - for each open set in a topological space $X$, satisfying a couple conditions. A basis for the topology on $X$ allows us to construct any other open set as a colimit of sets in the basis. When we apply the sheaf, then the rings we get for the general open sets can again be constructed as colimits of the rings we get from the open sets in the basis. Thus when we only define the sheaf for the basis elements, we are simultaneously defining it for all open sets, due to colimits of rings behaving nicely.\nIf we let $X$ be an affine algebraic set, then we define the sheaf of regular functions by\n$$\\mathcal{O}_X(D(f)) = \\Gamma(X)_f$$\nThis means that for any standard open set $D(f)$, the elements in the ring associated to it by the sheaf $\\mathcal{O}_X$, looks like fractions $\\frac{a}{f^n}$, where $a\\in \\Gamma(X)$.\nWe have not covered stalks and germs of sheaves yet, but intuitively stalks are what the sheaf does really really close to a point $x\\in X$. To be more precise, the stalk of $\\mathcal{O}_ X$ at the point $x$, is defined as the colimit $colim_{x\\in U} \\mathcal{O}_ X(U)$, and is denoted by $\\mathcal{O}_{X,x}$. For the above defined sheaf, every stalk inherits a ring structure, as the colimit of rings is again a ring. Every stalk is in fact a local ring, which by the way, is the reason for why $(-)_f$ is called localization, and the reason for calling rings local in the first place. Intuitively, we \u0026ldquo;zoom in\u0026rdquo; to the smallest open set around a point $x\\in X$, and there, the regular functions looks like the ring of global regular functions $\\Gamma(X)$, localized at the maximal ideal that corresponds to the point $x$.\nVarieties This means that we can turn any affine algebraic set into a ringed space by letting the associated sheaf be the sheaf of regular functions. We can then define what an affine algebraic variety is.\nDefinition (Affine algebraic variety): An affine algebraic variety is a ringed space $(X, \\mathcal{O}_X)$ that is isomorphic to $(V, \\mathcal{O}_V)$ for some affine algebraic set $V$.\nAs we above noted that the stalks of the sheaf of regular functions are in fact local rings, we call an affine algebraic variety a locally ringed space.\nThe only difference between an affine algebraic variety and a general algebraic variety is that we allow algebraic varieties to be sewn together by these affine algebraic varieties. Like manifolds, who locally look like Euclidean $n$-space, an algebraic variety locally looks like an affine algebraic variety. To be precise we include a proper formulation.\nDefinition (Algebraic variety): An algebraic variety is a locally ringed space $(X, \\mathcal{O}_ X)$ that admits an open cover $\\{U_i\\}$ such that $(U_i, \\mathcal{O}_{X|U_i})$ is an affine algebraic variety.\nHere $\\mathcal{O}_{X|U}$ means that we restrict our sheaf to only consider open subsets of $U$, instead of open sets on all of $X$. The above definition seemingly looks very much like the definition of a scheme we introduced in the beginning, so we conclude that we are on the right track.\nSchemes One of the things that stick out as a difference between the definition of an algebraic variety, and the definition we stated in the beginning of a scheme, is the object $Spec A_i$.\nThe spectrum as a topological space This is the gadget that makes a scheme more general than an algebraic variety, so lets define it.\nDefinition: Let $A$ be a commutative unital ring. We define the spectrum of $A$ (as a topological space) to be the set $\\text{Spec } A = \\{ p\\subseteq A | p \\text{ prime}\\}$, i.e. the set of prime ideals in $A$, together with the topology defined by letting the closed sets be of the form $V(a)=\\{ p\\in \\text{Spec } A| a\\subseteq p \\}$, where $a$ is any ideal in $A$.\nWe won\u0026rsquo;t prove that this is a topology on $\\text{Spec } A$, but it should remind us of the topology we had on an affine algebraic set, namely the Zariski topology. These are in fact the same topology, hence they also get the same name for both algebraic varieties and spectrums. As for affine algebraic varieties, we have a nice basis for this topology, defined by the sets\n$$D(f) = \\text{Spec }A\\setminus V(f)=\\{ p\\in \\text{Spec } A | f\\notin p\\}$$\nHere we start to see why using $\\text{Spec }A$ is a generalization of affine algebraic varieties. If we let $A=\\Gamma(X)$ for some affine algebraic set $X$, then by the weak nullstellensatz we know that the points in $X$ correspond to maximal ideals in its coordinate ring, $\\Gamma(X)$. All maximal ideals are prime, but not all prime ideals are maximal. Hence $\\text{Spec }\\Gamma(X)$ contains in some sense \u0026ldquo;more points\u0026rdquo; than $X$. As prime ideals in $\\Gamma(X)$ correspond to irreducible affine algebraic subsets of $X$, we get that $\\text{Spec }\\Gamma(X)$ contains both the information about the points in $X$, but also all the affine algebraic subsets.\nThe spectrum as a ringed space We saw all the way back in the introduction that a scheme was defined as a ringed space, so it should hopefully come as no surprise that we also need to give $\\text{Spec }A$ a sheaf of rings. This sheaf will hopefully look familiar.\nDefinition (Structure sheaf on $\\text{Spec }A$): Let $A$ be a commutative unital ring and $\\text{Spec } A$ its spectrum. We define a sheaf on $\\text{Spec }A$, called its structure sheaf, by\n$$\\mathcal{O}_{\\text{Spec }A}(D(f)) = A_f$$\nThis means that we can turn any ring $A$ into a ringed space by letting the topological space be $\\text{Spec }A$, and the sheaf be the structure sheaf $\\mathcal{O}_{\\text{Spec }A}$. This ringed space is called its spectrum. As for affine algebraic varieties, these ringed spaces are in fact locally ringed spaces, i.e. ringed spaces where the stalk at every point is a local ring. To be precise, and to sum up, we give the definition properly.\nDefinition (Spectrum of a ring): Let $A$ be a commutative unital ring. We define the spectrum of $A$ to be the locally ringed space $(\\text{Spec }A, \\mathcal{O}_ {\\text{Spec }A})$, where $\\mathcal{O}_{\\text{Spec }A}$ is the structure sheaf defined above. By abuse of notation we often denote this ringed space by just $\\text{Spec } A$.\nThese spaces are actually schemes, and we will see below that they are the basic building blocks for all schemes. This is maybe not surprising, as in the introduction we defined schemes to be locally ringed spaces that locally looked like these spectra of rings.\nThe definition Phew! That was a lot of construction. Luckily, we are now ready to define our objects of interest - schemes. As with algebraic varieties, we will first define an affine scheme, and then define a general scheme to be a ringed space that is locally affine. This means simply that the affine schemes are the building blocks of general schemes, just as affine algebraic varieties formed the building blocks of algebraic varieties.\nDefinition (Affine scheme): An affine scheme is a locally ringed space $(X, \\mathcal{O}_X)$ that is isomorphic to $\\text{Spec }A$ for some commutative unital ring $A$.\nHere we see what we stated above, i.e. that the spectra of rings actually form the building blocks we wanted. But we allow some isomorphisms in order to not be too strict in our definitions. Thus we can finally restate the definition from the introduction, and say that we understand the parts.\nDefinition (Scheme): A scheme is a locally ringed space $(X, \\mathcal{O}_ X)$ that admits an open cover $\\{U_i\\}$ such that $(U_i, \\mathcal{O}_{X|U_i})$ is an affine scheme.\nBy the definition of an affine scheme, this definition is really the definition we presented in the introduction, even though it looks slightly different. The reason we did not use the word affine scheme in the introduction is that using affine schemes to define schemes is not very enlightening without first understanding the whole affine construction.\nWe now hopefully understand what the different components of the definition are, as well as why they are defined that way. They do however look disturbingly similar to algebraic varieties, so are schemes actually useful?\nWhy the need for schemes? So why do we need this abstraction? The algebraic varieties we had earlier are most usable for rings that are algebras over an algebraically closed field $k$. In fact, big results like the general nullstellensatz only holds for algebraically closed fields. This is one place where the necessity for schemes arise, as schemes are usable for all commutative unital rings! Maybe most notably, the integers $\\mathbb{Z}$ is not a $k$-algebra. Hence, if we want to use algebro-geometric techniques in number theory - for example studying the vanishing set of $X^n+Y^n-Z^n$ over $\\mathbb{Z}$ for $n\\geq 3$- then we often need schemes to do so.\nBut, even in the world of algebraically closed fields, schemes show up as necessary. They do so for example in the study of intersections of plane curves. We have not really covered projective space and projective varieties in this blog post (maybe we will do that later), but one can study plane curves by studying homogeneous polynomials in $k[X,Y,T]$. Bezout\u0026rsquo;s theorem then tells us that the number of intersection points $V(F)\\cap V(G)$ of two homogeneous polynomials with no common components, is $s\\cdot t$, where $s$ is the degree of $F$ and $t$ the degree of $G$. This theorem only holds when we count multiplicities of intersections, which is a scheme-theoretic construction. Let us for example look at the intersection of the two plane curves we saw earlier:\nRecall that these curves are given by $F=X^2+Y^2-1$ and $G=XY-1$. These both have degree 2, but there are only 2 intersection points. As we really need these to be projective curves, we can possibly also have an intersection point \u0026ldquo;at infinity\u0026rdquo;. This is still only three possible points, so we need to have at least one intersection with \u0026ldquo;multiplicity 2\u0026rdquo;. If we were only allowed to use the structure of algebraic varieties here, then all these multiplicities will be 1, but if we allow for the intersection to admit a scheme structure, then we can \u0026ldquo;count correctly\u0026rdquo;. In this way we get the four intersection points that Bezout\u0026rsquo;s theorem tells us we should have.\nSchemes are of course useful in many other situations, where algebraic varieties turn out not to be general enough, or not the right tool. In one of the next coming days we will see a generalization of the first post i ever made, i.e. geometric intuition about Noether normalization, to these more general schemes. Maybe we\u0026rsquo;ll write a bit better what is stated in the first post as well\u0026hellip;\n","permalink":"https://torgeiraamboe.github.io/posts/2021/schemes/","summary":"The first two posts ([1],[2]) I ever did on this blog - now over a year ago - were posts about algebraic geometry. In particular we explored the geometric implications of some of the algebraic results I was learning in my commutative algebra class. Last summer I also wrote a post about sheaves, and left it off by claiming to soon write about schemes. If you scroll through the blog we have covered a bunch of different topics, but the blog post on schemes, seems to have fallen through the cracks.","title":"Schemes"},{"content":"For those that don’t know I am a fifth year mathematics student at NTNU, meaning I am finishing my masters degree after this semester. During my time at NTNU I have had some wonderful classes, and some wonderful teachers. Since most I post about on this blog is related to topology, it is very safe to assume that some of my most memorable courses are exactly the topology courses. I very recently looked at my notes from my first topology course, or rather one of the two first, as I took two in parallel during my fourth semester. The course was focused on differential topology and the study of smooth manifolds. It was taught by my now supervisor, but on a couple of the last lectures we had some guest appearances from the other topology professors at NTNU. One of these guest lectures is the focus of todays blog post.\nThe reason I still remember this particular lecture is because I left it understanding nothing. Some lectures takes some time to process, but this was not one of those. The information contained in the lecture was just so far above my head at the time, and it has taken me until now to understand it. I remember the lecture because it was inspiring, because I realized there is no cap on mathematical knowledge, because this is a field where one can always continue learning and never understanding it all. Not all lectures need to be understandable, or even exam-relevant (this one luckily wasn’t), some lectures just need to be inspiring and forward-looking.\nAnyways, below are my notes from that lecture. I have added some text to clarify some points and to make the post more cohesive, but the message and the theory is as written in the notes. If you want to see my actual notes for reference, you can find them here. You can also read the lecturers notes here. This material was presented in a 2×45 minute lecture, so details will be a bit sparse, and knowledge will mostly be presented on a need to know basis. As this comes from a lecture, the post is also somewhat long, so you are now officially warned.\nIntroduction to topology, 19.04.18\n2-dimensional topological quantum field theories A topological quantum field theory (TQFT) is a very rich topological gadget with many use cases. These objects encode many of the fundamental invariants that we associate to manifolds. More precisely, an n-dimensional TQFT is a symmetric monoidal functor $Z:nCob\\longrightarrow Vect_{\\mathbb{C}}$. Here the category $nCob$ is the category of $n$-dimensional manifolds and cobordisms, and the category $Vect_\\mathbb{C}$ is the category of complex vector spaces. The latter can be substituted by another linear category if wanted. When $n=2$ we have the following theorem.\nTheorem: There is an equivalence of categories $2TQFT\\simeq cFA_{\\mathbb{C}}$, where $2TQFT$ is the category of 2-dimensional TQFTs and $cFA_\\mathbb{C}$ is the category of commutative Frobenius algebras.\nThe goal of the lecture, and hence this blog post, will be to understand the statement of this theorem. We will not present a proof. To make sense of the statement of the theorem we will need to do two things.\n Understand the formalism we use to present the statement, in this case categories, functors, symmetric monoidal categories, and equivalences of categories. Understand the presented objects and the statement itself, in this case cobordisms and commutative frobenius algebras.  Categorical preliminaries We begin with understanding the formalism used to present the theorem, namely category theory. We only present the few bits we actually need, but a proper understanding of this theory would probably be useful for all readers.\nDefinition (Category): A category $\\mathcal{C}$ consists of objects $A, B, C, \\ldots$ , and morphisms $A\\rightarrow B$. We write $A\\in \\mathcal{C}$ for objects and $f\\in \\mathcal{C}(A, B)$ or $f\\in Hom_{\\mathcal{C}}(A, B)$ alternatively for morphisms. These objects and morphisms must subject to the following axioms:\n Given $A\\rightarrow B$, $B\\rightarrow C$ we can compose them to get $A\\rightarrow C$ Composition is associative, i.e. for morphisms $A\\rightarrow B\\rightarrow C\\rightarrow D$ we have $h\\circ(g\\circ f) = (h\\circ g)\\circ f$ For every $A\\in \\mathcal{C}$ there is an identity morphism $id_A:A\\rightarrow A$, such that for any morphism $f:A\\rightarrow B$ we have $f\\circ id_A = f = id_B \\circ f$  Examples are $Vect_\\mathbb{C}$, the category of vector spaces over $\\mathbb{C}$ with linear maps and $Top$, the category of topological spaces with continuous maps.\nIn mathematics we are often, or almost always more interested in maps between things instead of the things themselves. Hence we need maps between categories, which are called functors.\nDefinition (Functor): A functor $F:\\mathcal{C}\\longrightarrow \\mathcal{D}$ between two categories, consists of a map from the objects of $\\mathcal{C}$ to the objects of $\\mathcal{D}$, and a map $F_{A, B}: \\mathcal{C}(A, B)\\longrightarrow \\mathcal{D}(A, B)$, such that:\n Given $A\\rightarrow B\\rightarrow C$ in $\\mathcal{C}$, then $F_{A, C}(g\\circ f) = F_{B,C}(g)\\circ F_{A, B}(f)$ For every $A\\in \\mathcal{C}$ we have $F_{A,A}(id_A) = id_{F(A)}$.  As said, we are often interested in maps instead of objects, and the wonderful thing about category theory is that we can make sense of maps between other maps. If you are interested in such things I have a couple blog posts about higher category theory that flesches out this idea. Here we define maps between functors, which are called natural transformations.\nDefinition (Natural transformation): Let $F, G: \\mathcal{C}\\longrightarrow \\mathcal{D}$ be two functors. A natural transformation $\\eta:F\\Longrightarrow G$ assigns to each object $A\\in \\mathcal{C}$ a morphism $\\eta(A):F(A)\\longrightarrow G(A)$ in $\\mathcal{D}$, such that for each morphism $f:A\\longrightarrow B$ in $\\mathcal{C}$, we have $G_{A, B}(f)\\circ \\eta(A) = \\eta(B)\\circ F_{A,B}(f)$. We say $\\eta$ is a natural isomorphism if $\\eta(A)$ is an isomorphism for all $A$.\nThe reason we introduce these maps between maps, is because we want a way to compare categories to see if they are similar. In other fields of mathematics we usually define isomorphisms between objects to satisfy this need. These are usually defined to be maps $f:A\\longrightarrow B$ such that there exists a two sided inverse. In category theory however, it turns out that such isomorphisms between categories is a too strong notion of comparison, as they leave out categories we intuitively want to consider “the same”. In topology we also run into this problem, and we then can define homotopy equivalences instead. The following definition will hopefully be reminiscent of such types of “weaker” equivalences.\nWe say two categories\n$\\mathcal{C}$ and $\\mathcal{D}$ are equivalent if there exists two functors $F:\\mathcal{C}\\longrightarrow \\mathcal{D}$ and $G:\\mathcal{D}\\longrightarrow \\mathcal{C}$ such that $G\\circ F\\simeq id_\\mathcal{C}$ and $F\\circ G \\simeq id_\\mathcal{D}$.\nIf you want some more information on equivalences of categories I also have a post going into more details explaining why they are “more correct” than isomorphisms of categories.\nWe now have the basics covered, and will now start to add on more structure which we want later. We said that a TQFT was a symmetric monoidal functor, so we need to explain what we mean by that.\nDefinition (Strict monoidal category): A strict monoidal category $(\\mathcal{C}, \\otimes , I)$ is a category $\\mathcal{C}$ together with a functor $\\otimes:\\mathcal{C}\\times \\mathcal{C}\\longrightarrow \\mathcal{C}$ and an object $I\\in \\mathcal{C}$, such that $\\otimes$ is associative and $I$ is a left and a right unit for $\\otimes.$\nThis should be thought of as a not necessarily commutative product on the category. To make it nicer, i.e. introduce a notion of commutativity, we need the following definition.\nDefinition (Symmetric strict monoidal category): We say a strict monoidal category is symmetric if for each pair $A, B\\in \\mathcal{C}$ there is a twist map (also sometimes called a braid map) $\\tau_{A, B}:A\\otimes B\\longrightarrow B\\otimes A$ such that\n for any two maps $f:A\\longrightarrow A'$ and $g:B\\longrightarrow B'$ we have $g\\otimes f \\circ \\tau_{A. B} = \\tau_{A', B'}\\circ f\\otimes g$ for any triple $A, B, C \\in \\mathcal{C}$ we have $\\tau_{A, B\\otimes C} = \\tau_{A, B}\\otimes id_C \\circ id_B\\otimes \\tau_{A, C}$ for any pair $A, B\\in \\mathcal{C}$ we have $\\tau_{A, B}\\circ\\tau_{A, B} = id_{A\\otimes B}$.  As said above, this should be thought of as a commutative product on the category.\nThe last part of this categorical puzzle is to define a symmetric monoidal functor to be a functor between two symmetric monoidal categories such that the product structure is preserved. This can be thought of as being similar to group homomorphisms between abelian groups.\nCobordisms The next part of the puzzle is to define the different stuff used in the theorem we want to state. From here on out we will assume that all manifolds mentioned are smooth and compact. To define TQFTs we need two things; cobordisms and vector spaces. We assume the reader is familiar with vector spaces, so the remaining part are the cobordisms. We will however note that the category of vector spaces form a symmetric monoidal category with the tensor product operation on vector spaces. This is required for us to have a symmetric monoidal functor after all. Ok, over to the topology.\nLet $M, N$ be two oriented manifolds of dimension $n$. For example:\nA cobodism $W:M\\longrightarrow N$ is an oriented manifold $W$ of dimension $n+1$ such that $\\partial W = M\\coprod N$, for example\nCobordisms can be though of as evolving a manifold over time. It turns one manifold into another by some continuous, but somehow non-continuous process. If we chop the cobordism into slices we can play them after each other from start to finish and get a little movie for how the one manifolds twists, turns, bends, wobbles, splits, merges and deforms into another manifold. If you have ever seen the slice-images from scanning a brain from top to bottom you will hopefully get the picture.\nWe define $2Cob$ to be the category which has objects being closed oriented 1-dimensional manifolds and morphisms being orientation preserving boundary extending diffeomorphism classes of 2-dimensional cobordisms. This means that we consider two cobordisms $W_1, W_2: M\\longrightarrow N$ to be equivalent if there exists an orientation preserving diffeomorphism (smooth isomorphism) $f:W_1\\longrightarrow W_2$ that extends the isomorphism $\\partial W_1 \\cong M\\coprod N \\cong \\partial W_2$.\nFor any $M \\in 2Cob$, the identity morphism $id_M$ is given by $M\\times I$, where $I$ is the unit interval. Think about this a just a tube between the two manifolds. Composition of $W_1:M_1\\longrightarrow M_2$ and $W_2:M_2\\longrightarrow M_3$ is given by $W_1 \\coprod_{M_2} W_2$, i.e. gluing the two cobordisms together along their shared boundary $M_2$. Gluing together the following two cobordisms\nand\ngives us the new cobordism\nbetween $M_1$ and $M_3$. It is important to note that it is not trivial to give the composition the structure of a smooth manifold. It can be done in many different ways, but luckily for us they all produce equivalent cobordisms.\nWith this we have shown that $2Cob$ is in fact a category. If we let $\\otimes = \\coprod$, i.e. the normal disjoint union, then $(2Cob, \\coprod, \\emptyset )$ is a monoidal category, where $\\emptyset$ is the empty set. There is a diffeomorphism $M_1\\coprod M_2 \\longrightarrow M_2\\coprod M_1$. This diffeomorphism induces a cobordism $T: M_1\\coprod M_2 \\longrightarrow M_2\\coprod M_1$, which we call the twist cobordism. It can be visualized as\nRecall that all closed connected oriented 1-dimensional manifolds are equivalent to the circle. Hence the different manifolds, i.e. the objects in $2Cob$ are essentially just different amount of copies of the circle. This can be made more precise, but we will not need the entire formalism today. Instead we define a skeleton for $2Cob$ to be the full subcategory ${ 0, 1, 2, 3, \\ldots, n, \\ldots }$ with $n=\\coprod_n S^1$. By abuse of notation, we denote this category onwards by $2Cob$. It is important to note that the skeleton is equivalent as categories to the original category, but this new one is smaller and makes everything nicer and very much easier to draw!\nIn the drawings we have presented we notice that all the cobordisms seem to be built up from similar parts. They mostly seem to consist of tubes, splitting into more tubes or joining into fewer tubes. We will see that this is actually the case, but first we need a precise formulation of what this means.\nDefinition (Generating set): A generating set for a monoidal category $(\\mathcal{C}, \\otimes, I)$ is a set $S$ such that all morphisms in $\\mathcal{C}$ can be obtained from the elements in $S$ by composition or by $\\otimes$. If $S$ is a generating set, then we say $\\mathcal{C}$ is generated by $S$.\nThe point of the discussion we now go into is the fact that we can use the classification of surfaces to give an explicit description of $2Cob$ by generators and relations. This will allow us to say explicitly how the image of a functor $2Cob\\rightarrow Vect_\\mathbb{C}$ behaves.\nTheorem: The category $2Cob$ is generated by the following six cobordisms, often called the basic cobordisms.\nThis means that we can build any cobordism from these easy to handle pieces! This also extends to the following definition, which just described a decomposition of a cobordism into elements of the generating set above. For simplicity of notation we say a cobordism $W:m\\longrightarrow n$ has $m$ in-boundaries, and $n$ out-boundaries. From a drawing standpoint this just means we have $m$ circles as boundaries on the left, and $n$ circles as boundaries on the right.\nDefinition (Normal form): The normal form of a connected surface with $m$ in-boundaries, $n$ out-boundaries and genus $g$, is the decomposition of the surface into a number of basic cobordisms. We can for example decompose the following cobordism\ninto the following union of basic cobordisms\nNotice that it has the same number of in-boundaries, out-boundaries and the same genus.\nThe relations we need to have our explicit description of $2Cob$ are called identity, unit and counit, associativity and coassociativity, commutativity and cocommutativity, Frobenius and twisting. Since the category is generated by six cobordisms, we only need to see what happens on combinations of these. Visually, these are the relations we need.\nThe identity relation says that composing with the identity cobordism, i.e. the cylinder $S^1\\times I$ does nothing. i.e.\nThe unit and counit relation looks like:\nHopefully the associativity relation (top) is somewhat recognizable, and the coassociativity (bottom) relation is just the dual of it, i.e.\nThe same goes for the commutativity relation (top) and the cocommutativity relation (bottom):\nThe last two are maybe a bit less common. The Frobenius relation looks like:\nAnd the twisting looks like:\nTogether the six basic cobordisms and the above relations make $2Cob$ into a really nice category to work with, as we can just draw everything we want.\n2-dim TQFT\u0026rsquo;s and $cFA_\\mathbb{C}$ We have now almost arrived at the statement of the theorem. To remind ourselves we again state the definitions of the main components in the theorem.\nDefinition (TQFT): A 2-dimentional topological quantum field theory (2-dim TQFT) is a symmetric monoidal functor $Z: 2Cob\\longrightarrow Vect_{\\mathbb{C}}$.\nThese functors form a category where the objects are the 2-dim TQFTs and the morphisms are natural transformations between them. Denote this category by $2TQFT$. The other category we need is the category of commutative Frobenius algebras. We haven’t actually defined what we mean by this yet, so lets do that.\nDefinition (Commutative Frobenius algebra): A commutative Frobenius algebra consists of a complex vector space A together with a commutative and associative product $m:A\\times A\\longrightarrow A$ and a non-degenerate bilinear form $\\mu: A\\times A\\longrightarrow \\mathcal{C}$ such that $\\mu(m(a, b), c) = \\mu(a, m(b, c))$. We often write $m(a, b)$ as just $a\\cdot b$, and then the relation becomes $\\mu(a\\cdot b, c)=\\mu(a, b\\cdot c)$.\nThe most used examples of such algebras are matrix algebras $M_n(\\mathbb{C})$ where $\\mu(a, b)$ is the trace of their product, i.e. $\\mu(a, b)=tr(a\\cdot b)$.\nTo at least justify some part of the theorem, and see where the Frobenius algebras come into play we look at the following. Let $Z$ be a 2-dim TQFT. Then the image of the object $1=S^1$ in $2Cob$ hits some complex vector space, which we denote by $A$, i.e. $Z(S^1) = A$. Then $Z(n) = A^{\\otimes n} = A\\otimes \\cdots \\otimes A$ because $Z$ is symmetric monoidal. This also means that $Z(\\emptyset)=\\mathbb{C}$.\nFurther we have that $Z$ applied to morphisms in $2Cob$, i.e. the cobordisms, must produce morphisms between the different tensor products of $A$. For example:\nis a map between $A\\otimes A$ and $A$, because the cobordism is a morphism between $2$ and $1$. By the above relations this map is commutative and associative product, which makes $A$ into a commutative algebra with identity element given by\nThis is in fact the identity of the algebra product defined above, because of the unit relation. Moreover we have a map $A\\longrightarrow \\mathbb{C}$ given by\nand that the composition\nwhich we can denote by $\\mu$, is non-degenerate bilinear form on $A$. This means that we have a commutative associative product and a non-degenerate bilinear form on our vector space. The last piece of the puzzle comes from the Frobenius relation. This makes it so that $\\mu(a\\cdot b, c) = \\mu(a, b\\cdot c)$.\nHence $A$ is a commutative Frobenius algebra! This means that any vector space in the image of our 2-dim TQFT is in fact a commutative Frobenius algebra, and that we have a functor $F: 2TQFT\\longrightarrow cFA_\\mathbb{C}$ given by $F(Z) = Z(S^1$). The fact that every commutative Frobenius algebra arises this way is a lot harder to show and we will not cover it here. But it can be done, and once it is, we finally have our theorem:\nTheorem: The category of 2-dimentional topological quantum field theories, $2TQFT$, is equivalent to the category of commutative Frobenius algebras, i.e.\n$$2TQFT \\simeq cFA_\\mathbb{C}.$$\n","permalink":"https://torgeiraamboe.github.io/posts/2021/a-leqture-in-my-second-year/","summary":"For those that don’t know I am a fifth year mathematics student at NTNU, meaning I am finishing my masters degree after this semester. During my time at NTNU I have had some wonderful classes, and some wonderful teachers. Since most I post about on this blog is related to topology, it is very safe to assume that some of my most memorable courses are exactly the topology courses. I very recently looked at my notes from my first topology course, or rather one of the two first, as I took two in parallel during my fourth semester.","title":"A Lecture in My Second Year"},{"content":"Something I have been looking into a bit lately, due to it sadly not being taught at my university is knot theory. This is something I have always known to be a part of topology, and have known to have interesting applications in physics, medicine, chemistry and more. So to rectify the situation I thought I would prove that knots exist. It was also nice to take a brake from all the higher category theory we have been looking into lately!\nA knot is defined to be an embedding of the circle $S^1$ into $\\mathbb{R}^3$, so immediately we have proven our statement since the identity is an embedding. Hence we at least have one knot, called the unknot or the trivial knot, being just the circle itself. This is of course trivial, so the question “are there knots?” is better phrased as “are there other knots than the unknot?”. This question is not trivial and requires a proof, which is what we are doing today. We say two knots are the same, or are equivalent, if we can transform one into the other by transforming the space $\\mathbb{R}^3$ they are embedded in. These transformations are called ambient isotopies, and corresponds to manipulating the knot without cutting or letting parts of the knot pass through itself.\nReidemeister moves A nice property of knot theory is that it is a very graphical and visual theory. Everything (at least for us) happens in a low dimension, so we can always draw what we mean. We defined a knot to be an embedding of the circle into Euclidean three-space, but a nice way to draw them are called knot projections, or knot diagrams. This is just the projection of the knot into the plane, where we keep track of the crossings. Lets give an example. The following knot is called the figure-eight knot (maybe you can see why).\nWhen we talk about a knot for the rest of this post, we will mean the knot diagram of a knot. Even though we call it a knot, we still don’t know if we can deform, twist and turn this so that it becomes the unknot. A first attempt at distinguishing any knot from the unknot might be to try to count the crossings in its knot diagram. The unknot has no crossings, so any knot with crossings should be a different knot right? Sadly its not that easy. Notice that we can also have something equivalent to the unknot with any number of crossings, by simply twisting the unknot as many times as we need. Since, this simple twisting does not change the knot, we can’t use it to distinguish them either. We call this twisting the type-1 Reidemeister move, and it can be depicted by the drawing below. Remember here that we are only looking at a section of a knot, and not the whole knot.\nThere are two more of these moves that does not change the knot. We call these the type-2 and type-3 Reidemeister moves. The type-2 Reidemeister move can be though of as pulling back a strand that lies over another, and can be visualized as below.\nThe type-3 Reidemeister move can be thought of as pulling a strand over another crossing. This is maybe the most difficult move to intuitively agree that does not change the type of the knot. It can be visualized as below.\nOk, so how does these moves help us? Since they do not change the type of the knot, we can use them to get from one knot to another equivalent knot. Hence, two knots are equivalent is there is a sequence of Reidemeister moves connecting them. This fact is a famous theorem by the man Kurt Reidemeister himself.\nTricolorability You maybe notices that I used a word we haven’t yet defined, i.e. a strand. A strand is defined to be the part of a knot diagram going from one under-crossing to the next. This is again best seen by a drawing. I have colored one of the four strands in the figure-eight knot seen earlier.\nThere are an equal number of strands as there are crossings. We are now ready to define the machinery that will allow us to prove that there is a knot that is not the unknot. This machinery is called tricolorability. We say a knot can be tricolored, or is tricolorable, if we can color all its strands using three colors, such that at least two colors are used and such that at each crossing, either all colors are present, or only one is present. Lets check if our only two knots, the unknot and the figure-eight knot are tricolorable. In its simplest form, i.e. just the circle, we se that the unknot is not tricolorable, as a coloring of its unique strand only has one color. We will get back to the fact that all possible knots that are equal to the unknot must also be not tricolorable. What about the figure-eight knot? We start by trying to fill it in after the rules. We chose the same color orange for the middle strand that we colored earlier. Now, to follow the rules, either all three strands present in the central crossing must be orange, or two more must be present. If we try all orange we get\nand we see that the last strand also has to be orange, which means we failed to use at least two colors. Ok, lets try to have three different colors present at the central crossing. We then get\nwhere we see that if we must follow the second rule, the last strand must be all three colors at once. This is because it must be orange at its upper end, green at the blue-orange upper crossing, and blue at the bottom crossing. We are only allowed to color each strand once so we have actually proven that the figure-eight knot is not tricolorable.\nThere is something we have swept under the rug here so far, and that is showing that the Reidemeister moves doesn’t affect a knots tricolorability. If it did, then tricolorability wouldn’t be an invariant of the knot type, which is bad for showing two thing are the same or that two things are different.\nSince these moves are performed “inside” a knot, we must require that the beginnings and ends of the drawn strands have the same color both before and after the move. This is to make sure that we are only looking at the actual move affecting tricolorablity, and not changing something else about the knot colorwise. For the type-1 Reidemeister move, notice that we can only use one color both before and after the move, i.e.\nHence, if a knot is tricolorable, performing a type-1 Reidemeister move will not change that fact. For the Type-2 Reidemeister move, we notice that after we perform the move, we must have two separate strands, which means we can either have two different colors, or only one color. If we let both have the same color we assume that there is some other color elsewhere in the knot, not being affected by the move. We can them color the system with all same color before doing the move, so that case is fine. If we chose the two different colors, we get\nwhich shows that the tricolorability is preserved. For the type-3 Reidemeister move we can also choose the same color everywhere, in the same way as for the type-2 move. But, if we choose to tricolor the system using different colors, we get\nwhich still preserves the tricolorability! We have shown that Reidemeister moves does not affect the tricolorability of a knot, and hence that tricolorability is a knot invariant. This means that any knot equivalent to the unknot or the figure-eight knot is not tricolorable. This means that we cant use this machinery to show that the figure-eight knot is not the unknot, as they both are not tricolorable. But, it also mean that all we have to do to prove that knots different from the unknot exist, is to prove that there exists knots that are tricolorable! And this we can prove by example. I wont go for the standard example of a tricolorable knot, and we will instead show that the so-called Granny knot, is tricolorable. The Granny knot is the following knot:\nAnd all we have to do to prove that it is tricolorable is to find a tricoloring. This is as easy as just picking a strand to color in some color and following the rules. I then got the following coloring of the Granny knot\nwhich by inspection satisfies all the rules of a tricoloring of the knot. Hence, we have finally showed that there are knots! So the answer to the question in the title is yes.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/there-are-knots/","summary":"Something I have been looking into a bit lately, due to it sadly not being taught at my university is knot theory. This is something I have always known to be a part of topology, and have known to have interesting applications in physics, medicine, chemistry and more. So to rectify the situation I thought I would prove that knots exist. It was also nice to take a brake from all the higher category theory we have been looking into lately!","title":"Are There Knots?"},{"content":"A couple weeks ago I held a talk on introductory higher category theory. Most of the talk was based upon thing we already have discussed on this blog, such as the strict $2$-category $Cat$, bicategories, and why strictness fails for the category of topological spaces. The inly thing I talked about which I haven’t yet featured on this blog is the notion of quasi-categories, so I though that I would do that today. So, to see where we are headed, I just define it right away.\nDefinition (quasi-category): A quasi-category is a simplicial set where every inner horn has a filler.\nThis definition is incredibly short and sweet, but packs a serious punch once we unravel it. It is also often stated as a quasi-category being a simplicial set satisfying the weak Kan condition. There are many ways to intuitively justify the existence of quasi-categories, and one of them we almost already know. We have previously discussed $\\infty$-groupoids as just topological spaces through the homotopy hypothesis. From Quillen we know that the homotopy theory of topological spaces and the homotopy theory of simplicial sets are equivalent. More precisely, the category of topological spaces is Quillen equivalent to the category of simplicial sets. Instead of $\\infty$-groupoids—which are $(\\infty, 0)$-categories as every morphism of every degree is invertible up to a coherent homotopy—we can talk about $(\\infty, 1)$-categories. These are intuitively a collection of objects and morphisms such that all homsets are $\\infty$-groupoids. The most classical example being just the category of topological spaces, or more generally categories enriched in topological spaces, often called topological categories. Now we maybe start to see an idea of why quasi-categories are defined through simplicial sets. We can pass over to categories enriched in simplicial spaces, which gets us a bit closer to the definition, but not quite.\nI want to remark that the above section is only for broad intuition, and that I’m both shoving an incredible load of details under the rug, and lack a solid understanding of the technicalities. But, for me at least, it gives a picture of why we care about introducing simplicial sets into higher category theory, without going through the whole nerve of a category business.\nSimplicial sets Time to start unraveling the definition. I said a quasi-category was a simplicial set, so this is probably a good place to start. To define a simplicial set we first need to define the simplex category $\\Delta$.\nDefinition (the simplex category): The simplex category $\\Delta$ is the category consisting of all finite totally ordered sets with (non-strict) order preserving maps. We write the objects as $[n] = {0,1,2,3, \\ldots}$.\nThe category $\\Delta$ is generated by two important classes of maps, called the face maps and the degeneracy maps. The $i$‘th face map $\\delta_n^i$ is defined as the unique order preserving injection $\\delta_n^i: [n-1]\\longrightarrow [n]$ that misses $i$ and the $i$‘th degeneracy map $\\sigma_n^i$ is defined as the unique surjection $\\sigma_n^i:[n]\\longrightarrow [n-1]$ that hits $i$ twice.\nDefinition (simplicial set): A simplicial set is a functor $X: \\Delta^{op} \\longrightarrow Set$. We write $X_n = X([n])$ and call it the $n$-simplicies of $X$.\nThese again form a category, $sSet$ where the morphisms are the natural transformations between the simplicial sets.\nThe most important examples of simplicial sets are the so-called standard $n$-simplexes $\\Delta^n$. These are defined to be $\\Delta^n = Hom([n], -)$, where the functor $Hom([n], – )$ is on the opposite category, so we can use it as $Hom(-, [n])$ on the normal simplex category. These standard simplexes are the simplest ones to think about and the simplest to visualize. This is because we can apply the geometric realization functor, and these become the familiar $n$-simplexes we use in topology! Hence we can think of for example $\\Delta^3$ as\nDue to the Yoneda lemma, the $n$-simplicies of a simplicial set $X$ are in one to one correspondence with maps $\\Delta^n \\longrightarrow X$ in the category of simplicial sets.\nWe have now covered what a quasi-category consists of, namely a simplicial set. So, next we need to understand the condition we put on that simplicial set.\nHorns and fillers The condition we asked for included another simplicial set we need to define, namely the the simplicial $k$-horns. These are very similar to the standard simplices, but are missing one of the sides. To be rigorous we define the $i$‘th side of $\\delta^n$ to be the image of $\\Delta^{n-1}$ under the inclusion $\\iota_i$ onto the side of $\\Delta^n$ opposite to $i$. The $0$‘th side of $\\Delta^3$ under the geometric realization functor would then be the orange side in the following picture.\nWe then use these sides to construct what we call simplicial horns.\nDefinition (The simplicial k-horn): The simplicial $k$-horn is the union of all sides of $\\Delta^n$ except the $k$‘th one, i.e.\n$$\\Lambda_k^n = \\bigcup_{i\\neq k} Im(\\iota_i:\\Delta^{n-1}\\longrightarrow \\Delta^n). $$\nA $k$-horn in a simplicial set $X$ is then a map $\\Lambda_k^n \\longrightarrow X$. We call it an inner horn if $0\u0026lt;k\u0026lt;n$.\nWe wanted these $k$-horns in our simplicial set to satisfy a condition, which we called the weak Kan condition. This condition tells us that certain lifts of maps related to the $k$-horns in a simplicial set $X$ exists. We have a canonical inclusion from the simplicial $k$-horn into $\\Delta^n$ and we want there to exist a lift through this map for every inner horn in $X$, i.e. that the dotted map exists\nIf such a lift exists for all inner horns in a simplicial set $X$ we say it satisfies the weak Kan condition. We have now unrolled the definition, and we can state it with a bit more insight.\nDefinition (quasi-category): A quasi-category is a simplicial set $X$ such that every horn $\\Lambda_k^n \\longrightarrow X$ lifts to a map $\\Delta^n\\longrightarrow X$ through the canonical inclusion $\\Lambda_k^n\\subset \\Delta^n$.\nSo what does this definition really mean? What does this even have to do with categories? The connecting piece is interpreting horns as composable morphisms in a category. The easiest to visualize is the lift of the horn $\\Lambda_1^2$. If we draw it it looks like\nand an existing lift means there exists a dotted map\nmaking the triangle commute up to a higher morphism. In other words, we have some weaker form of composition of composable morphisms in the quasi-category. There may be many different ways to compose the morphisms, to we can’t talk about “the” composition, but all of the different compositions are related by higher morphisms. In this way we can view a quasi-category as a weaker notion of category, where we have morphisms that compose non-uniquely, and have an infinite tower of morphisms between morphisms to relate the compositions and higher relations. If we insist that the lift in the weak Kan condition is unique, we actually have an object we can use as a definition for a category, hence quasi-categories generalize categories, which is what we wanted, and justifies the word “quasi” being put in front.\nThat was all I wanted to say today, but we will definitely revisit quasi-categories later as the theory built by Lurie and Joyal around these objects are too interesting to not look deeper into!\n","permalink":"https://torgeiraamboe.github.io/posts/2020/quasi-categories/","summary":"A couple weeks ago I held a talk on introductory higher category theory. Most of the talk was based upon thing we already have discussed on this blog, such as the strict $2$-category $Cat$, bicategories, and why strictness fails for the category of topological spaces. The inly thing I talked about which I haven’t yet featured on this blog is the notion of quasi-categories, so I though that I would do that today.","title":"Quasi Categories"},{"content":"You may be thinking, what the heck is a monoid, and why the heck is it vertical? To explain this we will need some insight into classical categories and $2$-categories, which we luckily have been developing for the last few posts. First off, to let the familiar readers know, the objects of study today is called monads, not vertical monoids. But, I like to visualize them and think about them as somehow vertical, or at least something not strictly horizontal or one-dimensional.\nNot everyone is familiar with monoids, so to set the stage for the rest of the post we define a monoid to be a set $M$ together with a map $\\mu:M\\times M\\longrightarrow M$ and a distinguished element $1 \\in M$ such that $m(a, 1) = a = m(1, a)$ and $m(m(a, b), c) = m(a, m(b, c))$ for all $a, b, c \\in M$. This makes m an associative multiplication on $M$ with a two-sided unit $1$. We can kind of think about a monoid as a group without inverses, but pulling all intuition from groups might turn out bad.\nWe can define more general versions of monoids by using category theory. This makes use of monoidal categories, which we have talked about a little while ago. A monoid in a monoidal category $(\\mathcal{C}, \\otimes, I)$ is an object $M$ together with a map $\\mu:M\\otimes M\\longrightarrow M$, called multiplication, and a map $\\eta: I\\longrightarrow M$, called the unit, such that the associative law and left and right unit laws hold.\nHere $\\alpha$ is the associator in the monoidal category and $\\lambda$, $\\rho$ are the unitors. These are described a bit in the previously mentioned post. We see that this notion of monoid in a monoidal category is essentially equal to the one previously stated using sets, in fact the first definition is the same as a monoid in the monoidal category of sets, $Set$.\nIf we recall back to the discussion about $2$-categories in the post about the homotopy hypothesis, we defined what we called vertical composition of $2$-morphisms. This notion of vertical is the reason for saying that monads are somehow vertical monoids. If we draw $1$-morphisms horizontally, as we usually do, then we can draw $2$-morphisms vertically.\nWhich makes this whole notion of vertical composition a bit more graphical. In a $2$-category $\\mathcal{C}$ we always have a category $B(X, Y)$ of morphisms between objects. If we restrict ourselves to $1$-endomorphisms we can define a monoid in the monoidal category $B(X, X)$. Here the monoidal structure comes from composition of $1$-endomorphisms. If we recall what we need in order to have a monoidal category, we need a product (which here is horizonal composition), a unit (which here is the identity $1$-morphism $id_X$ at an object $X$), an associator and two unitors, that respectively satisfy the pentagon identity and the triangle identity. This is already ingrained into the definition of a $2$-category, and is made very explicit in the model we presented, i.e. bicategories. A monoid in this monoidal category of $1$-endomorphisms is the definition of a monad in a $2$-category. To make this even more explicit, and to summarize a kind of wild paragraph, we present a rigorous definition.\nDefinition (Monad): A monad $(X, T, \\mu, \\eta)$ consists of an object $X$, a $1$-endomorphism $T$, i.e. an object in the category of endomorphisms $B(X, X)$ together with two $2$-morphisms $\\mu: T\\circ T\\longrightarrow T$ and $\\eta: Id_X\\longrightarrow T$, such that the diagrams\nand\ncommute.\nIn the more classical setting, the definition of a monad comes from endofunctors of categories, i.e. $1$-endomorphisms in the category of categories, $Cat$. The most important, or at least some important examples of such monads comes from adjunctions. In fact every adjunction pair $(F, G)$ defines a monad. Here $G\\circ F$ defines an endofunctor $T=G\\circ F: \\mathcal{C}\\longrightarrow \\mathcal{C}$, the adjunction unit is a natural transformation $\\eta: Id_{\\mathcal{C}}\\longrightarrow G\\circ F$ and the monad multiplication comes from the adjunction counit $\\epsilon$ by\n$$\\mu: T\\circ T = G\\circ F\\circ G\\circ F \\overset{id_G \\circ \\epsilon \\circ id_F}\\longrightarrow G\\circ F = T$$\nThis monad kind of measures the failure of the adjoint pair $(F, G)$ to be an equivalence of categories.\nThe classical definition of a monoid i.e. the one using just sets can also be reformulated in this setting by letting our $2$-category have only one object, letting $1$-morphisms be sets where composition of sets is the cartesian product, and the $2$-morphisms be morphisms of sets. A monad in this category is then just a monoid. This idea is from John Baez, who also talks about connections to Feynman diagrams in physics in his posts. I don’t know enough physics to explore this now, but maybe another time.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/vertical-monoids/","summary":"You may be thinking, what the heck is a monoid, and why the heck is it vertical? To explain this we will need some insight into classical categories and $2$-categories, which we luckily have been developing for the last few posts. First off, to let the familiar readers know, the objects of study today is called monads, not vertical monoids. But, I like to visualize them and think about them as somehow vertical, or at least something not strictly horizontal or one-dimensional.","title":"Vertical Monoids"},{"content":"Last fall I held a talk about functors, natural transformations and equivalences of categories. This talk was part two of five in a student seminar on introductory category theory. There was mostly second year students attending but also a couple more experienced students. To make the talk a bit interesting for them as well I said that an equivalence of categories is the correct notion of “sameness” of categories, and not isomorphisms due to the fact that categories naturally lie in a $2$-category. An isomorphism of categories would be the correct notion of sameness if the category of categories had only trivial $2$-categorical structure, and we didn’t have to worry about higher morphisms. In this post I want to look at this statement and show that it is true.\nMotivation and hand waving Last post we talked a bit about $2$-categories and the differences between strict and weak $2$-categories. We introduced these through $Cat$, the category of (small) categories, which we discovered was a strict $2$-category. We also defined a bicategory, which is a way to explicitly describe a weak $2$-category. It can be smart to read that post to have some familiarity with the notion of $2$-categories. Since strict $2$-categories are special cases of weak $2$-categories, I will for simply use the term $2$-category instead of explicitly referring to one of them for most of this post.\nIn normal category theory we have for long understood that objects are not to be classified using equality, but some weaker notion of equivalence, usually called isomorphisms. For example in the category of abelian groups we want to use the first isomorphism theorem. This says that the image of a group homomorphism $f:G\\longrightarrow H$, is isomorphic to the domain modulo the kernel of the homomorphism. These two groups are essentially the same, i.e. the induced morphism on the quotient $\\overline{f}:G/Ker(f)\\longrightarrow Im(f)$ is an isomorphism. If we were only allowed to talk about groups being equal, this would not be a useful theorem, and our theory in general would not be as rich. So, we have learned that equality of objects is a bad notion in a standard category.\nClassical theory To understand what equivalences and isomorphisms of categories are, and how they relate to this higher $2$-categorical structure, we need to look at their classical definitions.\nDefinition (Isomorphism of categories): A functor $F:\\mathcal{C}\\longrightarrow \\mathcal{D}$ is called an isomorphism of categories if there exists a functor $G:\\mathcal{D}\\longrightarrow \\mathcal{C}$ such that $G\\circ F= id_{\\mathcal{C}}$ and $F\\circ G = id_{\\mathcal{D}}$.\nTo use a very suggesting notation, we let $=$ denote that the diagram commutes. Then we can express the definition as the two following diagrams.\nNote in particular that we have equalities $G\\circ F = Id_{\\mathcal{C}}$ and $F\\circ G = Id_{\\mathcal{D}}$. This is of course just because of composition, but remember that existence of composition is an axiom in the definition of a category. A priori, if we didn’t know we lived in a category, composition may not be defined. We could of course do two things in succession, but this does not a priori define a map. For example, if our objects are the points on a topological space, and the maps are paths parametrized by the unit interval, then composition of two paths is no longer a morphism, since it requires a twice as long interval. This can be fixed by a homotopy, but if we don\u0026rsquo;t pass to homotopy-classes if paths we will have undefined composition. This remark will become more important in a bit. Similarly we state the classical definition of an equivalence of categories.\nDefinition (Equivalence of categories): A functor $F:\\mathcal{C}\\longrightarrow \\mathcal{D}$ is called an equivalence of categories if there exists a functor $G:\\mathcal{D}\\longrightarrow \\mathcal{C}$ and two natural isomorphisms $\\eta$ and $\\epsilon$, such that $G\\circ F \\overset{\\eta}\\implies id_{\\mathcal{C}}$ and $F\\circ G \\overset{\\epsilon}\\implies id_{\\mathcal{D}}$.\nTo again use very leading diagram drawings, we can express the definition through the following two diagrams.\nIf we recall back to last post, we said that the category of (small) categories, $Cat$, naturally had the structure of a strict $2$-category, but a $2$-category nevertheless. This structure came from letting the objects be the categories, the $1$-morphisms be the functors and the $2$-morphisms be the natural transformations. But, we can also have another $2$-category structure on $Cat$, namely the trivial one. Any category is trivially a strict $2$-category, just by letting all $2$-morphisms be trivial, i.e. equalities. This is of course strict since composition of $1$-morphisms, i.e. normal morphisms in the category are associative by definition. Now we are starting to form the full picture of the statement, namely that the difference between equivalences of categories and isomorphisms is the choice of the canonical or the trivial $2$-category structure on $Cat$.\nEquivalences in 2-categories The last piece of the puzzle is the following discussion. In a general $2$-category, say described by a bicategory, we have objects, i.e. $0$-cells, and categories of morphisms between them. Thus, as we have learned in the hand waving part, it is bad to talk about equality between the $1$-cells in a bicategory, as they themselves are objects in a category. So what would we then want to describe very similar $1$-cells? Since the $1$-cells and $2$-cells are respectively objects and morphisms in a category, we have the notion of a $2$-cell being an isomorphism. This means that it is invertible on the nose. Since $2$-cells aren’t the objects in some category, we can easily talk about equality between them, and invertible then means that we have an actual inverse. Hence we can define very similar $2$-cells to be the $2$-cells that are invertible up to a $2$-cell isomorphism. This is called an equivalence in a $2$-category.\nDefinition (Equivalence in a 2-category): Let $A, B$ be $0$-cells in a bicategory $\\mathcal{C}$. A $1$-cell in $\\mathcal{C}$, i.e. an object $f:A\\longrightarrow B$ in the category $\\mathcal{C}(A, B)$, is called an equivalence if there exists a $1$-cell in $\\mathcal{C}(B, A)$, $g:B\\longrightarrow A$ and two isomorphism $2$-cells $\\alpha: g\\circ f\\implies id_A$ and $\\beta f\\circ g \\implies id_B$.\nMaybe a “new” cool drawing makes things simpler, more intuitive and hopefully more familiar.\nThese diagrams mysteriously look very similar to the ones defining equivalences of categories. The diagrams also visualize a bit better why we call the different pieces $0$, $1$ and $2$-cells, as they operate in the same way n-cells do in topology, especially simplicial sets. If we let our $2$-category be $Cat$ with the trivial $2$-morphisms, we see that an equivalence in that $2$-category is nothing but an isomorphism, since the $2$-isomorphism connecting the composition and the identity is the “equality morphism”. In the canonical $2$-category structure on $Cat$ we see that an equivalence in that $2$-category is an equivalence of categories, since the composition is connected to the identity functors by a $2$-isomorphism, also called a natural isomorphism in the classical setting.\nThis is the full picture, and we have explained what we set out to do!\n","permalink":"https://torgeiraamboe.github.io/posts/2020/equivalences-of-categories/","summary":"Last fall I held a talk about functors, natural transformations and equivalences of categories. This talk was part two of five in a student seminar on introductory category theory. There was mostly second year students attending but also a couple more experienced students. To make the talk a bit interesting for them as well I said that an equivalence of categories is the correct notion of “sameness” of categories, and not isomorphisms due to the fact that categories naturally lie in a $2$-category.","title":"Equivalence of Categories"},{"content":"A litmus test is a question asked in politics to a potential candidate for high office in which the answer determines if the person gets nominated or not. If a person or a committee holds the power of nominating candidates, they can use that power to make sure that a potential candidate holds their view on a certain matter. So, what does this have to do with mathematics, or especially with homotopy theory? There is a question worth asking certain objects to check if they should be allowed to be a suitable “definition” for a certain nice structure. The question, or test, which we will look more closely at soon, first started as a conjecture by Grothendieck, named later “the homotopy hypothesis”. This conjecture is still open in the way formulated by Grothendieck, but it can be turned on its head to form this test instead. The reason this is possible is because of ambiguity in a certain definition in higher category theory, and because there is seemingly many inequivalent “definitions” for the same object. Before exploring any theory at all, the conjecture states that $\\infty$-groupoids are equivalent to topological spaces. The litmus test then becomes; $X$ is considered a definition of $\\infty$-groupoids if and only if all $X$s’ are equivalent to topological spaces.\nMotivation Before jumping into definitions and theory, I wanted to first give a little motivation to why we are going past normal categories, and why stuff with the $\\infty$ prefix are interesting to study. As I understand it, the main reason to do $\\infty$ -stuff is to make “less strict” versions of our familiar objects from normal abstract algebra, and it turns out that the correct definition of “less strict” kind of means “up to homotopy”. This will hopefully become apparent throughout this post. The main $\\infty$ -object in this post will be $\\infty$ -groupoids, and it acts as one of the fundamental higher objects in homotopy theory, and it is of course the star of the beforementioned litmus test.\nThe motivating example for studying so-called higher categories is the category of categories, denoted $Cat$. Or, to avoid nasty set theoretic Russel paradox business, we actually define it as the category of small categories. Here the objects are (small) categories, and the morphisms are functors. As we have learned in regular category theory, there also exists morphisms between functors, called natural transformations. Hence we have more types of things in this new type of category. We have two types of morphisms, which we simply call $1$-morphisms, which are the functors in this case, and $2$-morphisms, which are the natural transformations. Since $2$ is the highest we have in this setting, we call it a $2$-category. From normal category theory we also know that the collection of functors between two categories form a category themselves, so we can also think about a $2$-category as a category where all the homsets are themselves categories. When we discussed cosmoi, we defined what we called an enriched category, and this is exactly what a $2$-category is, a category enriched over $Cat$. We can do this because $Cat$ is monoidal under the Cartesian product. This definition actually makes what we define as strict $2$-categories. These are categories where composition of $1$-morphisms has to be associative on the nose, because they are the morphisms of a category, i.e. strictly associative. This also means that strict $2$-categories actually also are normal categories with more information. We can then iteratively define a strict $n$-category to be a category enriched in a strict $(n-1)$-category. These strict versions are easy to define, and are nice to work with, but turns out to rarely show up in nature. As we mentioned, we want to have less strict versions of algebraic objects, not keep going with the same stuff.\nWeak higher categories The question then becomes; how do we define a non-strict, or more often called a weak $2$-category? This is not obvious, and require us to choose how to do it. Intuitively we want a $2$-category to be a collection of objects together with $1$-morphisms and $2$-morphisms, such that compositions of $1$-morphisms are associative up to invertible $2$-morphisms, but formalizing this in an exact definition is not trivial. One solution is called bicategories. These are created by weakening the notion of enrichment, and calling a bicategory a category weakly enriched in $Cat$. This is the oldest, and most used definition of a weak $2$-category.\nDefinition (Bicategory): A bicategory is a structure consisting of\n a collection of objects, often called $0$-cells for each pair of $0$-cells $x, y$, a category $B(x, y)$, whose objects are called $1$-cells and whose morphisms are called $2$-cells for each $0$-cell $x$ there is a distinguished $1$-cell $1_x \\in B(x,x)$ called the identity $1$-cell at $x$ for each triple of $0$-cells $x,y,z$ a functor $C_{x, y, z}: B(x, y)\\times B(y, z)\\longrightarrow B(x, z)$ which sends a pair of $1$-cells $(g, f) \\longmapsto g\\circ f$, called horizontal composition, and pairs of $2$-cells $(\\epsilon, \\eta )\\longmapsto \\epsilon \\ast \\eta$, called vertical composition for each pair of $0$-cells $x, y$ natural isomorphisms $l: f\\circ 1_x \\longrightarrow f$ and $r: 1_y \\circ f \\longrightarrow f$ called the left and right unitor respectively for each quadruple of $0$-cells $w, x, y, z$ a natural isomorphism $\\alpha: B(y, z)\\times B(x, y)\\times B(w, x) \\longrightarrow B(w, z)$ built from the functor $\\circ$, called the associator  such that the unitors satisfy the triangle identity\nand the associators satisfy the pentagon identity\nThis definition is a mouthful, but it shows how intricate the definitions of these higher objects can become. And remember, this is only a weak $2$-category. Imagine how many relations there are for even higher structures. The good thing is that we don’t have to imagine. We simply have to find another way of representing these objects with more familiar terms. We have to model them by something else. So for example for an $(\\infty, 1)$-category, there are already objects that behave in the way we want, and we just have to use the already well defined structure. We wont go through these in detail in this post, as I am saving them for a bit later. But, to mention one and the most used model for an $(\\infty, 1)$-category, which is an $\\infty$-category where all $k$-morphisms are weakly invertible for $k\\geq 2$, is called quasi-categories. These are special types of simplicial sets, and can be defined with little trouble. The theory of higher categories mainly consists of theory for $(\\infty, 1)$-categories, and mainly through the model of quasi-categories. We can define an $(\\infty, n)$-category sort of to be a category weakly enriched in $(\\infty, n-1)$-categories, which means that to understand $(\\infty, 1)$-categories, we need to understand $(\\infty, 0)$-categories, which are the $\\infty$-groupoids.\n$\\infty$-groupoids To describe the litmus test, we luckily only need one of the simpler $\\infty$-categories. For normal categories, one of the simplest types is the ones where all morphisms are invertible, i.e. groupoids. If we carry this logic over to our new setting, an $\\infty$-groupoid should be an $\\infty$-category where all of the $k$-morphisms are invertible up to an invertible $(k+1)$-morphism, which makes sense since we said they were the $(\\infty, 0)$-categories.\nAs we have seen, having all these higher morphisms comes with a lot of troubles, the most prominent one being how we are supposed to make a proper definition when we are required to make infinite choices for composition laws. So here we want to model $\\infty$-groupoids using other more familiar objects. We started by saying that “less strict” roughly means “up to homotopy” which hinted at the fact that we can use topological spaces and their homotopy theory to help us on the way.\nIf we take a topological space $X$, it has a category associated to it, namely the fundamental groupoid $\\Pi_1 X$. This is a category where the objects are all the points in $X$ and the morphisms are homotopy classes of paths between points. If we instead of homotopy classes use just paths as morphisms, the composition, i.e. concatenation of paths, becomes invertible up to homotopy. And this homotopy is invertible up to homotopy, and so we can continue ad infinitum. This category is called the fundamental $\\infty$-groupoid of $X$. So, if we define $1$-morphisms to be paths, $2$-morphisms to be homotopies of paths, $3$-morphisms to be homotopies of homotopies of paths etc, we get that topological spaces satisfy the intuitive definition we had of an $\\infty$-groupoid.\nThis is where the litmus test finally comes into play. This description of $\\infty$-groupoids as topological spaces is very nice, but there could be other models that serve other purposes. The litmus test then tells us that any suitable definition of $\\infty$-groupoids, i.e. any chosen model, should produce a category $\\infty grpd$, which is equivalent to $Top$, the category of topological spaces, i.e. $\\infty grpd \\simeq Top$. Any notion of $\\infty$-groupoids can then be interpreted as just drawing diagrams between dots by using paths and homotopies on a topological space, and the geometry of the topological space determines which paths can have homotopies between them etc.\nThis also tells us that any definition, or model of $\\infty$-groupoids will produce our familiar homotopy theory, which gives us many different views on the already familiar classical theory.\nThere are already many such models, and they are used for different things. One of the more used ones are Kan complexes, which are simplicial sets where every horn has a filler. There are also globular sets, marked simplicial sets, algebraic Kan complexes, etc. We will maybe see some of these later when we discuss $(\\infty, 1)$-categories. But, for now this is what I wanted to say about the homotopy hypothesis.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/the-homotopy-litmus-test/","summary":"A litmus test is a question asked in politics to a potential candidate for high office in which the answer determines if the person gets nominated or not. If a person or a committee holds the power of nominating candidates, they can use that power to make sure that a potential candidate holds their view on a certain matter. So, what does this have to do with mathematics, or especially with homotopy theory?","title":"The Homotopy Litmus Test"},{"content":"Since one of my main mathematical interests is homotopy theory, im bound to often bump into things that require the use of base-points. This has long been the classical way to study spaces, especially in terms of homotopy groups. When I was introduced to these so-called pointed spaces, I couldn’t help but feel that these we less natural, or more ad hoc, than regular spaces. I didn’t know much about categories then, but have since learned it is usually in this context that some form of naturality occur. It turns out that pointed spaces actually come from a very nice natural categorical construction, which of course is the focus of this post. I will assume introductory knowledge of categories, and I will try to keep this short for once.\nDefinition As the name implies, we will have something like “a category under some object”, but we will have to make this precise of course. Under categories are also sometimes called coslice categories, and they are in fact a special case of a construction called comma categories, which we will not cover today. The idea is roughly to fix an object, and study morphisms out of said fixed object instead the object itself. This will hopefully be clear from the definition.\nDefinition (Under category): Let $\\mathcal{C}$ be a category, and $c$ an object in it. The under category $c\\downarrow \\mathcal{C}$ is a category whose objects are all morphisms $f_A: c\\rightarrow A$ that start at $c$, and whose morphisms are commuting triangles of the form\nIt then (at least for me) makes intuitively sense that we call it the under category, since it consists off all things happening “under” an object $c$ in some nice way. It is in fact a category, since it has identity morphisms\nfor any object $f:c\\rightarrow A$ in the category, and composition of morphisms are associative because the commutivity of the inner triangles in the following diagram imply the commutivity of the outer triangle.\nThis is all we need in order to call $c\\downarrow \\mathcal{C}$ a category.\nExamples Our motivation was to create pointed topological spaces, so how do we get these as an under category? The category of pointed topological spaces with base-point preserving maps, is precisely the category $\\ast \\downarrow Top$ of topological spaces under a one point space! How can we see this? Any object in the under category is a map $b_A$ from a point to a space $A$. Call the image $x=b_A(\\ast)$ of this map the base-point of the space $X$. This information is exactly the same as having a space with a specified point $(X, x)$, i.e. an object in the category of pointed topological spaces. Also, maps in this under category are maps that commute with the formation of these base-points, i.e. diagrams\nwhich in terms of just the pointed spaces are maps that preserve the chosen base-points in the two spaces $A$ and $B$, because $f(b_A(\\ast))=b_B(\\ast)$, i.e. base-point preserving maps. Hence we have a nice categorical description of pointed spaces, and they are an example of a very natural construction. Neat!\nAnother example is the category of algebras over a ring. To recap the definition, an algebra over a ring $R$, also called an $R$-algebra, is a ring $A$ together with a ring map $s_A: R\\rightarrow A$, making it into an $R$-module in a compatible way. This is maybe starting to look familiar to the previous example. An $R$-algebra morphism is, now not surprisingly, a ring map between two $R$-algebras, such that it commutes with their respective map from $R$, i.e. a map such that\ncommutes. Hence, the category of $R$-algebras, is the under category $R\\downarrow Rings$ in the category of rings.\nIt said I would keep this short, so I wont say anything more for now. I will mention that the semester has started again, so not much time to write on the blog… But, I have started writing my master thesis, so maybe Ill do some writing here about what I write about there, or some progress updates etc. Time will tell.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/under-category/","summary":"Since one of my main mathematical interests is homotopy theory, im bound to often bump into things that require the use of base-points. This has long been the classical way to study spaces, especially in terms of homotopy groups. When I was introduced to these so-called pointed spaces, I couldn’t help but feel that these we less natural, or more ad hoc, than regular spaces. I didn’t know much about categories then, but have since learned it is usually in this context that some form of naturality occur.","title":"Under Category"},{"content":"This post is part two of a little two-part miniseries about defining the cosmos. To learn what a cosmos is in mathematics, or rather what we want it to be, you can read the first part. There we described a cosmos as a nice place to enrich a category, or a nice place to do enriched category theory, and to quickly recap, an enriched category is a category where we have objects of morphisms instead of just a collection of them, and these objects come from some monoidal category. In this post we will continue the story, and focus more on the definition rather than the setup.\nOk, since we have already decided we want to do enriched category theory, and a cosmos is supposed to be a nice category to enrich over, we already know at least two properties a cosmos must have.\n It must be a category That category must be monoidal  Now we at least have some base line for what a cosmos is! We began the introduction to a cosmos by comparing it to its brother in physics, and maybe it would be fun to continue this path. In physics one wants to be able to study the smallest building blocks, and the largest structures. We would kind of like to be able to “zoom in” and “zoom out” as much as we want, and both see the small local picture and the bigger picture.\nThe big, and the small The above analogy is maybe a bit of a stretch, but I think the intuition still kind of holds if we still want to pretend that we are using motivation from physics. In mathematics, and especially in this kind of abstract algebra, looking at the small and looking at the big is called limits and colimits. As said, this analogy is not perfect, as limits and colimits capture much more than just zooming in and out. They kind of capture the structure of seing the smaller and bigger picture, and they do so in every way possible. They are also somewhat difficult to grasp, but we will try our best.\nA diagam in a category $\\mathcal{C}$ can be thought of as a functor $D$ from a category $J$ to $\\mathcal{C}$, where we think of $J$ as a sort of indexing category, or a “shape” category. This means that $J$ determines the indexing, and where we have arrows in our diagram in $\\mathcal{C}$. Hence we sometimes reffer to such a diagram to have shape $J$. The diagram is then a collection of objects in $\\mathcal{C}$, that are indexed by the objects in $J$, and also has the same “pattern” or “shape” as $J$. If $J$ is a small category, i.e. both the collection of objects form a set, and all the collections of morphisms form sets, then we call $D$ a small diagram.\nDefinition (Cone and cocone): Let $D$ be a diagram in $\\mathcal{C}$ with the shape of $J$. A cone $(N, \\psi)$ to $D$ is an object $N$ in $\\mathcal{C}$ together with a collection of morphisms $\\psi_X : N\\longrightarrow D(X)$ indexed by the objects $X$ in $J$, such that for every morphism $f:X\\longrightarrow Y$ in $J$, we have $D(f) \\circ \\psi_X = \\psi_Y$, i.e. the diagram\ncommutes for all such $f$. Dually, a cocone $(M, \\mu)$ to $D$ is an object $M$ together with a collection of morphisms $\\mu_X : D(X)\\longrightarrow M$ indexed by the objects $J$, such that for every morphism $f:X\\longrightarrow Y$ in $J$, we have $\\mu_Y \\circ D(f) = \\mu_X$, i.e. the diagram\ncommutes for all such $f$.\nUnderstanding these cones and cocones is often the difficult part of understanding limits and colimits. There exists weird diagrams, and understanding the cone of one of these weird diagrams as an object itself is in my opinion often difficult. We wont dwelwe too much on these objects, but the reader should look at some examples like products, direct sums, disjoint unions, terminal and initial objects, and check that these are cones or cocones (ther are actually also limits or colimits). This also hints at the fact that limits are cones, and colimits are cocones, which will show up in the definition. They are kind of the biggest cones, and smallest cocones. This will also hopefully become clear from the definition.\nDefinition (Limit): A limit of a diagram $D$ in a category $\\mathcal{C}$ in the shape of $J$ is a universal cone $(L, \\phi)$ to $D$. This means that every other cone $(N, \\psi)$ uniquely factors through it, i.e. there exists a unique morphism $u: N\\longrightarrow L$ such that $\\phi_X \\circ u = \\psi_X$ for all $X$ in $J$. Or in a diagram form:\nIf the diagram is small, we call the limit a small limit.\nDefintion (Colimit): Similarily, a colimit of a diagram $D$ in a category $\\mathcal{C}$ in the shape of $J$ is a universal cocone $(L, \\phi)$ to $D$. In the same way as for the limit, this means that any other cocone factors uniquely through it. Or in a diagram form:\nIf the diagram is small we call the colimit a small colimit.\nIt is important to note that limits and colimits of a diagram need not always exist in a given category, but in the nice ones we usually work in, most likely they exist. A category where all small limits exists is called a complete category, and dually, a category where all small colimits exists is called cocomplete. Some authors call a category bicomplete if the category is both complete and cocomplete. In fact we did this when discussing model categories, which are bicomplete categories with a model structure.\nClosed categories We are actually almost done, but we are missing one final property, and that is a property called closedness. For a category to be closed, we need that everything regarding the category is a part of the category. This is a bit vague, but the simple intuitive definition is that not only the objects in the category are objects, but the collections of morphisms also are objects in the category. We can also think of this as the category being enriched over it self, which if we remember back to the examples of enriched categories, was something that a couple nice categories had, like Abelian groups and vector spaces. These are often categories one would like to mimic, or at least have categories that act as nicely as them. Since the game we are playing is enriched category theory, it might be smart that the category we enrich over, i.e. a cosmos, is also a kind of trivial enriched category, and this is exactly the case because of this property.\nClosedness is formalized by the notion of internal homs. From the intuitive definition, this should be some sort of way to compare the collections of morphisms to objects in the category. More precisely, an internal hom is a functor $[-,-]: \\mathcal{C}^{op} \\times \\mathcal{C} \\longrightarrow \\mathcal{C}$, that kind of works as a collection of morphisms. Every locally small category that has an internal hom functor has a forgetful functor to the category of sets, that sends the internal hom to the actual set of morphisms.\nDefinition (Closed category): A closed category is a category $\\mathcal{C}$ together with an unit object $I$ and an internal hom functor $[-,-]$, such that there are nice morphisms $L: [B, C]\\rightarrow [[A, B], [A, C]]$, $i_A: A\\rightarrow [I, A]$ and $j_A: I\\rightarrow [A, A]$, for three different definitions of nice respectively. What exactly the different “nice” morphisms are will not be covered here, because we wont need them for our definition of a cosmos. This is because when uniting the different structures we have, these nice maps becomes apart of a more known structure.\nWe have now defined all the structures that we need to state the definition of a cosmos. But, since we now have several structures at the same time, we need to make sure that these structures play nice together. As a recap, we recall that the structures we have are, category, monoidal, symmetry, complete, cocomplete and closedness. Luckily for us, the limits and colimits are not actually a structure of the category, but more like a property that we have internally. It says something about which objects exists, but not about structure. So these fit together with the other ones for free!\nFrom both the monoidal structure and from the closedness, we have a unit object, $I$. If we want a nice category that makes sense these two unit objects should of course be the same. Some of the structure is motivated, or at least inspired from the category of sets, where we have $[X,Y]={ f:X\\rightarrow Y}$, and $Hom(S, [X, Y])\\cong Hom(S\\times X, Y)$. So to carry this motivation further, we require that the internal hom functor $[X,-]$ is right adjoint to the monoidal product functor $-\\otimes X$ . Hence, in a closed and monoidal category we have a bijection $Hom(A, [X, Y])\\rightarrow Hom(A\\otimes X, Y)$, that is natural in all three variables. This map is often called “currying”, and is used in for example $\\lambda$-calculus, type theory and categorical logic. When this is the case, we concatenate the two structures and call the category a closed monoidal category, or sometimes a monoidal closed category.\nDefinition So, we have now defined everything, and united the structures. The journey has been long, and the concepts plenty, but we have finally arrived. To sum up the entire discussion, we will finally define a cosmos, more specifically Bénabou\u0026rsquo;s definition of a cosmos. This definition shows that a one sentence definition can take a long time to formulate, and a long time to process.\nDefinition (Cosmos): A cosmos is a bicomplete closed symmetric monoidal category $\\mathcal{C}$.\nWe havent really explored why this definition satisfies what we claimed at the introduction last time, i.e. that cosmoi are nice places to do enriched category theory, but trying to study it has made me realize it may be out of my reach as of now. I find the subject really interesting, so Ill try to visit back at this theory at a later time. Hopefully then we can explore how enriched categories over a cosmos behaves like normal category theory. Anyway, for now, this is it.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/defining-the-cosmos-2/","summary":"This post is part two of a little two-part miniseries about defining the cosmos. To learn what a cosmos is in mathematics, or rather what we want it to be, you can read the first part. There we described a cosmos as a nice place to enrich a category, or a nice place to do enriched category theory, and to quickly recap, an enriched category is a category where we have objects of morphisms instead of just a collection of them, and these objects come from some monoidal category.","title":"Defining the Cosmos: Properties and definition"},{"content":"I think there are many parts of physics worth studying for mathematicians, and the physical notion of a cosmos may be one of them, but, this post is not about physics. Even though the usual field of study one thinks of when hearing the word “cosmos” is physics, there is also a type of mathematical object with the same name. This type of object does have that name for a reason, which is not clear maybe from the object it self, but from what one can do with and in such an object. In physics, the cosmos is a word for the universe, but it includes also the universes structure. The cosmos is not just “all the stuff that exists”, but also their relations and complex interactions. It is therefore kind of the background, or the playing field of physics.\nA cosmos in mathematics is also a kind of nice playing field for mathematics. More specifically ncatlab says it is “a nice place to do category theory”. But what does this mean? Well, it is kind of complicated, but we will try to understand some of it. To be more precise without explaining anything more, one could say the idea is that the theory of categories enriched over a cosmos behave similarly to standard category theory itself. Much of this theory is still way above my head, so Ill try to keep it grounded. That said, we need to understand what an enriched category is to tell the story of the cosmos properly. This is the goal for this post, and next time we will come back to looking at what properties a cosmos should have for our above statement to be true. Throughout we will try our best to pretend that the definition is motivated by physics.\nMore structure Often when doing category theory or homological algebra we often find that we need some restrictions on our category to make it nicer to work with, or to have more nice properties. First of all we often note that it is usually enough to work in locally small categories, i.e. categories where the collection of morphisms between two objects always form a set. Many authors even require this for their definition of a category. Sets in themselves are not always exciting enough, so we often require that these sets of morphisms have some structure, often an algebraic one. This is intuitively exactly what an enriched category is, i.e. some category where all sets of morphisms are actually objects in some other fixed category, i.e. we have objects of morphisms. Hence we can talk about categories “enriched over” another category, or sometimes authors use “enriched in” instead.\nWe see quite quickly that the category from where we steal our objects of morphisms needs to have at least one property. In a category we need to be able to compose morphisms, and when these morphisms come from an object, their composition also must come from an object, and hence we need some way to take the product of objects. This is formalized by the category being a monoidal category, i.e. a category where we have some sort of product that behave nicely. This is easier said than done, and the following long definition reflects that.\nDefinition (Monoidal category): A monoidal category is a category $\\mathcal{C}$ equipped with a functor $\\otimes : \\mathcal{C} \\times \\mathcal{C} \\rightarrow \\mathcal{C},$ called the monoidal product, a unit object $1\\in \\mathcal{C}$ and three natural isomorphisms $\\lambda_A : 1\\otimes A \\rightarrow A$, $\\rho_A : A\\otimes 1\\rightarrow A$ and $\\alpha_{A,B,C} : (A\\otimes B)\\otimes C \\rightarrow A\\otimes (B\\otimes C)$ called the left unitor, right unitor and associator respectively, such that the following diagrams\ncalled the triangle identity, and\ncalled the pentagon identity, both commute.\nThe definition seems very difficult, and has a lot of moving parts, but in reality it is quite simple. We are using the symbol for the tensor product, $\\otimes$ for the monoidal product because the tensor product is usually the product we are using. So any intuition we have from using the tensor product can usually be applied to monoidal categories. If the three natural isomorphisms $\\lambda, \\rho, \\alpha$ are identities, then $\\mathcal{C}$ is called a strict monoidal category. These do rarely come up in nature, but every monoidal category is in fact equivalent to a strict monoidal category.\nA version of the monoidal category we will be using is actually a bit nicer, and comes with an extra bit of information, namely symmetry.\nDefinition (Symmetric monoidal category): Let $\\mathcal{C}$ be a monoidal category. We say $\\mathcal{C}$ is a symmetric monoidal category if there is a natural isomorphism $\\beta_{X,Y}: X\\otimes Y \\rightarrow Y \\otimes X$, called the braid isomorphism, such that $\\beta_{X,Y}\\circ \\beta_{Y,X} = id_{X\\otimes Y}$ and the following diagrams\ncalled the unit coherence, and\ncalled the associativity coherence, both commute.\nJust to mention it, there is a version of this type of category where we relax the definition a bit, such that the composition $\\beta_{X,Y}\\circ \\beta_{Y,X}$ is not the identity. This is then called a braided monoidal category, and is often used in knot theory.\nTo have some quick examples, most categories that appear in the wild are symmetric monoidal. For example the category of sets with the regular cartesian product is symmetric monoidal, the category of groups with the cartesian product is symmetric monoidal, and the category of finite dimensional vector spaces with the tensor product is symmetric monoidal.\nEnriched categories So, with that definition under our belt, we are ready to tackle the next definition, which is really what we want to understand, namely enriched categories.\nDefinition (Enriched category): Let $\\mathcal{V}$ be a monoidal category. A $\\mathcal{V}$-category $\\mathcal{C}$, or a category enriched over $\\mathcal{V}$, consists of a collection of objects, denoted $Ob\\mathcal{C}$, and for every pair $A,B$ of objects in $\\mathcal{C}$ we have an object $C(A,B) \\in \\mathcal{V}$, called the hom object, or the object of morphisms. These collections must satisfy that for any object $A$ in $\\mathcal{C}$ there is a morphism $j_A : 1\\rightarrow C(A,A)$ called the identity element, and for every triple of objects $A, B, C$ in $\\mathcal{C}$ there is a morphism $\\circ_{A,B,C}: C(B,C)\\otimes C(A,B)\\rightarrow C(A,C)$ called composition such that the following three diagrams commute.\nWhich expresses the associativity of composition,\nand\nwhere the latter two replace our standard notion of identity morphism with a more appropriate one when using the identity object 1 from our monoidal category $\\mathcal{V}$.\nWe see that our intuitive notion of an enriched category took quite a long time to explain, and had a lot of bits and pieces that needs to be correct. But, our intuitive explanation, i.e. a category where we have objects of morphisms instead of just collections of morphisms is still the nice way of thinking about these abstract complicated mathematical structures. To have a couple examples, we first look at the part we mentioned in the introduction, that we usually require our category to be locally small. Here our potential class of morphisms that usually define a category is required to be sets. So, we have taken sets, which form a monoidal category $Set$ under the cartesian product, and stolen them for our hom objects, i.e. a locally small category is just a $Set$-category, or a category enriched in Set. This is the first stepping stone to realizing that maybe enriched categories are nice to work with after all!\nIf we want some algebraic structures on these sets, we can instead enrich our category over the category of abelian groups, which is monoidal under the tensor product when viewing them as $\\mathbb{Z}$-modules. These categories are the pre-additive categories. Familiar examples such as the category of abelian groups, the category of modules over a commutative ring and the category of vector spaces are actually all enriched over themselves, as their morphisms all form objects in the category. There are of course some more wacky examples, such as viewing a generalized type of metric space as a category enriched over the poset $([0,\\infty], \\geq)$ of extended real numbers, where the monoidal product is just standard addition. An example related to this is a recent paper by of one of my favorite math-bloggers Math3ma, which used a similar idea to try to understand language as a category enriched over the unit interval with multiplication as the monoidal product. She and her collaborator did this by having the hom-objects be the conditional probability p(s'|s) that s is a subsequence of the sequence s', and use this to understand something which I didn’t understand.\nAs you can tell, the possibilities, and the examples are many and diverse. But we are not merely interested in these enriched categories. We are interested in which objects it is nice to enrich over. This will be done in part 2 of this mini series, where we explore the remaining pieces to defining a cosmos, and at the end hopefully define it in all its glory. To hint a bit at where we are heading, we want to define $\\mathcal{V}-Cat$ of categories enriched over $\\mathcal{V}$, and that this category behaves like a standard category, i.e. we have nice morphisms, natural transformations, a Yoneda lemma, equivalences and adjunctions etc. We will not prove that all of these have an enriched version, but interested readers can study “Basic concepts of enriched category theory” by G.M. Kelly.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/defining-the-cosmos-1/","summary":"I think there are many parts of physics worth studying for mathematicians, and the physical notion of a cosmos may be one of them, but, this post is not about physics. Even though the usual field of study one thinks of when hearing the word “cosmos” is physics, there is also a type of mathematical object with the same name. This type of object does have that name for a reason, which is not clear maybe from the object it self, but from what one can do with and in such an object.","title":"Defining the Cosmos: Enriched category theory"},{"content":"The last few posts have all been of relatively long length and have all taken some time to construct and write. I initially also wanted to produce shorter posts just discussing an example or a calculation etc, and today I tried to do just that, but failed. The post became somewhat longer than intended, but it is really informal and intuitive, so its fine in my opinion.\nIn a previous post we discussed both weak homotopy equivalences and regular homotopy equivalences, and we have also encountered the Whitehead theorem, which says that any weak homotopy equivalence between CW-complexes is in fact a regular homotopy equivalence. But, we did not discuss their differences, which is what we do in this post.\nAnyone who have studied some topology has encountered the classical counter-example used to prove that not all connected topological spaces are path connected, namely the “topologist sine curve”. We can use this space to construct a space which is weakly contractible, i.e. weakly homotopy equivalent to a point, but not contractible, i.e. homotopy equivalent to a point. Hence this space is a counter example to Whiteheads theorem for non-CW-complexes, and shows that that assumption is crucial for the theorem to hold. Recall that a map is called a weak homotopy equivalence if it induces an isomorphism on every homotopy group, and that it is called a homotopy equivalence if there exists a homotopy inverse, i.e. some map such that their composition both ways is homotopic to the respecive identity maps.\nThe what circle? The counter-example we will construct is called the Warsaw circle, and intuitively, it is a topologist sine curve sewn together to form something similar to a circle. Or equivalently, taking a circle, removing a segment, and replacing it with the topologist sine curve.\nTo have a formal mathematical construction, we can construct it as\n$$S_W = { (x, sin(\\pi/x)) , | , 0 \u0026lt; x \\leq 1 } \\cup {(0,y) , | , -1 \\leq y \\leq 1 } \\cup C $$\nwhere $C$ is a continuous curve in the plane connecting $(1,0)$ to $(0,0)$ without intersecting the other parts of the Warsaw circle. The curious thing about this construction is that the Warsaw circle, $S_W$ is actually path connected, which the topologist sine curve is not. The problem on the topologist sine curve is that a non-zero point can’t be connected to $(0,0)$ in the curve, but on the Warsaw circle, you can just go around the other way.\nNow, choose a map that sends the one-point space into the Warsaw circle. Since they are both path-connected spaces, they both have a trivial zeroth homotopy group, or equivalently just one path component. The one-point space has the rest of its homotopy groups trivial as well, and it is hopefully clear that the only possible non-zero homotopy group of the Warsaw sircle is its fundamental group.\nA shitty intro to shape theory To show (rather non-rigouously) that the fundamental group of the Warsaw circle is trivial, we are going to use shape theory, invented (I think) by Karol Borsuk in the 60’s. One more modern interpretation of shape theory is that it is to Čech homology the same as homotopy theory is to singular homology. As such, it is sometimes called Čech homotopy theory instead of shape theory. Čech homotopy has been developed a bit further, and is a bit more general to my understanding, but still this view holds strong if we don\u0026rsquo;t care about their relationship to cohomology. Anyway… Shape theory is the study of spaces that can be embedded in the Hilbert cube\n$$Q = \\prod \\left[-\\frac{1}{n}, \\frac{1}{n} \\right] $$\nand special maps called shape maps between them. Essentially, two spaces are shape equivalent if they are homotopy equivalent when we “thicken” them by some amount. If we thicken the Warsaw circle, it does no longer have that weird topological sine curve bit. This is because that whole infinitely tight together mess is now just a nice blob, and the thickened Warsaw circle is hence homotopy equivalent to the thickened normal circle, which is homotopy equivalent to the standard sircle $S^1$.\nSince the Warsaw circle it is not shape equivalent to a point, it cannot be homotopy equivalent to a point. To relate back to the theory hinted at, this shape equivalence says that both the Warsaw circle and the normal circle both have a non trivial first Čech homotopy group, and that they are isomorphic in the Borsuk shape category.\nThis is all very imprecise and non-rigorous, but if we think about what an element in the fundamental group would be if it was not trivial, it would be a path from the basepoint (the image of the one-point space) to itself, which is not the constant path. For such a path to exist, it has to travel through the topologist sine curve, which we know it cant do, since the topologist sine curve is not path connected. Hence it makes sense intuitively that there should be no such path, and hence that the fundamental group of the Warsaw circle is trivial.\nThis post became a bit longer than expected, and was maybe a bit less precise than I intended, but I think it was still fun and valuable.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/the-warsaw-circle/","summary":"The last few posts have all been of relatively long length and have all taken some time to construct and write. I initially also wanted to produce shorter posts just discussing an example or a calculation etc, and today I tried to do just that, but failed. The post became somewhat longer than intended, but it is really informal and intuitive, so its fine in my opinion.\nIn a previous post we discussed both weak homotopy equivalences and regular homotopy equivalences, and we have also encountered the Whitehead theorem, which says that any weak homotopy equivalence between CW-complexes is in fact a regular homotopy equivalence.","title":"The Warsaw Circle"},{"content":"For quite some time I have occasionally stumbled onto the Wikipedia page for orbifolds while looking at topology related mathematics. I have always been fascinated by them, and always though that they certainly will come up during studies at university, but they never have (at least not yet). On said wikipedia page it says that the word orbifold is short for “orbit manifold” and that these orbifolds are in fact a generalization of manifolds.\nIn this post we will focus on smooth orbifolds as these are nicer to draw, and are a nicer introduction to the objects. These will then be generalizations or smooth manifolds. So, one of first things to ask is maybe why smooth manifolds need generalizing at all? Smooth manifolds in them selves are very nice objects and are used all over mathematics, physics, robotics and more, but they can be a bit restrictive. Many natural objects have so-called singularities, or singular point. Take for example a pillow case. It has four such singular points, namely the four corners.\nThese types of points are not allowed on a smooth manifold, because there has to be a neighborhood around every point that looks like euclidean space. Smooth orbifolds however, allow these types of points and several other types of “irregularities” that are not allowed on smooth manifolds. They are actually much more general than this, and their full generality is to me still not understood. Orbifolds have been abstracted and made “nicer” by using heavier mathematical machinery (étale Lie groupoids or Deligne-Mumford stacks), but the classical definition is still worth discussing and learning, which is what we will attempt today.\nSo, the two questions I want to answer today is; What is a smooth orbifold? And how do they generalize smooth manifolds? Maybe sometime in the future we will study them closer and ask more nuanced questions.\nPreliminaries Recall that a manifold is a nice topological space that locally looks like Euclidean space. More precisely, around every point, there exists and open subset around it and a homeomorphism, called a chart, from that open subset to an open subset of Euclidean space. If all these homeomorphisms are in fact smooth maps, i.e. diffeomorphisms, then the manifold is called a smooth manifold. To motivate the future definition of a smooth orbifold a bit, we look at what can happen to Euclidean space when taking quotients by a group action. Don’t worry if you don’t know these terms yet, they will be explained later, but try to understand what is happening by looking at the pictures.\nLet $\\mathcal{M}=\\mathbb{R}^2$ and let $G=\\mathbb{Z}\\times \\mathbb{Z}$ act on $\\mathcal{M}$ by $(n, m) \\cdot (a, b) = (a+n, b+m)$, i.e. as a lattice. If we take their quotient, $\\mathcal{M}/G$ we get something that still has a smooth structure. In fact we get the torus. This is quite easy to think through, but it is maybe even easier by a visual “guide”.\nThe torus is a smooth manifold, so we have produces a nice object that is locally diffeomorphic to the object we started with. If we instead let $G = \\mathbb{Z}_4$ and let it act on $\\mathcal{M}$ by rotation around origin, we suddenly get something that does not have a smooth structure. We get a cone.\nThese are both examples of orbifolds, and they also hint at the fact that orbifolds generalize manifolds. To have a nice intuitive definition, akin that of the intuitive definition of a manifold, we can say that an orbifold is a nice topological space that locally looks like Euclidean space modulo some linear action from a finite group (or more general, a group acting properly discontinuously).\nWe have already used terms like “a group acting on a space” and “quotient by a group action”. To make sure we understand these before delving into the technicalities, we do some repetitions on a couple definitions.\nDefinition (group action): Let $X$ be a set and $G$ a group. A group action from $G$ on $X$ is a map $\\alpha : G\\times X\\rightarrow X$ such that $\\alpha (e,x)=x$ and $\\alpha (g,\\alpha (h,x)) = \\alpha (gh,x)$ for all $g,h\\in G$ and $x\\in X$. The action is also often just denoted $gx$. If $X$ is a topological space, a group action is called properly discontinuous if for every $x\\in X$ there exists an open neighborhood around $x$ such that $\\alpha (g, U) \\cap U \\neq \\emptyset$ for only a finite number of $g\\in G$. This holds trivially true for all finite groups.\nDefinition (quotient space): Let $X$ be a set and $G$ a group acting on $X$. We call the set $G_x = { gx\\in X , | , g\\in G}$ the orbit of $x$. We can form an equivalence relation on $X$ by saying two elements are equivalent if they are in the same orbit. The quotient of $X$ by that relation is called the orbit space, or the quotient space $X/G$. When $X$ is a topological space, the orbit space has a natural topology given by the quotient topology, and hence it is also a topological space.\nSo, the orbit space of a topological space is always a topological space. But, is the orbit space of a smooth manifold always a smooth manifold? No, we saw that in the examples with the cone, but the orbit space of a smooth manifold is always an orbifold!\nWhat is an orbifold? We have already made an intuitive definition, along the lines of the intuitive definition of a manifold. But, as all who have done manifold theory properly, there are some small details needed to make the intuitive definition precise, like charts and atlases. The same holds for orbifolds.\nDefinition (Smooth orbifold): A smooth orbifold $\\mathcal{O}$ is a Hausdorff topological space $X_{\\mathcal{O}}$ together with a covering ${U_k}$ such that for any element $U_i$ in the cover, there is a diffeomorphism $\\phi_i: U_i \\rightarrow V_i/\\Gamma_i$, where $V_i$ is a subset of $\\mathbb{R}^n$ and $\\Gamma_i$ is a finite group acting on $V_i$. Also, for any $U_j \\subset U_i$ there is an embedding $\\phi_{ji}: V_j \\rightarrow V_i$ and an injective group homomorphism $f_{ji}:U_j\\rightarrow U_i$, such that for any $\\gamma \\in \\Gamma_i$ we have $\\phi_{ji}(\\gamma x) = f_{ji}(\\gamma)\\phi_{ji}(x)$, and such that the following diagram commutes\nOk, that definition is a mouthful and a half, but it is just as precise as it needs to be to give us how we intuitively think about the informal definition we gave earlier. The covering makes sure that all points on the underlying topological space is part of one of these sets that look like a quotient, and the whole subset business makes sure that “zooming” in, or looking a bit closer around a point, does not reveal something wildly different.\nA nice class of examples comes from something similar to the two motivational examples we saw earlier, namely global quotients. The space we are taking the quotient of does not have to be the Euclidean plane, or even a Euclidean space, but can be any smooth manifold. Let\u0026rsquo;s formalize this class of examples by a lemma.\nLemma: Let $\\mathcal{M}$ be a smooth manifold and $G$ a group acting properly discontinuously on $\\mathcal{M}$. Then their quotient $\\mathcal{M}/G$ is a smooth orbifold.\nIt is important to note that not all orbifolds arise as such quotients of smooth manifolds. But these are nice for intuition, and make some nice examples, such as the example from the beginning, namely the pillow case. Take the smooth manifold $\\mathcal{M}$ to be the torus. Let this torus be constructed from rotating a circle of radius 1 around the origin in $\\mathbb{R}^3$, with the axis of rotation being the $z$-axis.\nIf we act on the torus by rotating $\\pi$ radians around the $y$-axis, we get a symmetry transformation, or equivalently a $\\mathbb{Z}_2$-action.\nIf we then take the quotient by this action, i.e. $\\mathcal{M}/ \\mathbb{Z}_2$, we get our wanted pillowcase. How can we see this? If we poke a stick into the torus, in the direction of the $y$-axis, we see that it penetrates the torus at four points. When we take the quotient, it is roughly the same as folding the torus in two, with the fold being around the stick.\nThe important bit here is that it is not just a fold, but a kind of merger after folding. The result looks something like this.\nWhich we can see, after a bit of delicious topological deformation, is the pillowcase we were after.\nAnother way of viewing it is to look first at only the points not in the $yz$-plane. After taking the quotient, we see that all the points not in the $yz$-plane form a cylinder. At the edges of this cylinder are the points that were on the $yz$-plane. These points formed two circles on the torus. The orbits of the points on these circles are just two points symmetrically above the $y$-axis, except at the four points that lie exactly on the $y$-axis. These four points are their own orbits, which means that the orbit space of the two circles is diffeomorphic to two disjoint lines. These two lines are then gluing shut the cylinder of all the other points. The following drawing is not at all mathematically precise, but it kind of illustrates the process I’m describing.\nThere are more than one way of constructing the pillowcase as a smooth orbifold, but I though this one made everything quite clear. It is also a relatively easy, but not too easy example of a smooth orbifold. There is many more examples that are worth looking into, and maybe I will some time, but for now I think this post is long enough.\nMotivation for further reading The theory around orbifolds seem to be very rich and interesting. The definitions I mentioned earlier, i.e. étale Lie groupoids and Deligne-Mumford stacks are objects that require some more deep insight then I have currently, but maybe they are cool to look at in the future some time. There is also a whole theory of algebraic topology, homotopy theory and differential geometry developed for orbifolds (both from the classical definition we have discussed here and from the fancy new definitions). To have such a theories one needs special definitions for orbifold coverings, orbifold fundamental groups and more generally orbifold homotopy groups, tangent orbibundles or more general orbibundles, orbifold Euler characteristics and many more. It may be fun to try to go through some of these in the future as well.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/orbifolds/","summary":"For quite some time I have occasionally stumbled onto the Wikipedia page for orbifolds while looking at topology related mathematics. I have always been fascinated by them, and always though that they certainly will come up during studies at university, but they never have (at least not yet). On said wikipedia page it says that the word orbifold is short for “orbit manifold” and that these orbifolds are in fact a generalization of manifolds.","title":"Orbifolds"},{"content":"This summer I’m participating in Ravi Vakils pseudocourse on algebraic geometry, AGITTOC. Hence this summer serves as a wonderful opportunity to learn and write about cool mathematics. For long I have wanted to dive deeper into this abstract topic after just dipping my toes in during my bachelor thesis, and now it is time. Ravi though us in the first lecture that we shouldn’t study abstract objects without a cause, i.e. we need to ask ourselves why we want to learn about the objects, or the mathematics that lies ahead. I want to study algebraic geometry because I really like algebraic topology, and a lot of the concepts and notions of algebraic topology are abstracted in algebraic geometry, and several concepts gets a new viewpoint or gets some new tools to use to study them. I thought I would start off by discussing one of the fundamental objects of study in algebraic geometry, namely sheaves. These objects abstract, concretize and formalize several other mathematical notions, some of which we already know. One of these in particular is sheaf cohomology which can be viewed to generalize both singular, deRham and Cech cohomology. We are going to look into this cohomology theory in a later post.\nWhen studying topology, it becomes clear pretty early that local information sewn together is often more interesting than global information. Manifolds are more interesting than Euclidean space, local sections of a vector bundle are more interesting global sections and fiber bundles are more interesting than the Cartesian product of spaces. By “more interesting” I mean more complicated, less restrictive and a more “rich” theory. Sheaves are a very good way of describing such types of local information and how this information relates to the local information elsewhere and the global information. They do not inherently describe spaces parameterized by other spaces like the vector and fiber bundles, but instead abstracts and concretizes the study of functions on a space.\nPre sheaves The main meat of the definition of a sheaf is formalized in the notion of a pre-sheaf. A pre-sheaf concerns the local information on a space we talked about previously, and how the information relate to information even more locally. Sheaves will then incorporate two additional descriptions about how the information related across local areas, and how we can glue local information together, but more on that a bit later.\nBefore we get to the proper definition, we consider an example, or a kind of motivating story. Many of the sheaves and pre-sheaves we will care about in algebraic geometry will be about functions on spaces as mentioned in the introduction. Thus this will be our motivating example. We consider continuous real-valued functions on some subset of the real line. Let $U\\subset \\mathbb{R}$ and $C(U)$ be the set of continuous functions on $U$. Since they take value in the real numbers we can express these functions by their graphs in the real plane. Let $f \\in C(U)$, for example the following graph.\nIf we restrict $f$ to a smaller subset $V\\subset U$ it is still a continuous function on that subset, i.e. $f_{|V}\\in C(V)$.\nBut, if we have a non-continuous function on U, this function could still be continuous on V\\subset U, i.e. $f\\notin C(U) \\nRightarrow f\\notin C(V)$. We can see this by the following picture.\nSince together with the above property, non-continuous functions on $V$ are also non-continuous on $U$ we get a well defined restriction map $(-)_ {|V}: C(U) \\rightarrow C(V)$. If we restrict to the same subset $U\\subset U$ we see that the restriction map $(-)_{|U}$ is actually the identity map $id_U$. If we instead continue this process one more time, i.e. with a set $W\\subset V\\subset U$, then we would get restriction maps $C(U)\\rightarrow C(V) \\rightarrow C(W)$. If we have a continuous function on $U$, say f, then we know $(f_{|V})_ {|W} = f_{|W}$, and hence we know that the following triangle commutes\nThese are actually all the properties we want to mimic when defining a pre-sheaf. So when you now read the definition, you have a concrete example in your intuition-bank! Since we said that pre-sheaves abstract the notion of functions on a space, we could form an intuitive definition of a pre-sheaf to be sets of elements associated to a topological space that behave similarly to the sets of continuous functions on the space. This is actually not very far from the precise definition which we now finally have arrived at.\nDefinition (pre-sheaf): Let $X$ be a topological space, and $\\mathscr{C}$ some category. A $\\mathscr{C}$-valued pre-sheaf $\\mathcal{F}$ on $X$ is an assignment of an object $A$ in $\\mathscr{C}$ to every open subset $U\\subset X$, i.e. $\\mathcal{F}(U) = A \\in \\mathscr{C}$, such that for every inclusion $V \\hookrightarrow U$ there is a morphism $res_{V\\subset U}: \\mathcal{F}(U)\\rightarrow \\mathcal{F}(V)$, called the restriction, satisfying the following two axioms.\n The restriction $res_{U\\subset U} = id_U$ If we have subsets $W\\subset V\\subset U$, then $res_{W\\subset V} \\circ res_{V\\subset U} = res_{W\\subset U}$, i.e. a commutative diagram  The sets $\\mathcal{F}(U)$ are called the sections of $\\mathcal{F}$ over $U$.\nThis construction looks and feels very functorial in nature, but how can we discuss $\\mathcal{F}$ as a functor if our domain is just a topological space? Well, it turns out that every topological space has the structure of a category in exactly the way we need. Recall that a topological space is a set $X$ together with a topology $T$ on $X$. This topology determines which subsets we decide to be open in $X$. We let these open sets be the objects of our category. For the morphisms, we let there be a single arrow $V\\rightarrow U$ between two open sets, if and only if $V\\subset U$. We then automatically have an identity morphism for every object, and composition is well defined and is associative. We call this category $O(X)$, for the category of open sets on $X$.\nWe can then equivalently define a $\\mathscr{C}$-valued pre-sheaf on a topological space $X$ to be a contravariant functor $\\mathcal{F}:O(X)\\rightarrow \\mathscr{C}$. Usually $\\mathscr{C}$ will be the category of sets, the category of Abelian groups, the category of rings or the category of modules over a ring. When we have these more specific categories, we call a pre-sheaf for example a pre-sheaf of Abelian groups on $X$, instead of an $Ab$-valued pre-sheaf. The same goes for case with rings and modules. Pre-sheaves, and sheaves of rings will be especially important when we later are going to study schemes.\nSheaves As said earlier, sheaves are like pre-sheaves that incorporate two additional descriptions about how information relates across local areas, and how we can glue local information together. To motivate these additional axioms, we again use the motivating example that we used before the definition of a pre-scheme, namely the continuous functions on a subset $U$ of the real line $\\mathbb{R}$.\nIf we have an open cover ${U_i}$ of $U$ we want to study how functions on each of the sets in the cover can give us information about functions on the whole of $U$, and how restricting the functions can tell us information about the function globally. Let $f, g \\in C(U)$ such that their restriction to the sets in the cover are equal, i.e. $f_{|U_i} = g_{U_i}$ for all sets $U_i$ in the cover.\nThen we can see that the functions must be equal on the entire set $U$, i.e. if $f_{|U_i} = g_{U_i}$ for all $U_i$, then $f=g$ on $U$. This property, that the function is determined by it’s restrictions to an open cover, is called the uniqueness axiom and will be one of the extra features of a sheaf. What about the other direction? If we have a function on every set in the cover that agrees on their overlaps, do we then have a function on the entire set? For these continuous functions the answer is yes.\nIf we just put all the functions together, we still get a continuous function. The key piece for this working is that the functions agree on the overlaps, i.e. they are equal on every intersection. More formally, if we have functions ${f_i}$ on the $U_i$‘s such that $(f_i){|U_i , \\cap U_j} = (f_j){|U_i, \\cap U_j}$ for all $i$ and $j$, then there is a continuous function $f$ on $U$ such that $f_{|U_i} = f_i$. This property, that we can put together functions defined locally to form functions globally, is called the glueability axiom, and will be the second extra feature of a sheaf.\nIn the definition of a pre-sheaf, we could be very general, and allow values in every category $\\mathscr{C}$. As we have seen in the example of the two extra axioms above, it looks almost unavoidable to actually use elements to talk about the axioms, and hence we need to have that $\\mathscr{C}$ is a concrete category, i.e. a category in which the objects consists of elements. It is possible to do this more generally without discussing elements, but I don’t quite understand it yet. The categories we are interested in are all concrete anyway, and I find the definition using elements to be more intuitive, and more in sync with the motivating intuition-building example we just gave. Hence this is the definition we focus on.\nDefinition (sheaf): Let $X$ be a topological space. A $\\mathscr{C}$-valued sheaf $\\mathcal{F}$ of $X$ is a $\\mathscr{C}$-valued pre-sheaf such that the two additional following axioms hold:\n  (Uniqueness). Let ${U_i}$ be an open cover of $U$ and $f,g \\in \\mathcal{F}(U)$. If $res_{U_i , \\subset U}(f) = res_{U_i , \\subset U}(g)$ for all $U_i$ in the cover, then $f=g$. The application of the restriction morphism $res_{V \\subset U}$ to the element f is often instead written as $f_{|V}$ to be more familiar. In that notation, we have if $f_{|U_i} = g_{|U_i}$ for all $U_i$ in the cover, then $f=g$.\n  (Glueability). Let ${U_i}$ be an open cover of $U$ and $f_i \\in \\mathcal{F}(U_i)$ such that $res_{U_i ,\\cap U_j\\subset U_i}(f_i) = res_{U_i ,\\cap U_j \\subset U_j}(f_j)$ for all of the functions $f_i$ and all of the open sets $U_i$ in the cover. Then there exists an element $f\\in \\mathcal{F}(U)$ such that $res_{U_i , \\subset U}(f)=f_i$ for all functions $f_i$ and open sets $U_i$ in the covering. In the alternative notation, we have that if $(f_i)_{|U_i\\cap U_j} = (f_j)_{|U_i\\cap U_j}$ for all of the functions and all sets in the cover, then there exists a function $f\\in \\mathcal{F}(U)$ such that $f_{|U_i} = f_i$.\nHere we quite clearly see the two extra properties we discussed above in the motivating example. We also see that sheaves exactly capture the information needed to move between local information and global information. We can also see that we can actually define a sheaf to be a pre-sheaf with only one extra axiom, namely unique glueability. Here we only use the last of the two axioms, i.e. glueability, but require the existence of a unique map on $U$ instead of just some map. As with the pre-sheaves, the usual categories we use are sets, Abelian groups, rings and modules. The same naming conventions apply for sheaves, so an $R$-mod-valued sheaf on $X$ will instead be called a sheaf of $R$-modules on $X$.\n  Next time we will study more examples of sheaves to build our intuition about them. Then we will study an alternative way of viewing sheaves, through étale spaces, or in proper french fashion, espace étale. This will require us to look at germs, stalks and sheafification which will be fun!\n","permalink":"https://torgeiraamboe.github.io/posts/2020/sheaves/","summary":"This summer I’m participating in Ravi Vakils pseudocourse on algebraic geometry, AGITTOC. Hence this summer serves as a wonderful opportunity to learn and write about cool mathematics. For long I have wanted to dive deeper into this abstract topic after just dipping my toes in during my bachelor thesis, and now it is time. Ravi though us in the first lecture that we shouldn’t study abstract objects without a cause, i.","title":"Sheaves"},{"content":"A part of mathematics I really an starting to enjoy more is mathematics that explain or develop connections between geometry or topology, and algebra. The first two posts on this blog was focused on developing some geometrical insight to two lemmas from commutative algebra, namely Noether’s normalization lemma and Zariski’s lemma. There are many more such connections worth discussing and exploring, and today I want to focus on one of these “bridges” between geometry and algebra, namely Swan’s theorem. This theorem tells us how nice objects “over” another object in geometry relate to nice objects “over” another object in algebra.\nBefore we reveal the connection we are discussing, we go through some preliminaries for stating the theorem precisely. In the informal statement above the object in geometry will be a compact Hausdorff space, and nice objects over it will be vector bundles, while the object in algebra will be a ring and objects over it will be projective modules. I will assume knowledge about rings and point-set topology, but we will develop the notion of projective modules and vector bundles to get a sense of how they are similar and relate to each other.\nVector bundles In the fibration series we have developed the notion of a fiber bundle, and a vector bundle will be such an object such that all of the fibers are vector spaced instead of arbitrary topological spaces. We developed an intuition that bundles over a space is a map that is locally a projection, and the space above it consists of similar fibers glued together possibly non-trivially.\nDefinition (vector bundle): Let $X$ be a topological space. A real vector bundle $(E,p)$ over $X$ is a space $E$, called the total space, together with a map $p:E\\rightarrow X$ such that for any point $x\\in X$, $p^{-1}(x)$ has the structure of a finite dimensional real vector space. In addition we need the bundle to satisfy the local trivialization condition, which says that for every point $y\\in X$ there is: an open neighborhood $U\\subset X$ containing $y$; a natural number $n$; a homeomorphism $\\phi : U\\times \\mathbb{R}^n \\rightarrow p^{-1}(U)$, such that for any point $x\\in U$ we have $p\\circ \\phi (x, v) = x$ for all $v\\in \\mathbb{R}^n$ and that the map $v\\mapsto \\phi(x,v)$ is a vector space isomorphism.\nThe topological space $X$ in the context of a vector bundle is referred to as the base space. If we can choose $U=X$ in the local trivialization, i.e. a global trivialization, we call $(E,p)$ a trivial bundle because we have $E\\cong X\\times \\mathbb{R}^n$ for some $n$. An example would be the trivial one dimensional real vector bundle over the circle, which would be an infinitely tall cylinder, or if we draw the real line as a finite line segment just a normal cylinder.\nAn important question when studying objects over another object, i.e. some sort of system $p:E\\rightarrow B$ where $p$ is at least surjective, is the question of when do we have an inverse map, or even more generally a one sided inverse. If we have a vector bundle $p:E\\rightarrow B$, we define a section of the bundle to be a continuous map $s:B\\rightarrow E$ such that $p\\circ s = id_B$. Such a map always exists when we are discussing vector bundles since we can send a point on the base space to the zero-vector in the vector space that is the fiber over it. This is called the zero section. If our vector bundle is the tangent bundle, then a section is just a vector field on the base space. A graphic example is an embedding of the circle into the trivial bundle we discussed previously.\nThese maps will be important for proving the theorem as they will function as the way we define the algebraic information by the topological information. Note that there exists a notion of local sections which are exactly the same but is a one sided inverse only on an open neighborhood $U$ instead of on the whole space $X$. Hence sections are also called global seqtions.\nThe last piece we need about vector bundles are maps between them. If we have two vector bundles $(E,p)$ and $(F,q)$ over the same base space $X$ then a map between them $\\tau: (E,p)\\rightarrow (F,q)$ is a map $\\tau: E\\rightarrow F$ such that the following triangle commutes.\nProjective modules The other nice object over another one which will be important for stating the theorem is a projective module over a ring. Recall that a module is an Abelian group together with an action from a ring often called the scalar product. A projective module is characterized by a certain lifting property.\nDefinition (projective module): Let $R$ be a ring. An $R$-module $P$ is called projective if for every surjective module homomorphism $f: N\\rightarrow M$ and every module homomorphism $g:P\\rightarrow M$ there exists a lift $h:N\\rightarrow P$ such that $g\\circ h = f$, i.e. the following diagram commutes.\nNotice that we don’t require the lift to be unique, and hence the lifting property is not a universal property. Recall that maps between modules are maps that respect both the additive group structure and the scalar product from the ring.\nAn example of projective modules are free modules. These modules behave very similar to vector spaces since they always have a basis which makes maps between them describable by matrices. Recall that if a module is generated by a finite set of elements, called its generators, then we call the module finitely generated. In fact projective modules and free modules have a lot in common. By using some commutative algebra one can show that all projective modules are locally free, meaning there exists a cover of ideals such that localization at every ideal in the cover is a free module. We can also define a projective module by being a summand of a free module. This is because there always exists a surjective module morphism from a free module $R^n$ onto any finitely generated module $M$, and by the lifting property the sequence $0\\rightarrow ker(f)\\rightarrow R^n \\rightarrow M\\rightarrow 0$ splits, and hence $R^n\\cong M\\bigoplus ker(F)$, i.e. $M$ is a direct summand of a free module.\nRight away, even before discussing the statement of the theorem we can notice that projective modules are locally free modules, and that vector bundles are locally trivial bundles. Since free modules behave very similarly to vector spaces, this hints at a connection between the two notions.\nSwan\u0026rsquo;s theorem So, we have now defined the objects needed to formulate the theorem. As stated in the introduction, the theorem will relate the objects discussed to each other. To understand how this relation occurs we need a good way of translating topological or geometric objects to algebraic objects, and the way we are going to do that in this theorem is through functions on the objects. If we take some nice topological space we can study the set of continuous real-valued functions on that topological space. Since the codomain, $\\mathbb{R}$, is a ring, we can define addition and multiplication of these continuous functions by the addition and multiplication of the real numbers that elements of the topological space map to, i.e. define the operations pointwise. Hence for a nice topological space $X$ we always have a corresponding ring, $C(X)$ of real-valued continuous functions on $X$. This is the correspondence that Swan’s theorem focuses on. The theorem tells us that nice geometric objects over nice topological spaces are the same as nice projective objects over the corresponding nice algebraic objects, or more precisely that real vector bundles over a compact Hausdorff space $X$ are the same as finitely generated projective modules over the ring of real-valued continuous functions $C(X)$. The precise formulation for the theorem encapsulates what I mean by “the same as” in a categorical language, but the information is the same.\nTheorem (Swan): The category of real vector bundles over a compact Hausdorff space $X$ is equivalent to the category of finitely generated projective modules over the ring of continuous real functions on $X$.\nJust as a quick disclaimer, I won’t cover the entirety of the proof, but we will look at the important pieces and the general idea. Since we have two categories we want to show are equivalent, we should find a fully faithful, essentially surjective functor , in other words an equivalence of categories, that shows that these categories are the same. Let $Vect(X)$ be the category of vector bundles over $X$ and $pmod(C(X))$ be the category of finitely generated projective modules over $C(X)$. If we let $p\\in Vect(X)$, i.e. $p$ is a vector bundle $E\\overset{p}\\rightarrow X$ then we denote the set of all sections of $p$ by $\\Gamma(p)$. Notice that $s\\in \\Gamma(p)$ is a map $s:X\\rightarrow E$, and since every point in the image lies in a vector space, we can define addition of sections by adding their images pointwise. We can also define scaling of the sections by continuous real-valued functions on $X$ by letting $f\\circ s (x) = f(x)\\cdot s(x)$. This in fact makes $\\Gamma(p)$ into a $C(X)$-module! If we have a map between two vector bundles over $X$, say $\\tau:p\\rightarrow q$ then we can define a map between their $C(X)$-modules of sections by post composition, i.e. sending a section $s\\in \\Gamma(p)$ to $\\tau \\circ s$. This is a section of $q$ because $q\\circ (\\tau \\circ s)=(q\\circ \\tau) \\circ s = p \\circ s = id_X$. These two together form a functor $\\Gamma : Vect(X)\\rightarrow mod(C(X))$ sending a vector bundle p to its $C(X)$-module of sections $\\Gamma(p)$ and a vector bundle map $\\tau$ to the $C(X)$–module map $\\Gamma(\\tau)=\\tau\\circ (-)$.\nTo see that this is in fact a functor only to projective finitely generated $C(X)$-modules we first note that trivial vector bundles, i.e. bundles of the form $X\\times \\mathbb{R}^n \\overset{p}\\rightarrow X$, correspond to free $C(X)$-modules under the defined functor $\\Gamma$. This is because a trivial vector bundle has a finite global basis, i.e. a finite set of sections of which the image of each point in $X$ is a basis for $p^{-1}(x)$, which determines a free basis for the module of sections. The next step is then to prove that every vector bundle is a direct summand of a trivial vector bundle. This only holds for vector bundles over compact Hausdorff spaces, hence the assumption in the theorem. This can be shown through the existence of an inner product on the vector bundle if the base space is paracompact Hausdorff, and hence allowing us to form inner orthogonal complement bundles, i.e. for any subbundle of the original bundle a vector bundle such that their direct sum bundle is the original bundle. If our base space is compact we can do this for every set in a finite trivialization and glue them together by partitions of unity. Our functor, i.e. taking the module of sections does in fact preserve direct sums, hence every $C(X)$-module is a direct summand of a free module, which we saw earlier is the same as being a projective module. Hence, every finite dimensional real vector bundle over $X$ in fact maps to a projective $C(X)$-module. The remaining part is to show that every $C(X)$-module homomorphism between projective modules actually comes from a unique map of vector bundles, i.e. that for every map $F:P\\rightarrow Q$ of projective modules there is a unique map $f:p\\rightarrow q$ between two vector bundles over $X$ such that $\\Gamma(f)=F$. This is a bit tricky to show, but comes mainly from the fact that any compact Hausdorff space is normal, and that we can extend local sections to global on normal spaces.\nThis is as far as I’ll go into the proof, but we have at least covered the basic elements. The whole proof revolves exactly around showing that the functor $\\Gamma$ is an equivalence of categories.\nClosing remarks There are a couple facts that should be mentioned when discussing this theorem. First, the theorem also hold if we instead of real vector bundles use complex vector bundles, and complex-valued continuous functions instead of real-valued ones. It does not however work if we use totally disconnected fields, like the rational numbers $\\mathbb{Q}$. Secondly, if we replace every “continuous” by “smooth”, i.e. try to have a version in differential geometry then the theorem still holds. This means replacing our topological space by a smooth manifold, the vector bundle by a smooth vector bundle, continuous functions by smooth functions and sections by smooth sections. Thirdly, there is an earlier version of the theorem in algebraic geometry instead of algebraic topology due to Serre, so the theorem is often named the Serre-Swan theorem. Serre proved that finite dimensional vector bundles over algebraic varieties are also the same as finitely generated projective modules over the similar ring of continuous functions in algebraic geometry. I am following Ravi Vakils summer course on algebraic geometry, so maybe I will cover that version of the theorem after learning some more algebraic geometry.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/swans-theorem/","summary":"A part of mathematics I really an starting to enjoy more is mathematics that explain or develop connections between geometry or topology, and algebra. The first two posts on this blog was focused on developing some geometrical insight to two lemmas from commutative algebra, namely Noether’s normalization lemma and Zariski’s lemma. There are many more such connections worth discussing and exploring, and today I want to focus on one of these “bridges” between geometry and algebra, namely Swan’s theorem.","title":"Swans Theorem"},{"content":"This is part 9 of a series leading up to and exploring model categories. For the other parts see 1, 2, 3, 4, 5 6, 7 and 8.\nLast time we ended by giving a definition of a homotopy between maps on the collection of bifibrant objects in a model category. Today we are going to expand further upon this idea, and try to build the theory we are familiar with for topological spaces but in the general setting. The goal is to have a well defined workable notion of a homotopy category, and understand what it consists of.\nMotivation In topological spaces, there are two ways to make a homotopy category. The first one is called the naive homotopy category and is made by having the same objects, i.e. all topological spaces, but instead of all maps we have homotopy classes of maps. As the name implies, the resulting category isn’t very well behaved in the way we want it to. Quillen introduced a better definition which is made through localization. Localization is defined by formally inverting a class of maps such that they become isomorphisms. The resulting category after localizing at the class of weak homotopy equivalences is called the Quillen homotopy category of topological spaces, or just the homotopy category. When actually working with the naive homotopy category, there are some alterations we can do to make the situation better. If we encounter a bad object that does not play nice, we replace it by a CW-approximation via a weak homotopy equivalence, which by the CW-approximation theorem always exists. There is also a famous theorem by Whitehead, called naturally the Whitehead theorem, which states that “two CW-complexes are weakly homotopy equivalent if and only if they are homotopy equivalent”. Hence, when we take homotopy classes of maps, every weak homotopy equivalence between CW-complexes will end up in the same equivalence class as an isomorphism, which makes weakly homotopy equivalent spaces isomorphic. Now we have two categories that are very similar, and these will be our motivation throughout.\nThe homotopy categegory Before we do anything else we define the homotopy category of a model category in the general setting, not just for topological spaces.\nDefinition (homotopy category): The homotopy category of a model category $\\mathscr{C}$ is defined to be the Quillen homotopy category of $\\mathscr{C}$, i.e. $Ho(\\mathscr{C})= W^{-1}\\mathscr{C}$ where $W$ is the collection of weak equivalences in the model structure.\nThis definition does not give us much in terms of workability. Even though we called it naive, we really like homotopy classes of maps, and this definition of a homotopy category does not reflect the definition we gave of homotopy at all. As we see, the homotopy category is purely dependent on the class of weak equivalences and doesn’t on the surface have anything to do with homotopy. But, as we will see soon, homotopy classes of maps do play a role here, but we got to do some work to show it.\nAs said earlier, we left of with the definition of homotopy in a model category. To mimic topological spaces we need this definition of homotopy to satisfy some properties, at least working nice with composition, having a notion of homotopy equivalence between objects and hopefully have some abstracted version of the Whitehead theorem to tell us we are one the right track. We didn’t show that left and right homotopies work nicely with composition, but I don’t think it is that hard to imagine, hence we leave it out to focus on the more important bits.\nDefinition (homotopy equivalence): We say two bifibrant spaces $X$ and $Y$ are homotopy equivalent if there exists morphisms $f:X\\rightarrow Y$ and $g:Y\\rightarrow X$ such that $g\\circ f \\sim id_X$ and $f\\circ g \\sim id_Y$.\nIn the Serre model structure on topological spaces the cofibrant objects are exactly the CW-complexes, and any object is fibrant. Hence, we can reformulate the Whitehead theorem as “two bifibrant objects are weakly homotopy equivalent if and only if they are homotopy equivalent”. This is starting to look like a general theorem that tells us that a nice definition of homotopy which leads to a nice notion of homotopy equivalence will in fact coincide with the pre-chosen class of weak equivalences when restricted to the class of “homotopy-nice” objects. This is the theorem that tells us we are on the right track towards a workable version of the naive homotopy category, because when we localize at the weak equivalences in the Quillen homotopy category, the homotopy equivalent objects will turn into isomorphic objects.\nThe generalized Whitehead theorem: Any two bifibrant objects in a model category $\\mathscr{C}$ are weakly equivalent if and only if they are homotopy equivalent.\nNow we are getting somewhere! Localizing at the weak equivalences also turns homotopy equivalences of bifibrant objects into isomorphisms! We are getting closer to a workable nice category. Now we have a subcategory of bifibrant objects, which we denote $\\mathscr{C}_ {b}$ or more standard $\\mathscr{C}_{cf}$, with a notion of homotopy being an equivalence relation, denoted $\\sim$. Hence we can form its naive homotopy category $\\mathscr{C}_b\\rightarrow \\mathscr{C}_b/\\sim$. By the generalized Whitehead theorem the map sends weak equivalences to isomorphisms, and hence it has to factor through its Quillen homotopy category $Ho(\\mathscr{C}_b)$. We also have an inclusion $\\mathscr{C}_b \\rightarrow \\mathscr{C}$ which induces a map on their Quillen homotopy categories, i.e. $Ho(\\mathscr{C}_b)\\rightarrow Ho(\\mathscr{C})$. The final piece of the puzzle of having a workable homotopy category will come from the fact that those maps form an equivalence of categories $Ho(\\mathscr{C})\\cong \\mathscr{C}_b/\\sim$, which means we have both a nice definition, and a nice way to work with it. I must admit I don’t fully understand the proof yet, hence I leave it out for now, but I will hopefully post an update with just this proof in the future.\nThis final theorem also means that we have isomorphisms\nwhere $A^{cf}$ means we have taken both a cofibrant followed by a fibrant replacement of $X$. I include this as a picture since this article had none, and I need a coverphoto… Also pictures are more fun.\nThe reader might be confused as to why the naive homotopy category of topological spaces exists, and why we don’t really need to pass down to only CW complexes. Recall that in the Strøm model structure on the category of topological spaces, all objects are both fibrant and cofibrant, hence localization at the homotopy equivalences results in the same category as just taking homotopy classes of maps. Hence, the naive homotopy category is the Quillen homotopy category of topological spaces with the Strøm model structure, while the “true” homotopy category is the Quillen homotopy category of topological spaces with the Serre model structure. This shows in my opinion that the Serre model structure is a bit nicer, but also more restrictive.\nDerived categories The algebraically inclined reader familiar with homological algebra will recognize the definition of the Quillen homotopy category as very similar to the derived category of a ring, or in general the derived category of an abelian category. As mentioned in part 7, an example of a model category is the category of chain complexes of modules over some ring, and localizing this category at its weak equivalences, namely the quasi isomorphisms gives the derived category of the ring, i.e. $D(R)=Q^{-1}C(ModR)$ where $Q$ is the class of quasi isomorphisms. Usually the reason for introducing the derived category in homological algebra is that working with chain homotopy classes of maps in chain complexes does not work nicely with the triangulated structure that naturally arises. In particular, a short exact sequence in the category of chain complexes may not be a distinguished triangle in the “homotopy category”. By homotopy category I here mean the category of chain complexes of modules over a ring with maps being chain homotopy classes of chain maps. This should rather be called the naive homotopy category, since it is exactly the same construction that we did for topological spaces. Passing to the derived category rectifies this, since every exact sequence gives a distinguished triangle. We will probably explore triangulated categories more in the fall, as I am going to follow a course focusing on them.\nIn the model structure on chain complexes of modules over a ring, the injective and projective resolutions are the fibrant and cofibrant replacements. We have showed that homotopy classes of maps between bifibrant objects gives an equivalent naive homotopy category to the Quillen homotopy category of the entire category, hence if we take an Abelian category with enough projectives and enough injectives, all objects have nice replacements that we can work with, and if we restrict ourselves to just these projective and injective chain complexes we have an equivalent category to the derived category that is more workable.\nNext time we will study functors between model categories, and what it means to preserve the model structure. We will also study what type of functor we need to make sure that both model categories have an equivalent homotopy category. As a teaser, derived functors will be an example of functors between model categories.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/the-homotopy-category/","summary":"This is part 9 of a series leading up to and exploring model categories. For the other parts see 1, 2, 3, 4, 5 6, 7 and 8.\nLast time we ended by giving a definition of a homotopy between maps on the collection of bifibrant objects in a model category. Today we are going to expand further upon this idea, and try to build the theory we are familiar with for topological spaces but in the general setting.","title":"The homotopy category"},{"content":"This is part 8 of a series leading up to and exploring model categories. For the other parts see 1, 2, 3, 4, 5 6, 7 and 9.\nLast time we finally defined the model category, gave some examples and tried (kind of) to give a motivation to why they are interesting and how they set the stage for homotopy theory. The first time I read the definition I was a bit confused about the lack of mention of homotopy, or at least some prototype of it that I could connect with. This structure on a category is supposed to embody where homotopy theory works, but failed to immediately convey that to me. But, that said, we will today go through the construction of homotopy, and prove that it is an equivalence relation on maps in nice cases. These cases we mentioned in the previous part, and will be maps between objects that are both fibrant and cofibrant, which I will refer to as bifibrant.\nAbstract homotopies We know from topology that homotopy requires some sort of interval or paths, and the abstract definition will in a way reflect that. What we are going to construct are so called cylinder objects, that imitates taking the product with the interval in regular topological homotopy. Dualy, we are going to define path objects, which will mimic the path space in topology. These two will respectively define left and right homotopies, which will be equivalence classes only on fibrant and cofibrant objects respectively. These two notions of homotopy will coincide and give the same equivalence relation on bifibrant objects. Note that in the definition we are using products $\\prod$ and coproducts $\\coprod$. Since we work in a model category these always exists because the product is a special case of a limit, and the coproduct is a special case of a colimit, which both exists because a model category is bicomplete.\nDefinition (cylinder object): Given an object $X$ in a model category $C$ we define the cylinder object of $X$, denoted $Cyl(X)$ to be factorization of the codiagonal map $X \\coprod X \\rightarrow X$ into $X \\coprod X \\overset{i_1+i_2} \\rightarrow Cyl(X) \\overset{p} \\rightarrow X$, where $p$ is a weak equivalence. If $X\\coprod X\\overset{i_1 + i_2}\\rightarrow Cyl(X)$ is a cofibration, we call $Cyl(X)$ a good cylinder object, and if in addition $p$ is an acyclic fibration, we call $Cyl(X)$ a very good cylinder object.\nDefinition (path object): Given an object $X$ in a model category $C$ we define the path object of $X$, denoted $Path(X)$ to be factorization of the diagonal map $X \\rightarrow X\\prod X$ into $X \\overset{i}\\rightarrow Path(X) \\overset{(p_1,p_2)}\\rightarrow X \\prod X$, where $i$ is a weak equivalence. Similarily to the cylinder object, if $Path(X)\\overset{p}\\rightarrow X\\prod X$ is a fibration, we call $Path(X)$ a good path object, and if in addition i is an acyclic cobration, we call $Path(X)$ a very good path object.\nBy the factorization axiom for model categories (MC4) every object has at least one very good cylinder object and one very good path object. It can be useful to use these in some cases, but in other cases we can actually be interested in cylinder and path objects that aren’t necessarily good, or very good. For example, in the Serre model structure on topological spaces, the standard cylinder object $Cyl(X)=X\\times I$ is only good when $X$ is a CW-complex.\nWe now have objects that behave in some of the same ways as the objects used to define homotopy of topological spaces. In topological spaces, the cylinder object is as mentioned the product with the unit interval. When we then define a topological homotopy from this cylinder, we require that the homotopy restricts to the maps we are constructing a homotopy between on each end of the cylinder, and this will be what motivates how we define it in the general setting as well.\nDefinition (left homotopy): Given two maps $f,g: X\\rightarrow Y$ we define a left homotopy $h:f\\sim_L g$ from $f$ to $g$ to be a map $h: Cyl(X)\\rightarrow Y$ such that the following diagram commutes\nDefinition (right homotopy): Given two maps $f,g: X\\rightarrow Y$ we define a right homotopy $h:f\\sim_R g$ from $f$ to $g$ to be a map $h: X\\rightarrow Path(Y)$ such that the following diagram commutes\nIf the cylinder object used to define the left homotopy is a good cylinder object then we call the homotopy a good left homotopy, and similarly if it is a very good cylinder object we call the homotopy a very good left homotopy. The same goes for the path object used to define the right homotopy, which gives us good right homotopies and very good right homotopies.\nEquivalence relation That homotopy is an equivalence relation is one of the most important and fundamental properties that homotopy has in the category of topological spaces, and hence it should also be important in the general setting. Before we do that, we note that we can upgrade any left homotopy $h$ to a good left homotopy by factoring the map $X\\rightarrow Cyl(X)$ into $X\\rightarrow Cyl(X)' \\overset{\\sigma}\\rightarrow Cyl(X)$ by the fourth axiom for model categories (MC4). Then $h\\circ \\sigma$ will be a good homotopy. If $Y$ is fibrant, then we can upgrade it further to a very good left homotopy by using the other factorization on $Cyl(X)\\rightarrow X$ to get $Cyl(X)\\rightarrow Cyl(X)'\\rightarrow X$. Since we assumed $Y$ was fibrant, we have a commutative diagram\nwhere $T$ is a terminal object. The lift comes from the third axiom for model categories and gives the very good left homotopy we wanted. Ok, so we have the opportunity to choose good left homotopies in general, and very good homotopies for fibrant objects. We will use this to prove the following lemma.\nLemma: Let $X$ be a cofibrant object. Then left homotopy defines an equivalence relation on $Hom(X,Y)$.\nProof: Using $X$ itself as a cylinder object together with the map $f:Cyl(X)=X\\rightarrow Y$ as a left homotopy shows that any map $f:X\\rightarrow Y$ is left homotopic to itself. It is symmetric since we can compose with the swithing map $X\\coprod X \\rightarrow X\\coprod X$ that just switches the components. This gives a homotopy “in the other direction”. Lastly, let $f_1\\sim_L f_2$ and $f_2\\sim_L f_3$ be good homotopies with cylinder objects being $Cyl(X)$ and $Cyl(X)'$ respectively. Then the pushout of the diagram $Cyl(X)' \\leftarrow X \\rightarrow Cyl(X)$ defines a new cylinder object and a homotopy $f_1\\sim f_3$. Hence the relation is reflexive, symmetric and transitive which is the definition of an equivalence relation.\nSomething I have not mentioned yet is that the opposite category of a model category is again a model category. The opposite category has the same weak equivalences, and switches the fibrations and cofibrations. Hence, many proofs in model categories are easier, since we can appeal to duality. For example, since cofibrations are fibrations, fibrant objects are cofibrant and the diagonal is the codiagonal and vice versa in the opposite category, left homotopy is a right homotopy in the opposite category. Hence the same proof as above in the opposite category shows that we can upgrade to a good homotopy and that right homotopy is an equivalence relation on $Hom(X,Y)$ when $Y$ is fibrant. By the way, this duality is the Eckman-Hilton duality in the category of topological spaces, which I referenced in part 3 of the fibration series. Recall that we then switched between loop spaces and suspensions, which are related to these path objects and cylinder objects and hence are dual to each other through the opposite category.\nRelations between the two types of homotopy When I first worked through this I was a bit uneased by the two different notions of homotopy that does not seem to be immediately identifiable with each other. But, when working with topological homotopy there is a good reason as to why we never see the two different concepts, because in both the Serre and the Strøm model structure, all objects are fibrant. Hence, by the next lemma, the existence of right homotopies always implies the existence of left homotopies in the category of topological spaces, hence we don’t ever need to bother with making the distinction.\nLemma: Let $f,g:X\\rightarrow Y$ be two maps. If $X$ is cofibrant and $f,g$ are left homotopic then they are right homotopic. Dually, if $Y$ is fibrant and $f,g$ are right homotopic, then they are left homotopic.\nProof: Choose a good cylinder object $X\\coprod X \\overset{i_1 + i_2}\\rightarrow Cyl(X) \\overset{j}\\rightarrow X$ and let $h:Cyl(X)\\rightarrow Y$ be a left homotopy between $f$ and $g$. Choose also a good path object $Y\\overset{q}\\rightarrow Path(Y) \\overset{(p_1, p_2)}\\rightarrow Y\\prod Y.$ We then have a commutative diagram\nwhich has a lift $\\overline{h}$ by the third axiom of model categories (MC3). Note here that we used the fact that $i_1$ is an acyclic cofibration which we have not proved, but it can be seen by the two out of three property since $X$ is assumed to be cofibrant together with the fact that it is a composition of two cofibrations. The composition $h\\circ i_2:X\\rightarrow Path(X)$ gives a right homotopy between $f$ and $g$ as desired. The dual statement has a dual proof.\nDefinition (homotopy): We say two maps $f,g:X\\rightarrow Y$ are homotopic, denoted $f\\sim g$ if they are both left homotopic and right homotopic.\nIf we then restrict our attention to just the bifibrant objects we have a well defined notion of homotopy that is an equivalence relation for all of the morphisms between the bifibrant objects. This will allow us next time to look at homotopy equivalences of objects, homotopy classes of maps and finally the homotopy category of a model category.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/homotopy-in-model-categories/","summary":"This is part 8 of a series leading up to and exploring model categories. For the other parts see 1, 2, 3, 4, 5 6, 7 and 9.\nLast time we finally defined the model category, gave some examples and tried (kind of) to give a motivation to why they are interesting and how they set the stage for homotopy theory. The first time I read the definition I was a bit confused about the lack of mention of homotopy, or at least some prototype of it that I could connect with.","title":"Homotopy in model categories"},{"content":"This is part 7 of a series leading up to and exploring model categories. For the other parts see 1, 2, 3, 4, 5 6, 8 and 9.\nFinally we have made it to the destination we set, namely, more abstraction. This post is focused on the definition and intuition on model categories, which abstracts the objects we have been studying for some weeks, namely fibrations and cofibrations. The main definition is that of a model structure on a category, which together with a nice category will form the definition of a model category. So, why do we want this? There are more than one reason.\n Homotopy theory is not only useful for topological spaces, and can be done in other settings, for example in chain complexes. Model categories tells us when we have a category that is suitable for homotopy. We often talk about different homology theories or cohomology theories, but can we also have different homotopy theories? When working in some category, we would like to invert a nice class of morphisms, but doing so arbitrarily is not certain to give a nice result. The result will be a zig-zag of morphisms, which we in full generality have no control over. If we invert the nice morphisms in a model category however, we have nice control.  Preliminaries As we can see, a model category is in a way a category such that its homotopy category exists and is well behaved. We will discuss this further and try to make it more precise, but before we state the definition, we need a couple preliminaries.\nDefinition (retraction): A map $f$ is called a retract, or a retraction of a map $g$ if there exists a diagram\nsuch that the horizontal maps compose to the identity map.\nDefinition (bicomplete category): A bicomplete category is a category where all of its small limits and small colimits exists. A small limit is a universal cone over a diagram where the index category is a set. A small colimit is similarly a universal cocone over a diagram where the index category is a set. The important feature for us will be that pullbacks and pushouts exists, and that terminal and initial objects exists. The last two will be explained better later.\nRecall also that a fibration is a map that satisfies the homotopy lifting property, and that a cofibration is a map that satisfies the homotopy extension property. When we explored them earlier, it was in the setting of topological spaces, hence we could use homotopies and intervals and the like in our constructions. When we define a model category soon we can’t rely on topological spaces, since we want to obtain a general theory, not just an axiomatization of the theory of topological homotopy that we already know. But these are classes of maps that we like, and that have nice properties. Hence we want to imitate these properties in the general setting. In the formal definition, there is one more class of maps that we like, and that is called weak equivalences. We haven’t discussed these yet, but they will kind of be the isomorphisms in the homotopy theory. Think about weak homotopy equivalences, which are maps that induce isomorphisms on all homotopy groups, and quasi isomorphisms as the motivating examples.\nModel categories We now have enough backstory and preliminaries to make a precise definition of a model structure on a category. Our goal is to generalize the stage for homotopy theory, but in the definition it will not however be intrinsically clear how we are going to define homotopy, because to be general, there are no reference to a unit interval or something similar. For me it is helpful to think about the motivating example, being the category of topological spaces, when reading the definition.\nDefinition (model structure): A model structure on a category $\\mathscr{C}$ consists of three classes of maps called fibrations, cofibrations and weak equivalences, such that the following axioms hold. To make some of the axioms easier, we call a fibration that is also a weak equivalence an acyclic fibration, and similarly we call a cofibration that is also a weak equivalence an acyclic cofibration.\nMC1: Any retraction of a map in one of the three classes is again in the same class. The classes are called retraction closed.\nMC2: The class of weak equivalences has the “two out of 3” property, i.e. if two out of $f, g, g\\circ f$ is a weak equivalence, then the last of them is also a weak equivalence.\nMC3: If we have a commutative square\nwhere either $i$ is a cofibration and $p$ is an acyclic fibration, or $i$ is an acyclic cofibration and $p$ a fibration, then there exists a map $h: B \\rightarrow X$ making both subdiagrams commute. This is often referred to as fibrations having the right lifting property with respect to acyclic cofibrations, and cofibrations having the left lifting property with respect to acyclic fibrations.\nMC4: Any map $f:X\\rightarrow Y$ has two factorizations $f=p\\circ i$ where $i$ is a cofibration and $p$ is an acyclic fibration, and $f=p\\circ i$ where $p$ is a fibration and $i$ is an acyclic cofibration.\nDefinition (Model category): A model category is a bicomplete category $\\mathscr{C}$ together with a model structure.\nThe definition seems a bit weird, and as mentioned, it has no reference to any homotopy going on, and does not give us anything extra for free. But, as time have shown since the first definition of a model category by Quillen in the 60’s, this is the correct definition. The definition we have given is a bit stricter than the original definition by Quillen, but the one presented here is equivalent to Quillens definition of a closed model category. Also, in the original formulation, the acyclic fibrations and acyclic cofibrations were called trivial fibrations and trivial cofibrations. These have been changed to avoid confusion between another term often referred to as trivial fibrations, namely fibrations where the total space is the product of the base space and the fiber. The name maybe also sound a bit weird, but it is kind of short for “the category of models”, which might make some sense. It consists of the models for where we can do homotopy, and “models” the homotopy category.\nBecause a model category is complete and cocomplete it has an initial object $I$ and a terminal object $T$. These are objects such that there exists an unique morphism out of, and into them respectively. If the unique morphism from an object $X\\rightarrow T$ is a fibration, then $X$ is called fibrant, and if the unique morphism $T\\rightarrow Y$ is a cofibration, then $Y$ is called cofibrant. We are going to define homotopy in a model category next time, but it will turn out that a proper homotopy theory will only work for a subclass of objects in the category, which are the objects that are both fibrant and cofibrant.\nExamples As I mentioned before, the important image to have in your head is the category of topological spaces, and this will also be our first example. This is complete and cocomplete, since the forgetful functor lifts both limits and colimits uniquely from the category of sets. It has more than one model structure, but the most familiar one has Serre fibrations as its fibrations and weak homotopy equivalences as its equivalences. We did not have a similar definition of cofibrations only with respect to CW complexes, so the cofibrations are not the ones we already know unfortunately. The cofibrations in this model structure is best described by being retracts of relative cell complexes, i.e. a retraction of a map $X\\rightarrow Y$ where $Y$ is made from $X$ by attaching cells. Weak homotopy equivalences are the maps we mentioned earlier, that induce isomorphisms on all homotopy groups. This historically was also the motivating example.\nAnother model structure on the category of topological spaces comes from Hurewicz fibrations, closed Hurewicz cofibrations and regular homotopy equivalences as the weak equivalences. This was proven by Arne Strøm, and is called the Strøm model structure on topological spaces. The unique thing about this model structure, that is certainly not the usual situation, is that every object is both fibrant and cofibrant.\nAnother example is the category of chain complexes of modules over some ring. Here the model structure consists of quasi isomorphisms as the weak equivalences, the fibrations are degreewise projections and the cofibrations are degreewise injections with projective cokernel. The homotopy theory in this setting is the same as regular homological algebra.\nThose who know homological algebra will know about projective and injective resolutions. These objects are what is called quasi isomorphic replacements, and this can also be defined in the general setting. Any morphism in the category can be factorized, so if we factorize the unique map into the terminal object $X\\rightarrow T$, into a weak equivalence and a fibration. This will make a space which is weakly equivalent to $X$ and is a fibrant object. This is called a fibrant replacement of $X$. The same can be done with the unique morphism out of the initial object, which will result in a cofibrant replacement. In the example of the category of chain complexes over a ring a projective resolution is an example of a cofibrant replacement, and an injective resolution is an example of a fibrant replacement.\nThe notions of fibrant and cofibrant replacements will be important when we introduce homotopy in a model category and the homotopy category of a model category. There are two ways to do this, and we will explore them both. One comes from constructing homotopy classes of maps, and the other by localization at the weak equivalences. But, we will save this for next time.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/model-categories/","summary":"This is part 7 of a series leading up to and exploring model categories. For the other parts see 1, 2, 3, 4, 5 6, 8 and 9.\nFinally we have made it to the destination we set, namely, more abstraction. This post is focused on the definition and intuition on model categories, which abstracts the objects we have been studying for some weeks, namely fibrations and cofibrations. The main definition is that of a model structure on a category, which together with a nice category will form the definition of a model category.","title":"Model categories"},{"content":"This is part 6 of a series leading up to and exploring model categories. For the other parts see 1, 2, 3, 4, 5 7, 8 and 9.\nThrough the series so far we have covered the basic uses of fibrations and related things, like the long exact sequence of homotopy groups, the Serre spectral sequence, fiber bundles and homotopy groups of spheres. But, we have not mentioned that fibrations has a dual construct, namely cofibrations. The road we are heading with this series, as mentioned before, is to define Model categories, and discover how to use them. Up until now, and including this post, I have been pretty comfortable with the objects of study, and I feel i know them quite well. After this post tho, I think I’m entering unknown territory for me, which is good!\nCofibrations We first defined fibrations through the homotopy lifting property. So if cofibrations are dual to fibrations, there should be a dual notion to homotopy lifting. So, what is the dual to a lift? It is an extension. So, the cofibrations will be defined in terms of the homotopy extension property. Intuitively, we can think of this as “any homotopy defined on a subspace can be extended to the entire space”. This lacks some precision, but is a good intuitive start. Notice also here the use of subspaces. We remarked that fibrations kind of looked like projections, so the dual object should intuitively kind of look like an inclusion. Hence, instead of lifting a homotopy through a projection, we extend a homotopy through an inclusion. This is at least how I think about it. As said, this is not precise, and rigorous mathematics require precise definitions, so we need to give one.\nDefinition (cofibration): A map $f:X\\rightarrow Y$ is called a Hurewicz cofibration if for any space $A$ and every map $g:Y\\rightarrow A$ and homotopy $h: X\\times I \\rightarrow A$ such that $h(-,0)= g\\circ f$, there exists a homotopy $\\overline{h}:Y\\times I\\rightarrow A$ such that $\\overline{h}\\circ (f\\times id_I) = h$. This is better summarized by the following diagram.\nIf the image of $X$ in $Y$ is a closed subspace, we call f a closed Hurewicz cofibration. From now on, if i say cofibration, i will mean closed Hurewicz cofibration.\nUnfortunately, cofibrations don’t have as good of a geometric interpretation that their dual has (at least that i know of). The algebraic duality, and the duality in the definition is clear, but I often thrive of geometric interpretation, which I haven’t yet succeeded in with cofibrations. But, we can ask some of the same questions to try to dually mimic the behavior of fibrations, and the first step is the long exact sequence. We have already seen that extensions are the dual to loop spaces, so if we try to develop a sequence similar to the Puppe sequence we developed in part 3, then we should expect to instead continue towards the right and use iterated suspensions.\nThe coexact Puppe sequence In the case of fibrations we did this by introducing the homotopy fiber, and this time we do the same by introducing the homotopy cofiber. Given a map $f: X\\rightarrow Y$, the homotopy cofiber is often better known as the mapping cone of $f$. The mapping cone $C(f)$ can be thought of as the homotopy version of a quotient space, but more precisely it is defined to be the gluing of $X\\times I$ to $Y$ along the image of $X$ under $f$ modulo the relation $(x,0)\\sim (x',0)$. This is written mathematically as $C(f)= ((X\\times I)\\coprod_f Y) /(x,0)\\sim (x',0)$. Here $(X\\times I)\\coprod_f Y$ means $((X\\times I)\\coprod Y)/(x,1)\\sim f(x)$, i.e. gluing $X$ to its image in $Y$. The whole construction is maybe more visually understandable with the following picture.\nOne important thing for us is that the mapping cone of a closed cofibration is homotopy equivalent to the quotient space $Y/f(X)$. Now, the sequence $X\\rightarrow Y\\rightarrow C(f)$ is a cofiber sequence, or also called a coexact sequence. This is a feature of a sequence that we have not encountered yet. We have a nice notion of when a sequence $A\\rightarrow B\\rightarrow C$ is exact, which is when the kernel of the second map is equal to the image of the first map. A natural question that arises is when does such an exact sequence induce an exact sequence of homotopy classes of maps. If the induced sequence $[-, A]\\rightarrow [-, B] \\rightarrow [-, C]$ is exact, we call the sequence a fiber sequence. If the induced sequence $[A, -]\\leftarrow [B, -] \\leftarrow [C, -]$ is exact, we call it a cofiber sequence, or a coexact sequence. The sequence of functors being exact means it the resulting sequence after evaluating at an object is always exact, i.e. $[A, X]\\leftarrow [B, X] \\leftarrow [C, X]$ exact for all $X$.\nSince the suspension is a functor we get from $X\\rightarrow Y \\rightarrow C(f)$ sequence $\\Sigma X \\rightarrow \\Sigma Y \\rightarrow C(\\Sigma f)$, which turns out is also coexact. We can see this by passing to Hom functors and applying the isomorphism to the adjoint, which is the loop functor. In the picture above, we can see that $Y$ sits nicely inside the mapping cone as a copy. Hence we can include $Y$ into it to joint the two sequences. This inclusion is a cofibration, and hence its mapping cone is homotopy equivalent to the quotient $C(f)/Y$, which is the same as the suspension of $X$. Recall from earlier that the suspension is defined as $\\Sigma X = (X\\times I)/(x,0)\\sim (x',0), (x,1)\\sim (x',1)$. A picture might help.\nWe then have the coexact sequence $X\\rightarrow Y \\rightarrow C(f) \\rightarrow \\Sigma X \\rightarrow \\Sigma Y \\rightarrow \\Sigma C(f)$. Iterating this construction, we get a long coexact sequence called the coexact Puppe sequence, or the topological cofiber sequence. There are a few details that I fave glossed over, and there maybe some cases that we should be careful about, but at least for CW complexes this should hold.\nOk, we know this is a coexact sequence, which means that if we apply a contravariant Hom functor on it, we will have a long exact sequence. What object should we use? In the case for the regular Puppe sequence, we used the homotopy Hom functor $[S^0, -]$, so what is the dual to this functor? It is $[-, K(\\mathbb{Z},k)]$. I think the reason this is true will become clear in a little bit, but to give a short note, recall that we used the adjointness between loop spaces and suspensions, and using $S^0$ was a good choice because the suspension of spheres is again a sphere in one dimension higher. So now, we also want to use this adjointness, but then we have iterated loop functors, and what spaces do we know that when used the loop functor on is again the same kind of space, but one dimension lower? You guessed it, its the Eilenberg-MacLane spaces we developed in part 5! Recall that we used that $\\Omega K(\\mathbb{Z},k) \\cong K(\\mathbb{Z}, k-1)$. Ok, so we then get the long exact sequence\n$$\\leftarrow [\\Sigma^n X, K(\\mathbb{Z}, k)] \\leftarrow [\\Sigma^n Y, K(\\mathbb{Z}, k)] \\leftarrow [\\Sigma^n C(f), K(\\mathbb{Z}, k)] \\leftarrow [\\Sigma^{n+1} X, K(\\mathbb{Z}, k)] \\leftarrow ,$$\nand since loops and suspensions is adjoint, we get\n$$\\leftarrow [X, \\Omega^n K(\\mathbb{Z}, k)] \\leftarrow [Y, \\Omega^n K(\\mathbb{Z}, k)] \\leftarrow [C(f), \\Omega^n K(\\mathbb{Z}, k)] \\leftarrow [X, \\Omega^{n+1} K(\\mathbb{Z}, k)] \\leftarrow ,$$\nwhich we know, as noted above, is the long exact sequence\n$$\\leftarrow [X, K(\\mathbb{Z}, k-n)] \\leftarrow [Y, K(\\mathbb{Z}, k-n)] \\leftarrow [C(f), K(\\mathbb{Z}, k-n)] \\leftarrow [X, K(\\mathbb{Z}, k-(n+1)] \\leftarrow .$$\nOk, now what? How does this help us at all? We are maybe expecting to find some dual notion of homotopy here, and in a way, that is what we get. There is a construction called cohomotopy (which we may explore in a later post), but this is not the construction we have here. What we have created is actually the long exact sequence in cohomology!\nCohomology The first time i learned this, I was surprised. How do we see this? Recall that a $K(\\mathbb{Z}, n)$ space in $(n-1)$-connected. Hence, by the Hurewicz theorem discussed in part 5, we have\n$$H_n(K(\\mathbb{Z}, n)) \\cong \\pi_n(K(\\mathbb{Z}, n))\\cong \\mathbb{Z},$$\nand\n$$Ext(H_{n-1}(K(\\mathbb{Z}, n)), \\mathbb{Z}) \\cong Ext(0, \\mathbb{Z}) \\cong 0,$$\nso by the cohomological universal coefficient theorem (cUCT) we have\n$$H^n(K(\\mathbb{Z}, n)) \\cong Hom(H_n(K(\\mathbb{Z}, n)), \\mathbb{Z}) \\cong Hom(\\mathbb{Z}, \\mathbb{Z}) \\cong \\mathbb{Z}.$$\nThis means that there is a canonical class in $H^n(K(\\mathbb{Z}, n))$ corresponding to the identity element $1\\in \\mathbb{Z}$, call this $\\iota$. Hence we have a natural map $[X, K(\\mathbb{Z}, n)] \\rightarrow H^n(X;\\mathbb{Z})$ given by evaluating the induced map in cohomology from a homotopy class of maps in $[X, K(\\mathbb{Z}, n)]$ on the canonical class, i.e. $[ f ]\\mapsto f_*(\\iota)$. This map is in fact an isomorphism of Abelian groups. We can see this by first confirming for spheres, and then for a bouquet of spheres, and use the skeleton structure of $X$ as a CW-complex, which gives the cofibration $X^{k-1}\\rightarrow X^k \\rightarrow \\bigvee S^k$ to get the result through induction on the degree of the skeleton, and lastly union over them all to get the result for $X$. Finally we are left with $[X, K(\\mathbb{Z}, n)] \\cong H^n(X;\\mathbb{Z})$, for all CW complexes $X$. If we assume the map f to be a cofibration, then the cohomology of the mapping cone is the same as the relative cohomology $H^n(Y,X)$. Finally, from the sequence\n$$\\leftarrow [X, K(\\mathbb{Z}, n)] \\leftarrow [Y, K(\\mathbb{Z}, n)] \\leftarrow [C(f), K(\\mathbb{Z}, n)] \\leftarrow [X, K(\\mathbb{Z}, n-1)] \\leftarrow ,$$\nwe have, under the isomorphisms discussed above, the long exact sequence\n$$\\leftarrow H^n(X;\\mathbb{Z}) \\leftarrow H^n(Y;\\mathbb{Z}) \\leftarrow H^n(Y,X;\\mathbb{Z}) \\leftarrow H^{n-1}(X;\\mathbb{Z}) \\leftarrow .$$\nThis is not the standard, and should not be the standard way to produce this exact sequence, but I still find it cool that it works this way. Cohomology doesn’t feel dual to homotopy, but in a way, this construction shows that they are, at least for some notion of dual. Maybe thinking of them as adjoint constructions is better, I don’t know. This was all I wanted to do for this post. There is another way to characterize cofibrations, namely through neighbourhood deformation retracts. The only reason i mention this is to have a relevant artwork by Fomenko to end the article with, so here is “A retraction of a space onto a subspace of it“.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/cofibrations/","summary":"This is part 6 of a series leading up to and exploring model categories. For the other parts see 1, 2, 3, 4, 5 7, 8 and 9.\nThrough the series so far we have covered the basic uses of fibrations and related things, like the long exact sequence of homotopy groups, the Serre spectral sequence, fiber bundles and homotopy groups of spheres. But, we have not mentioned that fibrations has a dual construct, namely cofibrations.","title":"Cofibrations"},{"content":" Some time ago I saw this problem of hanging a picture on the wall using a string and two nails in such a way that if you remove one of the nails from the wall, the picture falls down. This is a bad way to hang pictures you immediately say, and I would agree. I saw some solution to the problem, and didn’t think about it for many years, until this week when I figured out that we need homotopy, in particular the fundamental group, to do it! Finally a real world practical useful application of homotopy theory! Take that society.\nAnyway. What is this connection between hanging pictures on the wall and homotopy? Well, we are tasked to hang it with a string, and this string together with the picture forms a loop, which gives us a connection to homotopy groups. In particular it gives us a relation to the fundamental group, which is the first and simplest homotopy group. To be rigorous, lets define it properly.\nDefinition (fundamental group): Let $X$ be a path connected topological space with base point x. The fundamental group of $X$ at the point x, denoted $\\pi_1(X,x)$ is the set of loops in $X$ that start and end at $x$, modulo deformation. That means that we say two loops are the same if we can continuously deform them into each other. We define a group operation on this set by the concatenation of loops, i.e. we do one loop and then the other in succession. Since we can do a loop both one way and do the same loop backwards (which for the group inverses) we have a group. The identity element is just the constant loop at the basepoint.\nSince we are going to hang the pictures on the wall, this is equivalent to looking at the plane $\\mathbb{R}^2$ as our space to do homotopy. When we hammer two nails into the wall, this is the same as punching two holes into our plane, like in the picture below. Lets call these points $a$ and $b$. Then finally the space we are interested in is $\\mathbb{R}^2-{a,b}$, i.e. the plane but with the two points removed.\nRemoving one of the nails correspond to filling one of the holes. If we forget about the requirement described in the introduction, then to hang the picture on the wall we need to twist and turn the string around the two nails in some way. We will soon describe a particular way that meets the requirements, but first, we just look at any way to do this. Choose the basepoint in the space to be where the string is connected to the picture. Since the picture has to actually hang on the wall and not fall down, this must correspond to a non-zero element of the fundamental group $\\pi_1(\\mathbb{R}^2-{a,b}, x)$, i.e. some loop around the two nails that we can’t “pull away” or equivalently, can’t be deformed to the constant loop. If we could deform it to a constant loop, it would mean that the string really wasn’t well enough put around the two nails, and the picture falls down.\nPicture 3: A non-zero element in the homotopy group represented by a way to hang a picture on the wall. We will later call this particular way for $a^2b^{-1}ab^{-2}$, but more on the naming schemes in a little bit.\nOk, so we have figured out that any way to make the picture hang on the wall using the two nails correspond to a non-zero element in the group $\\pi_1(\\mathbb{R}^2-{a,b}, x)$. Can we describe this group in a more relatable simpler way? It turns out that we can, but not too simple. This description comes from a cool theorem in algebraic topology called the Seifert-van Kampen theorem. This theorem tells us that if we can decompose a space $X$ into two pieces, $U$ and $V$ such that the intersection of these two pieces is contractible and the base point lies in this intersection, then the fundamental group of the entire space is equal to the free product of the fundamental groups of the two pieces, i.e. $\\pi_1(X,x) = \\pi_1(U,x)\\ast \\pi_1(V,x)$. What the free product is will be explained soon, but first we need to know what this theorem can do for us? We can split $\\mathbb{R}^2-{a,b}$ into two pieces, each one containing just one of the points, and leaving a little overlap.\nThe basepoint already lies nicely in the intersection, and the intersection is just a infinite tall column, which is contractible. The fundamental group of each of the two pieces we can figure out, since each piece is homeomorphic to $\\mathbb{R}^2-{a}$ and $\\mathbb{R}^2-{b}$ respectively, which we know retracts to the sircle $S^1$, which have a fundamental group $\\pi_1(S^1)=\\mathbb{Z}$. Ok, this is maybe a bit heavy and complex looking, but think of it this way. If we were to hang the picture using only one nail, then all we could do was either wind the string around the nail in one direction, or in the opposite direction. Winding it first three times clockwise, then one more time clockwise is the same as winding it four times clockwise, and winding it three times clockwise then one time counterclockwise is the same as winding it just two times clockwise. You can maybe tell that this is the same as counting how many times we wind clockwise and counterclockwise, hence the group is the same as the integers. The identity element is just winding zero times around the nail, hence in our case, this means that the picture falls down.\nSo what have we learned? We now know that $\\pi_1(\\mathbb{R}^2-{a}) = \\pi_1(\\mathbb{R}^2-{b}) = \\mathbb{Z}$ and that $\\pi_1(\\mathbb{R}^2-{a, b}) = \\mathbb{Z}\\ast \\mathbb{Z}$ which is the notation for the free product of the groups. To understand this free product, it will be easier to describe the fundamental groups as the infinite cyclic group generated by one generator, i.e. $\\pi_1(\\mathbb{R}^2-{a}) = \\langle a \\rangle$ and $\\pi_1(\\mathbb{R}^2-{b}) = \\langle b \\rangle$. For simplicity we denoted the generator by the name of the point in which it represents the fundamental group of. Hence, $b^2$ now means winding two times clockwise around the point $b$, and $a^{-4}$ means winding four times counterclockwise around the point $a$, and so on. The free product is a bit tricky product, but in this situation we have described now, it consists of all finite lists of combinations of $a$ and $b$ where we multiply the $a$‘s and $b$‘s where we can. An example of an element would then be $a^2b^3a^{-6}ba^2b^{-2}$, and all other combinations you could think of. Multiplication of elements is just writing them after each other and contracting the elements that can be contracted. Inverse elements comes from writing the list of elements backwards and replacing all positive degrees with negative and vice versa. So for example, $a^2b^{-3}$ is the inverse of $b^3a^{-2}$ because their multiplication (concatenation of lists) is $a^2b^{-3}b^3a^{-2} = a^2b^0a^{-2} = a^2a^{-2} = a^0 = id$.\nOk, we now have algebraic descriptions of the fundamental groups, and we can use this to describe a way to hang the picture in the way we wanted. To recall the problem, we want to hang a picture on the wall using a string and two nails such that if we remove any of the two nails from the wall, the picture falls down. My guess is the following picture.\nIn the algebraic language we developed just prior, this would be called $aba^{-1}b^{-1}$. Anyone having done some abstract algebra, or especially some Lie theory would immediately recognize this as the so called commutator of $a$ and $b$. In the free product this commutator is not equal to the identity element, as we can see in the picture and since the group is non-Abelian. In an Abelian group however (like the fundamental group of the plane with just one point removed), all commutators are trivially equal to the identity element, and this is what we will use to make the picture fall down.\nSo, lets prove that my guess satisfies the requirement. Notice that removing the nail at the point $b$, or equivalently filling the hole b corresponds to a group homomorphism that sends an element of the free product group to the cyclic group on $a$, i.e. a homomorphism $f_a: \\langle a\\rangle \\ast \\langle b\\rangle \\rightarrow \\langle a\\rangle$ that is the identity on the elements of $\\langle a\\rangle$ and is the trivial homomorphism that sends everything to the identity on all elements of $\\langle b\\rangle$. For example,\n$$f_a(a^5b^{-3}a^{-3}b^2) = f_a(a^5)f_a(b^{-3})f_a(a^{-3})f_a(b^2)=a^5 \\cdot id_a \\cdot a^{-3}\\cdot id_a = a^5\\cdot a^{-3} = a^2.$$\nThe act of removing the nail at point a corresponds to the exact same construction, just for the group $\\langle b\\rangle$. Call this map $f_b$. Now, what happens when we use the maps that corresponds to removing nails on the commutator we designed earlier? We get\n$$f_a(aba^{-1}b^{-1})=f_a(a)f_a(b)f_a(a^{-1})f_a(b^{-1})) = a\\cdot id_a \\cdot a^{-1} \\cdot id_a = id_a$$\nand\n$$f_b(aba^{-1}b^{-1})=f_b(a)f_b(b)f_b(a^{-1})f_b(b^{-1})) = id_b\\cdot b \\cdot id_b \\cdot b^{-1} = id_b,$$\nand hence, removing any of the nails means that the loop no longer hangs on any of the nails, since for it to hang on one of the nails it has to have been wound around at least one time clockwise or counterclockwise! This is equivalent to saying that the picture falls to the ground, which proves that our guess actually fits the criteria. There are as you may notice very many other ways to do this, but i think the commutator way is the most simple and easiest to visualize. And by that we have successfully made a shitty way to hang a picture on a wall, but, we used homotopy, which makes it cool!\n","permalink":"https://torgeiraamboe.github.io/posts/2020/hanging-pictures-with-homotopy/","summary":"Some time ago I saw this problem of hanging a picture on the wall using a string and two nails in such a way that if you remove one of the nails from the wall, the picture falls down. This is a bad way to hang pictures you immediately say, and I would agree. I saw some solution to the problem, and didn’t think about it for many years, until this week when I figured out that we need homotopy, in particular the fundamental group, to do it!","title":"Hanging Pictures With Homotopy"},{"content":"This is part 5 of a series leading up to and exploring model categories. For the other parts see 1, 2, 3, 4, 6, 7, 8 and 9.\nAs promised in the previous part, we are going to calculate $\\pi_4(S^3)$. I think we will have to use all of the machinery (plus some new) that we have been through during this series to do the calculation. What more could we possibly need you ask? Last time we developed the machinery to calculate the cohomology of the total space of a fibration, but we want to compute homotopy. Hence we need a method for translating cohmological information into homotopical information, which is what we are missing to be able to do the calculation. There may be other processes that I haven’t learned, but the process I know goes through two steps. First we must translate cohomology into homology. This is done through the so called cohomological universal coefficient theorem (cUCT). Then we need to translate from homology to homotopy. This is done through the Hurewicz theorem. I think of these two theorems together as sort of a Rosetta stone for algebraic topology. It makes us able (with some computation and restrictions of course) to move between the three fundamental theories of invariants we have in algebraic topology, which I find beautiful. There is one more thing we need, which is a starting point for our calculation. We need a good fibration to extract the information we want which we are able to translate into homotopy afterwards. Therefore we need a space in the fibration that does not complicate things when we translate into homotopy, i.e. we need a space in which we completely understand its homotopy groups. The “homotopy-easy” spaces I’m describing are called Eilenberg-MacLane spaces. In cohomology (and homology) theory we have the easy spaces being spheres because we completely understand their cohomological structure. They cam be thought of as the building blocks for (co)homology. The same type of space for homotopy is exactly theese Eilenberg-MacLane spaces, and they form the building blocks for homotopy groups in the same way as the spheres for (co)homology. Hence we can combine these spaces and spheres in a fibration and use that to compute cohomology and then relatively easily translate this to homotopy, which is exactly our plan for computing $\\pi_4(S^3)$.\nExpanding our tool belt The first new tool, which we briefly mentioned above is called the Hurewicz theorem and allows us to move between homology and homotopy in certain nice cases. These nice cases happen when the topological space we are studying is very connected, i.e. at least both path connected and simply connected and often even the higher dimensional analog called n-connected. The level of connectedness can be formulated though the homotopy groups of the space, in particular we call a space $X$ for $n$–connected if $\\pi_k(X) = 0$ for all $k\\leq n$, here path connected corresponds to 0-connected, and simply connected corresponds to 1-connected.\nTheorem (Hurewicz): Let $n\\geq 2$. and $X$ be $(n-1)$-connected. Then $H_k(X) = 0$ for all $ 0 \u0026lt; k \u0026lt; n $ and the Hurewicz homomorphism $h_*: \\pi_n(X) \\rightarrow H_n(X)$ is an isomorphism.\nWe see that the absence of low degree homotopy groups also gives an absence of lower degree homology groups. The Hurewicz homomorphism is given by evaluating the induced map on homology from a homotopy class of a map $f:S^n\\rightarrow X$ in the fundamental class of $S^n$, i.e. the choice of a generator for the group $H_n(S^n)\\cong \\mathbb{Z}$. If we denote the fundamental class by $[S^n]$, then it is given by $h_*([f])=f_([S^n])$. What exactly the maps are will not be important for us, but the fact that it is an isomorphism in nice cases is very useful.\nTheorem (cUCT): Let $X$ be a topological space and $G$ an Abelian group. Then for any $i$ we have a short exact sequence\n$$0\\rightarrow Ext_{\\mathbb{Z}}(H_{i-1}(X;\\mathbb{Z}), G)\\rightarrow H^i(X;G) \\rightarrow Hom_{\\mathbb{Z}}(H_i(X;\\mathbb{Z}), G)\\rightarrow 0.$$\nThis tells us that cohomology is almost just maps from homology into the coefficients, except we might be a little bit off, but in a manner we understand, i.e. up to some extension. We are going to rely quite heavily on this theorem in the calculation later, but there are a few extra bits we need. There is a theorem by Serre that says that the homology groups of a simply connected space are finitely generated if and only if the homotopy groups are finitely generated. We know that the homology groups of spheres are finitely generated, hence all of the homotopy groups are also finitely generated. In the short exact sequence in cUCT, we also need to know a little bit about when there are no homomorphisms between two groups, and how the Ext group works. If we have a finite group $A$, then the group group $Hom(A,\\mathbb{Z})=0$. To have the converse statement we also need to know that A is finitely generated, i.e. if $A$ finitely generated then $Hom(A,\\mathbb{Z})$ is a free group. Hence if $Hom(A,\\mathbb{Z})=0$ then $A$ is a finite group. What we need to know about $Ext(A,\\mathbb{Z})$ is that $Ext(\\mathbb{Z}/2,\\mathbb{Z})\\cong \\mathbb{Z}/2$, and that the converse holds if we have a finiteness condition, i.e. if $A$ is a finite group and $Ext(A,\\mathbb{Z})=\\mathbb{Z}/2$, then $A\\cong \\mathbb{Z}/2 .$\nDefinition: A topological space $X$ is called an Eilenberg-MacLane space of type $K(G,n)$, or just a $K(G,n)$-space for short, if we have $\\pi_n(X) = G$ and all of its other homotopy groups are trivial.\nThe important cases for us in this computation is a $K(\\mathbb{Z}, 3)$ space and a $K(\\mathbb{Z}, 2)$ space. How do these spaces look? We know the simplest case, namely that the sircle $S^1$ is a $K(\\mathbb{Z}, 1)$ space. This we know because it has the integers as a fundamental group, and as discussed in part 3, it can have no maps from higher dimensional spheres, hence all higher homotopy groups are trivial, and this is our definition of a $K(\\mathbb{Z}, 1)$-space. In the computation later we need an explicit description of a $K(\\mathbb{Z}, 2)$-space, so before we jump to computation, we remark that $\\mathbb{C}P^{\\infty}$ is in fact a $K(\\mathbb{Z}, 2)$-space! This space is the space consisting of all complex lines passing through the origin in the infinite dimensional complex vector space $\\mathbb{C}^{\\infty}$. I’m not going to explain much about this space, but we will use it’s cohomology groups and it’s cohomology ring later.\nCalculation of $\\pi_4(S^3)$ I didn’t expect the preliminaries to be that long, but now the hard part is over (not really) and we are finally ready to compute! Lets start with the fibration $X\\rightarrow S^3 \\rightarrow K(\\mathbb{Z},3)$. This fibration is not super easy to get, but the idea is to iteratively attach higher dimensional cells to $S^3$ in order to kill off higher homotopy groups in degrees higher than 3. When we kill off all the higher homotopy groups, we are only left with a homotopy group in degree three, which is the integers since it is “made” from the 3-sphere, and this is our definition of a $K(\\mathbb{Z},3)$. This is sometimes referred to as “capping” of a space, giving a “capped” space. It is dual to the notion of a “killing space”, which is a cool name i thought i would mention. When we pass to the long exact sequence for this fibration we get\n$$\\cdots \\rightarrow \\pi_4(K(\\mathbb{Z},3)) \\rightarrow \\pi_3(X) \\rightarrow \\pi_3(S^3) \\rightarrow \\pi_3(K(\\mathbb{Z},3)) \\rightarrow \\pi_2(X) \\rightarrow \\pi_2(S^3) \\rightarrow \\cdots,$$\nin which we know several of the groups. We know that $K(\\mathbb{Z},3)$ only has homotopy in degree 3 and that $\\pi_2(S^3) = 0$. We also know that the map $\\pi_3(S^3) \\rightarrow \\pi_3(K(\\mathbb{Z},3))$ is an isomorphism, since that is the way we constructed the space $K(\\mathbb{Z},3)$. Further to the right we only have trivial groups. Hence we get $\\pi_3(X) \\cong \\pi_2(X) \\cong \\pi_1(X) \\cong \\pi_0(X) \\cong 0$. Further to the right we have that all of the homotopy groups of $K(\\mathbb{Z},3)$ are trivial, and because we know that the long sequence is exact, we get that $0 \\rightarrow \\pi_n(X) \\rightarrow \\pi_n(S^3) \\rightarrow 0$ is exact, hence the homotopy groups are isomorphic for all $n\u0026gt;3$. In particular we have $\\pi_4(X) \\cong \\pi_4(S^3)$ which is what we are going to use in order to calculate it. As mentioned earlier, all homotopy groups of spheres are finitely generated, and hence all of the homotopy groups of $X$ are as well. We see that we have to compute the homotopy groups of $X$, and to do this we are going to use the Rosetta stone we described in the introduction, by first computing its cohomology, and then translating through homology and then finally into homotopy.\nAs we did in the Puppe sequence in part 3, we can extend the inclusion of the fibers into the total space to a fibration with fibers being the loop space of the base space in the original fibration, i.e. $\\Omega K(\\mathbb{Z},3)\\rightarrow X \\rightarrow S^3$. Have we made things even more complicated? How does the loop space of an Eilenberg-MacLane space look? We have actually made it simpler. In part 3 we discussed the suspension functor, and noticed that the suspension of a sphere is a new sphere in one dimension higher. Hence the suspension functor should shift the degrees of the homotopy groups up by one. We mentioned that the loop space functor is adjoint to the suspension, and hence is shifts the degrees of the homotopy groups down by one. We can also see this by the fibration $\\Omega X\\rightarrow PX \\rightarrow X$, where $PX$ is the path space of $X$. The path space is contractible, and hence from it has only trivial homotopy groups, so when we pass to the long exact sequence of homotopy groups from the fibration we get that $\\pi_{n+1}(X) \\cong \\pi_{n}(\\Omega X)$. Because of this we get that $\\pi_n(\\Omega K(\\mathbb{Z},3)) = 0$ for $n\\geq 3$ and $\\pi_2(\\Omega K(\\mathbb{Z},3)) = \\mathbb{Z}$.\nHey, look at that, the loop space of the Eilenberg-MacLane space has only one non-trivial homotopy group, and thus by our definition it is an Eilenberg-MacLane space itself, namely a $K(\\mathbb{Z}, 2)$-space. Luckily for us we already know a $K(\\mathbb{Z}, 2)$-space, namely $\\mathbb{C}P^{\\infty}$. To summarize, our new fibration looks like $\\mathbb{C}P^{\\infty}\\rightarrow X \\rightarrow S^3$. Now we have something to put into a spectral sequence which we know computes the cohomology of $X$ from the cohomology of the base and the cohomology of the fibers. And, since $\\mathbb{C}P^{\\infty}$ is a nice CW-complex with one cell in each even degree, we know how its cohomology looks like, and even more important, we know how its cohomology ring looks like. We have $H^*(\\mathbb{C}P^{\\infty})\\cong \\mathbb{Z}[a_2]$, i.e. a polynomial ring with the generator in degree two. Lets throw all this information into the Serre spectral sequence. We get\nSince our base space is a sphere, we naturally get two columns, and since $\\mathbb{C}P^{\\infty}$ has cohomology in every even degree, these two columns continue all the way up to infinity. Luckily for us, we only care about a small portion of the spectral sequence. Since there are 3 “steps” between the two columns, all of the differentials on the second page has a trivial group as either it’s domain or it’s codomain. Hence nothing happens at the second page. When we flip to the third page, the differentials are “long” enough to connect our two columns. We know that the spectral sequence computes the cohomology of the topological space $X$, and since there are only one group along each of the diagonals, i.e. either $\\bigoplus_{p+q=n}E_r^{p,q} = E_r^{0,n}$ or $\\bigoplus_{p+q=n}E_r^{p,q} = E_r^{3,n}$. By this we know that the n‘th cohomology group of $X$ is actually the group showing up in the spectral sequence along the n‘th diagonal. From the computation of the homotopy groups of $X$ earlier, we know that $\\pi_3(X) = \\pi_2(X)=0$ and by the Hurewicz theorem we know that this implies that $H_3(X) = H_2(X) = 0$, which by cUCT implies that $H^3(X) = 0$. We have a group on the third diagonal, namely $E_3^{3,0}$, and it is hit by only one single differential, which is the differential $d:E_3^{0,2}\\rightarrow E_3^{3,0}$. Since all other differentials at the later pages are too long, we know that this differential is in fact the only differential hitting this group throughout the entire spectral sequence. Thus, we know that it has to be an isomorphism. Since the cohomology ring of $\\mathbb{C}P^{\\infty}$ has a generator a in the second degree, it lives in $E_3^{0,2}$ and it maps through $d_2$ to some generator of $E_3^{3,0}$, call this $x$, i.e. $d_2(a)=x$. The generator a lives in degree 2, so its square in the cohomology ring $a^2$ lives in degree 4, and hence lives in $E_3^{0,4}$. By the Leibniz rule that the differentials satisfy, we get that $d_4(a^2)= ax$ and that the map is multiplication by two. The cube of the generator $a^3$ lives in $E_3^{0,6}$ and maps to $a^2 x$ by multiplication by three and so on upwards. We can draw the information into the spectral sequence, just for a better visualization.\nWhen we flip to the fourth page, all of the differentials are too long to pass between the columns, and hence we get that $E_4 = E_{\\infty}$ which means that $H^4(X)=Ker(d_4)=Ker(\\cdot 2) = 0$ and latex $H^5(X) = Cok(d_4)= Cok(\\cdot 2) = \\mathbb{Z}/2$. Now we’re getting somewhere! We see the first evidence of what is to become $\\pi_4(S^3)$ after translating with the Rosetta stone. As described earlier, we need to translate into homology first, which we do by cUCT. We get the short exact sequence\n$$0\\rightarrow Ext_{\\mathbb{Z}}(H_{3}(X), \\mathbb{Z})\\rightarrow H^4(X) \\rightarrow Hom_{\\mathbb{Z}}(H_4(X), \\mathbb{Z})\\rightarrow 0.$$\nWe figured out that $H^4(X) = 0$ and $H_3(X)=0$, and therefore we get $Ext_{\\mathbb{Z}}(H_3(X),\\mathbb{Z}) = Ext_{\\mathbb{Z}}(0,\\mathbb{Z}) = 0$. Since the sequence is exact we must have $0 = H^4(X;\\mathbb{Z}) \\cong Hom_{\\mathbb{Z}}(H_4(X),\\mathbb{Z})$. Then $Hom_{\\mathbb{Z}}(H_4(X),\\mathbb{Z}) = 0$ which implies that $H_4(X)$ is a finite group. This we know since the homotopy groups of $X$ are finitely generated (discussed previously), hence the homology groups of $X$ are as well which gives us that it is a finite group by the discussion in the paragraph about cUCT. In one degree higher we also get a short exact sequence from cUCT, namely the sequence\n$$0\\rightarrow Ext_{\\mathbb{Z}}(H_{4}(X), \\mathbb{Z})\\rightarrow H^5(X) \\rightarrow Hom_{\\mathbb{Z}}(H_5(X), \\mathbb{Z})\\rightarrow 0.$$\nSince $H_4(X)$ is finitely generated we know $Hom_{\\mathbb{Z}}(H_5(X), \\mathbb{Z}) = 0$, because it is either this or it is equal to $\\mathbb{Z}/2$ and that option disappears since it is free. Now this means that $Ext_{\\mathbb{Z}}(H_{4}(X), \\mathbb{Z}) \\cong H^5(X) \\cong \\mathbb{Z}/2$ and since we know that $H_4(X)$ is a finite group, we get that $H_4(X)\\cong \\mathbb{Z}/2$. Phew… Almost done now.\nThankfully, the last part of the translation from homology to homotopy is easier in this case. Recall that we figured out that $\\pi_3(X) \\cong \\pi_2(X) \\cong \\pi_1(X) \\cong \\pi_0(X) \\cong 0$ in the beginning when constructing our fibrations. Hence we know that X is 3-connected, and by the Hurewicz theorem we have an isomorphism $H_4(X)\\cong \\pi_4(X)$ which means that we have $\\pi_4(X) \\cong \\mathbb{Z}/2$. Our whole reason for doing this calculation with the space $X$ was that we figured out from the long exact sequence from the fibration that $\\pi_4(X) \\cong \\pi_4(S^3)$, and by this we finally have our result, $\\mathbb{Z}/2\\cong H_4(X)\\cong \\pi_4(X) \\cong \\pi_4(S^3)$, or in short\n$$\\pi_4(S^3) \\cong \\mathbb{Z}/2 .$$\nI really like this computation because it is rather difficult, and has a lot of moving parts, which makes it more fun! I don’t think the next posts will be this long and detailed, because this is maybe a bit much information in one post, even though it is just one computation in essence. Onward we will discuss cofibrations and weak equivalences, and then move into model category territory. I think my goal will be to show that the homotopy category of topological spaces is equivalent to the homotopy category of simplicial sets, which also enables me to finally start reading May’s book “Simplicial objects in algebraic topology”. Anyway, as usual I will leave off with an artwork by Anatoly Fomenko, this time his piece called “The method of killing spaces in homotopic topology”, which is dually relevant.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/a-homotopy-group-of-a-sphere/","summary":"This is part 5 of a series leading up to and exploring model categories. For the other parts see 1, 2, 3, 4, 6, 7, 8 and 9.\nAs promised in the previous part, we are going to calculate $\\pi_4(S^3)$. I think we will have to use all of the machinery (plus some new) that we have been through during this series to do the calculation. What more could we possibly need you ask?","title":"A homotopy group of a sphere"},{"content":"This is part 4 of a series leading up to and exploring model categories. For the other parts see 1, 2, 3, 5 6, 7, 8 and 9.\nMy personal favorite part about fibrations is that they come equipped with a natural way to compute the cohomology of the total space from the cohomology of the base and the cohomology of the fibers. This process is encoded in a structure called a spectral sequence, and is a complicated object in its full generality. It consists of layers upon layers of intertwined cohomology groups, all sewn together by homomorphisms. But when I first learned their computing power, and learned how to use them, I fell in love with the structure. If you visit my homepage you will find several small write ups using spectral sequences to prove theorems and do computations of cohomology rings etc. Therefore, I want to create a nice introduction to how to use them, given a fibration. Technicalities of the structure of the spectral sequences will be omitted, but the definitions will of course be given.\nSpectral sequences A spectral sequence can be thought of as a book, with possibly infinite pages. Every page consists of multiple complexes of cohomology groups, each being the cohomology of one of the complexes on the previous page. The maps on a page will be “longer” than the maps on the previous page, and all of them will be almost diagonal. We will make all this more precise in a little bit, but it can be helpful to have this information in the back of the head will reading and exploring the definition. With that said we first remind ourselves of some basic definitions from homological algebra to be able to formulate and be precise with the spectral sequence afterwards.\nDefinition (chain complex): A sequence of abelian groups (or more generally modules, or even more generally objects in some abelian category)\n$$\\cdots \\rightarrow A_{n-1} \\overset{d_{n-1}}\\rightarrow A_n \\overset{d_n}\\rightarrow A_{n+1} \\rightarrow \\cdots $$\nis called a cochain complex if the composition of two arrows is zero, i.e. if $d^2 = 0$. This is equivalent to saying that $\\text{Im}(d_{n-1})\\subset \\text{Ker}(d_n)$.\nDefinition (cohomology): Let C be a cochain complex. We define the n‘th cohomology group of $C$ to be $H^n(C) = \\text{Ker}(d_n)/\\text{Im}(d_{n-1})$. This is often verbally stated as “cocycles modulo coboundaries”.\nThe most important cases for us is the use of cohomology of topological spaces. From a topological space $X$ we can define a cochain complex called the singular cochain complex on $X$. When we take the cohomology groups of this singular cochain complex, we get a lot of information about the topological structure of $X$. When we discuss cohomology groups from here on out, we will always mean this type of cohomology.\nDefinition (Spectral sequence): A spectral sequence is a tri-graded object, or a list of bi-graded objects $E^{p,q}_ r$ together with morphisms $d^r: E^{p,q}_ r \\rightarrow E^{p+r, q-r+1}_ r$ for all $r\u0026gt;0$ ,$p,q\\in \\mathbb{Z}$, and isomorphisms $E^{p,q}_{r+1}\\cong H(E^{p,q}_{r})$. The spectral sequence is called a first quadrant spectral sequence if $E^{p,q}_r = 0$ when $p\u0026lt; 0$ or $q\u0026lt;0$ .\nRemark: In the way we have developed the spectral sequence, it computes cohomology. I just want to mention that there is a completely analog version that computes homology. If we go through the same construction, just reversing all the arrows, and changing coefficients by tensoring instead of taking dual groups, we get a spectral sequence of homological type.\nThe first time I saw this definition, i didn’t understand anything. It was through a graduate course in algebraic topology, and roughly half the course focused on the use of spectral sequences. The problem with trying to introduce this abstract structure in this short of a text is that we don’t have enough time to explore it properly, and not even explain the definition properly with the care and precision it really deserves. That said, I feel the importance of the spectral sequence is not the understanding of the nitty gritty details, but how we can use it. The spectral sequence in all of its generality is for me not very nice, but there are special cases of them that pop up from different places, most important for us, from a fibration. This special case makes it relatively easy to depict what happens, and how topological spaces relate to each other through the fibrations. The proof that we in fact get a spectral sequence from a fibration is rather long and difficult, and I don’t want to go through it here (at least for now), so just trust me when i say that it works. If you don’t, I recommend Weibel’s book “An introduction to homological algebra” where the construction is explained further, or Hatcher’s book “Algebraic topology”.\nTo be more precise about how the spectral sequence from a fibration looks, we give a proper definition.\nDefinition (Serre spectral sequence): Given a fibration $F\\rightarrow X\\rightarrow B$ we get a first quadrant spectral sequence $E$ such that $E_r^{p,q}\\Rightarrow H^{p+q}(X, \\mathbb{Z})$ .\nThis spectral sequence starts at the second page which is given by $E_2^{p,q}\\cong H^p(B;H^q(F;\\mathbb{Z}))$.\nHere the \u0026lsquo;'$\\Rightarrow$\u0026rsquo;' means that it computes or “converges” to the cohomology of the total space. This roughly translates to taking the direct sum of all of the groups on the diagonal, i.e. $H^n(E) \\cong \\bigoplus_{p+q=n}E_{\\infty}^{p,q}$. This is not always completely correct, and we have to be a bit careful when doing this, but in the case of first quadrant bounded spectral sequences I think it holds. In the examples I will try to be more graphical, and use pictures of the spectral sequences to make the math clearer. Whenever I say spectral sequence from now, I will mean (unless otherwise stated) the Serre spectral sequence. Before we look at some examples lets look at a general picture for how the second page of the spectral sequence of a fibration $F\\rightarrow X\\rightarrow B$ looks like.\nHere we can quite clearly see the almost diagonal maps on the second page, and we also see the bi-graded grid of cohomology groups that is described in the definition. If I had drawn a bigger diagram, we would start to see to of the orange arrows after one another. The sequence of groups with these arrows called differentials form chain complexes as we mentioned in earlier, i.e. their composition will always be zero. I will not draw a general picture of the third page, but it would consist of the cohomology of the complexes formed by the orange differentials. The maps on the third page would go two down and three to the right, instead of one down and two to the right as in the second page we see depicted. Note that the maps being called differentials here are not because they are maps in the spectral sequence, but because they are differentials in the chain complexes, meaning they compose to zero and satisfy the generalized Leibniz rule. We will not need this, but it is important to know the naming conventions.\nComputing some examples To see that it actually works, it is maybe good to have a trivial example first, namely when the fibration $F \\rightarrow E \\rightarrow B$ comes from a trivial fiber bundle, also called the product, i.e. $E\\cong B\\times F$. Lets take a concrete example, say $S^2 \\rightarrow E= S^1\\times S^2 \\rightarrow S^1$. The spectral sequence associated to this fibration should in theory compute that the cohomology $H^n(S^1\\times S^2)$ is the same as the product of the cohomologies $H^n(S^1)\\times H^n(S^2)$. Let’s see how it pans out. We know that the cohomology groups of $S^1$ looks like the integers in degree zero and in degree one, i.e. $H^0(S^1;\\mathbb{Z}) \\cong \\mathbb{Z} \\cong H^1(S^1;\\mathbb{Z})$. We also know that the cohomology groups of $S^2$ looks like the integers in degree zero and in degree two, i.e. $H^0(S^2;\\mathbb{Z}) \\cong \\mathbb{Z} \\cong H^2(S^2;\\mathbb{Z})$, hence we get\nAs we see, the differentials miss all of the available groups, and every one of them is therefore the zero homomorphism, since remember that the sequences of objects they form are in fact complexes. Hence nothing changes when we flip to the next page, and the next after that, and we have $E_2 = E_{\\infty}$. Because of this the cohomology of the product is the sum along the diagonal and we get $H^0(S^1\\times S^2) \\cong \\mathbb{Z}$, $H^1(S^1\\times S^2) \\cong \\mathbb{Z}$ and $H^2(S^1\\times S^2)\\cong \\mathbb{Z}$, just as we expected.\nLet’s do another example. In part 3 of this fibration series we computed the third homotopy group of the sphere by using the long exact sequence of homotopy groups from the Hopf fibration. What happens in the spectral sequence associated to the Hopf fibration then? On the second page we get four cohomology groups as shown here:\nWe only have one non-zero differential, namely the morphism between $E_2^{0,1}$ and $E_2^{2,0}$. Hence, when we flip to the third page, we have\nOn the third page we see that all of the possible differentials are too long to hit any of the groups, hence we know that the third page is the last page, i.e. all pages after has to look exactly the same. We are lucky to already know how the cohomology of the spheres look, and since we know that the spectral sequence computes the cohomology of $S^3$ we know that the differential has to be an isomorphism, since it has to have both a trivial kernel and a trivial cokernel. To explain a bit better, if we were to sum along the diagonals to compute the cohomology of $S^3$, we would see $H^1(S^3)=Ker(d)$, but as mentioned we know that $H^1(S^3)=0$, thus we must have $Ker(d)= 0$. The exact same argument holds for $Cok(d)$, and since they are both zero, d has to be an isomorphism.\nFuture of the series Next time in the fibration series we will use the machinery we developed in here, together with some theorems to compute one more of the non-trivial homotopy groups of the spheres. We will show that $\\pi_4(S^3) \\cong \\mathbb{Z}/2$ which i think historically was the first computed homotopy group of a sphere that was non-trivial and also not just the integers, but a finite cyclic group. A tentative plan for this series is to introduce enough material so that I can start to learn about model categories properly. There is also loads more fun calculations to do and more theorems and concepts to study. Also, recently Eric Weinstein published a lecture describing his proposed theory of everything, i.e. a theory that unifies general relativity and quantum mechanics. In this theory he uses a generalized version of the universe as a manifold and constructs a certain fiber bundle over this manifold which he calls the Observerse. It would be cool to try to construct this bundle, and a related bundle which he calls the Chimeric bundle, to dip my toes into mathematical physics. The summer vacation is long, and corona makes sure that I have plenty of time at home to study. For reading to the end I last time left off with an incredible art piece by my favorite Russian mathematician and artist Anatoly Fomenko, picturing his vision on homotopy groups of spheres. I will leave off this time with yet another artwork by Fomenko, this time it naturally fits to leave off with his work “A spectral sequence“.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/the-serre-spectral-sequence/","summary":"This is part 4 of a series leading up to and exploring model categories. For the other parts see 1, 2, 3, 5 6, 7, 8 and 9.\nMy personal favorite part about fibrations is that they come equipped with a natural way to compute the cohomology of the total space from the cohomology of the base and the cohomology of the fibers. This process is encoded in a structure called a spectral sequence, and is a complicated object in its full generality.","title":"The Serre spectral sequence"},{"content":"This is part 3 of a series leading up to and exploring model categories. For the other parts see 1, 2, 4, 5 6, 7, 8 and 9.\nFor an introduction to the material, the definitions, motivation and some examples, please read part 1 and part 2 about fibrations and fiber bundles. This and the the following parts of this series will be about their usefulness, especially in computing homology and homotopy groups. This will be done through two different techniques, namely the long exact sequence of homotopy groups, and the spectral sequence associated to a fibration. In this this part, we look at the long exact sequence. This is a tool that will let us relate the homotopy groups of different kinds of spaces to each other, and ultimately, will help us compute the homotopy groups of fiberbundles from the homotopy groups of the base space, and the homotopy groups of the fibers. Forward, we always have pointed spaces, and the base spaces of our fibrations are simply connected. To be a bit more self contained, we remind ourselves what a long exact sequence is.\nDefinition (l.e.s): A long sequence of objects (in our case usually groups or pointed spaces)\n$$\\cdots \\longrightarrow A_{n+1} \\overset{d_{n+1}} \\longrightarrow A_n \\overset{d_n} \\longrightarrow A_{n-1} \\longrightarrow \\cdots $$\nis called exact at $A_n$ if $\\text{Ker}(d_n)=\\text{Im}(d_{n+1})$ . The sequence is called exact if it is exact for every $n.$\nThe Puppe sequence There are several ways to develop the long exact sequence of homotopy groups, but we will do it through the Puppe sequence, and for that we first need to look at the loop space $\\Omega X$ of a topological space $X$. This is, as the name says, the topological space consisting of all loops in $X$ , i.e. the space of all pointed maps from the pointed sircle $(S^1, \\infty)$ to $X$ . We also need the notion of the homotopy fiber of a map $f: X\\rightarrow Y$ . Intuitively, this is the fiber of $f$ , except we are allowed to move thing around by a homotopy. To be more precise, the homotopy fiber of a point $y\\in Y$ consists of pairs $(x,\\omega)$ such that $\\omega$ is a path from $f(x)$ to $y$ in $Y$ . We call the collection of the fibers of all the points for the homotopy fiber of $f$, denoted $hofib(f)$.\nNow, let $f:X\\longrightarrow Y$ be a map of topological spaces. We can turn this into an exact sequence by including the homotopy fiber into the picture, namely $hofib(f)\\rightarrow X\\rightarrow Y$ . The loop space of $Y$ injects nicely into the homotopy fiber, because it consists of the paths that both start and end at the same points. We can even include $\\Omega X$ , and get an exact sequence $\\Omega X \\rightarrow \\Omega Y \\rightarrow hofib(f)\\rightarrow X\\rightarrow Y$ . Iterating this process further by doing the same construction on the map $\\Omega X \\rightarrow \\Omega Y$ , we get a long exact sequence consisting of iterated loop spaces $\\Omega^n X, \\Omega^n Y$ and homotopy fibers. This long exact sequence is called the Puppe sequence, and as you may have guessed, it is going to give us the exact sequence of homotopy groups that we are after.\nThe long exact sequence in homotopy If we assume that the map in the Puppe sequence is a fibration, say $p: E\\rightarrow B$ , then we get an exact sequence\n$$\\cdots \\rightarrow \\Omega^n X \\rightarrow \\Omega^n Y \\rightarrow \\Omega^{n-1} hofib(p) \\rightarrow \\cdots .$$\nTaking homotopy classes of pointed maps from the zero sphere $S^0$ , we get a long exact sequence\n$$\\cdots \\rightarrow [S^0, \\Omega^n X] \\rightarrow [S^0, \\Omega^n Y] \\rightarrow [S^0, \\Omega^{n-1} hofib(p)] \\rightarrow \\cdots$$\nOn homotopy classes of pointed maps, the loop space functor $\\Omega (-)$ is adjoint to the suspension functor $\\Sigma (-)$. This is part of Eckmann-Hilton duality and takes some time to explain, so I will not do that here. Hence we get the sequence\n$$\\cdots \\rightarrow [\\Sigma^n S^0, X] \\rightarrow [\\Sigma^n S^0, Y] \\rightarrow [\\Sigma^{n-1} S^0, hofib(p)] \\rightarrow \\cdots .$$\nThe suspension of a space is defined to be the cartesian product with the unit interval modulo the relation that all points are equivalent at the endpoint at the interval. This is maybe more clear with a drawing of the suspension of $S^0$ , where we can see that it is in fact equal to $S^1$ .\nBecause it is fun to draw, I also include a drawing of the suspension of $S^1$ , to see that it is equal to $S^2$ .\nThis phenomenon continues, and we see that an $n$ -sphere is just the suspension of an $(n-1)$ -sphere. Hence, we have that the iterated suspension $\\Sigma^n S^0 \\simeq S^n$ and we get the sequence\n$$\\cdots \\rightarrow [S^n, X] \\rightarrow [S^n, Y] \\rightarrow [S^{n-1}, hofib(p)] \\rightarrow \\cdots .$$\nSince our map is a fibration, the homotopy fiber $hofib(p)$ has the same homotopy type as the usual fiber, and we can replace $[S^n, hofib(p)]$ by just $[S^n, F]$ . By this, we are done, since these spaces are the definitions of the higher homotopy groups, i.e. $\\pi_n(X)\\cong [S^n, X]$, thus we finally have our long exact sequence of homotopy groups\n$$\\cdots \\rightarrow \\pi_n(X) \\rightarrow \\pi_n(Y) \\rightarrow \\pi_{n-1}(F) \\rightarrow \\cdots .$$\nComputing some homotopy groups Our goal for introducing this long exact sequence was to be able to compute homotopy groups of spaces, so that is what we will do. We start by computing both of the examples of fiber bundles we discussed yesterday, namely the cylinder and the Möbius band. For the cylinder we have the fiber bundle $I \\rightarrow S^1\\times I \\rightarrow S^1$ , which gives us the exact sequence\n$$0 \\rightarrow \\pi_1 I \\rightarrow \\pi_1 S^1\\times I \\rightarrow \\pi_1 S^1 \\rightarrow 0$$\nSince $I$ is path connected, and $\\pi_2 S^1 =0$ since the circle has the real line as it’s universal cover and any map would then extend to the universal cover since the sphere is simply connected. Since $I$ is contractible, we get that $\\pi_1 I =0$ as well, which gives us that the fundamental group of the cylinder $\\pi_1 S^1\\times I$ is $\\mathbb{Z}$ . Since the cylinder is homotopy equivalent to the circle, this is maybe no surprise. For the Möbius band, we get the exact same sequence, and then the exact same fundamental group, no surprises.\nHistorically, the most sought after examples were the homotopy groups of the higher dimensional spheres, since (as an understatement) both homotopy and homology are devices for counting mathematical holes. The spheres have almost all trivial homology groups, and is they would have almost all trivial homotopy groups, then these invariants would be a lot more similar. But, as shown by Hopf, this was not the case. He did so by introducing the now-called Hopf fibration, $S^1 \\rightarrow S^3 \\rightarrow S^2$ . This can be seen geometrically since the 3-sphere is a double cover of the space $SO(3)$ which acts on the 2-sphere by rotation. This fibration produces the exact sequence\n$$\\pi_3 S^1 \\rightarrow \\pi_3 S^3 \\rightarrow \\pi_3 S^2 \\rightarrow \\pi_2 S^1$$\nwhere $\\pi_2 S^1$ is trivial as mentioned above, and for the same reason, $\\pi_3 S^1 =0$ . Hence we have an exact sequence $0 \\rightarrow \\pi_3 S^3 \\rightarrow \\pi_3 S^2 \\rightarrow 0$ , which means that $\\pi_3 S^3 \\cong \\pi_3 S^2$ , and since every group $\\pi_n S^n \\cong \\mathbb{Z}$ , we have the first non-trivial example for homotopy groups of spheres, namely $\\pi_3 S^2 \\cong \\mathbb{Z}$ .\nNext time we introduce the Serre spectral sequence, and use it to compute cohomology groups of some interesting spaces. If we get far enough, we compute another non-trivial example of homotopy groups of spheres, namely $\\pi_4 S^3$ . As a gift for bothering to read, I link an amazing artwork by my favorite Russian mathematical artist Anatoly Fomenko, called “Homotopy groups of spheres”.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/homotopy-groups/","summary":"This is part 3 of a series leading up to and exploring model categories. For the other parts see 1, 2, 4, 5 6, 7, 8 and 9.\nFor an introduction to the material, the definitions, motivation and some examples, please read part 1 and part 2 about fibrations and fiber bundles. This and the the following parts of this series will be about their usefulness, especially in computing homology and homotopy groups.","title":"Homotopy groups"},{"content":"This is part 2 of a series leading up to and exploring model categories. For the other parts see 1, 3, 4, 5 6, 7, 8 and 9.\nYesterday we discussed the standard definition of a fibration by the homotopy lifting property, and today we are continuing that discussion, but in a more visual manner. This we will do by first looking at fiber bundles, and then generalizing them. Since fibrations are generalized fiber bundles, every fiber bundle is an example of a fibration, and they have been the most important examples for me, as they help me visualize and get intuition into the fibrations without having to really use the full generality of the definition. The main idea of a fiber bundle is that of a family of topological spaces parameterized by another topological space. This family will again form a topological space usually called the total space of the fiber bundle, while the space that parameterizes it is called the base space. Before we get rigorous and technical with definitions, we explore an example.\nExamples and intuition The best two “starter examples” for me at least is the cylinder, and the Möbius band. How are these a family of topological spaces parameterized by another space you ask? They can both can be thought of as a collection of intervals parameterized by a circle. The following picture of the cylinder might make it more clear.\nFor every point on the circle $S^1$ we have an interval $F$ “above” that point. The map $\\pi_1$ from the cylinder to the circle is just the projection map $\\pi_1:S^1\\times I \\rightarrow S^1$, which then gives us our first example of a fibration, namely projections. We call the cylinder a fiber bundle over $S^1$ with typical fiber $F$ , or sometime an $F$ -bundle over $S^1$ . If we instead look at the Möbius band it is a bit more complicated, but not much. We again give a picture.\nWe see the same phenomenon as with the cylinder. Above every point on the circle we have a copy of the interval $F$ , but the difference is that this is no longer just the usual projection. We have a twist, which makes it a bit weirder, hence the Möbius band is equal to the twisted product $M= S^1\\times_t F$ . But, we see that can make it into the projection locally, and this is the key to understand fiber bundles. Now, what does it mean that a map is a projection locally? It means that on the inverse image of open sets in $B$, the map $p$ restricted to that inverse image is just the projection.\nDefinition and relation to fibrations In fact, in a fiber bundle we allow slightly more, we allow that it is locally a projection up to a homeomorphism. This is just saying that we allow some topological variation of the fibers, and that a fiber bundle is a topological object and not totally rigid because we allow deformations and continuous “disturbances” in $E$ . This is also reflected in the proper definition.\nDefinition (fiber bundle): A map $p:E\\rightarrow B$ is called a fiber bundle with typical fiber $F$ if for every point $b\\in B$ , there exists an open set $U$ around $b$ and a homeomorphism $h:p^{-1}(U)\\rightarrow U\\times F$ such that $p_{|p^{-1}(U)}= \\pi_1 \\circ h$ , where $\\pi_1$ is the projection onto the first component.\nNow that we have an ok understanding of fiber bundles we can ask how they relate to fibrations. I said last time that in a fibration, every fiber is homotopy equivalent, and this is the generalization. In a fiber bundle, all fibers are homeomorphic. We can see this because $\\pi_1^{-1}({b}) \\simeq F$ , and hence $p^{-1}({b}) \\simeq F$. If we instead require this to be a homotopy equivalence we get a fibration. Since all homeomorphisms are homotopy equivalences, all fiber bundles are fibrations.\nNow we know both the standard technical definition of a fibration, and we know how to visualize them and think about them. What remains is to learn how to use them, and this we will do in the upcoming posts. I will have one post for the long exact sequence of homotopy groups, and one for the spectral sequence associated to a fibration.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/fiber-bundles/","summary":"This is part 2 of a series leading up to and exploring model categories. For the other parts see 1, 3, 4, 5 6, 7, 8 and 9.\nYesterday we discussed the standard definition of a fibration by the homotopy lifting property, and today we are continuing that discussion, but in a more visual manner. This we will do by first looking at fiber bundles, and then generalizing them. Since fibrations are generalized fiber bundles, every fiber bundle is an example of a fibration, and they have been the most important examples for me, as they help me visualize and get intuition into the fibrations without having to really use the full generality of the definition.","title":"Fiber bundles"},{"content":"This is part 1 of a series leading up to and exploring model categories. For the other parts see 2, 3, 4, 5 6, 7, 8 and 9.\nMy main mathematical interest for the last couple years has been algebraic topology. I feel it suits my needs for intuition, and graphical picturing of what happens. A concept I have been learning more rigorously recently is fibrations, and how to use them in computing homotopy groups and homology groups of different spaces. There is something fun and exciting about computing the homology and homotopy groups of new spaces, as it usually requires different techniques and insight every time, and fibrations have certainly presented some new tools for my calculation toolbox. Since fibrations gives us nice tools, it would be nice to understand them better, and that is my plan for this post. As a remark, all spaces used and mentioned will be topological spaces, and all maps will be continuous.\nAs a short motivation to why we bother studying fibrations at all we recall one of the standard tools one usually learns in an introductory course in algebraic topology, namely the long exact sequence of relative homology groups from a pair of topological spaces $(X, A)$, where $A\\subset X$. This can be thought of as coming from an injection $A \\hookrightarrow X$ . Now, what map between spaces do we need in order to get a long exact sequence of homotopy groups? It turns out that we need a fibration $E \\rightarrow B$ . Unfortunately fibrations do not, in my opinion, have a very clear, intuitive, and easy definition. That said, I will try my best in two different ways. The first one, which we will discuss today is as a map having a certain property. The second one, which is maybe not really a definition, but certainly paints a nice geometric picture, will be as a generalization of certain families of topological spaces parameterized by another topological space. The latter will be discussed tomorrow, as to not make the post too long.\nDefinition 1 Recall that a homotopy between two functions $f,g: X \\rightarrow Y$ is a map $h: X\\times I \\rightarrow Y$ such that $h(x,0)=f(x)$ and $h(x,1)=g(x)$ for all $x\\in X$ , i.e. it is a continuous deformation between the functions. Let $p: E \\rightarrow B$ be the map we are studying. The property we want the map to have for it to be a fibration is the so-called homotopy lifting property. This roughly says that given a homotopy in $B$, where we can lift one of the endpoints in the homotopy through $p$ to $E$ , then we can lift the entire homotopy up to $E$ . This is at least the picture I have when thinking about fibrations. The proper definition is of course a bit more technical, but I find it helpful to have this rough picture in mind.\nDefinition (Hurewicz fibration): A map $p:E\\rightarrow B$ is called a Hurewicz fibration if for any space $X$ with a homotopy $f: X\\times I \\rightarrow B$ and for any map $\\overline{f}_0: X\\rightarrow E$ lifting $f$ at the start of the homotopy, i.e. $f(x,0)=p\\circ \\overline{f}_0$, there exixts a homotopy $\\overline{f}:X\\times I \\rightarrow E$ that lifts f in the same manner as above, i.e. such that $\\overline{f}_0 = \\overline{f} _{|X\\times {0}}$ .\nOk, that was a mouthful. But we see the idea of being able to pull the homotopy up to $E$ when we can lift an endpoint. It is easier visualized as a diagram:\nThe property described as you maybe have guessed is called “the homotopy lifting property”, and a Hurewicz fibration is exactly a map that satisfies this property for all topological spaces $X$ . A bit more general notion is that of a Serre fibration, which satisfies this property for all CW-complexes instead of all topological spaces, and this is what I will refer to as a fibration. A fact about fibrations that i will not prove today atleast, is that the fibers over any point in the basespace all have the same homotopy type. Hence we usually include this when writing a fibration, i.e. we write $F\\rightarrow E \\overset{p}\\rightarrow B$ , where $F$ denotes the fiber.\nThis fact that all of the fibers have the same homotopy type is the foundation of the next way to think about fibrations. But this exposition is getting quite long, and we have a lot to present to get to the next formulation, so I will save that formulation, and some examples for tomorrow. The definition given here is the standard and most general one, but for me at least, the one we are discussing tomorrow gives this definition a much clearer picture and more intuition.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/fibrations/","summary":"This is part 1 of a series leading up to and exploring model categories. For the other parts see 2, 3, 4, 5 6, 7, 8 and 9.\nMy main mathematical interest for the last couple years has been algebraic topology. I feel it suits my needs for intuition, and graphical picturing of what happens. A concept I have been learning more rigorously recently is fibrations, and how to use them in computing homotopy groups and homology groups of different spaces.","title":"Fibrations"},{"content":"Yesterday I wrote a geometric explanation of Noether’s normalization lemma, which you can find here. I’m going to use the geometric machinery developed in that post, so it can be useful to read that first.\nOne useful result that is often stated as a corollary to Noether’s normalization lemma is Zariski’s lemma. It is a corollary of the algebraic form of the normalization lemma, so i thought there ought to be a geometric version of it as well, which I think I have found. Zariski’s lemma holds true even for non algebraically closed fields, but I think the geometric picture becomes much clearer for algebraically closed fields.\nLemma (Zariski): Let $k$ be an algebraically closed field, and $A$ a finitely generated $k$-algebra which is also a field. Then $A$ is a finite field extension of $k$.\nThat $A $ is a finite field extension of $k $ is the same as saying that $A $ is an integral extension of $k $. Now this is starting to sound similar to our situation in Noether’s normalization lemma. This algebra $A$ is the coordinate ring of an affine algebraic variety $X $ in $k^n$ , and if that ring is in fact a field, then the ideal $I(X)$ associated to that variety must be maximal.\nThe weak nullstellensatz Now, we haven’t been through this yet, but we know precisely which varieties that have associated ideals which are maximal, namely varieties that are just points in $k^n$ . How do we see this? It is explained by the weak form of Hilbert’s nullstellensatz. Usually, if we don’t assume that our field is algebraically closed, then the weak form of Hilbert’s nullstellensatz is usually stated as a corollary to Zariski’s lemma by letting the field be algebraically closed, but today we flip the picture a little.\nThe weak Hilbert’s nullstellensatz: All maximal ideals $\\mathfrak{m}$ in the ring $k[x_1, \\cdots, x_n] $ where $k$ is an algebraically closed field are of the form $\\mathfrak{m}=\\mathfrak{m}_a=(x_1-a_1, \\cdots , x_n-a_n) $, where $a = (a_1, \\cdots, a_n)$ denotes a point in $k^n $.\nFor a detailed proof you can read my write up on the strong version on the nullstellensatz, where I also prove the weak one. You can find that here. For a geometric (and a big bit handwavy) approach, we note that prime ideals in $k[x_1, \\cdots, x_n]$ correspond to affine algebraic varieties $X$ in $k^n$ , and prime ideals in the coordinate ring of $X$ , i.e. $k[x_1, \\cdots, x_n]/I(X) = k[x_1, \\cdots, x_n]/ \\mathfrak{p}$ , then translates to affine subvarieties of $X$ because prime ideals in $k[x_1, \\cdots, x_n]/\\mathfrak{p}$ are exactly the prime ideals in $k[x_1, \\cdots, x_n] $ that contains $\\mathfrak{p}$ . All maximal ideals are also prime, so maximal ideals in $k[x_1, \\cdots, x_n] $ should translate to affine algebraic varieties that contain no affine algebraic subvarieties, i.e. points in $k^n$ .\nGeometric Zariski\u0026rsquo;s lemma Ok, we now know which affine algebraic varieties that have associated maximal ideals. Last time we translated certain integral extensions to certain surjective projections of varieties onto linear subspaces of $k^n$ . In fact, we showed that if we have a surjective projection from our affine algebraic variety to a linear subspace $L $ of $k^n$ we know that the coordinate ring of the variety is integral over the coordinate ring of the linear subspace. Now the trick to proving Zariski’s lemma becomes to find a suitable linear subspace. Since we have shown that our variety associated to the maximal ideal is a point, we only have one choice of linear subspace to surject to, namely the zero-dimensional linear subspace, $k^0 $. This is certainly a projection, and certainly surjective, hence our coordinate ring (or coordinate field really) $A$ is integral over the coordinate ring of the zero dimensional linear subspace of $k^n$ .\nNow, what is this ring? It is the ring $k[x_1, \\cdots, x_n]/I(k^0)$ , where $I(k^0)$ is the ideal of all polynomials in $k[x_1, \\cdots, x_n]$ that vanish on every point in $k^0$ which is only $0$ . Hence it is the ideal generated by all the variables, i.e. $I(k^0) = (x_1, \\cdots, x_n) $. Then we have $k[x_1, \\cdots, x_n]/(x_1, \\cdots, x_n)$ which is isomorphic to just $k$ . Hence, by Noether’s normalization lemma $A $ is an integral extension over the field $k $, hence it is a finite field extension of $k$ , which proves what we were after.\nTomorrow is the oral exam, and hopefully i get a chance to ramble on about geometric interpretations of these algebraic lemmas. Later, some day, I want to make a post about the duality between algebra and geometry in commutative algebra by interpreting the strong nullstellensatz in both an algebraic and a geometric way.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/more-geometric-intuition/","summary":"Yesterday I wrote a geometric explanation of Noether’s normalization lemma, which you can find here. I’m going to use the geometric machinery developed in that post, so it can be useful to read that first.\nOne useful result that is often stated as a corollary to Noether’s normalization lemma is Zariski’s lemma. It is a corollary of the algebraic form of the normalization lemma, so i thought there ought to be a geometric version of it as well, which I think I have found.","title":"More geometric intuition"},{"content":"Introduction This spring I have been taking a graduate class in commutative algebra, and I have yet to do algebraic geometry in a proper way, and have only gotten a small taste while writing my bachelor thesis. So this entire semester, I have felt this hinting at a geometric picture from the algebra itself, but i didn\u0026rsquo;t have the insight to figure it out. That said, I now think I have the geometric picture for Noether normalization, which in term implies a geometric picture of Hilbert nullstellensatz and some other results. It took a long time to convert the algebra into geometry for me, and i still have much to learn regarding this. What i have started to figure out is the close relationship between ideals and varieties. I have for a while known that this is one of the main reasons to introduce commutative algebra into algebraic geometry, but i couldn\u0026rsquo;t see the picture myself. Anyway, lets start with some introductory stuff.\nAn affine algebraic variety $X$ in $k^n$ is a subset of $k^n$ cut out by a collection of polynomials $F=\\{ f_i\\}_ {i\\in I}$, i.e. $X = \\{ x\\in k^n \\vert f_i(x)=0, \\forall f_i \\in F\\}$. The set $F$ of polynomials generate a prime ideal of $k[x_1, \\cdots, x_n]$, which we denote by $I(X)$. We can also start by taking a prime ideal $\\mathfrak{p}$ in $k[x_1, \\cdots, x_n]$ and generate its vanishing set $V(\\mathfrak{p})$, which will be it\u0026rsquo;s corresponding affine algebraic variety. More explicitly $V(\\mathfrak{p})= \\{ x\\in k^n \\vert f(x)=0, \\forall f\\in \\mathfrak{p}\\}$. The ring $P(X)=k[x_1, \\cdots, x_n]/I(X)$ is called the coordinate ring of the variety. This correspondence is the key bridge between the geometric picture and the algebra, and the full relation is described by Hilbert\u0026rsquo;s nullstellensatz.\nGeometry of normalization Before I explain the geometric meaning i have learned, I want to formulate the lemma in the regular algebraic way it is usually presented.\nLemma (Noether): Let $k$ be an algebraically closed infinite field and $A$ a finitely generated $k$-algebra. Then there exists an integer $d $ and algebraically independent generators $y_1, \\cdots ,y_d $ such that $A $ is a finitely generated module over $k[y_1, \\cdots, y_d] $.\nIt is often useful to know weather an affine algebraic variety $X$ projects onto a linear subspace of $k^n$. This can for example tell us information on the dimension of the variety, which again tells us other useful stuff. I have not yet explored dimension theory, hence the motivation behind this is maybe still a bit vague to me. This projection induces an injection on the cordinate rings. Let $A$ be the coordinate ring of an affine algebraic variety $X$ and $B$ the coordinate ring of a linear subspace $L$ of $k^n.$ By a coordinate change, $L \\cong k^d$, hence $I(L)$ is the zero ideal, because it consists of all polynomials in $d$ variables who vanish on every point in $k^d$, which is only the zero polynomial. Hence the coordinate ring $B$ is isomorphic to $k[x_1, \\cdots x_d] $.\nA given projection $X \\longrightarrow L$ then induces an injection $k[x_1, \\cdots, x_d]\\longrightarrow P(X) $, and a natural question that arises (somehow) is when is this injection a finite morphism. By definition this is the same as asking when $P(X) $ is a finitely generated module over $k[x_1, \\cdots, x_d] $ or when $P(X) $ is an integral extension of $k[x_1, \\cdots, x_d] $. Noether\u0026rsquo;s normalization lemma tells us that this is the case when the projection $X \\longrightarrow L $ is surjective.\nI\u0026rsquo;m not going to prove the lemma, but i will instead present an explicit example. Let $k=\\mathbb{R} $ and let $X $ be the variety defined by $x\\cdot y = 1$ in $\\mathbb{R}^2 $. This is a hyperbola with asymptotes along the $x$ and $y $ lines. If we take $L$ to be the linear subspace generated by $x$, i.e. the $x$-axis, then the canonical \u0026ldquo;straight down\u0026rdquo; and \u0026ldquo;straight up\u0026rdquo; projection hits the whole line except the origin.\nNow, what does this mean for our induced injection? The coordinate ring of $L$ is just $\\mathbb{R}[x]$ while the coordinate ring of $X$ is $P(X) = \\mathbb{R}[x, y]/(xy-1)$, hence we have the injection $\\mathbb{R}[x] \\longrightarrow \\mathbb{R}[x, y]/(xy-1) $. If this was an integral extension, then every prime ideal of $\\mathbb{R}[x] $ would have a prime ideal of $\\mathbb{R}[x, y]/(xy-1)$ laying over it, but there is no prime ideal in $\\mathbb{R}[x, y]/(xy-1)$ over the ideal generated by $x$, since all ideals in $\\mathbb{R}[x, y]/(xy-1)$ that contain $x $ must be the whole ring. Hence it can\u0026rsquo;t be an integral extension.\nBut, notice here that we in fact can do a linear coordinate change by rotating our axis $45^\\circ $, i.e. $x' = x+y $ and $y' = x-y $. Now the same projection is a surjection which in theory should make the injection an integral extension.\nThe coordinate change gives us $x = \\frac{x'+y'}{2} $ and $y = \\frac{x'-y'}{2} $, thus we get $0 = xy-1 = \\frac{(x'-y')(x'+y')}{4} -1 = x'^2 - y'^2 - 4 $. Hence our coordinate ring in the new generators is $\\mathbb{R}[x', y']/(x'^2 - y'^2 - 4) $. Now we see that this ring is integral over $\\mathbb{R}[x'] $ since we have a monic polynomial $f(t) = t^2 - (\\overline{x'}^2+4) $ which is zero at $y'$. Here $\\overline{x'} $ is the image of $x' $ in the ring $\\mathbb{R}[x', y']/(x'^2 - y'^2 - 4) $. Hence we have confirmed the lemma by an example. We made the integralness of $P(X) $ over $P(L) $ dependent of the projection, which is what we wanted.\n","permalink":"https://torgeiraamboe.github.io/posts/2020/geometric-intuition/","summary":"Introduction This spring I have been taking a graduate class in commutative algebra, and I have yet to do algebraic geometry in a proper way, and have only gotten a small taste while writing my bachelor thesis. So this entire semester, I have felt this hinting at a geometric picture from the algebra itself, but i didn\u0026rsquo;t have the insight to figure it out. That said, I now think I have the geometric picture for Noether normalization, which in term implies a geometric picture of Hilbert nullstellensatz and some other results.","title":"Geometric Intuition"}]